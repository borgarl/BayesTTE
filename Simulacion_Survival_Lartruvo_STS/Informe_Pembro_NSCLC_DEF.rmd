---
title: "Assessment of the KEYNOTE-024 trial for the Pembrolizumab (Keytruda) against Placebo in NSCLC"
author: "Borja G. López-Rey"
date: "`r Sys.Date()`"
output: 
  rmarkdown::html_vignette:
    code_folding: hide
vignette: >
  %\VignetteIndexEntry{Model checking with simulated data (survival model example)}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, eval = T, results = 'hide', echo = F}
knitr::opts_chunk$set(message = FALSE,
                      warning = FALSE,
                      fig.width = 8.5,  
                      fig.height = 6,
                      echo = TRUE)
```


```{r load-packages, eval = T, echo = F}

library(ggplot2)
library(survival)
library(tidyr)
library(gsDesign)
library(dplyr)
library(stringr)
library(tibble)
library(rstan)
rstan_options(auto_write = TRUE)
options(mc.cores = min(8, parallel::detectCores()))
library(loo)
library(openxlsx)
library(readxl)
options(digits=7)
library(flexsurv)
library(stringr)
library(SurvRegCensCov)
library(metafor)
library(knitr)
library(flexmix)
library(brms)
library(meta)
library(tidybayes)
library(ggdist)
library(forcats)
library(ggridges)
library(glue)
library(stats4)
library(kableExtra)
library(gt)

```

```{r load-functions, eval = T, echo = F}

source("sim_trials.r")
source("sim_freq.r")
source("sim_bayes.r")
source("surv_analysis_freq.r")
source("surv_analysis_bayes.r")
source("rand.r")
source("gen_surv_data.r")
source("get_boundaries_IA.r")
source("analysis_surv_data_freq.r")
source("analysis_surv_data_bayes.r")
source("plot_bayes.r")
source("plot_bayes_sep.r")

```

# Ejercicio de simulación

Partimos de la hipótesis que el uso de diseños Bayesianos podría haber optimizado el desarrollo de los ensayos clínicos oncológicos en aquellos donde se ha usado una diseño frecuentista. Para ello, se van a evaluar las características operantes de diferentes diseños Bayesianos con respecto al frecuentista para comprobar que podríamos haber necesitado un menor número de pacientes asegurando que no se infle el Error de Tipo I (ET1) a lo largo de diferntes escenarios.

Para ello, se van a usar 3 ensayos reales y vamos a simular los datos cogiendo como parámetros lo que el Sponsor tuvo en cuenta cuando justificó su tamaño muestral en el Statistical Analysis Plan (SAP). Así mismo, como los resultados de esos ensayos ya están disponibles, también se van como parámetros los datos reales obtenidos de estos ensayos usando como análisis los modelos escogidos anteriormente en la primera parte para ver el poder que hubiéramos tenido.

El primer ensayo tipo, es un ensayo robusto con suficiente poder y buenos resultados. Este es el Keynote024. 

# Keynote024
  
Pembrolizumab en monoterapia está indicado en el tratamiento en primera línea del CNMP metastásico en adultos cuyo tumor exprese PD-L1 con una proporción de marcador tumoral (TPS) ≥ 50% sin mutaciones positivas de EFGR o ALK.

Los datos de eficacia de pembrolizumab en primera línea en CNMP proceden del ensayo clínico KEYNOTE-024 (P024). Se trata de un ensayo clínico abierto, aleatorizado, multicéntrico, fase III, controlado con quimioterapia basada en platino en pacientes con CNMP metastásico (estadio IV) que no habían sido tratados previamente.

La variable primaria del estudio fue la supervivencia libre de progresión (SLP) evaluada mediante Revisión Central Independiente Enmascarada (RCIE) según criterios RECIST 1.1. Como variables
secundarias se incluyeron la supervivencia global (SG) y la tasa de respuesta objetiva (TRO), evaluada también según criterios RECIST 1.1 por RCIE. Otras variables exploratorias fueron la duración de la respuesta, el tiempo hasta la respuesta y los resultados percibidos por el paciente (RPP).

Un total de 305 sujetos fueron aleatorizados en proporción 1:1 a recibir tratamiento con pembrolizumab 200 mg cada 3 semanas administrado en perfusión intravenosa de 30 minutos (n=154) o bien el estándar de tratamiento elegido por el investigador (n=151).

El kaplan-Meier de los resultados en PFS son los siguientes:

```{r `Final results on PFS`, eval = T, echo = F}

knitr::include_graphics("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_GRAFICOS/Keynote024_PFS.jpg")

```

## Frequentist simulation

Como se ha especificado anteriormente, vamos a considerar los parámetros que ha usado la compañía en el SAP para el diseño de este estudio. Cabe destacar que todo el ejercicio de simulación tanto para la generación de datos simulados como para el análisis bayesiano se va a usar la distribución Weibull.

1) Shape parameter = 1. La Cy usa una exponencial para el diseño por lo que el parámetro es =1. Una Weibull con shape = 1 es una exponencial.
2) Sample size = 300.
3) ratio = 1:1.
4) rand_type = CR. Esto es la manera que se asigna grupo a cada paciente, esto es complete randomization.
5) Tmax = 20. En el SAP se dice esto: "an enrollment period of 14 months and at least 6 months PFS follow-up after enrollment completion"
6) Censor = 0.1/0.1. Se han escogido estos valores por lo que se dice en el SAP "a dropout rate of 10% per year". Son casi 2 años por lo que sería en verdad 0.08335 cada brazo pero para simplificar lo dejo así.
7) Alpha = 0.05.
8) test.type = 2. Esto es que el test es de dos colas.
9) seed = 24. A lo largo de este estudio en casi todas las simulaciones se usará esta semilla.

Con respecto a los efectos esperados, en el SAP está lo siguiente: 
  
"The planned PFS analysis will be conducted after approximately 175 PFS events are observed between the MK-3475 arm and control. The study has ~98% power to detect a HR of 0.55 at alpha = 2.5% (one-sided) at the final PFS analysis. A p-value less than 2.5% (one-sided) for PFS approximately corresponds to an empirical hazard ratio of < 0.744 (or approximately at least 7.4 months of median PFS in MK-3475 vs. 5.5 months of median
PFS in SOC).

The sample size calculation was based on PFS with the following assumptions: 1) PFS follows an exponential distribution with a median of 5.5 months in the control arm, 2) hazard ratio between pembrolizumab and control is 0.55, 3) enrollment period of 14 months and at least 6 months PFS follow-up after enrollment completion, and 4) a dropout rate of 10% per year."

A modo de introducción para la herramienta de simulación que he hecho, vamos a usar los parámetros considerados en el SAP, incluyendo las asunciones de que HR=0.55 y las medianas para el brazo control y experimental son 5.5 y 10 meses respectivamente. Los resultados comprenden 10.000 simulaciones para este escenario.

```{r `Simulation of the trial with the parameters from the protocol`, eval = T, echo = T}

shape_parameter <- 1

sample_size <- 300
ratio <- c(0.5,0.5)
rand_type <- "CR" 
scenarios_eff <- matrix(c(5.5,10), nrow = 1, ncol = 2, byrow = TRUE) # HR=0.55
censor <- c(0.1,0.1)
Tmax <- 20
alpha <- 0.05 
test.type <- 2
HR_1 <- FALSE
IA <- NULL
Plot_Power = FALSE 
plot_pvalues = FALSE
analysis = "freq" 
n_sim <- 10000
seed <- 24

sim1 <- sim_trials(n_sim = n_sim,
                   analysis = "freq",
                   sample_size = sample_size,
                   ratio = ratio,
                   rand_type = rand_type,
                   Tmax = Tmax,
                   shape_parameter = shape_parameter,
                   scenarios_eff = scenarios_eff,
                   censor = censor,
                   alpha = alpha,
                   test.type = test.type,
                   IA = IA,
                   method_IA = method_IA,
                   n_exp_events = n_exp_events,
                   HR_1 = HR_1,
                   seed=seed,
                   Plot_Power = Plot_Power,
                   plot_pvalues = plot_pvalues)

sim11 <- as.data.frame(sim1)
sim11 <- sim11 %>%
  select(-scenario) %>%
  mutate(sample_size = as.integer(sample_size))

table1 <- gt(sim11) %>%
  tab_header(title = "Frequentist simulation considering the parameters from the SAP") %>%
  fmt_number(columns = names(sim11)[-which(names(sim11) %in% c("sample_size", "count_significant", "count_not_significant"))], decimals = 4) %>%
  tab_style(style = cell_text(weight = "bold", align = "center"),locations = cells_column_labels(columns = everything())) %>%
  tab_options( column_labels.background.color = "lightsteelblue1",
    table.font.size = px(12),
    table.background.color = "white") %>%
  tab_style(style = cell_fill(color = "white"),
    locations = cells_body(rows = everything(), columns = everything())) %>%
  tab_style( style = cell_text(align = "center"),
    locations = cells_body(columns = everything()))

table1

```

Como podemos ver, la media del HR es 0.5542 (0.42, 0.73) y el % de estudios que han salido significativos es el 99% y donde el 95% de las veces el valor verdadero del HR (0.55) está contenido en los intervalos de confianza (Coverage Probability). 

También se ha obtenido otra tabla donde se incorporan todos los p-valores de los estudios, la utilidad de esto se verá más adelante.

# Evaluación del tamaño muestral con un efecto dado

Lo siguiente es evaluar mediante simulaciones como varían las características operantes en función de diferentes tamaños muestrales (así también se confirmará que 300 pacientes tiene un poder aprox del 98%).

Nota: A partir de ahora cuando debajo de la función principal para simular aparezcan unas líneas para leer un Excel es porque las simulaciones de mucha carga computacional se han hecho con el ordenador de multicore. 

```{r `Simulation of the trial with the parameters from the SAP w different sample size`, eval = T, echo = T}

shape_parameter <- 1
sample_size <- seq(from = 50, to= 350, by = 5)
ratio <- c(0.5,0.5)
rand_type <- "CR" 
scenarios_eff <- matrix(c(5.5,10), nrow = 1, ncol = 2, byrow = TRUE) # HR=0.55
censor <- c(0.1,0.1)
Tmax <- 20
alpha <- 0.05 
test.type <- 2
HR_1 <- TRUE
IA <- NULL
Plot_Power = TRUE
plot_pvalues = FALSE
analysis = "freq" 
n_sim <- 10000
seed <- 24

# sim2 <- sim_trials(n_sim = n_sim, 
#                    analysis = "freq",
#                    sample_size = sample_size,
#                    ratio = ratio,
#                    rand_type = rand_type,
#                    Tmax = Tmax, 
#                    shape_parameter = shape_parameter,
#                    scenarios_eff = scenarios_eff,
#                    censor = censor,
#                    alpha = alpha,
#                    test.type = test.type,
#                    IA = IA,
#                    method_IA = method_IA,
#                    n_exp_events = n_exp_events,
#                    HR_1 = HR_1,
#                    seed=seed,
#                    Plot_Power = Plot_Power,
#                    plot_pvalues = plot_pvalues)
# 
# sim2_power <- sim2[[2]]
# sim2_power_T1E <- sim2[[3]]
# sim2_power_MSE <- sim2[[4]]
# sim2_results <- sim2[[1]]

# Aquí los datos se leen del Excel con los datos simulados en el ordenador de multicore.

sheet_names <- c("Sheet1")
sim2_results <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/Power_samplesize_SAP_Parameters_10K_each.xlsx", sheet = sheet_names[1])


data <- subset(sim2_results, scenario == 1)

desired_powers <- c(0.8, 0.9)
sample_sizes_for_desired_powers <- sapply(desired_powers, function(x) 
  min(data$sample_size[data$prop_significant >= x]))

p1 <- ggplot(data, aes(x = sample_size, y = prop_significant)) +
  geom_point(size = 3, color = "steelblue") +  
  geom_line(linewidth = 1, color = "steelblue") +  
  geom_hline(yintercept = desired_powers, linetype = "dotted", color = c("purple", "green"), size = 1) + 
  scale_x_continuous(breaks = seq(min(data$sample_size)-5, max(data$sample_size)+5, 25)) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Power vs. Sample Size",
       x = "Sample Size",
       y = "Power") +
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 14, face = "bold"),
        axis.text = element_text(size = 12))

colors_for_annotation <- c("purple", "green")  
leftmost_x <- min(data$sample_size) + 5  
for (i in 1:length(desired_powers)) {
  p1 <- p1 + annotate("text", 
                      x = leftmost_x, 
                      y = desired_powers[i], 
                      label = sprintf("%.0f%% power", desired_powers[i] * 100), 
                      hjust = 0,  
                      vjust = -0.3,  
                      size = 3.5, 
                      color = colors_for_annotation[i])
}

p1

```

Como se puede ver, efectivamente con 300 pacientes se tiene un poder por encima del 98% (98.87%). También se identifica que con estos datos simulados, 130 pacientes son suficientes para obtener un poder del 80%, 150 pacientes para tener un poder del 85% y 175 pacientes para un poder del 90%.

La compañía fue bastante conservadora a la hora de diseñar este estudio aunque el tamaño muestral se puede deducir que se diseñó para OS por lo que necesitan más eventos que para PFS.

Ahora miramos los datos para el poder junto al Error de Tipo I:
  
```{r `Simulation of sample sizes: T1E`, eval = T, echo = T}

df <- data.frame(
  sample_size = sim2_results$sample_size,
  HR = sim2_results$scenario,
  power_and_T1E = sim2_results$prop_significant)


df$zoom <- ifelse(df$power_and_T1E <= 0.1, "Zoomed", "Regular")

suppressWarnings(
  p2 <- ggplot(data = df) +
    geom_line(aes(x = sample_size, y = power_and_T1E, color = as.factor(HR))) +
    labs(title = "Power and Type I Error by Sample Size",
         x = "Sample Size",
         y = "%",
         color = "scenarios") +
    scale_color_discrete(labels = c("HR = 0.55", "HR = 1")) +
    scale_linetype_discrete(labels = c("Power", "Type I Error")) +
    theme_minimal() +
    facet_grid(zoom ~ ., scales = "free_y") + 
    geom_hline(yintercept = 0.1, linetype = "dashed", color = "black", data = subset(df, zoom == "Zoomed"))
)
p2


```

Así mismo podemos ver que el error de tipo I se mantiene por debajo del valor especificado (5%, 2-sided) por lo que se demuestra que no se infla el ET1 (como era de esperar en un estudio frecuentista si está bien hecho).

Por último, se puede ver valores del MSE como varían en valores más pequeños según se aumenta el tamaño muestral.

```{r `Simulation sample sizes: MSE`, eval = T, echo = T}


p4 <-  ggplot(data, aes(x = sample_size, y = MSE)) +
  geom_point(size = 3, color = "steelblue") +  
  geom_line(linewidth = 1, color = "steelblue") +
  labs(title = "MSE vs. Sample Size",
                      x = "Sample Size",
                      y = "MSE") +
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 14, face = "bold"),
        axis.text = element_text(size = 12))
p4

```

# Evaluación de diferentes de efecto 

Ahora vamos a evaluar cómo afectan los compartamientos del efecto para cada uno de los brazos a un tamaño muestral dado. No sólo se va a hacer con los 300 pacientes planeados, si no también para X, Y y Z.

Ya que el tamaño del efecto depende de dos variables diferentes, efecto del brazo control y efecto del brazo experimental, tenemos que ver los dos escenarios de interés en base a un factor común, el HR.

Para ello, primero vamos a evaluar los diferentes escenarios en términos de medianas. Vamos a dejar fijo primero la mediana para el brazo control como está definido en el SAP (5.5) y luego dejamos fija la mediana para el brazo experimental (10). De esto modo, vemos cómo evoluciona todo el rango de Hazard Ratios relevantes a lo largo de los diferentes escenarios.

```{r `Medians w control arm at 5.5` , eval = T, echo = T}

shape_parameter <- 1

desired_HRs <- c(1.5, 1.6, 1.5, 1.4, 1.3, 1.2, 1.1, 1, 0.95, 0.9, 0.85, 0.8, 0.775, 0.75, 0.725, 0.7, 0.675, 0.65, 0.625, 0.6, 0.575, 0.55, 0.525, 0.5, 0.45, 0.4, 0.35, 0.3)
control_medians <- rep(5.5, times = length(desired_HRs))

medians_control_fijo <- matrix(NA, nrow = length(desired_HRs), ncol = 2, dimnames = list(paste0("HR ", desired_HRs), c("Control", "Treatment")))

for (i in 1:length(desired_HRs)) {
  medians_control_fijo[i, "Treatment"] <- control_medians[i] / (desired_HRs[i]^(1/shape_parameter))
  medians_control_fijo[i, "Control"] <- control_medians[i]
}

medians_control_fijo <- as.data.frame(medians_control_fijo)

medians_control_fijo <- medians_control_fijo %>%
  mutate(HR = desired_HRs) %>%
  select(HR, everything())

# Creamos la tabla
table2 <- gt(medians_control_fijo) %>%
  tab_header(title = "Effect Based on Different HR w Median control = 5.5") %>%
  fmt_number(
    columns = c("Control"),  # Aquí detallamos cuántos decimales queremos para los valores de estas columnas
    decimals = 1
  ) %>%
  fmt_number(
    columns = names(medians_control_fijo)[!names(medians_control_fijo) %in% c("Control")],  # Aplicamos estos decimales para los valores de todas las columnas menos las especificadas aquí
    decimals = 3
  ) %>%
  tab_style(
    style = cell_text(weight = "bold", align = "center"),
    locations = cells_column_labels(columns = everything())
  ) %>%
  tab_options(
    column_labels.background.color = "lightsteelblue1",
    table.font.size = px(12),
    table.background.color = "white"
  ) %>%
  tab_style(
    style = cell_fill(color = "lightsteelblue1"),
    locations = cells_body(rows = seq(2, nrow(medians_control_fijo), by = 2), columns = everything())
  ) %>%
  tab_style(
    style = cell_fill(color = "white"),
    locations = cells_body(rows = seq(1, nrow(medians_control_fijo), by = 2), columns = everything())
  ) %>% # En las tres sentencias anteriores es cómo hacemos que se alternen los colores
  tab_style(
    style = cell_fill(color = "lightsteelblue1"),  # Esto es para aplicar el color azul para valores de la primera columna
    locations = cells_body(columns = "HR")
  ) %>%
  tab_style(
    style = cell_text(weight = "bold"),  
    locations = cells_body(columns = "HR")
  ) %>%
  tab_style(
    style = cell_text(align = "center"),
    locations = cells_body(columns = everything())
  ) %>%
  tab_style(
    style = cell_borders(sides = "bottom", color = "black", weight = px(2)),
    locations = cells_column_labels(columns = names(medians_control_fijo)[names(medians_control_fijo) != "HR"])
  ) %>%
  tab_style(
    style = cell_borders(sides = "right", color = "black", weight = px(2)),
    locations = cells_body(columns = "HR")
  )

table2

```

Ahora dejando fija la mediana del brazo experimental a 10.

```{r `Medians w experimental arm at 10` , eval = T, echo = T}

shape_parameter <- 1

desired_HRs <- c(1.5, 1.6, 1.5, 1.4, 1.3, 1.2, 1.1, 1, 0.95, 0.9, 0.85, 0.8, 0.775, 0.75, 0.725, 0.7, 0.675, 0.65, 0.625, 0.6, 0.575, 0.55, 0.525, 0.5, 0.45, 0.4, 0.35, 0.3)
medians_experimiental_fijo <- rep(10, times = length(desired_HRs))

treatment_medians <- matrix(NA, nrow = length(desired_HRs), ncol = 2, 
                            dimnames = list(paste0("HR ", desired_HRs), c("Control", "Treatment")))

for (i in 1:length(desired_HRs)) {
  treatment_medians[i, "Control"] <- medians_experimiental_fijo[i] * (desired_HRs[i]^(1/shape_parameter))
  treatment_medians[i, "Treatment"] <- medians_experimiental_fijo[i]
}

treatment_medians <- as.data.frame(treatment_medians)

treatment_medians <- treatment_medians %>%
  mutate(HR = desired_HRs) %>%
  select(HR, everything())

# Creamos la tabla
table3 <- gt(treatment_medians) %>%
  tab_header(title = "Effect Based on Different HR w Median Treatment = 10") %>%
  fmt_number(
    columns = c("Treatment"),  # Aquí detallamos cuántos decimales queremos para los valores de estas columnas
    decimals = 0
  ) %>%
  fmt_number(
    columns = names(treatment_medians)[!names(treatment_medians) %in% c("Treatment")],  # Aplicamos estos decimales para los valores de todas las columnas menos las especificadas aquí
    decimals = 3
  ) %>%
  tab_style(
    style = cell_text(weight = "bold", align = "center"),
    locations = cells_column_labels(columns = everything())
  ) %>%
  tab_options(
    column_labels.background.color = "lightsteelblue1",
    table.font.size = px(12),
    table.background.color = "white"
  ) %>%
  tab_style(
    style = cell_fill(color = "lightsteelblue1"),
    locations = cells_body(rows = seq(2, nrow(treatment_medians), by = 2), columns = everything())
  ) %>%
  tab_style(
    style = cell_fill(color = "white"),
    locations = cells_body(rows = seq(1, nrow(treatment_medians), by = 2), columns = everything())
  ) %>% # En las tres sentencias anteriores es cómo hacemos que se alternen los colores
  tab_style(
    style = cell_fill(color = "lightsteelblue1"),  # Esto es para aplicar el color azul para valores de la primera columna
    locations = cells_body(columns = "HR")
  ) %>%
  tab_style(
    style = cell_text(weight = "bold"),  
    locations = cells_body(columns = "HR")
  ) %>%
  tab_style(
    style = cell_text(align = "center"),
    locations = cells_body(columns = everything())
  ) %>%
  tab_style(
    style = cell_borders(sides = "bottom", color = "black", weight = px(2)),
    locations = cells_column_labels(columns = names(treatment_medians)[names(treatment_medians) != "HR"])
  ) %>%
  tab_style(
    style = cell_borders(sides = "right", color = "black", weight = px(2)),
    locations = cells_body(columns = "HR")
  )

table3

```

Ahora vamos a simular ensayos clínicos yendo de un rango a otro tanto dejando la mediana del control fija como después la del tratamiento para los siguientes tamaños muestrales.

1) 300 -> Poder: 99%
2) 175 -> Poder: 90%
3) 150 -> Poder: 85%
4) 130 -> Poder: 80%

```{r `Simulation scenarios w fixed control`, eval = T, echo = T}
shape_parameter <- 1

desired_HRs <- c(1.5, 1.6, 1.5, 1.4, 1.3, 1.2, 1.1, 1, 0.95, 0.9, 0.85, 0.8, 0.775, 0.75, 0.725, 0.7, 0.675, 0.65, 0.625, 0.6, 0.575, 0.55, 0.525, 0.5, 0.45, 0.4, 0.35, 0.3)
control_medians <- rep(5.5, times = length(desired_HRs))

medians_control_fijo <- matrix(NA, nrow = length(desired_HRs), ncol = 2, dimnames = list(paste0("HR ", desired_HRs), c("Control", "Treatment")))

for (i in 1:length(desired_HRs)) {
  medians_control_fijo[i, "Treatment"] <- control_medians[i] / (desired_HRs[i]^(1/shape_parameter))
  medians_control_fijo[i, "Control"] <- control_medians[i]
}

shape_parameter <- 1
sample_size <- 300
ratio <- c(0.5,0.5)
rand_type <- "CR" 
scenarios_eff <- as.matrix(medians_control_fijo, nrow = length(medians_control_fijo), ncol = 2, byrow = TRUE)
censor <- c(0.1,0.1)
Tmax <- 20
alpha <- 0.05 
test.type <- 2
HR_1 <- FALSE
IA <- NULL
Plot_Power = FALSE
plot_pvalues = FALSE
Plot_Power_scenarios = FALSE
analysis = "freq" 
n_sim <- 10000
seed <- 24

# sim3 <- sim_trials(n_sim = n_sim, 
#                    analysis = "freq",
#                    sample_size = sample_size,
#                    ratio = ratio,
#                    rand_type = rand_type,
#                    Tmax = Tmax, 
#                    shape_parameter = shape_parameter,
#                    scenarios_eff = scenarios_eff,
#                    censor = censor,
#                    alpha = alpha,
#                    test.type = test.type,
#                    IA = IA,
#                    method_IA = method_IA,
#                    n_exp_events = n_exp_events,
#                    HR_1 = HR_1,
#                    seed=seed,
#                    Plot_Power = Plot_Power,
#                    plot_pvalues = plot_pvalues)

sheet_names <- c("Sheet1")
sim3_results <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/power_esc_10K_300.xlsx", sheet = sheet_names[1])

data <- sim3_results %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE))

data$desired_HRs <- desired_HRs[1:nrow(data)]

p3 <- ggplot(data, aes(x = desired_HRs, y = prop_significant)) +
  geom_point(size = 3, color = "steelblue") +
  geom_line(linewidth = 1, color = "steelblue") +
  geom_vline(xintercept = 1, linetype = "dashed", color = "red", size = 1) +
  geom_hline(yintercept = c(0.8, 0.9), linetype = "dotted", color = c("purple", "green"), size = 1) +
  scale_x_continuous(breaks = seq(min(desired_HRs), max(desired_HRs), 0.1), labels = sprintf("%.2f", seq(min(desired_HRs), max(desired_HRs), 0.1))) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Power vs Hazard Ratio",
       x = "Theoretical Hazard Ratio",
       y = "Power") +
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 14, face = "bold"),
        axis.text = element_text(size = 12))

p3 <- p3 +
  annotate("text", x = max(desired_HRs), y = 0.8, label = "80% power", hjust = 1, vjust = -0.5, size = 3.5, color = "purple") +
  annotate("text", x = max(desired_HRs), y = 0.9, label = "90% power", hjust = 1, vjust = -0.5, size = 3.5, color = "green")

for (i in 1:nrow(data)) {
  p3 <- p3 + annotate("text", x = data$desired_HRs[i], y = data$prop_significant[i],
                      label = sprintf("%.2f", data$mean_HR[i]), hjust = 1, vjust = 1.5, size = 4, color = "black")
}

p3

```

Y ahora dejando el tratamiento fijo (sale igual por lo que solo lo haremos con el control fijo a partir de ahora).

1) 300 -> Poder: 99%

Con el tamaño muestral de 300 es necesario:
  
1) Un HR de 0.66 para tener un poder del 80%
2) Un HR de 0.65 para tener un poder del 85%
3) Un HR de 0.60 para tener un poder del 90%

```{r `Simulation scenarios w fixed experimental`, eval = T, echo = T}

sheet_names <- c("Sheet1")
sim3_results <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/power_esc_10K_300_experimentalfijo.xlsx", sheet = sheet_names[1])

data <- sim3_results %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE))

data$desired_HRs <- desired_HRs[1:nrow(data)]

p4 <- ggplot(data, aes(x = desired_HRs, y = prop_significant)) +
  geom_point(size = 3, color = "steelblue") +
  geom_line(linewidth = 1, color = "steelblue") +
  geom_vline(xintercept = 1, linetype = "dashed", color = "red", size = 1) +
  geom_hline(yintercept = c(0.8, 0.9), linetype = "dotted", color = c("purple", "green"), size = 1) +
  scale_x_continuous(breaks = seq(min(desired_HRs), max(desired_HRs), 0.1), labels = sprintf("%.2f", seq(min(desired_HRs), max(desired_HRs), 0.1))) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Power vs Hazard Ratio",
       x = "Theoretical Hazard Ratio",
       y = "Power") +
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 14, face = "bold"),
        axis.text = element_text(size = 12))

p4 <- p4 +
  annotate("text", x = max(desired_HRs), y = 0.8, label = "80% power", hjust = 1, vjust = -0.5, size = 3.5, color = "purple") +
  annotate("text", x = max(desired_HRs), y = 0.9, label = "90% power", hjust = 1, vjust = -0.5, size = 3.5, color = "green")

for (i in 1:nrow(data)) {
  p4 <- p4 + annotate("text", x = data$desired_HRs[i], y = data$prop_significant[i],
                      label = sprintf("%.3f", data$mean_HR[i]), hjust = 1, vjust = 1.5, size = 3, color = "black")
}
p4
```


Vamos a ver los gráficos variando el tamaño muestral para el poder que antes se especificó:
  
1) 175 -> Poder con 300 pacientes: 90%

Con este tamaño muestral es necesario:
  
1) Un HR de 0.61 para tener un poder del 80%
2) Un HR de 0.58 para tener un poder del 85%
3) Un HR de 0.55 para tener un poder del 90%

```{r `Simulation scenarios w SS = 175`, eval = T, echo = T}

sheet_names <- c("Sheet1")
sim3_results <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/power_esc_10K_175.xlsx", sheet = sheet_names[1])

data <- sim3_results %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE))

data$desired_HRs <- desired_HRs[1:nrow(data)]

p4 <- ggplot(data, aes(x = desired_HRs, y = prop_significant)) +
  geom_point(size = 3, color = "steelblue") +
  geom_line(linewidth = 1, color = "steelblue") +
  geom_vline(xintercept = 1, linetype = "dashed", color = "red", size = 1) +
  geom_hline(yintercept = c(0.8, 0.9), linetype = "dotted", color = c("purple", "green"), size = 1) +
  scale_x_continuous(breaks = seq(min(desired_HRs), max(desired_HRs), 0.1), labels = sprintf("%.2f", seq(min(desired_HRs), max(desired_HRs), 0.1))) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Power vs Hazard Ratio",
       x = "Theoretical Hazard Ratio",
       y = "Power") +
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 14, face = "bold"),
        axis.text = element_text(size = 12))

p4 <- p4 +
  annotate("text", x = max(desired_HRs), y = 0.8, label = "80% power", hjust = 1, vjust = -0.5, size = 3.5, color = "purple") +
  annotate("text", x = max(desired_HRs), y = 0.9, label = "90% power", hjust = 1, vjust = -0.5, size = 3.5, color = "green")

for (i in 1:nrow(data)) {
  p4 <- p4 + annotate("text", x = data$desired_HRs[i], y = data$prop_significant[i],
                      label = sprintf("%.3f", data$mean_HR[i]), hjust = 1, vjust = 1.5, size = 3, color = "black")
}
p4


```

2) 150 -> Poder con 300 pacientes: 85%

Con este tamaño muestral es necesario:
  
1) Un HR de 0.58 para tener un poder del 80%
2) Un HR de 0.56 para tener un poder del 85%
3) Un HR de 0.53 para tener un poder del 90%

```{r `Simulation scenarios w SS = 150` , eval = T, echo = T}

sheet_names <- c("Sheet1")
sim3_results <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/power_esc_10K_150.xlsx", sheet = sheet_names[1])

data <- sim3_results %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE))

data$desired_HRs <- desired_HRs[1:nrow(data)]

p4 <- ggplot(data, aes(x = desired_HRs, y = prop_significant)) +
  geom_point(size = 3, color = "steelblue") +
  geom_line(linewidth = 1, color = "steelblue") +
  geom_vline(xintercept = 1, linetype = "dashed", color = "red", size = 1) +
  geom_hline(yintercept = c(0.8, 0.9), linetype = "dotted", color = c("purple", "green"), size = 1) +
  scale_x_continuous(breaks = seq(min(desired_HRs), max(desired_HRs), 0.1), labels = sprintf("%.2f", seq(min(desired_HRs), max(desired_HRs), 0.1))) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Power vs Hazard Ratio",
       x = "Theoretical Hazard Ratio",
       y = "Power") +
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 14, face = "bold"),
        axis.text = element_text(size = 12))

p4 <- p4 +
  annotate("text", x = max(desired_HRs), y = 0.8, label = "80% power", hjust = 1, vjust = -0.5, size = 3.5, color = "purple") +
  annotate("text", x = max(desired_HRs), y = 0.9, label = "90% power", hjust = 1, vjust = -0.5, size = 3.5, color = "green")

for (i in 1:nrow(data)) {
  p4 <- p4 + annotate("text", x = data$desired_HRs[i], y = data$prop_significant[i],
                      label = sprintf("%.3f", data$mean_HR[i]), hjust = 1, vjust = 1.5, size = 3, color = "black")
}
p4
```

3) 130 -> Poder con 300 pacientes: 80%

Con este tamaño muestral es necesario:
  
  1) Un HR de 0.56 para tener un poder del 80%
2) Un HR de 0.53 para tener un poder del 85%
3) Un HR de 0.5 para tener un poder del 90%

```{r `Simulation scenarios w SS = 130`, eval = T, echo = T}

sheet_names <- c("Sheet1")
sim3_results <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/power_esc_10K_130.xlsx", sheet = sheet_names[1])

data <- sim3_results %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE))

data$desired_HRs <- desired_HRs[1:nrow(data)]

p4 <- ggplot(data, aes(x = desired_HRs, y = prop_significant)) +
  geom_point(size = 3, color = "steelblue") +
  geom_line(linewidth = 1, color = "steelblue") +
  geom_vline(xintercept = 1, linetype = "dashed", color = "red", size = 1) +
  geom_hline(yintercept = c(0.8, 0.9), linetype = "dotted", color = c("purple", "green"), size = 1) +
  scale_x_continuous(breaks = seq(min(desired_HRs), max(desired_HRs), 0.1), labels = sprintf("%.2f", seq(min(desired_HRs), max(desired_HRs), 0.1))) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Power vs Hazard Ratio",
       x = "Theoretical Hazard Ratio",
       y = "Power") +
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 14, face = "bold"),
        axis.text = element_text(size = 12))

p4 <- p4 +
  annotate("text", x = max(desired_HRs), y = 0.8, label = "80% power", hjust = 1, vjust = -0.5, size = 3.5, color = "purple") +
  annotate("text", x = max(desired_HRs), y = 0.9, label = "90% power", hjust = 1, vjust = -0.5, size = 3.5, color = "green")

for (i in 1:nrow(data)) {
  p4 <- p4 + annotate("text", x = data$desired_HRs[i], y = data$prop_significant[i],
                      label = sprintf("%.3f", data$mean_HR[i]), hjust = 1, vjust = 1.5, size = 3, color = "black")
}
p4
```

Es de interés evaluar diferentes escenarios en medianas tanta de un brazo como de otro en función de HR dado. Esto será útil más adelante cuando evaluemos los Bayesianos ya que en principio, se van a comparar los modelos para diferentes tamaños muestrales y en función de diferentes escenarios de HR.

Los HR que se van a considerar son los siguientes en base al estudio anterior de cómo varía el HR necesario para conseguir un poder el 80%, 85% y 90% para los tamaños muestrales de 300, 175, 150 y 130.

1) HR: 0.5
2) HR: 0.55
3) HR: 0.6
4) HR: 0.65
5) HR: 0.70
6) HR: 0.75
7) HR: 0.8

Esto se va a calcular para evaluar las características operantes de Poder, Error de Tipo I y MSE. Los que cumplan buenas condiciones para los escenarios plausibles se calculará el tamaño muestral y el poder para seleccionar el ahorro que ofrecen con respecto al frecuentista.

```{r `Medians W HR fixed`, eval = T, echo = T}

shape_parameter <- 1 

control_medians <- c(3.5,3.75,4,4.25,4.5,4.75,5,5.25,5.5,5.75,6,6.25,6.5,6.75,7,7.25,7.5)

medians <- matrix(NA, nrow = length(control_medians), ncol = 3, 
                  dimnames = list(NULL, c("Control", "Treatment", "HR")))

desired_HR = 0.55

for (i in 1:length(control_medians)) {
  medians[i, "Control"] <- control_medians[i]
  
  lambda_control = control_medians[i] / (log(2)^(1/shape_parameter))
  lambda_treatment = lambda_control / desired_HR^(1/shape_parameter)
  
  medians[i, "Treatment"] = lambda_treatment * (log(2)^(1/shape_parameter))
  medians[i, "HR"] = (lambda_control / lambda_treatment)^shape_parameter
}

medians <- as.data.frame(medians)

medians <- medians %>%
  select(HR, everything())

# Creamos la tabla
table4 <- gt(medians) %>%
  tab_header(title = "Effect in medians when HR = 0.55") %>%
  fmt_number(
    columns = c("HR", "Control"),  # Aquí detallamos cuántos decimales queremos para los valores de estas columnas
    decimals = 2
  ) %>%
  fmt_number(
    columns = names(medians)[!names(medians) %in% c("HR", "Control")],  # Aplicamos estos decimales para los valores de todas las columnas menos las especificadas aquí
    decimals = 3
  ) %>%
  tab_style(
    style = cell_text(weight = "bold", align = "center"),
    locations = cells_column_labels(columns = everything())
  ) %>%
  tab_options(
    column_labels.background.color = "lightsteelblue1",
    table.font.size = px(12),
    table.background.color = "white"
  ) %>%
  tab_style(
    style = cell_fill(color = "lightsteelblue1"),
    locations = cells_body(rows = seq(2, nrow(medians), by = 2), columns = everything())
  ) %>%
  tab_style(
    style = cell_fill(color = "white"),
    locations = cells_body(rows = seq(1, nrow(medians), by = 2), columns = everything())
  ) %>% # En las tres sentencias anteriores es cómo hacemos que se alternen los colores
  tab_style(
    style = cell_fill(color = "lightsteelblue1"),  # Esto es para aplicar el color azul para valores de la primera columna
    locations = cells_body(columns = "HR")
  ) %>%
  tab_style(
    style = cell_text(weight = "bold"),  
    locations = cells_body(columns = "HR")
  ) %>%
  tab_style(
    style = cell_text(align = "center"),
    locations = cells_body(columns = everything())
  ) %>%
  tab_style(
    style = cell_borders(sides = "bottom", color = "black", weight = px(2)),
    locations = cells_column_labels(columns = names(medians)[names(medians) != "HR"])
  ) %>%
  tab_style(
    style = cell_borders(sides = "right", color = "black", weight = px(2)),
    locations = cells_body(columns = "HR")
  )

table4


```

# Análisis Bayesiano

Se usa para la variable de tipo-hasta un modelo Weibull para la inferencia de los datos.
He cambiado el código para, en vez de calcular el tamaño efecto como variable aleatoria, ahora calculo cada uno de los brazos por separado como variables aleatorias; de este modo podré especificar prior distributions para cada uno de los brazos por separado ya que vamos a asumir siempre que el brazo tratamiento va a tener una prior no informativa.

A continuación muestro el modelo STAN que tenía como efectos conjuntos (variable aleatorio diferencia de tratamiento en función de la pendiente de la regresión):
  
```{r `stan-file slope`, eval = T}

cat(readLines("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/weibull_model_def.stan"), sep = "\n")

```

Y este es el modelo que uso a partir de ahora evaluando el efecto de cada uno de los brazos por separado.

Tenemos tres parámetros a estimar en el modelo.

1. Shape: Este es común para los dos brazos.
2. Scale_control: Es es el parámetro escala para el brazo control en el modelo Weibull.
3. Scale_treatment: Es es el parámetro escala para el brazo tratamiento en el modelo Weibull.

Para las 3 variables se usa una distribución a prior gamma. 

Estas distribuciones a priori son proper ya que integra 1 en todo su dominio, ya que todas las prior son gamma y están parametrizadas para tener sólo valores positivos en los parámetros. Esto tiene sentido ya que en análisis de supervivencia sólo valores positivos son considerados. Una ejemplo común de improper es escoger una dist. uniforme sobre todos los valores reales por una media ya que esta dist. tiene valores infinitos bajo la curva.

Así mismo, estas prior son commensurate. Esto se refiere a que si puede tomar valores lógicos con el análisis de supervivencia. Estos priors lo son porque sólo pueden tomar valores positivos respetando la naturaleza y la escala de los datos. 

```{r `stan-file separate arms`, eval = T, echo = T}

cat(readLines("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/weibull_gamma_def.stan"), sep = "\n")

```

Antes de continuar, merece la pena evaluar la comparabilidad entre un ensayo frecuentista y Bayesiano en términos no sólo de decision (rechazar o no rechazar una hipótesis) si no que la fuerza con que se rechaza tiene que ser similar para el mismo dataset de cada uno de los ensayos simulados. Hay que tener en cuenta que los resultados no son para nada lo mismo (el concepto de p-valores y 1-Posterior son totalmente diferentes) y que para el frecuentista se hace una regresión de Cox y en el Bayesiano una regresión de Weibull.

Cabe destacar que aunque aquí no lo muestro, también he comparado los resultados de una regresión Weibull con mi frecuentista con el Weibull de Bayesiano y arroja resultados similares.

A continuación muestro los parámetros que he usado para el ensayo frecuentista para obtener los p-valores:
  
```{r `pvalues freq`, eval = T, echo = T}

shape_parameter <- 1.130169 # Este valor se ha sacado de la regresión weibull de los datos IPD
sample_size <- 300
ratio <- c(0.5,0.5)
rand_type <- "CR" 
scenarios_eff <- matrix(c(5.5,7.4), nrow = 1, ncol = 2, byrow = TRUE)
censor <- c(0.2,0.2)
Tmax <- 16
alpha <- 0.05 
test.type <- 2
HR_1 <- FALSE
IA <- NULL
Plot_Power = FALSE 
plot_pvalues = TRUE
analysis = "freq" 
n_sim <- 10000
seed <- 55

sim1 <- sim_trials(n_sim = n_sim, 
                   analysis = "freq",
                   sample_size = sample_size,
                   ratio = ratio,
                   rand_type = rand_type,
                   Tmax = Tmax, 
                   shape_parameter = shape_parameter,
                   scenarios_eff = scenarios_eff,
                   censor = censor,
                   alpha = alpha,
                   test.type = test.type,
                   IA = IA,
                   method_IA = method_IA,
                   n_exp_events = n_exp_events,
                   HR_1 = HR_1,
                   seed=seed,
                   Plot_Power = Plot_Power,
                   plot_pvalues = plot_pvalues)

pvalues1 <- sim1[[2]]
sim11 <- sim1[[1]]

```

Ahora muestro el código que se ha usado para el Bayesiano con una distribución a priori no informativa para los dos brazos:
  
```{r `1-Posterior values`, eval = T}

shape_parameter <- 1.130169 
sample_size <- 300
ratio <- c(0.5,0.5)
rand_type <- "CR" 
scenarios_eff <- matrix(c(5.5,7.4), nrow = 1, ncol = 2, byrow = TRUE)
censor <- c(0.2,0.2)
Tmax <- 16
alpha <- 0.05 
test.type <- 2
HR_1 <- FALSE
IA <- NULL
Plot_Power = FALSE 
plot_pvalues = TRUE 
analysis = "bayes"
n_sim <- 10000
seed <- 55
method_IA <- "Bayes"
n_exp_events <- 175
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = FALSE
# 1) Shape control, 2) rate control, 3) Shape experimental y 4) rate experimental
prior_gamma <- matrix(c(0.00001, 0.00001, 0.00001, 0.00001), nrow = 2, ncol = 2, byrow = TRUE) 
prior_type <- c("Non informative prior") # Este vector es para que aparezca el nombre en las tablas
P_HR_data_Boundary <- 0.8 # P(HR < 0.8 | data)
modelo_weibull_sep <- rstan::stan_model("weibull_gamma_def.stan" ,verbose = F)
modelo = modelo_weibull_sep
modelo_bayes_test = "weibull"

# sim4 <- sim_trials(n_sim = n_sim,  
#                    analysis = "bayes",
#                    sample_size = sample_size, 
#                    ratio = ratio,
#                    rand_type = rand_type,
#                    Tmax = Tmax, 
#                    scenarios_eff = scenarios_eff,
#                    shape_parameter = shape_parameter,
#                    censor = censor,
#                    test.type = test.type,
#                    alpha = alpha,
#                    method_IA = method_IA,
#                    IA = IA,
#                    n_exp_events = n_exp_events,
#                    HR_1 = HR_1,
#                    Plot_Power = Plot_Power,
#                    prior = prior,
#                    modelo = modelo,
#                    modelo_bayes_test = modelo_bayes_test,
#                    prior_type = prior_type,
#                    P_HR_data_Boundary = P_HR_data_Boundary,
#                    prior_gamma = prior_gamma,
#                    Plot_Power_scenarios = Plot_Power_scenarios,
#                    desired_HRs = desired_HRs,
#                    plot_pvalues = plot_pvalues,
#                    Plot_Control_Scenarios = Plot_Control_Scenarios,
#                    seed = seed)
# 
# pvalues4 <- sim4[[2]]
# sim44 <- sim4[[1]]

# Leemos los datos porque la simulación es de muchas horas:

sheet_names <- c("Sheet1","Sheet2")
pvalues4 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/p_values_non_informative_gamma.xlsx", sheet = sheet_names[2])

```

Juntamos los datos de los dos enfoques para los mismos resultados de cada uno de los ensayos clínicos y se enseña un plot donde se muestra que todos los puntos están alineados alrededor de la línea identidad, mostrando una gran consistencia entre el enfoque frecuentista y el Bayesiano con priors no informativas.

```{r `Comparison pvalues vs 1-Posterior 1`, eval = T}

pvalues1$p_value <- pvalues1$p_value/2
plot_pvalues <- inner_join(pvalues1, pvalues4, by = "n_sim") # Si solo cogemos los de Cox y Bayes

# Cuando el "p-valor" Bayesiano supera el 50% hay que hacer 1-(1-post_prob) para hacer este valor
# comparable con el p-valor frecuentista
plot_pvalues <- plot_pvalues %>%
  mutate(`1-post_prob` = ifelse(`1-post_prob` > 0.5, (1 - `1-post_prob`), `1-post_prob`))

ggplot(plot_pvalues, aes(x = p_value, y = `1-post_prob`)) +
  geom_point() +
  geom_abline(slope = 1, intercept = 0, color = "red") +
  xlab("P-value") +
  ylab("1 - Posterior Probability") +
  ggtitle("Frequentist P-value vs Bayesian 1 - Posterior Probability") +
  theme_minimal()

```

Además, en la siguiente figura (donde se ha hecho zoom en la zona entre 0 y 0.05) se muestra que en la mayoría de los casos simulados, el frecuentista y Bayesiano llegan a la misma conclusión con respecto a la significancia de los datos.

```{r `Comparison pvalues vs 1-Posterior 2`, eval = T}

plot_pvalues_table <- plot_pvalues %>%
  mutate(
    p_value_significant = ifelse(p_value < 0.025, 1, 0),
    post_prob_significant = ifelse(`1-post_prob` < 0.025, 1, 0)
  )

agreement_proportion <- mean(plot_pvalues_table$p_value_significant == plot_pvalues_table$post_prob_significant)

disagree_trials <- plot_pvalues_table %>%
  filter(p_value_significant != post_prob_significant)

n_disagree <- nrow(disagree_trials)

frequentist_only <- disagree_trials %>%
  filter(p_value_significant == 1 & post_prob_significant == 0)

bayesian_only <- disagree_trials %>%
  filter(p_value_significant == 0 & post_prob_significant == 1)

freq_only_prop <- nrow(frequentist_only) / n_disagree
bayes_only_prop <- nrow(bayesian_only) / n_disagree

p1 <- ggplot(plot_pvalues, aes(x = p_value, y = `1-post_prob`)) +
  geom_point() +
  geom_abline(slope = 1, intercept = 0, color = "black") +
  geom_vline(xintercept = 0.025, linetype = "dashed", color = "red") +
  geom_hline(yintercept = 0.025, linetype = "dashed", color = "red") +
  annotate("text", x = 0.0375, y = 0.0125, label = "Only Bayesian test is significant", size = 5) +
  annotate("text", x = 0.0125, y = 0.0375, label = "Only frequentist test is significant", size = 5) +
  xlim(c(0, 0.05)) +
  ylim(c(0, 0.05)) +
  xlab("P-values") +
  ylab("1- Posterior Probabilities") +
  ggtitle("P-values vs 1-Posterior Probabilities") +
  theme_minimal() +
  theme(plot.title = element_text(size = 13, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 9))

p1
```

Por ultimo, aquí muestro la comparación entre los dos enfoques con el porcentaje total de "fallos", lo que se ve que es muy residual.

```{r `Comparison pvalues vs 1-Posterior 3`, eval = T}

freq_only_prop <- nrow(frequentist_only) / nrow(plot_pvalues_table)
bayes_only_prop <- nrow(bayesian_only) / nrow(plot_pvalues_table)

p2 <- ggplot(plot_pvalues_table, aes(x = p_value, y = `1-post_prob`)) +
  geom_point() +
  geom_abline(slope = 1, intercept = 0, color = "red") +
  geom_vline(xintercept = 0.05, linetype = "dashed", color = "red") +
  geom_hline(yintercept = 0.05, linetype = "dashed", color = "red") +
  annotate("text", x = 0.3, y = 0.02, label = paste("Only Bayesian test is significant (", round(bayes_only_prop*100, 2), "%)", sep = ""), size = 5) +  
  annotate("text", x = 0.15, y = 0.4, label = paste("Only frequentist test is significant (", round(freq_only_prop*100, 2), "%)", sep = ""), size = 5) +  
  xlim(c(0, 0.55)) +
  ylim(c(0, 0.55)) +
  xlab("P-values") +
  ylab("1-Posterior Probabilities") +
  ggtitle("P-values vs 1-Posterior Probabilities") +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 13, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 10, face = "bold"),
    axis.text = element_text(size = 9)
  )
p2

```

```{r T1E_combined_all, eval = T}

library(cowplot)

p11 <- p1 + theme(plot.background = element_rect(colour = "black", size = 0.5, fill = NA))
p22 <- p2 + theme(plot.background = element_rect(colour = "black", size = 0.5, fill = NA))

plots_row <- plot_grid(p22, p11, ncol = 2, labels = c("A", "B"), label_size = 14)

combined_plot <- plot_grid(
  plots_row,
  #legend,
  ncol = 1,                 
  rel_heights = c(3, 0.4)   
)

print(combined_plot)

```

De manera preliminar (y sin detallar nada a modo de resumen). Se van a considerar 3 modelos Bayesianos diferentes donde se van a considerar 3 prior distribution diferentes para el brazo control considerando siempre una prior no informativa para el brazo tratamiento.
Esta información a priori sigue una distribución beta y aunque los resultados a partir de ahora se muestran en términos de medianas, las prior se van a especificar en términos de la escala weibull para este tratamiento.

La fórmula para transformar las medianas en parámetro escala para la Weibull es la siguiente (asumiendo un shape=1 que es exponencial):
  
parameters <- medians / (log(2)^(1/shape_parameter))

Por ejemplo, si estos análisis consideramos como hasta ahora con un tamaño muestral de 300 que la mediana para el brazo control es 5.5 y 10 para el brazo experimental considerando un HR de 0.55, la transformación en términos de escala Weibull es:
  
Control: Mediana de 5.5 es 7.934823
Experimental: Mediana de 10 es 14.42695

A continuación muestro los 3 plots de densidad para la prior del brazo control.

1) Prior no informativa: Equivalente al frecuentista porque "dejamos que los datos hablen por sí mismos" a través de la función de verosimilitud.

2) Prior débil: Damos una idea de en qué rangos debería estar el parámetro para la mediana pero es información muy vaga y que no aporta gran conocimiento.

3) Prior muy informativa: Tenemos una certeza absoluta de qué valor es el valor real de la mediana y dejamos poco espacio a la incertidumbre (muy poca variabilidad).

```{r `Gamma priors`, eval = T}

parameters_gamma <- data.frame(shape = c(0.00001, 7.213475, 793.4823),
                               rate = c( 0.00001, 1, 100),
                               label = c("Non-informative: Gamma(0.00001, 0.00001)", "Weak: Gamma(7.213475, 1)", "Informative: Gamma(793.4823, 100)"))

gamma_density <- function(shape, rate, label) {
  data.frame(x = seq(0, 20, length.out = 100)) %>%
    mutate(density = dgamma(x, shape = shape, rate = rate),
           parameter = label)
}

densities <- purrr::pmap_df(parameters_gamma, gamma_density)


ggplot(densities, aes(x, density, color = parameter)) +
  geom_line(size = 1.2) + geom_line() +
  labs(
    title = "Gamma Prior Distributions",
    x = "Scale Parameter for the Control Arm",
    y = "Density",
    color = "Scale Prior Distributions"  
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 10, face = "bold"),
    axis.text = element_text(size = 12),
    axis.title.x = element_text(size = 12),
    axis.title.y = element_text(size = 12),
    legend.margin = margin(12, 12, 12, 12),
    legend.text = element_text(size = 11),
    legend.title = element_text(size = 12, face = "bold")
  )

```



A continuación, pasamos a evaluar las características operantes para los 3 modelos Bayesianos propuestos. Se va a estudiar como anteriormente, el Poder, el Error de Tipo I y el MSE.

Se va a evaluar un escenario donde el HR = 0.55 y se asume una exponencial. Se van a considerar los parámetros del SAP como si no tuviéramos conocimiento de los resultados finales.

A continuación está el Bayesiano con prior no informativa:

```{r `Bayes: Non informative prior distribution`, eval = T}

shape_parameter <- 1 

control_medians <- c(3.5,3.75,4,4.25,4.5,4.75,5,5.25,5.5,5.75,6,6.25,6.5,6.75,7,7.25,7.5)

medians <- matrix(NA, nrow = length(control_medians), ncol = 3, 
                  dimnames = list(NULL, c("Control", "Treatment", "Hazard Ratio")))

desired_HR = 0.55

for (i in 1:length(control_medians)) {
  medians[i, "Control"] <- control_medians[i]
  
  lambda_control = control_medians[i] / (log(2)^(1/shape_parameter))
  lambda_treatment = lambda_control / desired_HR^(1/shape_parameter)
  
  medians[i, "Treatment"] = lambda_treatment * (log(2)^(1/shape_parameter))
  medians[i, "Hazard Ratio"] = (lambda_control / lambda_treatment)^shape_parameter
}

medians <- medians[,1:2]
sample_size <- 300  
ratio <- c(0.5,0.5)
rand_type <- "CR" 
scenarios_eff <- as.matrix(medians, nrow = length(control_medians), ncol = 2, byrow = TRUE)
censor <- c(0.1,0.1)
Tmax <- 20
alpha <- 0.05 
test.type <- 2
HR_1 <- TRUE
IA <- NULL
method_IA <- "bayes"
n_exp_events <- 175
Plot_Power <- FALSE
plot_pvalues = FALSE 
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = TRUE

analysis = "bayes"
n_sim <- 2000
seed <- 24
# 1) Shape control, 2) rate control, 3) Shape experimental y 4) rate experimental
prior_gamma <- matrix(c(0.00001, 0.00001, 0.00001, 0.00001), nrow = 2, ncol = 2, byrow = TRUE) 
prior_type <- c("Non informative prior") # Este vector es para que aparezca el nombre en las tablas
P_HR_data_Boundary <- 0.8 # P(HR < 0.8 | data)
modelo_weibull_sep <- rstan::stan_model("prueba3_sep.stan" ,verbose = F)
modelo = modelo_weibull_sep
modelo_bayes_test = "weibull"

# sim5 <-  sim_trials(n_sim = n_sim,  
#                     analysis = "bayes",
#                     sample_size = sample_size, 
#                     ratio = ratio,
#                     rand_type = rand_type,
#                     Tmax = Tmax, 
#                     scenarios_eff = scenarios_eff,
#                     shape_parameter = shape_parameter,
#                     censor = censor,
#                     test.type = test.type,
#                     alpha = alpha,
#                     method_IA = method_IA,
#                     IA = IA,
#                     n_exp_events = n_exp_events,
#                     HR_1 = HR_1,
#                     Plot_Power = Plot_Power,
#                     modelo = modelo,
#                     modelo_bayes_test = modelo_bayes_test,
#                     prior_type = prior_type,
#                     P_HR_data_Boundary = P_HR_data_Boundary,
#                     prior_gamma = prior_gamma,
#                     Plot_Power_scenarios = Plot_Power_scenarios,
#                     desired_HRs = desired_HRs,
#                     plot_pvalues = plot_pvalues,
#                     Plot_Control_Scenarios = Plot_Control_Scenarios,
#                     seed = seed)
# sim5[[2]]
# sim5[[3]]
# sim5[[4]]
# 
# sim55 <- sim5[[1]]
# 
# wd <- createWorkbook()
# addWorksheet(wd, "Sheet1")
# writeData(wd, "Sheet1", sim55)
# saveWorkbook(wd, "non_informative_gamma_300_2000_HR_055.xlsx", overwrite = TRUE)
# 


sheet_names <- c("Sheet1")
non_informative_gamma <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/non_informative_gamma_300_2000_HR_055.xlsx", sheet = sheet_names[1])


```

El Bayesiano con una prior muy poco informativa (débil):
  
```{r `Bayes: Weak informative prior distribution`, eval = T}

sample_size <- 300  
ratio <- c(0.5,0.5)
rand_type <- "CR" 
scenarios_eff <- as.matrix(medians, nrow = length(control_medians), ncol = 2, byrow = TRUE)
censor <- c(0.1,0.1)
Tmax <- 20
alpha <- 0.05 
test.type <- 2
HR_1 <- TRUE
IA <- NULL
method_IA <- "bayes"
n_exp_events <- 175
Plot_Power <- FALSE
plot_pvalues = FALSE 
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = TRUE

analysis = "bayes"
n_sim <- 2000
seed <- 24
# 1) Shape control, 2) rate control, 3) Shape experimental y 4) rate experimental
prior_gamma <- matrix(c(7.213475, 1, 0.00001, 0.00001), nrow = 2, ncol = 2, byrow = TRUE) 
prior_type <- c("Weak informative prior") # Este vector es para que aparezca el nombre en las tablas
P_HR_data_Boundary <- 0.8 # P(HR < 0.8 | data)
modelo_weibull_sep <- rstan::stan_model("weibull_gamma_def.stan" ,verbose = F)
modelo = modelo_weibull_sep
modelo_bayes_test = "weibull"

# sim6 <-  sim_trials(n_sim = n_sim,  
#                     analysis = "bayes",
#                     sample_size = sample_size, 
#                     ratio = ratio,
#                     rand_type = rand_type,
#                     Tmax = Tmax, 
#                     scenarios_eff = scenarios_eff,
#                     shape_parameter = shape_parameter,
#                     censor = censor,
#                     test.type = test.type,
#                     alpha = alpha,
#                     method_IA = method_IA,
#                     IA = IA,
#                     n_exp_events = n_exp_events,
#                     HR_1 = HR_1,
#                     Plot_Power = Plot_Power,
#                     modelo = modelo,
#                     modelo_bayes_test = modelo_bayes_test,
#                     prior_type = prior_type,
#                     P_HR_data_Boundary = P_HR_data_Boundary,
#                     prior_gamma = prior_gamma,
#                     Plot_Power_scenarios = Plot_Power_scenarios,
#                     desired_HRs = desired_HRs,
#                     plot_pvalues = plot_pvalues,
#                     Plot_Control_Scenarios = Plot_Control_Scenarios,
#                     seed = seed)
# sim6[[2]]
# sim6[[3]]
# sim6[[4]]
# 
# sim66 <- sim6[[1]]
# 
# wd <- createWorkbook()
# addWorksheet(wd, "Sheet1")
# writeData(wd, "Sheet1", sim66)
# saveWorkbook(wd, "weak_informative_gamma_300_2000_HR_055.xlsx", overwrite = TRUE)


sheet_names <- c("Sheet1")
weak_informative_gamma <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/weak_informative_gamma_300_2000_HR_055.xlsx", sheet = sheet_names[1])


```


Y el Bayesiano con prior muy informativa:
  
```{r `Bayes: Strong informative prior distribution`, eval = T}

sample_size <- 300  
ratio <- c(0.5,0.5)
rand_type <- "CR" 
scenarios_eff <- as.matrix(medians, nrow = length(control_medians), ncol = 2, byrow = TRUE)
censor <- c(0.1,0.1)
Tmax <- 20
alpha <- 0.05 
test.type <- 2
HR_1 <- TRUE
IA <- NULL
method_IA <- "bayes"
n_exp_events <- 175
Plot_Power <- FALSE
plot_pvalues = FALSE 
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = TRUE

analysis = "bayes"
n_sim <- 2000
seed <- 24
# 1) Shape control, 2) rate control, 3) Shape experimental y 4) rate experimental
prior_gamma <- matrix(c(793.4823, 100, 0.00001, 0.00001), nrow = 2, ncol = 2, byrow = TRUE) 
prior_type <- c("Strong informative prior") # Este vector es para que aparezca el nombre en las tablas
P_HR_data_Boundary <- 0.8 # P(HR < 0.8 | data)
modelo_weibull_sep <- rstan::stan_model("weibull_gamma_def.stan" ,verbose = F)
modelo = modelo_weibull_sep
modelo_bayes_test = "weibull"

# sim7 <-  sim_trials(n_sim = n_sim,  
#                     analysis = "bayes",
#                     sample_size = sample_size, 
#                     ratio = ratio,
#                     rand_type = rand_type,
#                     Tmax = Tmax, 
#                     scenarios_eff = scenarios_eff,
#                     shape_parameter = shape_parameter,
#                     censor = censor,
#                     test.type = test.type,
#                     alpha = alpha,
#                     method_IA = method_IA,
#                     IA = IA,
#                     n_exp_events = n_exp_events,
#                     HR_1 = HR_1,
#                     Plot_Power = Plot_Power,
#                     modelo = modelo,
#                     modelo_bayes_test = modelo_bayes_test,
#                     prior_type = prior_type,
#                     P_HR_data_Boundary = P_HR_data_Boundary,
#                     prior_gamma = prior_gamma,
#                     Plot_Power_scenarios = Plot_Power_scenarios,
#                     desired_HRs = desired_HRs,
#                     plot_pvalues = plot_pvalues,
#                     Plot_Control_Scenarios = Plot_Control_Scenarios,
#                     seed = seed)
# sim7[[2]]
# sim7[[3]]
# sim7[[4]]
# 
# sim77 <- sim7[[1]]
# 
# wd <- createWorkbook()
# addWorksheet(wd, "Sheet1")
# writeData(wd, "Sheet1", sim77)
# saveWorkbook(wd, "strong_informative_gamma_300_2000_HR_055.xlsx", overwrite = TRUE)


sheet_names <- c("Sheet1")
strong_informative_gamma <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/strong_informative_gamma_300_2000_HR_055.xlsx", sheet = sheet_names[1])


```

Por último, leemos los datos del frecuentista para HR=0.55:
  
```{r `Bayes: freq HR=0.55`, eval = T}

sample_size <- 300  
ratio <- c(0.5,0.5)
rand_type <- "CR" 
scenarios_eff <- as.matrix(medians, nrow = length(control_medians), ncol = 2, byrow = TRUE)
censor <- c(0.1,0.1)
Tmax <- 20
alpha <- 0.05 
test.type <- 2
HR_1 <- TRUE
IA <- NULL
method_IA <- "freq"
n_exp_events <- 175
Plot_Power <- FALSE
plot_pvalues = FALSE 
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = TRUE

analysis = "freq"
n_sim <- 2000
seed <- 24


# sim8 <-  sim_trials(n_sim = n_sim,  
#                     analysis = "freq",
#                     sample_size = sample_size, 
#                     ratio = ratio,
#                     rand_type = rand_type,
#                     Tmax = Tmax, 
#                     scenarios_eff = scenarios_eff,
#                     shape_parameter = shape_parameter,
#                     censor = censor,
#                     test.type = test.type,
#                     alpha = alpha,
#                     method_IA = method_IA,
#                     IA = IA,
#                     n_exp_events = n_exp_events,
#                     HR_1 = HR_1,
#                     Plot_Power = Plot_Power,
#                     modelo = modelo,
#                     modelo_bayes_test = modelo_bayes_test,
#                     prior_type = prior_type,
#                     P_HR_data_Boundary = P_HR_data_Boundary,
#                     prior_gamma = prior_gamma,
#                     Plot_Power_scenarios = Plot_Power_scenarios,
#                     desired_HRs = desired_HRs,
#                     plot_pvalues = plot_pvalues,
#                     Plot_Control_Scenarios = Plot_Control_Scenarios,
#                     seed = seed)
# sim8[[2]]
# sim8[[3]]
# sim8[[4]]
# 
# sim88 <- sim8[[1]]
# 
# wd <- createWorkbook()
# addWorksheet(wd, "Sheet1")
# writeData(wd, "Sheet1", sim8)
# saveWorkbook(wd, "freq_300_2000_HR_055.xlsx", overwrite = TRUE)


sheet_names <- c("Sheet1")
frequentist <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/freq_300_2000_HR_055.xlsx", sheet = sheet_names[1])


```

Una vez que hemos recogido los resultados de la simulación vamos a comparar en los mismos gráficos el rendimiento de cada uno de los modelos. También se incorpora el frecuentista para tenerlo como referencia.

A continuación recogemos los datos para poder dibujarlos

```{r `Data gathering `, eval = T}

if(HR_1 == TRUE){hr_1 <- replicate(n = ncol(scenarios_eff), scenarios_eff[, 1])
scenarios_eff <- rbind(scenarios_eff, hr_1)}

scenarios_eff_df <- as.data.frame(scenarios_eff)
colnames(scenarios_eff_df) <- c("median_control", "median_treatment")

scenarios_eff_df$scenario <- seq_len(nrow(scenarios_eff_df))

# Non-informative
data_non_informative <- non_informative_gamma %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "Non-informative Prior: Gamma(0.00001, 0.00001)")

data_filtered_diff_not_zero_non_informative <- data_non_informative %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_non_informative <- data_non_informative %>%
  filter(median_control == median_treatment)

# Very informative
data_informative <- strong_informative_gamma %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "Informative Prior: Gamma (760.6836, 100)")

data_filtered_diff_not_zero_informative <- data_informative %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_informative <- data_informative %>%
  filter(median_control == median_treatment)

# Mid informative
data_mid_informative <- weak_informative_gamma %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "Weak Informative Prior: Gamma(7.213475, 1)")

data_filtered_diff_not_zero_mid_informative <- data_mid_informative %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_mid_informative <- data_mid_informative %>%
  filter(median_control == median_treatment)


# Frequentist
data_frequentist <- frequentist %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "Frequentist")

data_filtered_diff_not_zero_frequentist <- data_frequentist %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_frequentist <- data_frequentist %>%
  filter(median_control == median_treatment)


median_control_center <- median(data_filtered_diff_not_zero_informative$median_control)
median_control_center_zero_diff <- median(data_filtered_diff_zero_informative$median_control)

combined_data_diff_not_zero <- bind_rows(data_filtered_diff_not_zero_non_informative, 
                                         data_filtered_diff_not_zero_informative, 
                                         data_filtered_diff_not_zero_mid_informative,
                                         data_filtered_diff_not_zero_frequentist)

combined_data_diff_zero <- bind_rows(data_filtered_diff_zero_non_informative, 
                                     data_filtered_diff_zero_informative, 
                                     data_filtered_diff_zero_mid_informative,
                                     data_filtered_diff_zero_frequentist)

```

Primero observamos cómo de bien se ajustan las inferencias a los datos verdaderos (poblacionales dentro de la simulación). 

Los resultados de MSE son prácticamente iguales para el modelo frecuentista como el bayesiano con las priors no informativas. Con respecto a la Weak, 

Por último la informativa tiene un comportamiento espectacular en escenarios donde la mediana real para el control son muy cercanos a 5.5 pero muy malos según se van alejando del valores central de esta prior.

```{r MSE, eval = T}

p6 <- ggplot(combined_data_diff_not_zero, aes(x = median_control, y = mean_MSE, color = Prior)) + 
  geom_line(size = 1.2) +
  geom_vline(xintercept = median_control_center, linetype = "solid") +
  labs(
    title = "Mean Square Error (MSE)",
    x = "Median Control Arm (in months)",
    y = "Mean MSE",
    color = "Bayesian Prior Distributions"
  ) +
  theme_minimal() + 
  theme(
    plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 10, face = "bold"),
    axis.text = element_text(size = 12),
    axis.title.x = element_text(size = 11),
    axis.title.y = element_text(size = 11),
    legend.margin = margin(9, 9, 9, 9),
    legend.text = element_text(size = 9),
    legend.title = element_text(size = 10, face = "bold")
  ) +
  scale_color_discrete(name = "Bayesian Prior Distributions") +
  scale_x_continuous(breaks = seq(min(combined_data_diff_not_zero$median_control), max(combined_data_diff_not_zero$median_control), by = 0.5)) +
  scale_y_continuous(limits = c(0, 0.075))

p6



```

Con respecto al poder...

```{r Power, eval = T}

p7 <- ggplot(combined_data_diff_not_zero, aes(x = median_control, y = prop_significant, color = Prior)) +
  geom_line(size = 1.2) + 
  geom_line() +
  geom_vline(xintercept = median_control_center, linetype = "dashed") +
  labs(title = "Power", x = "Median Control Arm (in months)", y = "Proportion of Significant Trials", color = "Bayesian Prior Distributions") +
  theme_minimal() + 
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 12),
    axis.title.x = element_text(size = 11),
    axis.title.y = element_text(size = 11),
       legend.margin = margin(9, 9, 9, 9),
    legend.text = element_text(size = 9),
    legend.title = element_text(size = 10, face = "bold")) +
  scale_color_discrete(name = "Bayesian Prior Distributions") +
  scale_linetype_discrete(name = "Bayesian Prior Distributions") +
  scale_x_continuous(breaks = seq(min(combined_data_diff_not_zero$median_control), max(combined_data_diff_not_zero$median_control), by = 0.5)) +
  scale_y_continuous(limits = c(0.8, 1))
p7

```

Por último, el error de Tipo I vemos que se controla para el bayesiano no informativo y el weak. Sin embargo, en el bayesiano informativo para valores mayores de 5.5 el error de tipo I se infla de una manera exponencial. Esto demuestra que este modelo no debería usarse a no ser que exista un consenso de que estos valores son "seguros".

```{r T1E, eval = T}

p8 <- ggplot(combined_data_diff_zero, aes(x = median_control, y = prop_significant, color = Prior)) +
  geom_line(size = 1.2) +
  geom_line() +
  geom_vline(xintercept = median_control_center, linetype = "dashed") +
  geom_hline(yintercept = 0.025, linetype = "dashed", color = "green") +
  geom_hline(yintercept = 0.05, linetype = "dashed", color = "purple") +
  labs(title = "Type I Error (T1E)", x = "Median Control (in months)", y = "Proportion of Significant Trials", color = "Bayesian Prior Distributions") +
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 12),
    axis.title.x = element_text(size = 11),
    axis.title.y = element_text(size = 11),
      legend.margin = margin(9, 9, 9, 9),
    legend.text = element_text(size = 9),
    legend.title = element_text(size = 10, face = "bold")) +
  scale_color_discrete(name = "Bayesian Prior Distributions") +
  scale_linetype_discrete(name = "Bayesian Prior Distributions") +
  scale_x_continuous(breaks = seq(min(combined_data_diff_zero$median_control), max(combined_data_diff_zero$median_control), by = 0.5)) +
  scale_y_continuous(limits = c(0, 0.2))
p8

```

```{r T1E_combined_all, eval = T}

library(cowplot)

p66 <- p6 + scale_color_discrete(
  name = "Bayesian Prior Distributions:", 
  labels = c(
    "Frequentist",
    "Informative Prior\ncentered at 5.5 months",
    "Non-informative Prior\ncentered at 5.5 months",
    "Weak Informative Prior:\nCentered at 5.5 months"
  )
) +
  guides(color = guide_legend(ncol = 4))  

legend <- get_legend(
  p66 +
    theme(
      # legend.box = "horizontal", 
      legend.justification = c(0, 1),
      # legend.margin = margin(8, 8, 8, 8),
      legend.text = element_text(size = 10), 
      legend.title = element_text(size = 11, face = "bold")
    )
)

# Remove individual legends from the plots
p66 <- p66 + theme(legend.position = "none")
p77 <- p7 + theme(legend.position = "none")
p88 <- p8 + theme(legend.position = "none")

p66 <- p66 + theme(plot.background = element_rect(colour = "black", size = 0.5, fill = NA))
p77 <- p77 + theme(plot.background = element_rect(colour = "black", size = 0.5, fill = NA))
p88 <- p88 + theme(plot.background = element_rect(colour = "black", size = 0.5, fill = NA))

plots_row <- plot_grid(p66, p77, p88, ncol = 3, labels = c("A", "B", "C"), label_size = 14)

combined_plot <- plot_grid(
  plots_row,
  legend,
  ncol = 1,                 
  rel_heights = c(3, 0.4)   
)

print(combined_plot)

```

También resulta valioso cómo afectan diferentes asunciones para la prior informativa en el brazo control si vamos moviendo el HR. Esto nos va a permitir ver cómo asunciones demasiado pesimistas para el brazo control favorece que sea más fácil ver diferencias entre brazos y por lo tanto, considerar el estudio como significativo. Por otro lado, es relativamente común ver cuando un estudio sale fallido achacar la culpa a que la mediana del brazo control ha sido más buena de lo esperado y por lo tanto, es más difícil demostrar eficacia.

Ahora vamos a usar el gráfico que ya se presentó anteriormente sólo para el frecuentista con priors muy informativas y comparar cómo afectan estas asunciones informativas a la facilidad o dificultad para declarar eficacia. Esto también se puede ver traducido a la importancia de elegir un threshold para demostrar eficacia ya que esto es totalmente comparable a usar un prior muy muy informativa a un valor determinado.

Recordar que siempre se usa un prior no informativa para el brazo experimental.

Se va a hacer sólo para los parámetros que la compañía usó en el SAP, i.e., distribución exponencial (shape parameter = 1), tamaño muestral de 300 y mediana de control de 5.5

Aquí recuerdo los datos para el efecto dadas estas asunciones (sólo a partir de 1.3 esta vez):
  
```{r `Medians w control arm at 5.5 Part 2` , eval = T, echo = T}

shape_parameter <- 1

desired_HRs <- c(1.3, 1.2, 1.1, 1, 0.95, 0.9, 0.85, 0.8, 0.775, 0.75, 0.725, 0.7, 0.675, 0.65, 0.625, 0.6, 0.575, 0.55, 0.525, 0.5, 0.45, 0.4, 0.35, 0.3)
control_medians <- rep(5.5, times = length(desired_HRs))

medians_control_fijo <- matrix(NA, nrow = length(desired_HRs), ncol = 2, dimnames = list(paste0("HR ", desired_HRs), c("Control", "Treatment")))

for (i in 1:length(desired_HRs)) {
  medians_control_fijo[i, "Treatment"] <- control_medians[i] / (desired_HRs[i]^(1/shape_parameter))
  medians_control_fijo[i, "Control"] <- control_medians[i]
}

```

A continuación se cogen los datos del frecuentista para los que se hizo en la gráfica original:
  
```{r `Bayes: freq HR=0.55 Power changing HRs`, eval = T}

shape_parameter <- 1
sample_size <- 300
ratio <- c(0.5,0.5)
rand_type <- "CR" 
scenarios_eff <- as.matrix(medians_control_fijo, nrow = length(medians_control_fijo), ncol = 2, byrow = TRUE)
censor <- c(0.1,0.1)
Tmax <- 20
alpha <- 0.05 
test.type <- 2
HR_1 <- FALSE
IA <- NULL
Plot_Power = FALSE
plot_pvalues = FALSE
Plot_Power_scenarios = FALSE
analysis = "freq" 
n_sim <- 1000
seed <- 24

# sim3 <- sim_trials(n_sim = n_sim,
#                    analysis = "freq",
#                    sample_size = sample_size,
#                    ratio = ratio,
#                    rand_type = rand_type,
#                    Tmax = Tmax,
#                    shape_parameter = shape_parameter,
#                    scenarios_eff = scenarios_eff,
#                    censor = censor,
#                    alpha = alpha,
#                    test.type = test.type,
#                    IA = IA,
#                    method_IA = method_IA,
#                    n_exp_events = n_exp_events,
#                    HR_1 = HR_1,
#                    seed=seed,
#                    Plot_Power = Plot_Power,
#                    plot_pvalues = plot_pvalues)

#
# wd <- createWorkbook()
# addWorksheet(wd, "Sheet1")
# writeData(wd, "Sheet1", sim3)
# saveWorkbook(wd, "freq_2000_HR_changing.xlsx", overwrite = TRUE)
# 
sheet_names <- c("Sheet1")
sim3_results <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/freq_2000_HR_changing.xlsx", sheet = sheet_names[1])


```

Vamos a ver la densidad para cada una de las distribuciones informativas del control forzando valores de 3.5, 5.5 y 7.5.

```{r `Gamma priors informatives`, eval = T}

# Vamos a presentarlo en términos de medianas en vez de escala Weibull (aunque luego sea esto lo que se meta como input en el model STAN)

# En términos del parámetro escala
# parameters <- medians / (log(2)^(1/shape_parameter))
# En términos de mediana
# medians <- parameters * (log(2))^(1/shape_parameter)

parameters_gamma <- data.frame(shape = c(350, 550, 750),
                               rate = c( 100, 100, 100),
                               label = c("Informative: Gamma(504.9433, 100)", "Informative: Gamma(793.4823, 100)", "Informative: Gamma(1082.021, 100)"))

gamma_density <- function(shape, rate, label) {
  data.frame(x = seq(0, 20, length.out = 100)) %>%
    mutate(density = dgamma(x, shape = shape, rate = rate),
           parameter = label)
}

densities <- purrr::pmap_df(parameters_gamma, gamma_density)

ggplot(densities, aes(x, density, color = parameter)) +
  geom_line(size = 1.2) + 
  geom_line() +
  labs(
    title = "Gamma Prior Distributions",
    x = "Scale Parameter for the Control Arm",
    y = "Density",
    color = "Scale Prior Distributions"  
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 10, face = "bold"),
    axis.text = element_text(size = 12),
    axis.title.x = element_text(size = 12),
    axis.title.y = element_text(size = 12),
    legend.margin = margin(12, 12, 12, 12),
    legend.text = element_text(size = 11),
    legend.title = element_text(size = 12, face = "bold")
  )

```

Simulamos los resultados forzando a la prior informativa del control a ser de 3.5 

```{r `Bayes: Bayes infor med: 3.5 HR=0.55 Power changing HRs`, eval = T}

shape_parameter <- 1 

desired_HRs <- c(1.3, 1.2, 1.1, 1, 0.95, 0.9, 0.85, 0.8, 0.775, 0.75, 0.725, 0.7, 0.675, 0.65, 0.625, 0.6, 0.575, 0.55, 0.525, 0.5, 0.45, 0.4, 0.35, 0.3)
control_medians <- rep(5.5, times = length(desired_HRs))

medians_control_fijo <- matrix(NA, nrow = length(desired_HRs), ncol = 2, dimnames = list(paste0("HR ", desired_HRs), c("Control", "Treatment")))

for (i in 1:length(desired_HRs)) {
  medians_control_fijo[i, "Treatment"] <- control_medians[i] / (desired_HRs[i]^(1/shape_parameter))
  medians_control_fijo[i, "Control"] <- control_medians[i]
}

sample_size <- 300  
ratio <- c(0.5,0.5)
rand_type <- "CR" 
scenarios_eff <- as.matrix(medians_control_fijo, nrow = dim(medians_control_fijo)[1], ncol = 2, byrow = TRUE)
censor <- c(0.1,0.1)
Tmax <- 20
alpha <- 0.05 
test.type <- 2
HR_1 <- FALSE
IA <- NULL
method_IA <- "bayes"
n_exp_events <- 175
Plot_Power <- FALSE
plot_pvalues = FALSE 
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = FALSE

analysis = "bayes"
n_sim <- 2000
seed <- 24
# 1) Shape control, 2) rate control, 3) Shape experimental y 4) rate experimental
prior_gamma <- matrix(c(504.9433, 100, 0.00001, 0.00001), nrow = 2, ncol = 2, byrow = TRUE) 
prior_type <- c("Non informative prior") # Este vector es para que aparezca el nombre en las tablas
P_HR_data_Boundary <- 0.8 # P(HR < 0.8 | data)
modelo_weibull_sep <- rstan::stan_model("weibull_gamma_def.stan" ,verbose = F)
modelo = modelo_weibull_sep
modelo_bayes_test = "weibull"

# sim5 <-  sim_trials(n_sim = n_sim,  
#                     analysis = "bayes",
#                     sample_size = sample_size, 
#                     ratio = ratio,
#                     rand_type = rand_type,
#                     Tmax = Tmax, 
#                     scenarios_eff = scenarios_eff,
#                     shape_parameter = shape_parameter,
#                     censor = censor,
#                     test.type = test.type,
#                     alpha = alpha,
#                     method_IA = method_IA,
#                     IA = IA,
#                     n_exp_events = n_exp_events,
#                     HR_1 = HR_1,
#                     Plot_Power = Plot_Power,
#                     modelo = modelo,
#                     modelo_bayes_test = modelo_bayes_test,
#                     prior_type = prior_type,
#                     P_HR_data_Boundary = P_HR_data_Boundary,
#                     prior_gamma = prior_gamma,
#                     Plot_Power_scenarios = Plot_Power_scenarios,
#                     desired_HRs = desired_HRs,
#                     plot_pvalues = plot_pvalues,
#                     Plot_Control_Scenarios = Plot_Control_Scenarios,
#                     seed = seed)
# 
# wd <- createWorkbook()
# addWorksheet(wd, "Sheet1")
# writeData(wd, "Sheet1", sim5)
# saveWorkbook(wd, "informative_gamma35_300_2000_HR_changing.xlsx", overwrite = TRUE)
# 


sheet_names <- c("Sheet1")
informative_gamma_3.5 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/informative_gamma35_300_2000_HR_changing.xlsx", sheet = sheet_names[1])

```

Simulamos los resultados forzando a la prior informativa del control a ser de 5.5 

```{r `Bayes: Bayes infor med: 5.5 HR=0.55 Power changing HRs`, eval = T}

shape_parameter <- 1 

desired_HRs <- c(1.3, 1.2, 1.1, 1, 0.95, 0.9, 0.85, 0.8, 0.775, 0.75, 0.725, 0.7, 0.675, 0.65, 0.625, 0.6, 0.575, 0.55, 0.525, 0.5, 0.45, 0.4, 0.35, 0.3)
control_medians <- rep(5.5, times = length(desired_HRs))

medians_control_fijo <- matrix(NA, nrow = length(desired_HRs), ncol = 2, dimnames = list(paste0("HR ", desired_HRs), c("Control", "Treatment")))

for (i in 1:length(desired_HRs)) {
  medians_control_fijo[i, "Treatment"] <- control_medians[i] / (desired_HRs[i]^(1/shape_parameter))
  medians_control_fijo[i, "Control"] <- control_medians[i]
}

sample_size <- 300  
ratio <- c(0.5,0.5)
rand_type <- "CR" 
scenarios_eff <- as.matrix(medians_control_fijo, nrow = dim(medians_control_fijo)[1], ncol = 2, byrow = TRUE)
censor <- c(0.1,0.1)
Tmax <- 20
alpha <- 0.05 
test.type <- 2
HR_1 <- FALSE
IA <- NULL
method_IA <- "bayes"
n_exp_events <- 175
Plot_Power <- FALSE
plot_pvalues = FALSE 
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = FALSE

analysis = "bayes"
n_sim <- 2000
seed <- 24
# 1) Shape control, 2) rate control, 3) Shape experimental y 4) rate experimental
prior_gamma <- matrix(c(793.4823, 100, 0.00001, 0.00001), nrow = 2, ncol = 2, byrow = TRUE) 
prior_type <- c("Non informative prior") # Este vector es para que aparezca el nombre en las tablas
P_HR_data_Boundary <- 0.8 # P(HR < 0.8 | data)
modelo_weibull_sep <- rstan::stan_model("weibull_gamma_def.stan" ,verbose = F)
modelo = modelo_weibull_sep
modelo_bayes_test = "weibull"

# sim5 <-  sim_trials(n_sim = n_sim,  
#                     analysis = "bayes",
#                     sample_size = sample_size, 
#                     ratio = ratio,
#                     rand_type = rand_type,
#                     Tmax = Tmax, 
#                     scenarios_eff = scenarios_eff,
#                     shape_parameter = shape_parameter,
#                     censor = censor,
#                     test.type = test.type,
#                     alpha = alpha,
#                     method_IA = method_IA,
#                     IA = IA,
#                     n_exp_events = n_exp_events,
#                     HR_1 = HR_1,
#                     Plot_Power = Plot_Power,
#                     modelo = modelo,
#                     modelo_bayes_test = modelo_bayes_test,
#                     prior_type = prior_type,
#                     P_HR_data_Boundary = P_HR_data_Boundary,
#                     prior_gamma = prior_gamma,
#                     Plot_Power_scenarios = Plot_Power_scenarios,
#                     desired_HRs = desired_HRs,
#                     plot_pvalues = plot_pvalues,
#                     Plot_Control_Scenarios = Plot_Control_Scenarios,
#                     seed = seed)
# 
# wd <- createWorkbook()
# addWorksheet(wd, "Sheet1")
# writeData(wd, "Sheet1", sim5)
# saveWorkbook(wd, "informative_gamma55_300_2000_HR_changing.xlsx", overwrite = TRUE)
# 


sheet_names <- c("Sheet1")
informative_gamma_5.5 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/informative_gamma55_300_2000_HR_changing.xlsx", sheet = sheet_names[1])

```

Simulamos los resultados forzando a la prior informativa del control a ser de 7.5 

```{r `Bayes: Bayes infor med: 7.5 HR=0.55 Power changing HRs`, eval = T}

shape_parameter <- 1 

desired_HRs <- c(1.3, 1.2, 1.1, 1, 0.95, 0.9, 0.85, 0.8, 0.775, 0.75, 0.725, 0.7, 0.675, 0.65, 0.625, 0.6, 0.575, 0.55, 0.525, 0.5, 0.45, 0.4, 0.35, 0.3)
control_medians <- rep(5.5, times = length(desired_HRs))

medians_control_fijo <- matrix(NA, nrow = length(desired_HRs), ncol = 2, dimnames = list(paste0("HR ", desired_HRs), c("Control", "Treatment")))

for (i in 1:length(desired_HRs)) {
  medians_control_fijo[i, "Treatment"] <- control_medians[i] / (desired_HRs[i]^(1/shape_parameter))
  medians_control_fijo[i, "Control"] <- control_medians[i]
}

sample_size <- 300  
ratio <- c(0.5,0.5)
rand_type <- "CR" 
scenarios_eff <- as.matrix(medians_control_fijo, nrow = dim(medians_control_fijo)[1], ncol = 2, byrow = TRUE)
censor <- c(0.1,0.1)
Tmax <- 20
alpha <- 0.05 
test.type <- 2
HR_1 <- FALSE
IA <- NULL
method_IA <- "bayes"
n_exp_events <- 175
Plot_Power <- FALSE
plot_pvalues = FALSE 
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = FALSE

analysis = "bayes"
n_sim <- 2000
seed <- 24
# 1) Shape control, 2) rate control, 3) Shape experimental y 4) rate experimental
prior_gamma <- matrix(c(1082.021, 100, 0.00001, 0.00001), nrow = 2, ncol = 2, byrow = TRUE) 
prior_type <- c("Non informative prior") # Este vector es para que aparezca el nombre en las tablas
P_HR_data_Boundary <- 0.8 # P(HR < 0.8 | data)
modelo_weibull_sep <- rstan::stan_model("weibull_gamma_def.stan" ,verbose = F)
modelo = modelo_weibull_sep
modelo_bayes_test = "weibull"

# sim5 <-  sim_trials(n_sim = n_sim,  
#                     analysis = "bayes",
#                     sample_size = sample_size, 
#                     ratio = ratio,
#                     rand_type = rand_type,
#                     Tmax = Tmax, 
#                     scenarios_eff = scenarios_eff,
#                     shape_parameter = shape_parameter,
#                     censor = censor,
#                     test.type = test.type,
#                     alpha = alpha,
#                     method_IA = method_IA,
#                     IA = IA,
#                     n_exp_events = n_exp_events,
#                     HR_1 = HR_1,
#                     Plot_Power = Plot_Power,
#                     modelo = modelo,
#                     modelo_bayes_test = modelo_bayes_test,
#                     prior_type = prior_type,
#                     P_HR_data_Boundary = P_HR_data_Boundary,
#                     prior_gamma = prior_gamma,
#                     Plot_Power_scenarios = Plot_Power_scenarios,
#                     desired_HRs = desired_HRs,
#                     plot_pvalues = plot_pvalues,
#                     Plot_Control_Scenarios = Plot_Control_Scenarios,
#                     seed = seed)
# 
# wd <- createWorkbook()
# addWorksheet(wd, "Sheet1")
# writeData(wd, "Sheet1", sim5)
# saveWorkbook(wd, "informative_gamma75_300_2000_HR_changing.xlsx", overwrite = TRUE)
# 


sheet_names <- c("Sheet1")
informative_gamma_7.5 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/informative_gamma75_300_2000_HR_changing.xlsx", sheet = sheet_names[1])

```


Aquí juntamos los datos:
  
```{r `Simulation scenarios w fixed experimental & bayes w data`, eval = T, echo = T}


data_sim3_results <- sim3_results %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE))%>%
  mutate(Prior = "Frequentist")

data_informative_gamma_3.5 <- informative_gamma_3.5 %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  mutate(Prior = "Informative: Median control at 3.5")

data_informative_gamma_5.5 <- informative_gamma_5.5 %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  mutate(Prior = "Informative:  Median control at 5.5")

data_informative_gamma_7.5 <- informative_gamma_7.5 %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  mutate(Prior = "Informative:  Median control at 7.5")  


combined_data <- bind_rows(data_sim3_results,
                           data_informative_gamma_3.5, 
                           data_informative_gamma_5.5, 
                           data_informative_gamma_7.5)


combined_data <- combined_data %>%
  group_by(Prior) %>%
  mutate(desired_HRs = (desired_HRs))

# La diferencia la he considerado en valor absoluto (se podría también al cuadrado para que salgan siempre positivos)
combined_data <- combined_data %>%
  mutate(diff_HR = abs(mean_HR - desired_HRs))

```

Ahora los dibujamos juntos: 
  
```{r `Simulation scenarios w fixed experimental & bayes w plot`, eval = T, echo = T}


p4 <- ggplot(combined_data, aes(x = desired_HRs, y = prop_significant, group = Prior, color = Prior)) +
  geom_point(size = 3) +
  geom_line(linewidth = 1) +
  geom_vline(xintercept = 1, linetype = "dashed", color = "red", size = 1) +
  geom_vline(xintercept = 0.55, linetype = "dashed", color = "red", size = 1) +
  geom_vline(xintercept = 0.5, linetype = "dashed", color = "red", size = 1) +
  geom_hline(yintercept = c(0.8, 0.9), linetype = "dotted", color = c("purple", "green"), size = 1) +
  scale_x_continuous(breaks = seq(min(combined_data$desired_HRs), max(combined_data$desired_HRs), 0.1), labels = sprintf("%.2f", seq(min(combined_data$desired_HRs), max(combined_data$desired_HRs), 0.1))) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Power vs Hazard Ratio",
       x = "Theoretical Hazard Ratio",
       y = "Power") +
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 10, face = "bold"),
    axis.text = element_text(size = 12),
    axis.title.x = element_text(size = 12),
    axis.title.y = element_text(size = 12),
    legend.margin = margin(12, 12, 12, 12),
    legend.text = element_text(size = 11),
    legend.title = element_text(size = 12, face = "bold"),
        legend.position = "right")


p4 <- p4 +
  annotate("text", x = max(combined_data$desired_HRs), y = 0.8, label = "80% power", hjust = 1, vjust = -0.5, size = 3.5, color = "purple") +
  annotate("text", x = max(combined_data$desired_HRs), y = 0.9, label = "90% power", hjust = 1, vjust = -0.5, size = 3.5, color = "green") +
  geom_label(aes(x = 1, y = Inf, label = "H0"), vjust = 2, color = "black", fill = "white", size = 3.5, label.size = 0, fontface = "bold") +
  geom_label(aes(x = 0.55, y = Inf, label = "H1"), vjust = 2, color = "black", fill = "white", size = 3.5, label.size = 0, fontface = "bold") +
  geom_label(aes(x = 0.5, y = Inf, label = "Real HR"), vjust = 2, color = "black", fill = "white", size = 3.5, label.size = 0, fontface = "bold")

p4

ggplot(densities, aes(x, density, color = parameter)) +
  geom_line() +
  labs(
    title = "Gamma Prior Distributions",
    x = "Scale Parameter for the Control Arm",
    y = "Density",
    color = "Scale Prior Distributions"  
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 10, face = "bold"),
    axis.text = element_text(size = 12),
    axis.title.x = element_text(size = 12),
    axis.title.y = element_text(size = 12),
    legend.margin = margin(12, 12, 12, 12),
    legend.text = element_text(size = 11),
    legend.title = element_text(size = 12, face = "bold")
  )


p5 <- ggplot(combined_data, aes(x = desired_HRs, y = diff_HR, color = Prior)) +
  geom_point(size = 3) +
  geom_line(aes(group = Prior), linewidth = 1) +
  scale_x_continuous(breaks = seq(min(combined_data$desired_HRs), max(combined_data$desired_HRs), 0.1), labels = sprintf("%.2f", seq(min(combined_data$desired_HRs), max(combined_data$desired_HRs), 0.1))) +
  labs(title = "Diff btw Simulated HR and Theoretical HRs",
       x = "Theoretical Hazard Ratio",
       y = "Difference") +
  theme_minimal() +
  theme(plot.title = element_text(size = 10, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 8, face = "bold"),
        axis.text = element_text(size = 8),
        legend.position = "right")

p5
```


También es interesante en vez de dibujar todas las prior muy informativas con diferentes asunciones para la mediana del control (e.g., 3.5, 5.5 y 7.5) es ver cómo se comportan diferentes priors (i.e., no informativa, weak informative y strong informative) para la misma asunción del efecto de mediana 3.5, 5.5 y 7.5.

Como ya tenemos estos valores para las strong informative para cada uno de los escenarios, vamos a poner ahora los parámetros para la no informativa (son los mismos datos para todos los escenarios) y la weak.

Empezamos con la no informativa para todos los escenarios 

```{r `Bayes: Bayes Non-Infor HR=0.55 Power changing HRs`, eval = T}

shape_parameter <- 1 

desired_HRs <- c(1.3, 1.2, 1.1, 1, 0.95, 0.9, 0.85, 0.8, 0.775, 0.75, 0.725, 0.7, 0.675, 0.65, 0.625, 0.6, 0.575, 0.55, 0.525, 0.5, 0.45, 0.4, 0.35, 0.3)
control_medians <- rep(5.5, times = length(desired_HRs))

medians_control_fijo <- matrix(NA, nrow = length(desired_HRs), ncol = 2, dimnames = list(paste0("HR ", desired_HRs), c("Control", "Treatment")))

for (i in 1:length(desired_HRs)) {
  medians_control_fijo[i, "Treatment"] <- control_medians[i] / (desired_HRs[i]^(1/shape_parameter))
  medians_control_fijo[i, "Control"] <- control_medians[i]
}

sample_size <- 300  
ratio <- c(0.5,0.5)
rand_type <- "CR" 
scenarios_eff <- as.matrix(medians_control_fijo, nrow = dim(medians_control_fijo)[1], ncol = 2, byrow = TRUE)
censor <- c(0.1,0.1)
Tmax <- 20
alpha <- 0.05 
test.type <- 2
HR_1 <- FALSE
IA <- NULL
method_IA <- "bayes"
n_exp_events <- 175
Plot_Power <- FALSE
plot_pvalues = FALSE 
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = FALSE

analysis = "bayes"
n_sim <- 2000
seed <- 24
# 1) Shape control, 2) rate control, 3) Shape experimental y 4) rate experimental
prior_gamma <- matrix(c(0.00001, 0.00001, 0.00001, 0.00001), nrow = 2, ncol = 2, byrow = TRUE) 
prior_type <- c("Non informative prior") # Este vector es para que aparezca el nombre en las tablas
P_HR_data_Boundary <- 0.8 # P(HR < 0.8 | data)
modelo_weibull_sep <- rstan::stan_model("weibull_gamma_def.stan" ,verbose = F)
modelo = modelo_weibull_sep
modelo_bayes_test = "weibull"

# sim5 <-  sim_trials(n_sim = n_sim,
#                     analysis = "bayes",
#                     sample_size = sample_size,
#                     ratio = ratio,
#                     rand_type = rand_type,
#                     Tmax = Tmax,
#                     scenarios_eff = scenarios_eff,
#                     shape_parameter = shape_parameter,
#                     censor = censor,
#                     test.type = test.type,
#                     alpha = alpha,
#                     method_IA = method_IA,
#                     IA = IA,
#                     n_exp_events = n_exp_events,
#                     HR_1 = HR_1,
#                     Plot_Power = Plot_Power,
#                     modelo = modelo,
#                     modelo_bayes_test = modelo_bayes_test,
#                     prior_type = prior_type,
#                     P_HR_data_Boundary = P_HR_data_Boundary,
#                     prior_gamma = prior_gamma,
#                     Plot_Power_scenarios = Plot_Power_scenarios,
#                     desired_HRs = desired_HRs,
#                     plot_pvalues = plot_pvalues,
#                     Plot_Control_Scenarios = Plot_Control_Scenarios,
#                     seed = seed)
# 
# wd <- createWorkbook()
# addWorksheet(wd, "Sheet1")
# writeData(wd, "Sheet1", sim5)
# saveWorkbook(wd, "non_informative_gamma_300_2000_HR_changing.xlsx", overwrite = TRUE)

sheet_names <- c("Sheet1")
non_informative_gamma <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/non_informative_gamma_300_2000_HR_changing.xlsx", sheet = sheet_names[1])

```

Ahora dibujamos las densidades para las weak prior que estarán centradas en los valores de 3.5, 5.5 y 7.5:
  
```{r `Gamma priors weak informatives`, eval = T}

# Vamos a presentarlo en términos de medianas en vez de escala Weibull (aunque luego sea esto lo que se meta como input en el model STAN)

# En términos del parámetro escala
# parameters <- medians / (log(2)^(1/shape_parameter))
# En términos de mediana
# medians <- parameters * (log(2))^(1/shape_parameter)

# parameters_gamma <- data.frame(shape = c(3.50, 5.50, 7.50),
#                          rate = c( 1, 1, 1),
#                          label = c("Informative: Gamma(5.049433, 1)", "Informative: Gamma(7.934823, 1)", "Informative: Gamma(10.82021, 1)"))

parameters_gamma <- data.frame(shape = c(5.049433, 7.934823, 10.82021),
                               rate = c( 1, 1, 1),
                               label = c("Informative: Gamma(5.049433, 1)", "Informative: Gamma(7.934823, 1)", "Informative: Gamma(10.82021, 1)"))


gamma_density <- function(shape, rate, label) {
  data.frame(x = seq(0, 20, length.out = 100)) %>%
    mutate(density = dgamma(x, shape = shape, rate = rate),
           parameter = label)
}

densities <- purrr::pmap_df(parameters_gamma, gamma_density)

ggplot(densities, aes(x, density, color = parameter)) +
  geom_line(size = 1.2) + 
  geom_line() +
  labs(
    title = "Gamma Prior Distributions",
    x = "Scale Parameter for the Control Arm",
    y = "Density",
    color = "Scale Prior Distributions"  
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 10, face = "bold"),
    axis.text = element_text(size = 12),
    axis.title.x = element_text(size = 12),
    axis.title.y = element_text(size = 12),
    legend.margin = margin(12, 12, 12, 12),
    legend.text = element_text(size = 11),
    legend.title = element_text(size = 12, face = "bold")
  )


```

Parámetros weak para mediana del 3.5

```{r `Bayes: Bayes weak infor med: 3.5 HR=0.55 Power changing HRs`, eval = T}

shape_parameter <- 1 

desired_HRs <- c(1.3, 1.2, 1.1, 1, 0.95, 0.9, 0.85, 0.8, 0.775, 0.75, 0.725, 0.7, 0.675, 0.65, 0.625, 0.6, 0.575, 0.55, 0.525, 0.5, 0.45, 0.4, 0.35, 0.3)
control_medians <- rep(5.5, times = length(desired_HRs))

medians_control_fijo <- matrix(NA, nrow = length(desired_HRs), ncol = 2, dimnames = list(paste0("HR ", desired_HRs), c("Control", "Treatment")))

for (i in 1:length(desired_HRs)) {
  medians_control_fijo[i, "Treatment"] <- control_medians[i] / (desired_HRs[i]^(1/shape_parameter))
  medians_control_fijo[i, "Control"] <- control_medians[i]
}

sample_size <- 300  
ratio <- c(0.5,0.5)
rand_type <- "CR" 
scenarios_eff <- as.matrix(medians_control_fijo, nrow = dim(medians_control_fijo)[1], ncol = 2, byrow = TRUE)
censor <- c(0.1,0.1)
Tmax <- 20
alpha <- 0.05 
test.type <- 2
HR_1 <- FALSE
IA <- NULL
method_IA <- "bayes"
n_exp_events <- 175
Plot_Power <- FALSE
plot_pvalues = FALSE 
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = FALSE

analysis = "bayes"
n_sim <- 2000
seed <- 24
# 1) Shape control, 2) rate control, 3) Shape experimental y 4) rate experimental
prior_gamma <- matrix(c(5.049433, 1, 0.00001, 0.00001), nrow = 2, ncol = 2, byrow = TRUE) 
prior_type <- c("Non informative prior") # Este vector es para que aparezca el nombre en las tablas
P_HR_data_Boundary <- 0.8 # P(HR < 0.8 | data)
modelo_weibull_sep <- rstan::stan_model("weibull_gamma_def.stan" ,verbose = F)
modelo = modelo_weibull_sep
modelo_bayes_test = "weibull"

# sim5 <-  sim_trials(n_sim = n_sim,
#                     analysis = "bayes",
#                     sample_size = sample_size,
#                     ratio = ratio,
#                     rand_type = rand_type,
#                     Tmax = Tmax,
#                     scenarios_eff = scenarios_eff,
#                     shape_parameter = shape_parameter,
#                     censor = censor,
#                     test.type = test.type,
#                     alpha = alpha,
#                     method_IA = method_IA,
#                     IA = IA,
#                     n_exp_events = n_exp_events,
#                     HR_1 = HR_1,
#                     Plot_Power = Plot_Power,
#                     modelo = modelo,
#                     modelo_bayes_test = modelo_bayes_test,
#                     prior_type = prior_type,
#                     P_HR_data_Boundary = P_HR_data_Boundary,
#                     prior_gamma = prior_gamma,
#                     Plot_Power_scenarios = Plot_Power_scenarios,
#                     desired_HRs = desired_HRs,
#                     plot_pvalues = plot_pvalues,
#                     Plot_Control_Scenarios = Plot_Control_Scenarios,
#                     seed = seed)
# 
# wd <- createWorkbook()
# addWorksheet(wd, "Sheet1")
# writeData(wd, "Sheet1", sim5)
# saveWorkbook(wd, "weak_informative_gamma_3.5_300_2000_HR_changing.xlsx", overwrite = TRUE)

sheet_names <- c("Sheet1")
weak_informative_gamma_3.5 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/weak_informative_gamma_3.5_300_2000_HR_changing.xlsx", sheet = sheet_names[1])

```

Parámetros weak informative de 5.5

```{r `Bayes: Bayes weak infor med: 5.5 HR=0.55 Power changing HRs`, eval = T}

shape_parameter <- 1 

desired_HRs <- c(1.3, 1.2, 1.1, 1, 0.95, 0.9, 0.85, 0.8, 0.775, 0.75, 0.725, 0.7, 0.675, 0.65, 0.625, 0.6, 0.575, 0.55, 0.525, 0.5, 0.45, 0.4, 0.35, 0.3)
control_medians <- rep(5.5, times = length(desired_HRs))

medians_control_fijo <- matrix(NA, nrow = length(desired_HRs), ncol = 2, dimnames = list(paste0("HR ", desired_HRs), c("Control", "Treatment")))

for (i in 1:length(desired_HRs)) {
  medians_control_fijo[i, "Treatment"] <- control_medians[i] / (desired_HRs[i]^(1/shape_parameter))
  medians_control_fijo[i, "Control"] <- control_medians[i]
}

sample_size <- 300  
ratio <- c(0.5,0.5)
rand_type <- "CR" 
scenarios_eff <- as.matrix(medians_control_fijo, nrow = dim(medians_control_fijo)[1], ncol = 2, byrow = TRUE)
censor <- c(0.1,0.1)
Tmax <- 20
alpha <- 0.05 
test.type <- 2
HR_1 <- FALSE
IA <- NULL
method_IA <- "bayes"
n_exp_events <- 175
Plot_Power <- FALSE
plot_pvalues = FALSE 
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = FALSE

analysis = "bayes"
n_sim <- 2000
seed <- 24
# 1) Shape control, 2) rate control, 3) Shape experimental y 4) rate experimental
prior_gamma <- matrix(c(7.934823, 1, 0.00001, 0.00001), nrow = 2, ncol = 2, byrow = TRUE) 
prior_type <- c("Non informative prior") # Este vector es para que aparezca el nombre en las tablas
P_HR_data_Boundary <- 0.8 # P(HR < 0.8 | data)
modelo_weibull_sep <- rstan::stan_model("weibull_gamma_def.stan" ,verbose = F)
modelo = modelo_weibull_sep
modelo_bayes_test = "weibull"

# sim5 <-  sim_trials(n_sim = n_sim,
#                     analysis = "bayes",
#                     sample_size = sample_size,
#                     ratio = ratio,
#                     rand_type = rand_type,
#                     Tmax = Tmax,
#                     scenarios_eff = scenarios_eff,
#                     shape_parameter = shape_parameter,
#                     censor = censor,
#                     test.type = test.type,
#                     alpha = alpha,
#                     method_IA = method_IA,
#                     IA = IA,
#                     n_exp_events = n_exp_events,
#                     HR_1 = HR_1,
#                     Plot_Power = Plot_Power,
#                     modelo = modelo,
#                     modelo_bayes_test = modelo_bayes_test,
#                     prior_type = prior_type,
#                     P_HR_data_Boundary = P_HR_data_Boundary,
#                     prior_gamma = prior_gamma,
#                     Plot_Power_scenarios = Plot_Power_scenarios,
#                     desired_HRs = desired_HRs,
#                     plot_pvalues = plot_pvalues,
#                     Plot_Control_Scenarios = Plot_Control_Scenarios,
#                     seed = seed)
# 
# wd <- createWorkbook()
# addWorksheet(wd, "Sheet1")
# writeData(wd, "Sheet1", sim5)
# saveWorkbook(wd, "weak_informative_gamma_5.5_300_2000_HR_changing.xlsx", overwrite = TRUE)

sheet_names <- c("Sheet1")
weak_informative_gamma_5.5 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/weak_informative_gamma_5.5_300_2000_HR_changing.xlsx", sheet = sheet_names[1])

```

Parámetros weak informative de 7.5

```{r `Bayes: Bayes weak infor med: 7.5 HR=0.55 Power changing HRs`, eval = T}

shape_parameter <- 1 

desired_HRs <- c(1.3, 1.2, 1.1, 1, 0.95, 0.9, 0.85, 0.8, 0.775, 0.75, 0.725, 0.7, 0.675, 0.65, 0.625, 0.6, 0.575, 0.55, 0.525, 0.5, 0.45, 0.4, 0.35, 0.3)
control_medians <- rep(5.5, times = length(desired_HRs))

medians_control_fijo <- matrix(NA, nrow = length(desired_HRs), ncol = 2, dimnames = list(paste0("HR ", desired_HRs), c("Control", "Treatment")))

for (i in 1:length(desired_HRs)) {
  medians_control_fijo[i, "Treatment"] <- control_medians[i] / (desired_HRs[i]^(1/shape_parameter))
  medians_control_fijo[i, "Control"] <- control_medians[i]
}

sample_size <- 300  
ratio <- c(0.5,0.5)
rand_type <- "CR" 
scenarios_eff <- as.matrix(medians_control_fijo, nrow = dim(medians_control_fijo)[1], ncol = 2, byrow = TRUE)
censor <- c(0.1,0.1)
Tmax <- 20
alpha <- 0.05 
test.type <- 2
HR_1 <- FALSE
IA <- NULL
method_IA <- "bayes"
n_exp_events <- 175
Plot_Power <- FALSE
plot_pvalues = FALSE 
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = FALSE

analysis = "bayes"
n_sim <- 2000
seed <- 24
# 1) Shape control, 2) rate control, 3) Shape experimental y 4) rate experimental
prior_gamma <- matrix(c(10.82021, 1, 0.00001, 0.00001), nrow = 2, ncol = 2, byrow = TRUE) 
prior_type <- c("Non informative prior") # Este vector es para que aparezca el nombre en las tablas
P_HR_data_Boundary <- 0.8 # P(HR < 0.8 | data)
modelo_weibull_sep <- rstan::stan_model("weibull_gamma_def.stan" ,verbose = F)
modelo = modelo_weibull_sep
modelo_bayes_test = "weibull"

# sim5 <-  sim_trials(n_sim = n_sim,
#                     analysis = "bayes",
#                     sample_size = sample_size,
#                     ratio = ratio,
#                     rand_type = rand_type,
#                     Tmax = Tmax,
#                     scenarios_eff = scenarios_eff,
#                     shape_parameter = shape_parameter,
#                     censor = censor,
#                     test.type = test.type,
#                     alpha = alpha,
#                     method_IA = method_IA,
#                     IA = IA,
#                     n_exp_events = n_exp_events,
#                     HR_1 = HR_1,
#                     Plot_Power = Plot_Power,
#                     modelo = modelo,
#                     modelo_bayes_test = modelo_bayes_test,
#                     prior_type = prior_type,
#                     P_HR_data_Boundary = P_HR_data_Boundary,
#                     prior_gamma = prior_gamma,
#                     Plot_Power_scenarios = Plot_Power_scenarios,
#                     desired_HRs = desired_HRs,
#                     plot_pvalues = plot_pvalues,
#                     Plot_Control_Scenarios = Plot_Control_Scenarios,
#                     seed = seed)
# 
# wd <- createWorkbook()
# addWorksheet(wd, "Sheet1")
# writeData(wd, "Sheet1", sim5)
# saveWorkbook(wd, "weak_informative_gamma_7.5_300_2000_HR_changing.xlsx", overwrite = TRUE)

sheet_names <- c("Sheet1")
weak_informative_gamma_7.5 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/weak_informative_gamma_7.5_300_2000_HR_changing.xlsx", sheet = sheet_names[1])

```

Ahora juntamos los datos para dibujar cada uno de los escenarios.

```{r `Simulation scenarios w fixed experimental & bayes w data 2`, eval = T, echo = T}


data_sim3_results <- sim3_results %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE))%>%
  mutate(Prior = "Frequentist")

data_non_informative <- non_informative_gamma %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE))%>%
  mutate(Prior = "Non informative")

data_weak_informative_gamma_3.5 <- weak_informative_gamma_3.5 %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE))%>%
  mutate(Prior = "Weak Informative: Median control at 3.5")


data_informative_gamma_3.5 <- informative_gamma_3.5 %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  mutate(Prior = "Informative: Median control at 3.5")

data_weak_informative_gamma_5.5 <- weak_informative_gamma_5.5 %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE))%>%
  mutate(Prior = "Weak Informative: Median control at 5.5")

data_informative_gamma_5.5 <- informative_gamma_5.5 %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  mutate(Prior = "Informative:  Median control at 5.5")

data_weak_informative_gamma_7.5 <- weak_informative_gamma_7.5 %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE))%>%
  mutate(Prior = "Weak Informative: Median control at 7.5")      

data_informative_gamma_7.5 <- informative_gamma_7.5 %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  mutate(Prior = "Informative:  Median control at 7.5")  

# 3.5
combined_data_3.5 <- bind_rows(data_sim3_results,
                               data_non_informative, 
                               data_weak_informative_gamma_3.5, 
                               data_informative_gamma_3.5)

combined_data_3.5 <- combined_data_3.5 %>%
  group_by(Prior) %>%
  mutate(desired_HRs = (desired_HRs))

combined_data_3.5 <- combined_data_3.5 %>%
  mutate(diff_HR = abs(mean_HR - desired_HRs))

# 5.5
combined_data_5.5 <- bind_rows(data_sim3_results,
                               data_non_informative, 
                               data_weak_informative_gamma_5.5, 
                               data_informative_gamma_5.5)


combined_data_5.5 <- combined_data_5.5 %>%
  group_by(Prior) %>%
  mutate(desired_HRs = (desired_HRs))

combined_data_5.5 <- combined_data_5.5 %>%
  mutate(diff_HR = abs(mean_HR - desired_HRs))

# 7.5

combined_data_7.5 <- bind_rows(data_sim3_results,
                               data_non_informative, 
                               data_weak_informative_gamma_7.5, 
                               data_informative_gamma_7.5)

combined_data_7.5 <- combined_data_7.5 %>%
  group_by(Prior) %>%
  mutate(desired_HRs = (desired_HRs))

combined_data_7.5 <- combined_data_7.5 %>%
  mutate(diff_HR = abs(mean_HR - desired_HRs))

```

Dibujamos los de la mediana de 3.5

```{r `Simulation scenarios w fixed experimental & bayes w plot 3.5`, eval = T, echo = T}

p6 <- ggplot(combined_data_3.5, aes(x = desired_HRs, y = prop_significant, group = Prior, color = Prior)) +
  geom_point(size = 3) +
  geom_line(linewidth = 1) +
  geom_vline(xintercept = 1, linetype = "dashed", color = "red", size = 1) +
  geom_vline(xintercept = 0.55, linetype = "dashed", color = "red", size = 1) +
  #geom_vline(xintercept = 0.5, linetype = "dashed", color = "red", size = 1) +
  geom_hline(yintercept = c(0.8, 0.9), linetype = "dotted", color = c("purple", "green"), size = 1) +
  scale_x_continuous(breaks = seq(min(data$desired_HRs), max(data$desired_HRs), 0.1), labels = sprintf("%.2f", seq(min(data$desired_HRs), max(data$desired_HRs), 0.1))) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Power Varying Hazard Ratios with Prior Median Control at 3.5 Months",
       x = "Theoretical Hazard Ratios",
       y = "Power",
    color = "Scale Prior Distributions") +
  theme_minimal() +
  theme(plot.title = element_text(size = 9, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 9, face = "bold"),
    axis.text = element_text(size = 8),
    axis.title.x = element_text(size = 9),
    axis.title.y = element_text(size = 9),
    legend.margin = margin(12, 12, 12, 12),
    legend.text = element_text(size = 11),
    legend.title = element_text(size = 9, face = "bold"),
        legend.position = "right")

p6 <- p6 +
  annotate("text", x = max(data$desired_HRs), y = 0.8, label = "80% power", hjust = 1, vjust = -0.5, size = 3.5, color = "purple") +
  annotate("text", x = max(data$desired_HRs), y = 0.9, label = "90% power", hjust = 1, vjust = -0.5, size = 3.5, color = "green") +
  geom_label(aes(x = 1, y = Inf, label = "H0"), vjust = 2, color = "black", fill = "white", size = 3.5, label.size = 0, fontface = "bold") +
  geom_label(aes(x = 0.55, y = Inf, label = "H1"), vjust = 2, color = "black", fill = "white", size = 3.5, label.size = 0, fontface = "bold") 
# +
#   geom_label(aes(x = 0.5, y = Inf, label = "Real HR"), vjust = 2, color = "black", fill = "white", size = 3.5, label.size = 0, fontface = "bold")

p6



# Graficamos las diferencias

p7 <- ggplot(combined_data_3.5, aes(x = desired_HRs, y = diff_HR, color = Prior)) +
  geom_point(size = 3) +
  geom_line(aes(group = Prior), linewidth = 1) +
  scale_x_continuous(breaks = seq(min(combined_data_3.5$desired_HRs), max(combined_data_3.5$desired_HRs), 0.1), labels = sprintf("%.2f", seq(min(combined_data_3.5$desired_HRs), max(combined_data_3.5$desired_HRs), 0.1))) +
  labs(title = "Diff btw Simulated HR and Theoretical HRs w prior median control = 3.5",
       x = "Theoretical Hazard Ratio",
       y = "Difference") +
  theme_minimal() +
  theme(plot.title = element_text(size = 10, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 8, face = "bold"),
        axis.text = element_text(size = 8),
        legend.position = "right")

p7
```

Dibujamos los de la mediana de 5.5

```{r `Simulation scenarios w fixed experimental & bayes w plot 5.5`, eval = T, echo = T}


p8 <- ggplot(combined_data_5.5, aes(x = desired_HRs, y = prop_significant, group = Prior, color = Prior)) +
  geom_point(size = 3) +
  geom_line(linewidth = 1) +
  geom_vline(xintercept = 1, linetype = "dashed", color = "red", size = 1) +
  geom_vline(xintercept = 0.55, linetype = "dashed", color = "red", size = 1) +
  #geom_vline(xintercept = 0.5, linetype = "dashed", color = "red", size = 1) +
  geom_hline(yintercept = c(0.8, 0.9), linetype = "dotted", color = c("purple", "green"), size = 1) +
  scale_x_continuous(breaks = seq(min(data$desired_HRs), max(data$desired_HRs), 0.1), labels = sprintf("%.2f", seq(min(data$desired_HRs), max(data$desired_HRs), 0.1))) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Power Varying Hazard Ratios with Prior Median Control at  5.5 Months",
       x = "Theoretical Hazard Ratio",
       y = "Power",
    color = "Scale Prior Distributions") +
  theme_minimal() +
  theme(plot.title = element_text(size = 9, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 9, face = "bold"),
    axis.text = element_text(size = 8),
    axis.title.x = element_text(size = 9),
    axis.title.y = element_text(size = 9),
    legend.margin = margin(12, 12, 12, 12),
    legend.text = element_text(size = 11),
    legend.title = element_text(size = 9, face = "bold"),
        legend.position = "right")

p8 <- p8 +
  annotate("text", x = max(data$desired_HRs), y = 0.8, label = "80% power", hjust = 1, vjust = -0.5, size = 3.5, color = "purple") +
  annotate("text", x = max(data$desired_HRs), y = 0.9, label = "90% power", hjust = 1, vjust = -0.5, size = 3.5, color = "green") +
  geom_label(aes(x = 1, y = Inf, label = "H0"), vjust = 2, color = "black", fill = "white", size = 3.5, label.size = 0, fontface = "bold") +
  geom_label(aes(x = 0.55, y = Inf, label = "H1"), vjust = 2, color = "black", fill = "white", size = 3.5, label.size = 0, fontface = "bold") 
# +
#   geom_label(aes(x = 0.5, y = Inf, label = "Real HR"), vjust = 2, color = "black", fill = "white", size = 3.5, label.size = 0, fontface = "bold")

p8

# Graficamos las diferencias

p9 <- ggplot(combined_data_5.5, aes(x = desired_HRs, y = diff_HR, color = Prior)) +
  geom_point(size = 3) +
  geom_line(aes(group = Prior), linewidth = 1) +
  scale_x_continuous(breaks = seq(min(combined_data_5.5$desired_HRs), max(combined_data_5.5$desired_HRs), 0.1), labels = sprintf("%.2f", seq(min(combined_data_5.5$desired_HRs), max(combined_data_5.5$desired_HRs), 0.1))) +
  scale_y_continuous(limits = c(NA, 0.4)) + # Setting the y-axis max limit here
  labs(title = "Diff btw Simulated HR and Theoretical HRs w prior median control = 5.5",
       x = "Theoretical Hazard Ratio",
       y = "Difference") +
  theme_minimal() +
  theme(plot.title = element_text(size = 12, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 10),
        legend.position = "right")

p9

```

Dibujamos los de la mediana de 7.5

```{r `Simulation scenarios w fixed experimental & bayes w plot 7.5`, eval = T, echo = T}


p10 <- ggplot(combined_data_7.5, aes(x = desired_HRs, y = prop_significant, group = Prior, color = Prior)) +
  geom_point(size = 3) +
  geom_line(linewidth = 1) +
  geom_vline(xintercept = 1, linetype = "dashed", color = "red", size = 1) +
  geom_vline(xintercept = 0.55, linetype = "dashed", color = "red", size = 1) +
  #geom_vline(xintercept = 0.5, linetype = "dashed", color = "red", size = 1) +
  geom_hline(yintercept = c(0.8, 0.9), linetype = "dotted", color = c("purple", "green"), size = 1) +
  scale_x_continuous(breaks = seq(min(data$desired_HRs), max(data$desired_HRs), 0.1), labels = sprintf("%.2f", seq(min(data$desired_HRs), max(data$desired_HRs), 0.1))) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Power Varying Hazard Ratios with Prior Median Control at 7.5 Months",
       x = "Theoretical Hazard Ratio",
       y = "Power",
    color = "Scale Prior Distributions") +
  theme_minimal() +
  theme(plot.title = element_text(size = 9, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 9, face = "bold"),
    axis.text = element_text(size = 8),
    axis.title.x = element_text(size = 9),
    axis.title.y = element_text(size = 9),
    legend.margin = margin(12, 12, 12, 12),
    legend.text = element_text(size = 11),
    legend.title = element_text(size = 9, face = "bold"),
        legend.position = "right")

p10 <- p10 +
  annotate("text", x = max(data$desired_HRs), y = 0.8, label = "80% power", hjust = 1, vjust = -0.5, size = 3.5, color = "purple") +
  annotate("text", x = max(data$desired_HRs), y = 0.9, label = "90% power", hjust = 1, vjust = -0.5, size = 3.5, color = "green") +
  geom_label(aes(x = 1, y = Inf, label = "H0"), vjust = 2, color = "black", fill = "white", size = 3.5, label.size = 0, fontface = "bold") +
  geom_label(aes(x = 0.55, y = Inf, label = "H1"), vjust = 2, color = "black", fill = "white", size = 3.5, label.size = 0, fontface = "bold") 
# +
#   geom_label(aes(x = 0.5, y = Inf, label = "Real HR"), vjust = 2, color = "black", fill = "white", size = 3.5, label.size = 0, fontface = "bold")
# 
# p10

# Graficamos las diferencias

p11 <- ggplot(combined_data_7.5, aes(x = desired_HRs, y = diff_HR, color = Prior)) +
  geom_point(size = 3) +
  geom_line(aes(group = Prior), linewidth = 1) +
  scale_x_continuous(breaks = seq(min(combined_data_7.5$desired_HRs), max(combined_data_7.5$desired_HRs), 0.1), labels = sprintf("%.2f", seq(min(combined_data_7.5$desired_HRs), max(combined_data_7.5$desired_HRs), 0.1))) +
  labs(title = "Diff btw Simulated HR and Theoretical HRs w prior median control = 7.5",
       x = "Theoretical Hazard Ratio",
       y = "Difference") +
  theme_minimal() +
  theme(plot.title = element_text(size = 12, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 10),
        legend.position = "right")

p11
```


```{r Changing_HRs_combined_all, eval = T}

library(cowplot)

p66 <- p6 + scale_color_discrete(
  name = "Bayesian Prior Distributions:", 
  labels = c(
    "Frequentist",
    "Informative Prior",
    "Non-informative Prior",
    "Weak Informative Prior"
  )
) +
  guides(color = guide_legend(ncol = 4))  

legend <- get_legend(
  p66 +
    theme(
      # legend.box = "horizontal", 
      legend.justification = c(0, 1),
      # legend.margin = margin(8, 8, 8, 8),
      legend.text = element_text(size = 10), 
      legend.title = element_text(size = 11, face = "bold")
    )
)

# Remove individual legends from the plots
p66 <- p66 + theme(legend.position = "none")
p88 <- p8 + theme(legend.position = "none")
p100 <- p10 + theme(legend.position = "none")

p66 <- p66 + theme(plot.background = element_rect(colour = "black", size = 0.5, fill = NA))
p88 <- p88 + theme(plot.background = element_rect(colour = "black", size = 0.5, fill = NA))
p100 <- p100 + theme(plot.background = element_rect(colour = "black", size = 0.5, fill = NA))

plots_row <- plot_grid(p66, p88, p100, ncol = 3, labels = c("A", "B", "C"), label_size = 13)

combined_plot <- plot_grid(
  plots_row,
  legend,
  ncol = 1,                 
  rel_heights = c(3, 0.4)   
)

print(combined_plot)


```



Ahora hacemos lo mismo para asumiendo un HR = 0.7. Aquí las curvas van a ser más pronunciadas porque no está todo tan a favor como para que salgan significativos.

```{r `Bayes: Non informative prior distribution HR=0.7`, eval = F}

shape_parameter <- 1 

control_medians <- c(3.5,3.75,4,4.25,4.5,4.75,5,5.25,5.5,5.75,6,6.25,6.5,6.75,7,7.25,7.5)

medians <- matrix(NA, nrow = length(control_medians), ncol = 3, 
                  dimnames = list(NULL, c("Control", "Treatment", "Hazard Ratio")))

desired_HR = 0.7

for (i in 1:length(control_medians)) {
  medians[i, "Control"] <- control_medians[i]
  
  lambda_control = control_medians[i] / (log(2)^(1/shape_parameter))
  lambda_treatment = lambda_control / desired_HR^(1/shape_parameter)
  
  medians[i, "Treatment"] = lambda_treatment * (log(2)^(1/shape_parameter))
  medians[i, "Hazard Ratio"] = (lambda_control / lambda_treatment)^shape_parameter
}

medians <- medians[,1:2]
sample_size <- 300  
ratio <- c(0.5,0.5)
rand_type <- "CR" 
scenarios_eff <- as.matrix(medians, nrow = length(control_medians), ncol = 2, byrow = TRUE)
censor <- c(0.1,0.1)
Tmax <- 20
alpha <- 0.05 
test.type <- 2
HR_1 <- TRUE
IA <- NULL
method_IA <- "bayes"
n_exp_events <- 175
Plot_Power <- FALSE
plot_pvalues = FALSE 
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = TRUE

analysis = "bayes"
n_sim <- 2000
seed <- 24
# 1) Shape control, 2) rate control, 3) Shape experimental y 4) rate experimental
prior_gamma <- matrix(c(0.00001, 0.00001, 0.00001, 0.00001), nrow = 2, ncol = 2, byrow = TRUE) 
prior_type <- c("Non informative prior") # Este vector es para que aparezca el nombre en las tablas
P_HR_data_Boundary <- 0.8 # P(HR < 0.8 | data)
modelo_weibull_sep <- rstan::stan_model("weibull_gamma_def.stan" ,verbose = F)
modelo = modelo_weibull_sep
modelo_bayes_test = "weibull"

# sim5 <-  sim_trials(n_sim = n_sim,  
#                     analysis = "bayes",
#                     sample_size = sample_size, 
#                     ratio = ratio,
#                     rand_type = rand_type,
#                     Tmax = Tmax, 
#                     scenarios_eff = scenarios_eff,
#                     shape_parameter = shape_parameter,
#                     censor = censor,
#                     test.type = test.type,
#                     alpha = alpha,
#                     method_IA = method_IA,
#                     IA = IA,
#                     n_exp_events = n_exp_events,
#                     HR_1 = HR_1,
#                     Plot_Power = Plot_Power,
#                     modelo = modelo,
#                     modelo_bayes_test = modelo_bayes_test,
#                     prior_type = prior_type,
#                     P_HR_data_Boundary = P_HR_data_Boundary,
#                     prior_gamma = prior_gamma,
#                     Plot_Power_scenarios = Plot_Power_scenarios,
#                     desired_HRs = desired_HRs,
#                     plot_pvalues = plot_pvalues,
#                     Plot_Control_Scenarios = Plot_Control_Scenarios,
#                     seed = seed)
# sim5[[2]]
# sim5[[3]]
# sim5[[4]]
# 
# sim55 <- sim5[[1]]
# 
# wd <- createWorkbook()
# addWorksheet(wd, "Sheet1")
# writeData(wd, "Sheet1", sim55)
# saveWorkbook(wd, "non_informative_gamma_300_2000_HR_07.xlsx", overwrite = TRUE)
# 


sheet_names <- c("Sheet1")
non_informative_gamma <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/non_informative_gamma_300_2000_HR_07.xlsx", sheet = sheet_names[1])


```

El Bayesiano con una prior muy poco informativa (débil):
  
```{r `Bayes: Weak informative prior distribution HR=0.7`, eval = F}

sample_size <- 300  
ratio <- c(0.5,0.5)
rand_type <- "CR" 
scenarios_eff <- as.matrix(medians, nrow = length(control_medians), ncol = 2, byrow = TRUE)
censor <- c(0.1,0.1)
Tmax <- 20
alpha <- 0.05 
test.type <- 2
HR_1 <- TRUE
IA <- NULL
method_IA <- "bayes"
n_exp_events <- 175
Plot_Power <- FALSE
plot_pvalues = FALSE 
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = TRUE

analysis = "bayes"
n_sim <- 2000
seed <- 24
# 1) Shape control, 2) rate control, 3) Shape experimental y 4) rate experimental
prior_gamma <- matrix(c(7.213475, 1, 0.00001, 0.00001), nrow = 2, ncol = 2, byrow = TRUE) 
prior_type <- c("Weak informative prior") # Este vector es para que aparezca el nombre en las tablas
P_HR_data_Boundary <- 0.8 # P(HR < 0.8 | data)
modelo_weibull_sep <- rstan::stan_model("weibull_gamma_def.stan" ,verbose = F)
modelo = modelo_weibull_sep
modelo_bayes_test = "weibull"

# sim6 <-  sim_trials(n_sim = n_sim,  
#                     analysis = "bayes",
#                     sample_size = sample_size, 
#                     ratio = ratio,
#                     rand_type = rand_type,
#                     Tmax = Tmax, 
#                     scenarios_eff = scenarios_eff,
#                     shape_parameter = shape_parameter,
#                     censor = censor,
#                     test.type = test.type,
#                     alpha = alpha,
#                     method_IA = method_IA,
#                     IA = IA,
#                     n_exp_events = n_exp_events,
#                     HR_1 = HR_1,
#                     Plot_Power = Plot_Power,
#                     modelo = modelo,
#                     modelo_bayes_test = modelo_bayes_test,
#                     prior_type = prior_type,
#                     P_HR_data_Boundary = P_HR_data_Boundary,
#                     prior_gamma = prior_gamma,
#                     Plot_Power_scenarios = Plot_Power_scenarios,
#                     desired_HRs = desired_HRs,
#                     plot_pvalues = plot_pvalues,
#                     Plot_Control_Scenarios = Plot_Control_Scenarios,
#                     seed = seed)
# sim6[[2]]
# sim6[[3]]
# sim6[[4]]
# 
# sim66 <- sim6[[1]]
# 
# wd <- createWorkbook()
# addWorksheet(wd, "Sheet1")
# writeData(wd, "Sheet1", sim66)
# saveWorkbook(wd, "weak_informative_gamma_300_2000_HR_07.xlsx", overwrite = TRUE)


sheet_names <- c("Sheet1")
weak_informative_gamma <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/weak_informative_gamma_300_2000_HR_07.xlsx", sheet = sheet_names[1])


```

Y el Bayesiano con prior muy informativa:
  
```{r `Bayes: Strong informative prior distribution HR=0.7`, eval = F}

sample_size <- 300  
ratio <- c(0.5,0.5)
rand_type <- "CR" 
scenarios_eff <- as.matrix(medians, nrow = length(control_medians), ncol = 2, byrow = TRUE)
censor <- c(0.1,0.1)
Tmax <- 20
alpha <- 0.05 
test.type <- 2
HR_1 <- TRUE
IA <- NULL
method_IA <- "bayes"
n_exp_events <- 175
Plot_Power <- FALSE
plot_pvalues = FALSE 
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = TRUE

analysis = "bayes"
n_sim <- 2000
seed <- 24
# 1) Shape control, 2) rate control, 3) Shape experimental y 4) rate experimental
prior_gamma <- matrix(c(793.4823, 100, 0.00001, 0.00001), nrow = 2, ncol = 2, byrow = TRUE) 
prior_type <- c("Strong informative prior") # Este vector es para que aparezca el nombre en las tablas
P_HR_data_Boundary <- 0.8 # P(HR < 0.8 | data)
modelo_weibull_sep <- rstan::stan_model("weibull_gamma_def.stan" ,verbose = F)
modelo = modelo_weibull_sep
modelo_bayes_test = "weibull"

# sim7 <-  sim_trials(n_sim = n_sim,  
#                     analysis = "bayes",
#                     sample_size = sample_size, 
#                     ratio = ratio,
#                     rand_type = rand_type,
#                     Tmax = Tmax, 
#                     scenarios_eff = scenarios_eff,
#                     shape_parameter = shape_parameter,
#                     censor = censor,
#                     test.type = test.type,
#                     alpha = alpha,
#                     method_IA = method_IA,
#                     IA = IA,
#                     n_exp_events = n_exp_events,
#                     HR_1 = HR_1,
#                     Plot_Power = Plot_Power,
#                     modelo = modelo,
#                     modelo_bayes_test = modelo_bayes_test,
#                     prior_type = prior_type,
#                     P_HR_data_Boundary = P_HR_data_Boundary,
#                     prior_gamma = prior_gamma,
#                     Plot_Power_scenarios = Plot_Power_scenarios,
#                     desired_HRs = desired_HRs,
#                     plot_pvalues = plot_pvalues,
#                     Plot_Control_Scenarios = Plot_Control_Scenarios,
#                     seed = seed)
# sim7[[2]]
# sim7[[3]]
# sim7[[4]]
# 
# sim77 <- sim7[[1]]
# 
# wd <- createWorkbook()
# addWorksheet(wd, "Sheet1")
# writeData(wd, "Sheet1", sim77)
# saveWorkbook(wd, "strong_informative_gamma_300_2000_HR_07.xlsx", overwrite = TRUE)


sheet_names <- c("Sheet1")
strong_informative_gamma <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/strong_informative_gamma_300_2000_HR_07.xlsx", sheet = sheet_names[1])

```

Por último, leemos los datos del frecuentista para HR=0.7:
  
```{r `Bayes: freq HR=0.7`, eval = F}

sample_size <- 300  
ratio <- c(0.5,0.5)
rand_type <- "CR" 
scenarios_eff <- as.matrix(medians, nrow = length(control_medians), ncol = 2, byrow = TRUE)
censor <- c(0.1,0.1)
Tmax <- 20
alpha <- 0.05 
test.type <- 2
HR_1 <- TRUE
IA <- NULL
method_IA <- "freq"
n_exp_events <- 175
Plot_Power <- FALSE
plot_pvalues = FALSE 
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = TRUE

analysis = "freq"
n_sim <- 2000
seed <- 24


# sim8 <-  sim_trials(n_sim = n_sim,  
#                     analysis = "freq",
#                     sample_size = sample_size, 
#                     ratio = ratio,
#                     rand_type = rand_type,
#                     Tmax = Tmax, 
#                     scenarios_eff = scenarios_eff,
#                     shape_parameter = shape_parameter,
#                     censor = censor,
#                     test.type = test.type,
#                     alpha = alpha,
#                     method_IA = method_IA,
#                     IA = IA,
#                     n_exp_events = n_exp_events,
#                     HR_1 = HR_1,
#                     Plot_Power = Plot_Power,
#                     modelo = modelo,
#                     modelo_bayes_test = modelo_bayes_test,
#                     prior_type = prior_type,
#                     P_HR_data_Boundary = P_HR_data_Boundary,
#                     prior_gamma = prior_gamma,
#                     Plot_Power_scenarios = Plot_Power_scenarios,
#                     desired_HRs = desired_HRs,
#                     plot_pvalues = plot_pvalues,
#                     Plot_Control_Scenarios = Plot_Control_Scenarios,
#                     seed = seed)
# sim8[[2]]
# sim8[[3]]
# sim8[[4]]
# 
# sim88 <- sim8[[1]]
# 
# wd <- createWorkbook()
# addWorksheet(wd, "Sheet1")
# writeData(wd, "Sheet1", sim8)
# saveWorkbook(wd, "freq_300_2000_HR_07.xlsx", overwrite = TRUE)


sheet_names <- c("Sheet1")
frequentist <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/freq_300_2000_HR_07.xlsx", sheet = sheet_names[1])


```

Una vez que hemos recogido los resultados de la simulación vamos a comparar en los mismos gráficos el rendimiento de cada uno de los modelos. También se incorpora el frecuentista para tenerlo como referencia.

A continuación recogemos los datos para poder dibujarlos

```{r `Data gathering HR=0.7`, eval = F}

if(HR_1 == TRUE){hr_1 <- replicate(n = ncol(scenarios_eff), scenarios_eff[, 1])
scenarios_eff <- rbind(scenarios_eff, hr_1)}

scenarios_eff_df <- as.data.frame(scenarios_eff)
colnames(scenarios_eff_df) <- c("median_control", "median_treatment")

scenarios_eff_df$scenario <- seq_len(nrow(scenarios_eff_df))

# Frequentist
data_frequentist <- frequentist %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "Frequentist")

data_filtered_diff_not_zero_frequentist <- data_frequentist %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_frequentist <- data_frequentist %>%
  filter(median_control == median_treatment)

# Non-informative
data_non_informative <- non_informative_gamma %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "Non-informative: Gamma(0.00001, 0.00001)")

data_filtered_diff_not_zero_non_informative <- data_non_informative %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_non_informative <- data_non_informative %>%
  filter(median_control == median_treatment)

# Very informative
data_informative <- strong_informative_gamma %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "Informative Prior: Gamma(760.6836, 100)")

data_filtered_diff_not_zero_informative <- data_informative %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_informative <- data_informative %>%
  filter(median_control == median_treatment)

# Mid informative
data_mid_informative <- weak_informative_gamma %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "Weak Informative Prior: Gamma(7.213475, 1)")

data_filtered_diff_not_zero_mid_informative <- data_mid_informative %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_mid_informative <- data_mid_informative %>%
  filter(median_control == median_treatment)

median_control_center <- median(data_filtered_diff_not_zero_informative$median_control)
median_control_center_zero_diff <- median(data_filtered_diff_zero_informative$median_control)

combined_data_diff_not_zero <- bind_rows(data_filtered_diff_not_zero_frequentist,
                                         data_filtered_diff_not_zero_non_informative, 
                                         data_filtered_diff_not_zero_informative, 
                                         data_filtered_diff_not_zero_mid_informative)

combined_data_diff_zero <- bind_rows(data_filtered_diff_zero_frequentist,
                                     data_filtered_diff_zero_non_informative, 
                                     data_filtered_diff_zero_informative, 
                                     data_filtered_diff_zero_mid_informative)

```


```{r `MSE HR=0.7`, eval = F}

p6 <- ggplot(combined_data_diff_not_zero, aes(x = median_control, y = mean_MSE, color = Prior, linetype = Prior)) +
  geom_line() +
  geom_vline(xintercept = median_control_center, linetype = "dashed") +
  labs(title = "MSE", x = "Median Control", y = "Prop. Significant") +
  theme_minimal() +
  theme_minimal() +
  scale_color_discrete(name = "Priors") +
  scale_linetype_discrete(name = "Priors") +
  scale_x_continuous(breaks = seq(min(combined_data_diff_not_zero$median_control), max(combined_data_diff_not_zero$median_control), by = 0.5)) +
  scale_y_continuous(limits = c(0, 0.13))
p6

```

Con respecto al poder...

```{r `Power HR=0.7`, eval = F}

p7 <- ggplot(combined_data_diff_not_zero, aes(x = median_control, y = prop_significant, color = Prior)) +
  geom_line() +
  geom_vline(xintercept = median_control_center, linetype = "dashed") +
  labs(title = "Power", x = "Median Control", y = "Prop. Significant") +
  theme_minimal() +
  scale_color_discrete(name = "Priors") +
  scale_linetype_discrete(name = "Priors") +
  scale_x_continuous(breaks = seq(min(combined_data_diff_not_zero$median_control), max(combined_data_diff_not_zero$median_control), by = 0.5)) +
  scale_y_continuous(limits = c(0, 1))
p7

```

Por último, el error de Tipo I vemos que se controla para el bayesiano no informativo y el weak. Sin embargo, en el bayesiano informativo para valores mayores de 5.5 el error de tipo I se infla de una manera exponencial. Esto demuestra que este modelo no debería usarse a no ser que exista un consenso de que estos valores son "seguros".

```{r `T1E HR=0.7`, eval = F}

p8 <- ggplot(combined_data_diff_zero, aes(x = median_control, y = prop_significant, color = Prior)) +
  geom_line() +
  geom_vline(xintercept = median_control_center, linetype = "dashed") +
  geom_hline(yintercept = 0.025, linetype = "dashed", color = "green") +
  geom_hline(yintercept = 0.05, linetype = "dashed", color = "purple") +
  labs(title = "T1E", x = "Median Control", y = "Prop. Significant") +
  theme_minimal() +
  scale_color_discrete(name = "Priors") +
  scale_linetype_discrete(name = "Priors") +
  scale_x_continuous(breaks = seq(min(combined_data_diff_zero$median_control), max(combined_data_diff_zero$median_control), by = 0.5)) +
  scale_y_continuous(limits = c(0, 0.3))
p8

```

# Incorporación de información externa para el brazo control de otros estudios.

Como brazo control usand el best standard of care (BSC) y para ello hay diferentes posibles tratamientos:
  
1) gemcitabine + carboplatin (20 Pts)
2) gemcitabine + cisplatin (11 Pts)
3) pemetrexed + carboplatin (66 Pts)
4) pemetrexed + cisplatin (36 Pts)

He encontrado diferentes fuentes externas (todas mencionadas por la Cy a la hora de diseñar este estudio)

Aquí también he usado la digitalización de las curvas KM para obtener un dataset con datos pseudo-IPD

1) Gemcitabine plus cisplatin vs. gemcitabine plus carboplatin in stage IIIb and IV non-small cell lung cancer: a phase III randomized trial  

```{r `1GGG` , eval = T}

# Este estudio compara 2 de los brazos control del Keynote024

data_hist1 <- read.csv("IPD_KEYNOTE026_NSCLC_PFS_gemcis_gemcarbo.csv")
data_hist1$arm <- str_trim(data_hist1$arm)

gem_cis <- subset(data_hist1, arm == "GP")
gem_carbo <- subset(data_hist1, arm == "GC")

# gemcitabine + cisplatin (GP) 
# gemcitabine + carboplatin (GC) 


fit_hist1 <- coxph(Surv(time, status) ~ arm, data = data_hist1)
Estimate <- c(1/exp(confint(fit_hist1))[2], 1/summary(fit_hist1)$coefficients[2], 1/exp(confint(fit_hist1))[1])

fit_gem_cis <- survfit(Surv(time, status) ~ 1, data = gem_cis)
fit_gem_carbo <- survfit(Surv(time, status) ~ 1, data = gem_carbo)

# Regresión de Weibull para sacar los parametros de interes
weibull_gem_cis <- survreg(Surv(time, status) ~ 1, dist = "weibull", data = gem_cis)
weibull_gem_carbo <- survreg(Surv(time, status) ~ 1, dist = "weibull", data = gem_carbo)

time_seq <- seq(min(data_hist1$time), max(data_hist1$time), length.out = 100)

# P de supervivencia usando el modelo Weibull
weibull_gem_cis_surv <- 1 - pweibull(time_seq, shape = 1/weibull_gem_cis$scale, scale = exp(weibull_gem_cis$coefficients))
weibull_gem_carbo_surv <- 1 - pweibull(time_seq, shape = 1/weibull_gem_carbo$scale, scale = exp(weibull_gem_carbo$coefficients))

# Comparamos
plot(fit_gem_cis, col = "blue", main = "Kaplan-Meier Plot with Weibull Fits", xlab = "Time", ylab = "Survival Probability", lty = 1, conf.int = FALSE)
lines(fit_gem_carbo, col = "red", lty = 1, conf.int = FALSE)
lines(time_seq, weibull_gem_cis_surv, col = "green", lty = 2)
lines(time_seq, weibull_gem_carbo_surv, col = "black", lty = 2)

# Vemos que modelos se ajustan mejor
weibull_mod <- flexsurvreg(Surv(time, status) ~ arm, data = data_hist1, dist = "weibull")
exp_mod <- flexsurvreg(Surv(time, status) ~ arm, data = data_hist1, dist = "exp")
gompertz_mod <- flexsurvreg(Surv(time, status) ~ arm, data = data_hist1, dist = "gompertz")
lognormal_mod <- flexsurvreg(Surv(time, status) ~ arm, data = data_hist1, dist = "lnorm")

# Compare models
model_list <- list(Weibull = weibull_mod, Exponential = exp_mod, Gompertz = gompertz_mod, LogNormal = lognormal_mod)
#sapply(model_list, AIC)

```

2) Maintenance pemetrexed plus best supportive care versus placebo plus best supportive care for non-small-cell lung cancer: a randomised, double-blind, phase 3 study.


```{r `Maintenance pemetrexed + BSC vs placebo + BSC.`, eval = T}
# Aqui solo nos interesa uno de los brazos, Pemetrexed + BSC en non-squamous population

data_hist2 <- read.csv("IPD_KEYNOTE026_NSCLC_PFS_pem_bsc.csv")

fit_hist2 <- coxph(Surv(time, status) ~ 1, data = data_hist2)

fit_pem_bsc <- survfit(Surv(time, status) ~ 1, data = data_hist2)

# Regresión de Weibull para sacar los parametros de interes
weibull_pem_bsc <- survreg(Surv(time, status) ~ 1, dist = "weibull", data = data_hist2)

time_seq <- seq(min(data_hist2$time), max(data_hist2$time), length.out = 100)

# P de supervivencia usando el modelo Weibull
weibull_pem_bsc_surv <- 1 - pweibull(time_seq, shape = 1/weibull_pem_bsc$scale, scale = exp(weibull_pem_bsc$coefficients))

# Comparamos
plot(fit_pem_bsc, col = "blue", main = "Kaplan-Meier Plot with Weibull Fits", xlab = "Time", ylab = "Survival Probability", lty = 1, conf.int = FALSE)
lines(time_seq, weibull_pem_bsc_surv, col = "green", lty = 2)

# Vemos que modelos se ajustan mejor
weibull_mod <- flexsurvreg(Surv(time, status) ~ 1, data = data_hist2, dist = "weibull")
exp_mod <- flexsurvreg(Surv(time, status) ~ 1, data = data_hist2, dist = "exp")
gompertz_mod <- flexsurvreg(Surv(time, status) ~ 1, data = data_hist2, dist = "gompertz")
lognormal_mod <- flexsurvreg(Surv(time, status) ~ 1, data = data_hist2, dist = "lnorm")

# Comparar models
model_list <- list(Weibull = weibull_mod, Exponential = exp_mod, Gompertz = gompertz_mod, LogNormal = lognormal_mod)
#sapply(model_list, AIC)

```

3) Maintenance therapy with pemetrexed plus best supportive care versus placebo plus best supportive care after induction therapy with pemetrexed plus cisplatin for advanced non-squamous non-small-cell lung cancer (PARAMOUNT): a double-blind, phase 3, randomised controlled trial. 

```{r `Maintenance therapy with pemetrexed + BSC vs placebo + BSC (PARAMOUNT)` , eval = T}
# Aqui solo nos interesa uno de los brazos, Pemetrexed + BSC en non-squamous population
# Tambien lo que nos interesa es el Pemetrexed+BSC

data_hist3 <- read.csv("IPD_POSEIDON_NSCLC_PFS_pem_bsc.csv")

fit_hist3 <- coxph(Surv(time, status) ~ 1, data = data_hist3)

fit_pem_bsc_poseidon <- survfit(Surv(time, status) ~ 1, data = data_hist3)

# Regresión de Weibull para sacar los parametros de interes
weibull_pem_bsc_poseidon <- survreg(Surv(time, status) ~ 1, dist = "weibull", data = data_hist3)

time_seq <- seq(min(data_hist3$time), max(data_hist3$time), length.out = 100)

# P de supervivencia usando el modelo Weibull
weibull_pem_bsc_surv_poseidon <- 1 - pweibull(time_seq, shape = 1/weibull_pem_bsc_poseidon$scale, scale = exp(weibull_pem_bsc_poseidon$coefficients))

# Comparamos
plot(fit_pem_bsc_poseidon, col = "blue", main = "Kaplan-Meier Plot with Weibull Fits", xlab = "Time", ylab = "Survival Probability", lty = 1, conf.int = FALSE)
lines(time_seq, weibull_pem_bsc_surv_poseidon, col = "green", lty = 2)

# Vemos que modelos se ajustan mejor
weibull_mod <- flexsurvreg(Surv(time, status) ~ 1, data = data_hist3, dist = "weibull")
exp_mod <- flexsurvreg(Surv(time, status) ~ 1, data = data_hist3, dist = "exp")
gompertz_mod <- flexsurvreg(Surv(time, status) ~ 1, data = data_hist3, dist = "gompertz")
lognormal_mod <- flexsurvreg(Surv(time, status) ~ 1, data = data_hist3, dist = "lnorm")

# Compare models
model_list <- list(Weibull = weibull_mod, Exponential = exp_mod, Gompertz = gompertz_mod, LogNormal = lognormal_mod)
#sapply(model_list, AIC)

```

# Análisis Bayesiano incorporando información externa

El primer método que se va a considerar es el MAP donde incorpora en la Prior información top-level externa para el brazo control.

Primer paper de referencia es "Robust Meta-Analytic-Predictive Priors in Clinical Trials with
Historical Control Information". Aquí discuten el uso de una mezcla entre MAP y no informativo o weak en caso de que haya un conflicto entre los datos del control con el histórico. 

Al tener varios estudios históricos se van a hacer los siguientes modelos:
  
1) MAP -> Varios ensayos históricos
2) Conjugate MAP w weak prior info -> Varios ensayos históricos. (Pesos desde 0.05 hasta 0.5 para la parte informativa)
3) Conjugate MAP w weak prior info -> Varios ensayos históricos. (Peso como variable aleatoria) 

A continuación se va a seguir un procedimiento para la incorporación de información externa a través de la pre-especificación de una prior con parámetros sacados de un meta-análisis (MAP).

Hay muchas maneras de hacer esto pero vamos a centrarnos en la siguiente metodología:
  
1- Obtener la información externa para el brazo control: Me he centrado principalmente en coger los ensayos especificados por el promotor para justificar la asunción para el tamaño muestral del brazo control.

2- Obtener los parámetros para la dist exponencial/weibull de los ensayos históricos: Al ser datos de supervivencia (con binario no existe este problema), es necesario tener los datos paciente a paciente para poder sacar los valores de la distribución paramétrica que consideremos, ya sea exponencial/weibull. Al no ser posible, se digitalizan las curvas para poder hacer esta regresión paramétrica.

3- Una vez tengamos estos valores de la regresión paramétrica, lambda para la exponencial, y lambda y shape para la weibull, en todos los ensayos históricos, vamos a realizar el meta-análisis.

4- El meta-análisis aquí se va a considerar de dos maneras, frecuentista y Bayesiano. Para el enfoque frecuentista se va a utilizar el paquete ampliamente usado "metafor" y para el Bayesiano el "brms". Se van a comparar los dos en este informe y ya vemos si usamos uno, otro o los dos.

5- El MAP se va a hacer para la propuesta de una prior usando sólo 1 ensayo clínico y varios.

6- Una vez tengamos la media y SD del MAP, se transformarán estos valores en términos de la distribución Gamma para el modelo STAN.

# Meta-Analytic Prior

1) MAP -> Un ensayo histórico. 

Esto es básicamente a poner como prior las asunciones de este ensayo. Se va a hacer con la exponencial en vez de con la weibull porque 1) aunque estamos usando una regresión weibull, la generación de datos se hace en función de una exponencial como está especificado en el SAP y 2) Al haber 2 parámetros que varían, es muy difícil elegir un valor para la scale del control porque estamos comparando diferentes shapes y la variable shape, de momento, voy a dejarlo como no informativo.


```{r MAP_1_Historical_Data , eval = T}

# Ensayo: Gemcitabine plus cisplatin vs. gemcitabine plus carboplatin in stage IIIb and IV non-small cell lung cancer: a phase III randomized trial

data_hist1 <- read.csv("IPD_KEYNOTE026_NSCLC_PFS_gemcis_gemcarbo.csv")
data_hist1$arm <- str_trim(data_hist1$arm)

gem_cis <- subset(data_hist1, arm == "GP")
gem_carbo <- subset(data_hist1, arm == "GC") # Este es el bueno para el control

exp_gem_carbo <- survreg(Surv(time, status) ~ 1, dist = "exponential", data = gem_carbo)

scale_param_gem_carbo <- exp(exp_gem_carbo$coefficients[1])
se_scale_gem_carbo <- sqrt(vcov(exp_gem_carbo)[1])


MAP <- rma.uni(yi = scale_param_gem_carbo, sei = se_scale_gem_carbo)
#forest(MAP)

mu <- MAP$b[1]
sigma <- MAP$se

alpha <- (mu/sigma)^2
beta <- mu/sigma^2

curve(dgamma(x, shape=alpha, rate=beta), from=0, to=15, lwd=2, ylab="Density", xlab="Value", main="Gamma Density Plot")
grid()

```

Se puede ver por la densidad que la distribución es muy informativa con esta Gamma(2755.138, 451.531). Aquí no hacía falta hacer el MAP pero bueno, lo dejo así.

Cabe destacar que a diferencia de la mayoría de los meta-análisis, aquí no estoy sacando el efecto que se ha obtenido si no que estoy cogiendo los pseudos IPDs para luego hacer una regresión exponencial y entonces, así saco la escala para el brazo control para poner la prior en el análisis de la simulación.

1) MAP -> Varios ensayos históricos

A continuación se muestra el resultado del meta-análisis desde un punto de vista frecuentista utilizando los resultados globales de los estudios anteriormente descritos. 


```{r MAP_Multiple_Historical_Data , eval = T, fig.width=12, fig.height=8}

# Ensayo: Gemcitabine plus cisplatin vs. gemcitabine plus carboplatin in stage IIIb and IV non-small cell lung cancer: a phase III randomized trial

data_hist1 <- read.csv("IPD_KEYNOTE026_NSCLC_PFS_gemcis_gemcarbo.csv")
data_hist1$arm <- str_trim(data_hist1$arm)

gem_cis <- subset(data_hist1, arm == "GP")
gem_carbo <- subset(data_hist1, arm == "GC") # Este es el bueno para el control

exp_gem_carbo <- survreg(Surv(time, status) ~ 1, dist = "exponential", data = gem_carbo)

n_gem_carbo <- dim(gem_carbo)[1]
scale_param_gem_carbo <- exp(exp_gem_carbo$coefficients[1])
se_scale_gem_carbo <- sqrt(vcov(exp_gem_carbo)[1])


# 2) Maintenance pemetrexed plus best supportive care versus placebo plus best supportive care for non-small-cell lung cancer: a randomised, double-blind, phase 3 study.

data_hist2 <- read.csv("IPD_KEYNOTE026_NSCLC_PFS_pem_bsc.csv")

exp_pem_bsc <- survreg(Surv(time, status) ~ 1, dist = "exponential", data = data_hist2)

n_pem_bsc <- dim(data_hist2)[1]
scale_param_pem_bsc <- exp(exp_pem_bsc$coefficients[1])
se_scale_pem_bsc <- sqrt(vcov(exp_pem_bsc)[1])


# 3) Maintenance therapy with pemetrexed plus best supportive care versus placebo plus best supportive care after induction therapy with pemetrexed plus cisplatin for advanced non-squamous non-small-cell lung cancer (PARAMOUNT): a double-blind, phase 3, randomised controlled trial. 

data_hist3 <- read.csv("IPD_POSEIDON_NSCLC_PFS_pem_bsc.csv")

exp_pem_bsc_poseidon <- survreg(Surv(time, status) ~ 1, dist = "exponential", data = data_hist3)

n_pem_bsc_poseidon <- dim(data_hist3)[1]
scale_param_pem_bsc_poseidon <- exp(exp_pem_bsc_poseidon$coefficients[1])
se_scale_pem_bsc_poseidon <- sqrt(vcov(exp_pem_bsc_poseidon)[1])

# Juntamos los datos

df <- data.frame(
  study = c('Zatloukal et al. (2003)', 'Ciuleanu et al. (2009)', 'Paz-Ares et al. (2012)'),
  year = c(2003, 2009, 2012),
  ni = c(n_gem_carbo, n_pem_bsc, n_pem_bsc_poseidon),
  yi = c(scale_param_gem_carbo, scale_param_pem_bsc, scale_param_pem_bsc_poseidon),
  vi = c(se_scale_gem_carbo^2, se_scale_pem_bsc^2, se_scale_pem_bsc_poseidon^2),
  sei = c(se_scale_gem_carbo, se_scale_pem_bsc, se_scale_pem_bsc_poseidon)
)


map_meta <- metagen(TE = df$yi, seTE = df$sei, studlab = df$study, data = df, prediction = TRUE, method.tau = "PM",test = "knha")           



```

A continuación se muestra el resultado del meta-análisis desde un punto de vista Bayesiano utilizando los resultados globales de los estudios anteriormente descritos. 

```{r MAP_Multiple_Historical_Data_Bayes , eval = T}

df <- data.frame(
  study = c('Zatloukal et al. (2003)', 'Ciuleanu et al. (2009)', 'Paz-Ares et al. (2012)'),
  year = c(2003, 2009, 2012),
  ni = c(n_gem_carbo, n_pem_bsc, n_pem_bsc_poseidon),
  yi = c(scale_param_gem_carbo, scale_param_pem_bsc, scale_param_pem_bsc_poseidon),
  vi = c(se_scale_gem_carbo^2, se_scale_pem_bsc^2, se_scale_pem_bsc_poseidon^2),
  sei = c(se_scale_gem_carbo, se_scale_pem_bsc, se_scale_pem_bsc_poseidon)
)


# Estas priors son muy comunes para los meta-análisis

priors <- c(prior(normal(0,1), class = Intercept),
            prior(cauchy(0,0.5), class = sd))

brm_out <- brm( yi | se(sei) ~ 1 + (1 | study),
                data = df,
                prior = priors,
                iter = 4000)

out_f <- spread_draws(brm_out, b_Intercept) %>% 
  mutate(study = "Average")

out_r <- spread_draws(brm_out, r_study[study,term], b_Intercept) %>% 
  mutate(b_Intercept = r_study + b_Intercept)

avg_effects <- out_r %>% group_by(.iteration) %>% summarise(avg_r_study = mean(r_study, na.rm = TRUE))

out_f <- out_f %>%
  left_join(avg_effects, by = ".iteration") %>%
  mutate(b_Intercept = b_Intercept + avg_r_study)

out_all <- bind_rows(out_r, out_f) %>% 
  ungroup() %>%
  mutate(study = fct_relevel(study, "Average"),
         study = str_replace_all(study, "\\.", " "))

out_all_sum <- group_by(out_all, study) %>% 
  mean_qi(b_Intercept)

out_all %>%   
  ggplot(aes(b_Intercept, study)) +
  geom_vline(xintercept = 6.5, size = .25, lty = 2) +
  stat_halfeye(.width = c(.8, .95), fill = "dodgerblue") +
  geom_text(
    data = mutate_if(out_all_sum, is.numeric, round, 2),
    aes(label = str_glue("{b_Intercept} [{.lower}, {.upper}]"), x = 4.1),  
    hjust = "inward"
  ) +
  geom_point(
    data = df %>% mutate(study = str_replace_all(study, "\\.", " ")), 
    aes(x=yi), position = position_nudge(y = -.05), shape = 1
  ) +
  coord_cartesian(xlim = c(4, 9)) +
  scale_y_discrete(name = "External Control Studies") +
  theme(
    panel.background = element_rect(fill = "white")
)

```

Ahora vamos a extraer los parámetros para especificar nuestras prior informativas basado en los MAPs.

```{r MAP_Multiple_Historical_Data_Bayes_Freq , eval = T}

# MAP Frecuentista

# Esto cuanta con toda la variabilidad, intra y externa


yi <- map_meta$TE 
vi <- map_meta$seTE^2  
tau2 <- map_meta$tau2  
mu <- map_meta$TE.random  

# Los efectos estimados para cada estudio
#Borenstein, M., Hedges, L. V., Higgins, J. P. T., & Rothstein, H. R. (2009). Introduction to Meta-Analysis. John Wiley & Sons.
theta_hat <- (1/vi + 1/tau2)^(-1) * (yi/vi + mu/tau2)

# Cuantificamos la variabilidad:
frequentist_sd <- sd(theta_hat)

# Esto calcula solo tau^2 que calcula la heterogeneida entre estudios pero no cuenta con la intra
# mean_estimate <- map_meta$TE.random
# CI_lower <- map_meta$lower.random
# CI_upper <- map_meta$upper.random
# 
# SE <- (CI_upper - CI_lower) / (2 * 1.96)
#SE <- SE*3

# Gamma parameters
alpha_map_freq <- (mu/frequentist_sd)^2
beta_map_freq  <- mu/frequentist_sd^2

## MAP Bayesiano ##

post_samples <- brms::posterior_samples(brm_out)

fixed_effects <- post_samples$b_Intercept

#colnames(post_samples)[grep("r_study", colnames(post_samples))]

random_effects <- post_samples[, grep("r_study", colnames(post_samples))]

combined_effects <- sweep(as.matrix(random_effects), 2, fixed_effects, `+`)

true_avg_effect <- apply(combined_effects, 1, mean)

combined_mean <- mean(true_avg_effect)
combined_sd <- sd(true_avg_effect)

# Gamma

alpha_map_bayes <- (combined_mean/combined_sd)^2
beta_map_bayes <- combined_mean / combined_sd^2

parameters_gamma <- data.frame(shape = c(0.00001, 1, 7.934823, 793.4823, alpha_map_freq, alpha_map_bayes),
                               rate = c( 0.00001, 1/6, 1, 100, beta_map_freq, beta_map_bayes),
                               label = c("Non-informative: Gamma(0.00001, 0.00001)", "Non-informative: Gamma(1, 1)", "Weak: Gamma(7.934823, 1)", "Informative: Gamma(793.4823, 100)", "Frequentist Meta-Analysis", "Bayesian Meta-Analysis"))

gamma_density <- function(shape, rate, label) {
  data.frame(x = seq(0, 35, length.out = 100)) %>%
    mutate(density = dgamma(x, shape = shape, rate = rate),
           parameter = label)
}

densities <- purrr::pmap_df(parameters_gamma, gamma_density)

ggplot(densities, aes(x, density, color = parameter)) +
  geom_line(size = 1.2) + 
  geom_line() +
  labs(
    title = "Gamma Prior Distributions",
    x = "Scale Parameter for the Control Arm",
    y = "Density",
    color = "Scale Prior Distributions"  
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 10, face = "bold"),
    axis.text = element_text(size = 12),
    axis.title.x = element_text(size = 12),
    axis.title.y = element_text(size = 12),
    legend.margin = margin(12, 12, 12, 12),
    legend.text = element_text(size = 11),
    legend.title = element_text(size = 12, face = "bold")
  )

```


```{r `Gamma priors Tesis`, eval = T}

parameters_gamma <- data.frame(
  shape = c(0.00001, 7.213475, 793.4823, 350, 550, 5.049433, 10.82021, alpha_map_freq, alpha_map_bayes),
  rate = c(0.00001, 1, 100, 100, 100, 1, 1, beta_map_freq, beta_map_bayes),
  label = factor(
    c(
      "Non-informative Prior", 
      "Weak Informative Prior centered at 5.5 months", 
      "Informative Prior centered at 5.5 months", 
      "Informative Prior centered at 3.5 months", 
      "Informative Prior centered at 7.5 months", 
      "Weak Informative Prior centered at 3.5 months", 
      "Weak Informative Prior centered at 7.5 months", 
      "Frequentist Meta-Analysis", 
      "Bayesian Meta-Analysis"
    ),
    levels = c(
      "Non-informative Prior",
      "Weak Informative Prior centered at 5.5 months",
      "Informative Prior centered at 5.5 months",
      "Informative Prior centered at 7.5 months",
      "Informative Prior centered at 3.5 months",
      "Weak Informative Prior centered at 7.5 months",
      "Weak Informative Prior centered at 3.5 months",
      "Frequentist Meta-Analysis",
      "Bayesian Meta-Analysis"
    )
  )
)

gamma_density <- function(shape, rate, label) {
  data.frame(x = seq(0, 20, length.out = 1000)) %>%
    mutate(density = dgamma(x, shape = shape, rate = rate),
           parameter = label)
}

densities <- purrr::pmap_df(parameters_gamma, gamma_density)

ggplot(densities, aes(x, density, color = parameter, linetype = parameter)) +
  geom_line(size = 1.2) +
  scale_color_manual(
    values = c(
      "Non-informative Prior" = "blue",
      "Weak Informative Prior centered at 5.5 months" = "orange",
      "Informative Prior centered at 5.5 months" = "green",
      "Informative Prior centered at 3.5 months" = "purple",
      "Informative Prior centered at 7.5 months" = "red",
      "Weak Informative Prior centered at 3.5 months" = "brown",
      "Weak Informative Prior centered at 7.5 months" = "deeppink2",
      "Frequentist Meta-Analysis" = "black",
      "Bayesian Meta-Analysis" = "turquoise"
    )
  ) +
  scale_linetype_manual(
    values = c(
      "Non-informative Prior" = "solid",
      "Weak Informative Prior centered at 5.5 months" = "solid",
      "Informative Prior centered at 5.5 months" = "solid",
      "Informative Prior centered at 3.5 months" = "dotted",
      "Informative Prior centered at 7.5 months" = "dotted",
      "Weak Informative Prior centered at 3.5 months" = "dotdash",
      "Weak Informative Prior centered at 7.5 months" = "dotdash",
      "Frequentist Meta-Analysis" = "dashed",
      "Bayesian Meta-Analysis" = "dashed")
  ) +
  labs(
    title = "Gamma Prior Distributions",
    x = "Scale Parameter for the Control Arm",
    y = "Density",
    color = "Scale Prior Distributions",
    linetype = "Scale Prior Distributions"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 10, face = "bold"),
    axis.text = element_text(size = 12),
    axis.title.x = element_text(size = 12),
    axis.title.y = element_text(size = 12),
    legend.margin = margin(12, 12, 12, 12),
    legend.text = element_text(size = 11),
    legend.title = element_text(size = 12, face = "bold")
  )



```

A continuación, vamos a evaluar las características operantes cogiendo los parámetros obtenido por el MAP tanto frecuentista como Bayesiano.

Características Operantes del MAP Frecuentista:
  
```{r `Bayes: Frequentist MAP`, eval = T}

shape_parameter <- 1 

control_medians <- c(3.5,3.75,4,4.25,4.5,4.75,5,5.25,5.5,5.75,6,6.25,6.5,6.75,7,7.25,7.5)

medians <- matrix(NA, nrow = length(control_medians), ncol = 3, 
                  dimnames = list(NULL, c("Control", "Treatment", "Hazard Ratio")))

desired_HR = 0.55

for (i in 1:length(control_medians)) {
  medians[i, "Control"] <- control_medians[i]
  
  lambda_control = control_medians[i] / (log(2)^(1/shape_parameter))
  lambda_treatment = lambda_control / desired_HR^(1/shape_parameter)
  
  medians[i, "Treatment"] = lambda_treatment * (log(2)^(1/shape_parameter))
  medians[i, "Hazard Ratio"] = (lambda_control / lambda_treatment)^shape_parameter
}

medians <- medians[,1:2]

sample_size <- 300  
ratio <- c(0.5,0.5)
rand_type <- "CR" 
scenarios_eff <- as.matrix(medians, nrow = length(control_medians), ncol = 2, byrow = TRUE)
censor <- c(0.1,0.1)
Tmax <- 20
alpha <- 0.05 
test.type <- 2
HR_1 <- TRUE
IA <- NULL
method_IA <- "bayes"
n_exp_events <- 175
Plot_Power <- FALSE
plot_pvalues = FALSE 
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = TRUE

analysis = "bayes"
n_sim <- 2000
seed <- 24
# 1) Shape control, 2) rate control, 3) Shape experimental y 4) rate experimental
prior_gamma <- matrix(c(alpha_map_freq, beta_map_freq, 0.00001, 0.00001), nrow = 2, ncol = 2, byrow = TRUE) 
prior_type <- c("Strong informative prior") # Este vector es para que aparezca el nombre en las tablas
P_HR_data_Boundary <- 0.8 # P(HR < 0.8 | data)
modelo_weibull_sep <- rstan::stan_model("weibull_gamma_def.stan" ,verbose = F)
modelo = modelo_weibull_sep
modelo_bayes_test = "weibull"
# 
# sim10 <-  sim_trials(n_sim = n_sim,
#                     analysis = "bayes",
#                     sample_size = sample_size,
#                     ratio = ratio,
#                     rand_type = rand_type,
#                     Tmax = Tmax,
#                     scenarios_eff = scenarios_eff,
#                     shape_parameter = shape_parameter,
#                     censor = censor,
#                     test.type = test.type,
#                     alpha = alpha,
#                     method_IA = method_IA,
#                     IA = IA,
#                     n_exp_events = n_exp_events,
#                     HR_1 = HR_1,
#                     Plot_Power = Plot_Power,
#                     modelo = modelo,
#                     modelo_bayes_test = modelo_bayes_test,
#                     prior_type = prior_type,
#                     P_HR_data_Boundary = P_HR_data_Boundary,
#                     prior_gamma = prior_gamma,
#                     Plot_Power_scenarios = Plot_Power_scenarios,
#                     desired_HRs = desired_HRs,
#                     plot_pvalues = plot_pvalues,
#                     Plot_Control_Scenarios = Plot_Control_Scenarios,
#                     seed = seed)
# sim10[[2]]
# sim10[[3]]
# sim10[[4]]
# 
# sim100 <- sim10[[1]]
# 
# wd <- createWorkbook()
# addWorksheet(wd, "Sheet1")
# writeData(wd, "Sheet1", sim100)
# saveWorkbook(wd, "MAP_freq_informative_gamma_300_2000_HR_055.xlsx", overwrite = TRUE)


sheet_names <- c("Sheet1")
MAP_freq <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/MAP_freq_300_2000_HR_055.xlsx", sheet = sheet_names[1])

```

Características Operantes del MAP Frecuentista:
  
```{r `Bayes: Frequentist MAP_CO1`, eval = T}

shape_parameter <- 1 

control_medians <- c(3.5,3.75,4,4.25,4.5,4.75,5,5.25,5.5,5.75,6,6.25,6.5,6.75,7,7.25,7.5)

medians <- matrix(NA, nrow = length(control_medians), ncol = 3, 
                  dimnames = list(NULL, c("Control", "Treatment", "Hazard Ratio")))

desired_HR = 0.55

for (i in 1:length(control_medians)) {
  medians[i, "Control"] <- control_medians[i]
  
  lambda_control = control_medians[i] / (log(2)^(1/shape_parameter))
  lambda_treatment = lambda_control / desired_HR^(1/shape_parameter)
  
  medians[i, "Treatment"] = lambda_treatment * (log(2)^(1/shape_parameter))
  medians[i, "Hazard Ratio"] = (lambda_control / lambda_treatment)^shape_parameter
}

medians <- medians[,1:2]

sample_size <- 300  
ratio <- c(0.5,0.5)
rand_type <- "CR" 
scenarios_eff <- as.matrix(medians, nrow = length(control_medians), ncol = 2, byrow = TRUE)
censor <- c(0.1,0.1)
Tmax <- 20
alpha <- 0.05 
test.type <- 2
HR_1 <- TRUE
IA <- NULL
method_IA <- "bayes"
n_exp_events <- 175
Plot_Power <- FALSE
plot_pvalues = FALSE 
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = TRUE

analysis = "bayes"
n_sim <- 2000
seed <- 24
# 1) Shape control, 2) rate control, 3) Shape experimental y 4) rate experimental
prior_gamma <- matrix(c(alpha_map_bayes, beta_map_bayes, 0.00001, 0.00001), nrow = 2, ncol = 2, byrow = TRUE) 
prior_type <- c("Strong informative prior") # Este vector es para que aparezca el nombre en las tablas
P_HR_data_Boundary <- 0.8 # P(HR < 0.8 | data)
modelo_weibull_sep <- rstan::stan_model("weibull_gamma_def.stan" ,verbose = F)
modelo = modelo_weibull_sep
modelo_bayes_test = "weibull"
# 
# sim11 <-  sim_trials(n_sim = n_sim,
#                     analysis = "bayes",
#                     sample_size = sample_size,
#                     ratio = ratio,
#                     rand_type = rand_type,
#                     Tmax = Tmax,
#                     scenarios_eff = scenarios_eff,
#                     shape_parameter = shape_parameter,
#                     censor = censor,
#                     test.type = test.type,
#                     alpha = alpha,
#                     method_IA = method_IA,
#                     IA = IA,
#                     n_exp_events = n_exp_events,
#                     HR_1 = HR_1,
#                     Plot_Power = Plot_Power,
#                     modelo = modelo,
#                     modelo_bayes_test = modelo_bayes_test,
#                     prior_type = prior_type,
#                     P_HR_data_Boundary = P_HR_data_Boundary,
#                     prior_gamma = prior_gamma,
#                     Plot_Power_scenarios = Plot_Power_scenarios,
#                     desired_HRs = desired_HRs,
#                     plot_pvalues = plot_pvalues,
#                     Plot_Control_Scenarios = Plot_Control_Scenarios,
#                     seed = seed)
# sim11[[2]]
# sim11[[3]]
# sim11[[4]]
# 
# sim110 <- sim11[[1]]
# 
# wd <- createWorkbook()
# addWorksheet(wd, "Sheet1")
# writeData(wd, "Sheet1", sim110)
# saveWorkbook(wd, "MAP_freq_300_2000_HR_055.xlsx", overwrite = TRUE)


sheet_names <- c("Sheet1")
MAP_bayes <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/MAP_bayes_300_2000_HR_055.xlsx", sheet = sheet_names[1])

```


```{r `Data gathering2 `, eval = T}

# MAP Frequentist
data_map_freq <- MAP_freq %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "Frequentist Meta-Analysis Prior")

data_filtered_diff_not_zero_map_freq <- data_map_freq %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_map_freq <- data_map_freq %>%
  filter(median_control == median_treatment)

# MAP Bayes
data_map_bayes <- MAP_bayes %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "Bayesian Meta-Analysis Prior")

data_filtered_diff_not_zero_map_bayes <- data_map_bayes %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_map_bayes <- data_map_bayes %>%
  filter(median_control == median_treatment)


combined_data_diff_not_zero <- bind_rows(data_filtered_diff_not_zero_frequentist,
                                         data_filtered_diff_not_zero_non_informative, 
                                         data_filtered_diff_not_zero_informative, 
                                         data_filtered_diff_not_zero_mid_informative,
                                         data_filtered_diff_not_zero_map_freq,
                                         data_filtered_diff_not_zero_map_bayes)

combined_data_diff_not_zero$Prior <- factor(
  combined_data_diff_not_zero$Prior,
  levels = c(
    "Frequentist",
     "Informative Prior: Gamma (760.6836, 100)",
     "Non-informative Prior: Gamma(0.00001, 0.00001)",
    "Weak Informative Prior: Gamma(7.213475, 1)",
    "Frequentist Meta-Analysis Prior",
    "Bayesian Meta-Analysis Prior"
  )
)

combined_data_diff_zero <- bind_rows(data_filtered_diff_zero_frequentist,
                                     data_filtered_diff_zero_non_informative, 
                                     data_filtered_diff_zero_informative, 
                                     data_filtered_diff_zero_mid_informative,
                                     data_filtered_diff_zero_map_freq,
                                     data_filtered_diff_zero_map_bayes)

combined_data_diff_zero$Prior <- factor(
  combined_data_diff_not_zero$Prior,
  levels = c(
    "Frequentist",
     "Informative Prior: Gamma (760.6836, 100)",
     "Non-informative Prior: Gamma(0.00001, 0.00001)",
    "Weak Informative Prior: Gamma(7.213475, 1)",
    "Frequentist Meta-Analysis Prior",
    "Bayesian Meta-Analysis Prior"
  )
)

```


En el gráfico de MSE vemos que el MAP frecuentista funciona muy bien en escenarios donde la mediana control está cerca de 4.5 pero el rendimiento va empeorando según se aleja, tiene un rendimiento parecido a la muy informativa (no tan bueno en valores centrales de su densidad porque no es tan informativa). Por otro lado, el MAP bayesiano tiene un mejor rendimiento a lo largo de todos los valores de la mediana, estando por debajo incluso de la weak, frecuentista, etc.

```{r MSE_w_MAP, eval = T}


p6 <- ggplot(combined_data_diff_not_zero, aes(x = median_control, y = mean_MSE, color = Prior)) + 
  geom_line(size = 1.2) +
  geom_vline(xintercept = median_control_center, linetype = "solid") +
  labs(
    title = "Mean Square Error (MSE)",
    x = "Median Control Arm (in months)",
    y = "Mean MSE",
    color = "Bayesian Prior Distributions"
  ) +
  theme_minimal() + 
  theme(
    plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 10, face = "bold"),
    axis.text = element_text(size = 12),
    axis.title.x = element_text(size = 11),
    axis.title.y = element_text(size = 11),
    legend.margin = margin(9, 9, 9, 9),
    legend.text = element_text(size = 9),
    legend.title = element_text(size = 10, face = "bold")
  ) +
  scale_color_discrete(name = "Bayesian Prior Distributions") +
  scale_x_continuous(breaks = seq(min(combined_data_diff_not_zero$median_control), max(combined_data_diff_not_zero$median_control), by = 0.5)) +
  scale_y_continuous(limits = c(0, 0.075))

p6


```

Con respecto al poder, al ser un tamaño muestral muy alto para lo que se necesita es difícil distinguirlo. Aún así, se ven que los dos métodos tienen bastante poder.

```{r Power_w_MAP, eval = T}

p7 <- ggplot(combined_data_diff_not_zero, aes(x = median_control, y = prop_significant, color = Prior)) +
  geom_line(size = 1.2) + 
  geom_line() +
  geom_vline(xintercept = median_control_center, linetype = "dashed") +
  labs(title = "Power", x = "Median Control Arm (in months)", y = "Proportion of Significant Trials", color = "Bayesian Prior Distributions") +
  theme_minimal() + 
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 12),
        axis.title.x = element_text(size = 12),
        axis.title.y = element_text(size = 12),
        legend.margin = margin(12, 12, 12, 12),
        legend.text = element_text(size = 11),
        legend.title = element_text(size = 12, face = "bold")) +
  scale_color_discrete(name = "Bayesian Prior Distributions") +
  scale_linetype_discrete(name = "Bayesian Prior Distributions") +
  scale_x_continuous(breaks = seq(min(combined_data_diff_not_zero$median_control), max(combined_data_diff_not_zero$median_control), by = 0.5)) +
  scale_y_continuous(limits = c(0.8, 1))
p7


```

Por último, el error de Tipo I: El MAP frecuentista se dispara según se aleja de 4.5 (media aproximada), podemos ver que tiene un peor comportamiento que la muy informativa. Coger alguna de las dos es como la lotería, si aciertas te llevas el premio gordo pero si no, el ET1 se dispara. Por eso es más importante ser conservador.

Por otro lado, el MAP Bayes infla el ET1 en valores superiores a 6. Aún así, no se dispara mucho y con un poco de ajuste podemos controlar este error mientras que guardamos el buen rendimiento de este modelo.

```{r T1E_w_MAP, eval = T}

p8 <- ggplot(combined_data_diff_zero, aes(x = median_control, y = prop_significant, color = Prior)) +
  geom_line(size = 1.2) + 
  geom_line() +
  geom_vline(xintercept = median_control_center, linetype = "dashed") +
  geom_hline(yintercept = 0.025, linetype = "dashed", color = "green") +
  geom_hline(yintercept = 0.05, linetype = "dashed", color = "purple") +
  labs(title = "Type I Error (T1E)", x = "Median Control (in months)", y = "Proportion of Significant Trials", color = "Bayesian Prior Distributions") +
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 12),
        axis.title.x = element_text(size = 12),
        axis.title.y = element_text(size = 12),
        legend.margin = margin(12, 12, 12, 12),
        legend.text = element_text(size = 11),
        legend.title = element_text(size = 12, face = "bold")) +
  scale_color_discrete(name = "Bayesian Prior Distributions") +
  scale_linetype_discrete(name = "Bayesian Prior Distributions") +
  scale_x_continuous(breaks = seq(min(combined_data_diff_zero$median_control), max(combined_data_diff_zero$median_control), by = 0.5)) +
  scale_y_continuous(limits = c(0, 0.2))
p8

```


```{r T1E_combined_all, eval = T}

library(cowplot)

p66 <- p6 + scale_color_discrete(
  name = "Bayesian Prior Distributions", 
  labels = c(
        "Frequentist",
         "Informative Prior\ncentered at 5.5 months",
    "Non-informative Prior",
    "Weak Informative Prior\ncentered at 5.5 months",
        "Frequentist\nMeta-Analysis Prior",
    "Bayesian\nMeta-Analysis Prior"

  )
) +
  guides(color = guide_legend(ncol = 6))  

legend <- get_legend(
  p66 +
    theme(
      # legend.box = "horizontal", 
      legend.justification = c(0, 1),
      # legend.margin = margin(8, 8, 8, 8),
      legend.text = element_text(size = 10), 
      legend.title = element_text(size = 11, face = "bold")
    )
)

# Remove individual legends from the plots
p66 <- p66 + theme(legend.position = "none")
p77 <- p7 + theme(legend.position = "none")
p88 <- p8 + theme(legend.position = "none")

p66 <- p66 + theme(plot.background = element_rect(colour = "black", size = 0.5, fill = NA))
p77 <- p77 + theme(plot.background = element_rect(colour = "black", size = 0.5, fill = NA))
p88 <- p88 + theme(plot.background = element_rect(colour = "black", size = 0.5, fill = NA))

plots_row <- plot_grid(p66, p77, p88, ncol = 3, labels = c("A", "B", "C"), label_size = 14)

combined_plot <- plot_grid(
  plots_row,
  legend,
  ncol = 1,                 
  rel_heights = c(3, 0.4)   
)

print(combined_plot)

```

Ahora evaluamos los diferentes HRs para el MAP frecuentista

```{r ` MAP Freq Power changing HRs`, eval = T}

shape_parameter <- 1 

desired_HRs <- c(1.3, 1.2, 1.1, 1, 0.95, 0.9, 0.85, 0.8, 0.775, 0.75, 0.725, 0.7, 0.675, 0.65, 0.625, 0.6, 0.575, 0.55, 0.525, 0.5, 0.45, 0.4, 0.35, 0.3)
control_medians <- rep(5.5, times = length(desired_HRs))

medians_control_fijo <- matrix(NA, nrow = length(desired_HRs), ncol = 2, dimnames = list(paste0("HR ", desired_HRs), c("Control", "Treatment")))

for (i in 1:length(desired_HRs)) {
  medians_control_fijo[i, "Treatment"] <- control_medians[i] / (desired_HRs[i]^(1/shape_parameter))
  medians_control_fijo[i, "Control"] <- control_medians[i]
}

sample_size <- 300  
ratio <- c(0.5,0.5)
rand_type <- "CR" 
scenarios_eff <- as.matrix(medians_control_fijo, nrow = dim(medians_control_fijo)[1], ncol = 2, byrow = TRUE)
censor <- c(0.1,0.1)
Tmax <- 20
alpha <- 0.05 
test.type <- 2
HR_1 <- FALSE
IA <- NULL
method_IA <- "bayes"
n_exp_events <- 175
Plot_Power <- FALSE
plot_pvalues = FALSE 
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = FALSE

analysis = "bayes"
n_sim <- 2000
seed <- 24
# 1) Shape control, 2) rate control, 3) Shape experimental y 4) rate experimental
prior_gamma <- matrix(c(alpha_map_freq, beta_map_freq, 0.00001, 0.00001), nrow = 2, ncol = 2, byrow = TRUE) 
prior_type <- c("Non informative prior") # Este vector es para que aparezca el nombre en las tablas
P_HR_data_Boundary <- 0.8 # P(HR < 0.8 | data)
modelo_weibull_sep <- rstan::stan_model("weibull_gamma_def.stan" ,verbose = F)
modelo = modelo_weibull_sep
modelo_bayes_test = "weibull"

# sim12 <-  sim_trials(n_sim = n_sim,
#                     analysis = "bayes",
#                     sample_size = sample_size,
#                     ratio = ratio,
#                     rand_type = rand_type,
#                     Tmax = Tmax,
#                     scenarios_eff = scenarios_eff,
#                     shape_parameter = shape_parameter,
#                     censor = censor,
#                     test.type = test.type,
#                     alpha = alpha,
#                     method_IA = method_IA,
#                     IA = IA,
#                     n_exp_events = n_exp_events,
#                     HR_1 = HR_1,
#                     Plot_Power = Plot_Power,
#                     modelo = modelo,
#                     modelo_bayes_test = modelo_bayes_test,
#                     prior_type = prior_type,
#                     P_HR_data_Boundary = P_HR_data_Boundary,
#                     prior_gamma = prior_gamma,
#                     Plot_Power_scenarios = Plot_Power_scenarios,
#                     desired_HRs = desired_HRs,
#                     plot_pvalues = plot_pvalues,
#                     Plot_Control_Scenarios = Plot_Control_Scenarios,
#                     seed = seed)
# 
# wd <- createWorkbook()
# addWorksheet(wd, "Sheet1")
# writeData(wd, "Sheet1", sim12)
# saveWorkbook(wd, "MAP_freq_300_2000_HR_changing.xlsx", overwrite = TRUE)



sheet_names <- c("Sheet1")
MAP_freq_HRs <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/MAP_freq_300_2000_HR_changing.xlsx", sheet = sheet_names[1])

```

Ahora evaluamos los diferentes HRs para el MAP Bayes

```{r `Bayes: MAP Bayes Power changing HRs`, eval = T}

shape_parameter <- 1 

desired_HRs <- c(1.3, 1.2, 1.1, 1, 0.95, 0.9, 0.85, 0.8, 0.775, 0.75, 0.725, 0.7, 0.675, 0.65, 0.625, 0.6, 0.575, 0.55, 0.525, 0.5, 0.45, 0.4, 0.35, 0.3)
control_medians <- rep(5.5, times = length(desired_HRs))

medians_control_fijo <- matrix(NA, nrow = length(desired_HRs), ncol = 2, dimnames = list(paste0("HR ", desired_HRs), c("Control", "Treatment")))

for (i in 1:length(desired_HRs)) {
  medians_control_fijo[i, "Treatment"] <- control_medians[i] / (desired_HRs[i]^(1/shape_parameter))
  medians_control_fijo[i, "Control"] <- control_medians[i]
}

sample_size <- 300  
ratio <- c(0.5,0.5)
rand_type <- "CR" 
scenarios_eff <- as.matrix(medians_control_fijo, nrow = dim(medians_control_fijo)[1], ncol = 2, byrow = TRUE)
censor <- c(0.1,0.1)
Tmax <- 20
alpha <- 0.05 
test.type <- 2
HR_1 <- FALSE
IA <- NULL
method_IA <- "bayes"
n_exp_events <- 175
Plot_Power <- FALSE
plot_pvalues = FALSE 
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = FALSE

analysis = "bayes"
n_sim <- 2000
seed <- 24
# 1) Shape control, 2) rate control, 3) Shape experimental y 4) rate experimental
prior_gamma <- matrix(c(alpha_map_bayes, beta_map_bayes, 0.00001, 0.00001), nrow = 2, ncol = 2, byrow = TRUE) 
prior_type <- c("Non informative prior") # Este vector es para que aparezca el nombre en las tablas
P_HR_data_Boundary <- 0.8 # P(HR < 0.8 | data)
modelo_weibull_sep <- rstan::stan_model("weibull_gamma_def.stan" ,verbose = F)
modelo = modelo_weibull_sep
modelo_bayes_test = "weibull"

# sim13 <-  sim_trials(n_sim = n_sim,
#                     analysis = "bayes",
#                     sample_size = sample_size,
#                     ratio = ratio,
#                     rand_type = rand_type,
#                     Tmax = Tmax,
#                     scenarios_eff = scenarios_eff,
#                     shape_parameter = shape_parameter,
#                     censor = censor,
#                     test.type = test.type,
#                     alpha = alpha,
#                     method_IA = method_IA,
#                     IA = IA,
#                     n_exp_events = n_exp_events,
#                     HR_1 = HR_1,
#                     Plot_Power = Plot_Power,
#                     modelo = modelo,
#                     modelo_bayes_test = modelo_bayes_test,
#                     prior_type = prior_type,
#                     P_HR_data_Boundary = P_HR_data_Boundary,
#                     prior_gamma = prior_gamma,
#                     Plot_Power_scenarios = Plot_Power_scenarios,
#                     desired_HRs = desired_HRs,
#                     plot_pvalues = plot_pvalues,
#                     Plot_Control_Scenarios = Plot_Control_Scenarios,
#                     seed = seed)
# 
# wd <- createWorkbook()
# addWorksheet(wd, "Sheet1")
# writeData(wd, "Sheet1", sim13)
# saveWorkbook(wd, "MAP_bayes_300_2000_HR_changing.xlsx", overwrite = TRUE)



sheet_names <- c("Sheet1")
MAP_bayes_HRs <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/MAP_bayes_300_2000_HR_changing.xlsx", sheet = sheet_names[1])

```

```{r `Data combined MAPs`, eval = T}

data_sim3_results <- sim3_results %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE))%>%
  mutate(Prior = "Frequentist")

data_non_informative <- non_informative_gamma %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE))%>%
  mutate(Prior = "Non informative")

data_weak_informative_gamma_3.5 <- weak_informative_gamma_3.5 %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE))%>%
  mutate(Prior = "Weak Informative: Median control at 3.5")


data_informative_gamma_3.5 <- informative_gamma_3.5 %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  mutate(Prior = "Informative: Median control at 3.5")

data_weak_informative_gamma_5.5 <- weak_informative_gamma_5.5 %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE))%>%
  mutate(Prior = "Weak Informative: Median control at 5.5")

data_informative_gamma_5.5 <- informative_gamma_5.5 %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  mutate(Prior = "Informative:  Median control at 5.5")

data_weak_informative_gamma_7.5 <- weak_informative_gamma_7.5 %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE))%>%
  mutate(Prior = "Weak Informative: Median control at 7.5")      

data_informative_gamma_7.5 <- informative_gamma_7.5 %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  mutate(Prior = "Informative:  Median control at 7.5")  
# MAP FREQ

data_map_freq_HRs <- MAP_freq_HRs %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) +                                          sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  mutate(Prior = "MAP FREQ") 

# MAP BAYES

data_map_bayes_HRs <- MAP_bayes_HRs %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) +                                          sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  mutate(Prior = "MAP BAYES")   

# 3.5
combined_data_3.5 <- bind_rows(data_sim3_results,
                               #data_non_informative, 
                               data_weak_informative_gamma_3.5, 
                               data_informative_gamma_3.5,
                               data_map_freq_HRs,
                               data_map_bayes_HRs)

combined_data_3.5 <- combined_data_3.5 %>%
  group_by(Prior) %>%
  mutate(desired_HRs = (desired_HRs))

combined_data_3.5 <- combined_data_3.5 %>%
  mutate(diff_HR = abs(mean_HR - desired_HRs))

# 5.5
combined_data_5.5 <- bind_rows(data_sim3_results,
                               # data_non_informative, 
                               data_weak_informative_gamma_5.5, 
                               data_informative_gamma_5.5,
                               data_map_freq_HRs,
                               data_map_bayes_HRs)


combined_data_5.5 <- combined_data_5.5 %>%
  group_by(Prior) %>%
  mutate(desired_HRs = (desired_HRs))

combined_data_5.5 <- combined_data_5.5 %>%
  mutate(diff_HR = abs(mean_HR - desired_HRs))

# 7.5

combined_data_7.5 <- bind_rows(data_sim3_results,
                               #   data_non_informative, 
                               data_weak_informative_gamma_7.5, 
                               data_informative_gamma_7.5,
                               data_map_freq_HRs,
                               data_map_bayes_HRs)

combined_data_7.5 <- combined_data_7.5 %>%
  group_by(Prior) %>%
  mutate(desired_HRs = (desired_HRs))

combined_data_7.5 <- combined_data_7.5 %>%
  mutate(diff_HR = abs(mean_HR - desired_HRs))

```

Dibujamos los de la mediana de 3.5

```{r `Simulation scenarios w fixed experimental & bayes w plot 3.5_2`, eval = T, echo = T}


p6 <- ggplot(combined_data_3.5, aes(x = desired_HRs, y = prop_significant, group = Prior, color = Prior)) +
  geom_point(size = 3) +
  geom_line(linewidth = 1) +
  geom_vline(xintercept = 1, linetype = "dashed", color = "red", size = 1) +
  geom_vline(xintercept = 0.55, linetype = "dashed", color = "red", size = 1) +
  geom_vline(xintercept = 0.5, linetype = "dashed", color = "red", size = 1) +
  geom_hline(yintercept = c(0.8, 0.9), linetype = "dotted", color = c("purple", "green"), size = 1) +
  scale_x_continuous(breaks = seq(min(combined_data_3.5$desired_HRs), max(combined_data_3.5$desired_HRs), 0.1), labels = sprintf("%.2f", seq(min(combined_data_3.5$desired_HRs), max(combined_data_3.5$desired_HRs), 0.1))) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Power vs Hazard Ratio w prior median control at 3.5",
       x = "Theoretical Hazard Ratio",
       y = "Power") +
  theme_minimal() +
  theme(plot.title = element_text(size = 12, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 10),
        legend.position = "right")

p6 <- p6 +
  annotate("text", x = max(combined_data_3.5$desired_HRs), y = 0.8, label = "80% power", hjust = 1, vjust = -0.5, size = 3.5, color = "purple") +
  annotate("text", x = max(combined_data_3.5$desired_HRs), y = 0.9, label = "90% power", hjust = 1, vjust = -0.5, size = 3.5, color = "green") +
  geom_label(aes(x = 1, y = Inf, label = "H0"), vjust = 2, color = "black", fill = "white", size = 3.5, label.size = 0, fontface = "bold") +
  geom_label(aes(x = 0.55, y = Inf, label = "H1"), vjust = 2, color = "black", fill = "white", size = 3.5, label.size = 0, fontface = "bold") +
  geom_label(aes(x = 0.5, y = Inf, label = "Real HR"), vjust = 2, color = "black", fill = "white", size = 3.5, label.size = 0, fontface = "bold")

p6

# Graficamos las diferencias

p7 <- ggplot(combined_data_3.5, aes(x = desired_HRs, y = diff_HR, color = Prior)) +
  geom_point(size = 3) +
  geom_line(aes(group = Prior), linewidth = 1) +
  scale_x_continuous(breaks = seq(min(combined_data_3.5$desired_HRs), max(combined_data_3.5$desired_HRs), 0.1), labels = sprintf("%.2f", seq(min(combined_data_3.5$desired_HRs), max(combined_data_3.5$desired_HRs), 0.1))) +
  labs(title = "Diff btw Simulated HR and Theoretical HRs w prior median control = 3.5",
       x = "Theoretical Hazard Ratio",
       y = "Difference") +
  theme_minimal() +
  theme(plot.title = element_text(size = 10, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 8, face = "bold"),
        axis.text = element_text(size = 8),
        legend.position = "right")

p7
```

Dibujamos los de la mediana de 5.5

```{r `Simulation scenarios w fixed experimental & bayes w plot 5.5_2`, eval = T, echo = T}


p8 <- ggplot(combined_data_5.5, aes(x = desired_HRs, y = prop_significant, group = Prior, color = Prior)) +
  geom_point(size = 3) +
  geom_line(linewidth = 1) +
  geom_vline(xintercept = 1, linetype = "dashed", color = "red", size = 1) +
  geom_vline(xintercept = 0.55, linetype = "dashed", color = "red", size = 1) +
  geom_vline(xintercept = 0.5, linetype = "dashed", color = "red", size = 1) +
  geom_hline(yintercept = c(0.8, 0.9), linetype = "dotted", color = c("purple", "green"), size = 1) +
  scale_x_continuous(breaks = seq(min(combined_data_5.5$desired_HRs), max(combined_data_5.5$desired_HRs), 0.1), labels = sprintf("%.2f", seq(min(combined_data_5.5$desired_HRs), max(combined_data_5.5$desired_HRs), 0.1))) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Power vs Hazard Ratio w prior median control at 5.5",
       x = "Theoretical Hazard Ratio",
       y = "Power") +
  theme_minimal() +
  theme(plot.title = element_text(size = 12, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 10),
        legend.position = "right")

p8 <- p8 +
  annotate("text", x = max(combined_data_5.5$desired_HRs), y = 0.8, label = "80% power", hjust = 1, vjust = -0.5, size = 3.5, color = "purple") +
  annotate("text", x = max(combined_data_5.5$desired_HRs), y = 0.9, label = "90% power", hjust = 1, vjust = -0.5, size = 3.5, color = "green") +
  geom_label(aes(x = 1, y = Inf, label = "H0"), vjust = 2, color = "black", fill = "white", size = 3.5, label.size = 0, fontface = "bold") +
  geom_label(aes(x = 0.55, y = Inf, label = "H1"), vjust = 2, color = "black", fill = "white", size = 3.5, label.size = 0, fontface = "bold") +
  geom_label(aes(x = 0.5, y = Inf, label = "Real HR"), vjust = 2, color = "black", fill = "white", size = 3.5, label.size = 0, fontface = "bold")

p8

# Graficamos las diferencias

p9 <- ggplot(combined_data_5.5, aes(x = desired_HRs, y = diff_HR, color = Prior)) +
  geom_point(size = 3) +
  geom_line(aes(group = Prior), linewidth = 1) +
  scale_x_continuous(breaks = seq(min(combined_data_5.5$desired_HRs), max(combined_data_5.5$desired_HRs), 0.1), labels = sprintf("%.2f", seq(min(combined_data_5.5$desired_HRs), max(combined_data_5.5$desired_HRs), 0.1))) +
  scale_y_continuous(limits = c(NA, 0.4)) + # Setting the y-axis max limit here
  labs(title = "Diff btw Simulated HR and Theoretical HRs w prior median control = 5.5",
       x = "Theoretical Hazard Ratio",
       y = "Difference") +
  theme_minimal() +
  theme(plot.title = element_text(size = 10, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 8, face = "bold"),
        axis.text = element_text(size = 8),
        legend.position = "right")

p9

```

Dibujamos los de la mediana de 7.5

```{r `Simulation scenarios w fixed experimental & bayes w plot 7.5_2`, eval = T, echo = T}


p10 <- ggplot(combined_data_7.5, aes(x = desired_HRs, y = prop_significant, group = Prior, color = Prior)) +
  geom_point(size = 3) +
  geom_line(linewidth = 1) +
  geom_vline(xintercept = 1, linetype = "dashed", color = "red", size = 1) +
  geom_vline(xintercept = 0.55, linetype = "dashed", color = "red", size = 1) +
  geom_vline(xintercept = 0.5, linetype = "dashed", color = "red", size = 1) +
  geom_hline(yintercept = c(0.8, 0.9), linetype = "dotted", color = c("purple", "green"), size = 1) +
  scale_x_continuous(breaks = seq(min(combined_data_7.5$desired_HRs), max(combined_data_7.5$desired_HRs), 0.1), labels = sprintf("%.2f", seq(min(combined_data_7.5$desired_HRs), max(combined_data_7.5$desired_HRs), 0.1))) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Power vs Hazard Ratio w prior median control at 7.5",
       x = "Theoretical Hazard Ratio",
       y = "Power") +
  theme_minimal() +
  theme(plot.title = element_text(size = 12, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 10),
        legend.position = "right")

p10 <- p10 +
  annotate("text", x = max(combined_data_7.5$desired_HRs), y = 0.8, label = "80% power", hjust = 1, vjust = -0.5, size = 3.5, color = "purple") +
  annotate("text", x = max(combined_data_7.5$desired_HRs), y = 0.9, label = "90% power", hjust = 1, vjust = -0.5, size = 3.5, color = "green") +
  geom_label(aes(x = 1, y = Inf, label = "H0"), vjust = 2, color = "black", fill = "white", size = 3.5, label.size = 0, fontface = "bold") +
  geom_label(aes(x = 0.55, y = Inf, label = "H1"), vjust = 2, color = "black", fill = "white", size = 3.5, label.size = 0, fontface = "bold") +
  geom_label(aes(x = 0.5, y = Inf, label = "Real HR"), vjust = 2, color = "black", fill = "white", size = 3.5, label.size = 0, fontface = "bold")

p10

# Graficamos las diferencias

p11 <- ggplot(combined_data_7.5, aes(x = desired_HRs, y = diff_HR, color = Prior)) +
  geom_point(size = 3) +
  geom_line(aes(group = Prior), linewidth = 1) +
  scale_x_continuous(breaks = seq(min(combined_data_7.5$desired_HRs), max(combined_data_7.5$desired_HRs), 0.1), labels = sprintf("%.2f", seq(min(combined_data_7.5$desired_HRs), max(combined_data_7.5$desired_HRs), 0.1))) +
  labs(title = "Diff btw Simulated HR and Theoretical HRs w prior median control = 7.5",
       x = "Theoretical Hazard Ratio",
       y = "Difference") +
  theme_minimal() +
  theme(plot.title = element_text(size = 10, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 8, face = "bold"),
        axis.text = element_text(size = 8),
        legend.position = "right")

p11
```

# Mixture Meta-Analytic Prior with non-informative

Para hacer el mixture es apropiado considerar la 2 diferentes priors, informativa usando MAP y no informativa, de la misma distribución.

Por otro lado, para elegir el % de información que se usa en una distribución y en otra, podemos hacer una simulación que vaya de 0.1 en 0.1 hasta 0.5.


Por un lado tenemos:
  
1) Mixture Prior: Combinación de 2 priors

2) Robust Mixture Prior: Combinación de un MAP + Componente no informativo (the MAP prior is not available in analytical form. To allow for a concise description of the prior and tractable posterior analysis we approximate the MAP prior by a mixture of conjugate priors, with the Kullback–Leibler divergence as a measure of discrepancy.)

Ver también cuánto tamaño muestral nos ahorramos por cada calibración del peso puede ser interesante. Claro, pero aquí serían diferentes shape parameter para el componen.

Ahora vamos a ejecutar el código para obtener los resultados para diferentes mixture priors con diferentes w. 
W es el peso que se da a la parte informativa, en este caso obtenido en el MAP.
No tiene sentido proponer un diseño donde se de un peso de más del 50% a la parte informativa, por lo que este valor va a ser el cap.

Vamos a ir de 5 en 5 para el porcentaje de información para la parte informativa, i.e., 0.05, 0.1, 0.15, 0.20, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5.

Sólo se va a ensañar un código en el informe pero se ha realizado para todos los pesos y mostramos sus características.

Primero se van a mostrar los resultados usando un MAP hecho desde un punto de vista frecuentista. Así mismo, como tenía dudas de qué prior no informativa usar, he cogido 2:
  
- La anteriormente usada, una Gamma(1, 1/6)

- Otra nueva que es no informativa pero restringe a valores que son lógicos (e.g, aunque se pasa abarca puntos hasta que se permite la duración del ensayo ya que puntos más lejanos se censuran automáticamente). Esta es una Gamma(0.00001, 0.00001).

Para ilustrar primero el tema de las priors no informativas, a continuación vemos su forma usando diferentes pesos:
  
```{r Densities_mixture_MW2, eval = T}

# Dibujamos las densidades del mixture

gamma_density_1 <- function(x, alpha, beta) {
  dgamma(x, shape=alpha, rate=beta)
}

gamma_density_2 <- function(x) {
  # dgamma(x, shape=0.00001, rate=0.00001)
  dgamma(x, shape=1, rate=0.1666667)
  
}

gamma_density_3 <- function(x, alpha, beta) {
  dgamma(x, shape=alpha, rate=beta)
}

mixture_density_1 <- function(x, w1, alpha1, beta1) {
  w1 * gamma_density_1(x, alpha1, beta1) + (1-w1) * gamma_density_2(x)
}

mixture_density_2 <- function(x, w2, alpha2, beta2) {
  w2 * gamma_density_3(x, alpha2, beta2) + (1-w2) * gamma_density_2(x)
}

alpha1 = alpha_map_freq
beta1 = beta_map_freq
alpha2 = alpha_map_bayes
beta2 = beta_map_bayes
w1 = 0.15
w2 = 0.50

x_seq <- seq(0, 20, length.out = 400)
gamma1_densities <- gamma_density_1(x_seq, alpha1, beta1)
gamma2_densities <- gamma_density_2(x_seq)
gamma3_densities <- gamma_density_3(x_seq, alpha2, beta2)
mixture1_densities <- sapply(x_seq, function(x) mixture_density_1(x, w1, alpha1, beta1))
mixture2_densities <- sapply(x_seq, function(x) mixture_density_2(x, w2, alpha2, beta2))

df <- data.frame(x = x_seq, 
                 Prior_MAP_Frequentist = gamma1_densities, 
                 Prior_Non_informative = gamma2_densities,
                 Prior_MAP_Bayes = gamma3_densities,
                 Mixture_Bayes_weight_0.15_informative_part = mixture1_densities,
                 Mixture_Bayes_weight_0.5_informative_part = mixture2_densities)

ggplot(df, aes(x = x)) + 
  geom_line(aes(y = Prior_MAP_Frequentist, color = "Prior_MAP_Frequentist")) + 
  geom_line(aes(y = Prior_Non_informative, color = "Prior_Non_informative")) +
  geom_line(aes(y = Prior_MAP_Bayes, color = "Prior_MAP_Bayes")) +
  geom_line(aes(y = Mixture_Bayes_weight_0.15_informative_part, color = "Mixture_Bayes_weight_0.15_informative_part")) +
  geom_line(aes(y = Mixture_Bayes_weight_0.5_informative_part, color = "Mixture_Bayes_weight_0.5_informative_part")) +
  labs(title = "Gamma Densities and Their Mixtures", 
       x = "x", 
       y = "Density", 
       color = "Density Legend") + 
  theme_minimal()

# Dibujamos todas las densidades inclyendo las mixture

parameters_gamma <- data.frame(shape = c(0.00001, 1, 7.934823, 793.4823, alpha_map_freq, alpha_map_bayes),
                               rate = c(0.00001, 1/6, 1, 100, beta_map_freq, beta_map_bayes),
                               label = c("Non-informative: Gamma(0.00001, 0.00001)", "Non-informative: Gamma(1, 1)", "Weak: Gamma(7.934823, 1)", "Informative: Gamma(793.4823, 100)", "MAP freq", "MAP bayes"))

gamma_density <- function(shape, rate, label) {
  data.frame(x = seq(0, 35, length.out = 400)) %>%
    mutate(density = dgamma(x, shape = shape, rate = rate),
           parameter = label)
}

densities <- purrr::pmap_df(parameters_gamma, gamma_density)

alpha1 = alpha_map_bayes  
beta1 = beta_map_bayes   
w1 = 0.15
w2 = 0.50

gamma_density_1 <- function(x, alpha, beta) {
  dgamma(x, shape=alpha, rate=beta)
}

gamma_density_2 <- function(x) {
  dgamma(x, shape=1, rate=0.1666667)
}

gamma_density_3 <- function(x, alpha, beta) {
  dgamma(x, shape=alpha, rate=beta)
}

Mixture_weight_0.15_informative_part <- function(x, w1, alpha1, beta1) {
  w1 * gamma_density_1(x, alpha1, beta1) + (1-w1) * gamma_density_2(x)
}

Mixture_weight_0.5_informative_part <- function(x, w2, alpha2, beta2) {
  w2 * gamma_density_3(x, alpha2, beta2) + (1-w2) * gamma_density_2(x)
}

x_seq <- seq(0, 20, length.out = 400) # Make sure this covers the range of both plots

mixture_df <- data.frame(
  x = x_seq,
  density = c(
    sapply(x_seq, function(x) Mixture_weight_0.15_informative_part(x, w1, alpha1, beta1)),
    sapply(x_seq, function(x) Mixture_weight_0.5_informative_part(x, w2, alpha1, beta1))
  ),
  parameter = c(rep("Mixture_weight_0.15_informative_part", length(x_seq)), rep("Mixture_weight_0.5_informative_part", length(x_seq)))
)

final_df <- bind_rows(densities, mixture_df)

ggplot(mixture_df, aes(x = x, y = density, color = parameter)) +
  geom_line() +
  labs(title = "Gamma Prior Distributions and Their Mixtures", 
       x = "x", 
       y = "Density", 
       color = "Density Legend") +
  theme_minimal()


```

Primero se hicieron unos resultados usando un MAP hecho desde un punto de vista frecuentista. Aún así, como se puede ver anteriormente en la sección de los MAPs, el frecuentista es muy informativo con poca variabilidad por lo que va a inflar el ET1 en muchos escenarios. Por eso, las simulaciones a partir de ahora están hechas con el MAP Bayesiano. De todos modos, este se podría dar artificialemtne más variabilidad para que sea menos informativa. Se podría ver.

```{r MAP_Freq_Mixture_Prior_w, eval = T}

shape_parameter <- 1 

control_medians <- c(3.5,3.75,4,4.25,4.5,4.75,5,5.25,5.5,5.75,6,6.25,6.5,6.75,7,7.25,7.5)

medians <- matrix(NA, nrow = length(control_medians), ncol = 3, 
                  dimnames = list(NULL, c("Control", "Treatment", "Hazard Ratio")))

desired_HR = 0.55

for (i in 1:length(control_medians)) {
  medians[i, "Control"] <- control_medians[i]
  
  lambda_control = control_medians[i] / (log(2)^(1/shape_parameter))
  lambda_treatment = lambda_control / desired_HR^(1/shape_parameter)
  
  medians[i, "Treatment"] = lambda_treatment * (log(2)^(1/shape_parameter))
  medians[i, "Hazard Ratio"] = (lambda_control / lambda_treatment)^shape_parameter
}

medians <- medians[,1:2]
sample_size <- 300  
ratio <- c(0.5,0.5)
rand_type <- "CR" 
scenarios_eff <- as.matrix(medians, nrow = length(medians), ncol = 2, byrow = TRUE)
censor <- c(0.1,0.1)
Tmax <- 20
alpha <- 0.05 
test.type <- 2
HR_1 <- TRUE
IA <- NULL
method_IA <- "bayes"
n_exp_events <- 175
Plot_Power <- FALSE
plot_pvalues = FALSE 
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = TRUE

analysis = "bayes"
n_sim <- 2000
seed <- 24
# 1) Shape control, 2) rate control, 3) Shape experimental y 4) rate experimental
prior_gamma <- matrix(c(alpha_map_freq, beta_map_freq, 0.00001, 0.00001), nrow = 2, ncol = 2, byrow = TRUE) 
prior_type <- c("Non informative prior") # Este vector es para que aparezca el nombre en las tablas
P_HR_data_Boundary <- 0.8 # P(HR < 0.8 | data)
modelo_weibull_sep <- rstan::stan_model("weibull_mixture_gamma_def.stan" ,verbose = F)
modelo = modelo_weibull_sep
modelo_bayes_test = "weibull"
w = 0.15

# sim14 <-  sim_trials(n_sim = n_sim,
#                      analysis = "bayes",
#                      sample_size = sample_size,
#                      ratio = ratio,
#                      rand_type = rand_type,
#                      Tmax = Tmax,
#                      scenarios_eff = scenarios_eff,
#                      shape_parameter = shape_parameter,
#                      censor = censor,
#                      test.type = test.type,
#                      alpha = alpha,
#                      method_IA = method_IA,
#                      IA = IA,
#                      n_exp_events = n_exp_events,
#                      HR_1 = HR_1,
#                      Plot_Power = Plot_Power,
#                      modelo = modelo,
#                      modelo_bayes_test = modelo_bayes_test,
#                      prior_type = prior_type,
#                      P_HR_data_Boundary = P_HR_data_Boundary,
#                      prior_gamma = prior_gamma,
#                      Plot_Power_scenarios = Plot_Power_scenarios,
#                      desired_HRs = desired_HRs,
#                      plot_pvalues = plot_pvalues,
#                      Plot_Control_Scenarios = Plot_Control_Scenarios,
#                      w = w,
#                      seed = seed)
# 
# sim14[[2]]
# sim14[[3]]
# sim14[[4]]
# 
# sim140 <- sim14[[1]]

# wd <- createWorkbook()
# addWorksheet(wd, "Sheet1")
# writeData(wd, "Sheet1", sim140)
# saveWorkbook(wd, "MAP_bayes_mixture_w_0.15_300_2000_HR_changing.xlsx", overwrite = TRUE)

## Leemos los datos de las tablas obtenidas con el ordenador multicore ##

sheet_names <- c("Sheet1")
MAP_freq_mixture_w_0.15 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/MAP_bayes_mixture_w_0.15_300_2000_HR_changing.xlsx", sheet = sheet_names[1])
MAP_freq_mixture_w_0.25 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/MAP_bayes_mixture_w_0.25_300_2000_HR_changing.xlsx", sheet = sheet_names[1])

## Ahora juntamos los datos para graficarlos ##

# MAP Frequentist Mixture prior w weight of 0.15

data_map_freq_mixture_w_0.15 <- MAP_freq_mixture_w_0.15 %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "MAP Frequentist Mixture prior w weight of 0.15")

data_filtered_diff_not_zero_map_freq_mixture_w_0.15 <- data_map_freq_mixture_w_0.15 %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_map_freq_mixture_w_0.15 <- data_map_freq_mixture_w_0.15 %>%
  filter(median_control == median_treatment)

# MAP Frequentist Mixture prior w weight of 0.25

data_map_freq_mixture_w_0.25 <- MAP_freq_mixture_w_0.25 %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "MAP Frequentist Mixture prior w weight of 0.25")

data_filtered_diff_not_zero_map_freq_mixture_w_0.25 <- data_map_freq_mixture_w_0.25 %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_map_freq_mixture_w_0.25 <- data_map_freq_mixture_w_0.25 %>%
  filter(median_control == median_treatment)

combined_data_diff_not_zero <- bind_rows(data_filtered_diff_not_zero_frequentist,
                                         data_filtered_diff_not_zero_map_freq,
                                         data_filtered_diff_not_zero_map_freq_mixture_w_0.15,
                                         data_filtered_diff_not_zero_map_freq_mixture_w_0.25)

combined_data_diff_zero <- bind_rows(data_filtered_diff_zero_frequentist,
                                     data_filtered_diff_zero_map_freq,
                                     data_filtered_diff_zero_map_freq_mixture_w_0.15,
                                     data_filtered_diff_zero_map_freq_mixture_w_0.25)

## Ahora sacamos las gráficas de las características operantes usando como prior el MAP frecuentista con pesos ##

# Este es el gráfico de las densidades de las prior que se han considerado 

# Parte informativa: MAP frecuentista
gamma_density_1 <- function(x, alpha, beta) {
  dgamma(x, shape=alpha, rate=beta)
}

# Parte no informativa (antigua)
gamma_density_2 <- function(x) {
  dgamma(x, shape=0.00001, rate=0.00001)
}

# La unión de las dos prior con peso prespecificado
mixture_density_1 <- function(x, w1, alpha, beta) {
  w1 * gamma_density_1(x, alpha, beta) + (1-w1) * gamma_density_2(x)
}

mixture_density_2 <- function(x, w2, alpha2, beta2) {
  w2 * gamma_density_3(x, alpha, beta) + (1-w2) * gamma_density_2(x)
}

# # Parámetros obtenidos del MAP frecuentista para la distribución Gamma
# alpha = alpha_map_freq
# beta = beta_map_freq
# 
# w1 = 0.15
# w2 = 0.25
# 
# x_seq <- seq(0, 20, length.out = 400)
# gamma1_densities <- gamma_density_1(x_seq, alpha, beta)
# gamma2_densities <- gamma_density_2(x_seq)
# mixture1_densities <- sapply(x_seq, function(x) mixture_density_1(x, w1, alpha, beta))
# mixture2_densities <- sapply(x_seq, function(x) mixture_density_2(x, w2, alpha, beta))
# 
# df <- data.frame(x = x_seq, 
#                  MAP_Frequentist = gamma1_densities, 
#                  Non_Informative = gamma2_densities,
#                  Mixture_weight_0.15 = mixture1_densities,
#                  Mixture_weight_0.25 = mixture2_densities)
# 
# ggplot(df, aes(x = x)) + 
#   geom_line(aes(y = MAP_Frequentist, color = "MAP_Frequentist")) + 
#   geom_line(aes(y = Non_Informative, color = "Non-Informative")) +
#   geom_line(aes(y = Mixture_weight_0.15, color = "Mixture_weight_0.15")) +
#   geom_line(aes(y = Mixture_weight_0.25, color = "Mixture_weight_0.25")) +
#   labs(title = "Gamma Pior Distributions and Their Mixtures", 
#        x = "x", 
#        y = "Density", 
#        color = "Density Legend") + 
#   theme_minimal()

# MSE

p6 <- ggplot(combined_data_diff_not_zero, aes(x = median_control, y = mean_MSE, color = Prior, linetype = Prior)) +
  geom_line() +
  geom_vline(xintercept = median_control_center, linetype = "dashed") +
  labs(title = "MSE", x = "Median Control", y = "Mean MSE") +
  theme_minimal()  + 
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 14, face = "bold"),
        axis.text = element_text(size = 12)) +
  scale_color_discrete(name = "Priors") +
  scale_linetype_discrete(name = "Priors") +
  scale_x_continuous(breaks = seq(min(combined_data_diff_not_zero$median_control), max(combined_data_diff_not_zero$median_control), by = 0.5)) +
  scale_y_continuous(limits = c(0, 0.075))
p6

# Power

p7 <- ggplot(combined_data_diff_not_zero, aes(x = median_control, y = prop_significant, color = Prior)) +
  geom_line() +
  geom_vline(xintercept = median_control_center, linetype = "dashed") +
  labs(title = "Power", x = "Median Control", y = "Prop. Significant") +
  theme_minimal() + 
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 14, face = "bold"),
        axis.text = element_text(size = 12)) +
  scale_color_discrete(name = "Priors") +
  scale_linetype_discrete(name = "Priors") +
  scale_x_continuous(breaks = seq(min(combined_data_diff_not_zero$median_control), max(combined_data_diff_not_zero$median_control), by = 0.5)) +
  scale_y_continuous(limits = c(0, 1))
p7

# ET1

p8 <- ggplot(combined_data_diff_zero, aes(x = median_control, y = prop_significant, color = Prior)) +
  geom_line() +
  geom_vline(xintercept = median_control_center, linetype = "dashed") +
  geom_hline(yintercept = 0.025, linetype = "dashed", color = "green") +
  geom_hline(yintercept = 0.05, linetype = "dashed", color = "purple") +
  labs(title = "Type I Error", x = "Median Control", y = "Prop. Significant") +
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 14, face = "bold"),
        axis.text = element_text(size = 12)) +
  scale_color_discrete(name = "Priors") +
  scale_linetype_discrete(name = "Priors") +
  scale_x_continuous(breaks = seq(min(combined_data_diff_zero$median_control), max(combined_data_diff_zero$median_control), by = 0.5)) +
  scale_y_continuous(limits = c(0, 0.5))
p8

```

Tras ver los resultados anteriores, se ha decidido ignorar el MAP frecuentista ya que al haber tan poca variabilidad entre estudios (y la poca cantidad de estudios) la parte informative sale muy informativa, inflando el error de tipo 1, incluso en las mixture con poco peso. Esto se ve afectado por lo poco informativa que es la parte no informativa, dejándose llevar por cualquier tipo de evidencia por poca fuerza que tenga en la likelihood.

Por eso, 

1) Vamos a usar un MAP Bayesiando en vez de frecuentista 

2) Se va a coger una prior no informativa mucho más robusta, es decir que no permita dejarse llevar por cualquier ruido por poco sentido que tenga. Por ello, se va a coger una prior Ga(1, 1/6), permitiendo rangos plausibles que van más allá de la duración permitida del estudio y permitiendo tomar cualquier valor, en ese rango posible, haciéndola no informativa. Por otro lado y desde el punto de vista logístico, esta prior más robusta permite tardar mucho menos tiempo (de 11h a 6h) a la hora de obtener resultados, porque el algoritmo de MCMC no tiene que evaluar tantos puntos en un rangio tan amplio.

A continuación se muestran los resultados incorporando esta nueva decisión.

```{r MAP_Bayes_Mixture_Prior_w , eval = T}

shape_parameter <- 1 

control_medians <- c(3.5,3.75,4,4.25,4.5,4.75,5,5.25,5.5,5.75,6,6.25,6.5,6.75,7,7.25,7.5)

medians <- matrix(NA, nrow = length(control_medians), ncol = 3, 
                  dimnames = list(NULL, c("Control", "Treatment", "Hazard Ratio")))

desired_HR = 0.55

for (i in 1:length(control_medians)) {
  medians[i, "Control"] <- control_medians[i]
  
  lambda_control = control_medians[i] / (log(2)^(1/shape_parameter))
  lambda_treatment = lambda_control / desired_HR^(1/shape_parameter)
  
  medians[i, "Treatment"] = lambda_treatment * (log(2)^(1/shape_parameter))
  medians[i, "Hazard Ratio"] = (lambda_control / lambda_treatment)^shape_parameter
}

medians <- medians[,1:2]
sample_size <- 300  
ratio <- c(0.5,0.5)
rand_type <- "CR" 
scenarios_eff <- as.matrix(medians, nrow = length(medians), ncol = 2, byrow = TRUE)
censor <- c(0.1,0.1)
Tmax <- 20
alpha <- 0.05 
test.type <- 2
HR_1 <- TRUE
IA <- NULL
method_IA <- "bayes"
n_exp_events <- 175
Plot_Power <- FALSE
plot_pvalues = FALSE 
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = TRUE

analysis = "bayes"
n_sim <- 2000
seed <- 24
# 1) Shape control, 2) rate control, 3) Shape experimental y 4) rate experimental
prior_gamma <- matrix(c(alpha_map_bayes, beta_map_bayes, 0.00001, 0.00001), nrow = 2, ncol = 2, byrow = TRUE) 
prior_type <- c("Mixture prior") # Este vector es para que aparezca el nombre en las tablas
P_HR_data_Boundary <- 0.8 # P(HR < 0.8 | data)
modelo_weibull_sep <- rstan::stan_model("weibull_mixture_gamma_def_ga_robust.stan" ,verbose = F) # Este es el STAN con Ga(1, 1/6)
#modelo_weibull_sep <- rstan::stan_model("weibull_mixture_gamma_mult_def.stan" ,verbose = F) # Aquí evitamos el logmix


modelo = modelo_weibull_sep
modelo_bayes_test = "weibull"
w = 0.15

# sim14 <-  sim_trials(n_sim = n_sim,
#                      analysis = "bayes",
#                      sample_size = sample_size,
#                      ratio = ratio,
#                      rand_type = rand_type,
#                      Tmax = Tmax,
#                      scenarios_eff = scenarios_eff,
#                      shape_parameter = shape_parameter,
#                      censor = censor,
#                      test.type = test.type,
#                      alpha = alpha,
#                      method_IA = method_IA,
#                      IA = IA,
#                      n_exp_events = n_exp_events,
#                      HR_1 = HR_1,
#                      Plot_Power = Plot_Power,
#                      modelo = modelo,
#                      modelo_bayes_test = modelo_bayes_test,
#                      prior_type = prior_type,
#                      P_HR_data_Boundary = P_HR_data_Boundary,
#                      prior_gamma = prior_gamma,
#                      Plot_Power_scenarios = Plot_Power_scenarios,
#                      desired_HRs = desired_HRs,
#                      plot_pvalues = plot_pvalues,
#                      Plot_Control_Scenarios = Plot_Control_Scenarios,
#                      w = w,
#                      seed = seed)
# 
# sim14[[2]]
# sim14[[3]]
# sim14[[4]]
# 
# sim140 <- sim14[[1]]
# 
# wd <- createWorkbook()
# addWorksheet(wd, "Sheet1")
# writeData(wd, "Sheet1", sim140)
# saveWorkbook(wd, "MAP_bayes_bayes_mixture_w_0.15_300_2000_HR_changing.xlsx", overwrite = TRUE)

## Leemos los datos de las tablas obtenidas con el ordenador de multicore ##

sheet_names <- c("Sheet1")

MAP_bayes_mixture_w_0.05_Ga_Robust <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/MAP_bayes_bayes_mixture_w_0.05_300_2000_Ninf11.xlsx", sheet = sheet_names[1])

MAP_bayes_mixture_w_0.1_Ga_Robust <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/MAP_bayes_bayes_mixture_w_0.1_300_2000_Ninfo11.xlsx", sheet = sheet_names[1])

MAP_bayes_mixture_w_0.15_Ga_Robust <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/MAP_bayes_bayes_mixture_w_0.15_300_2000_Ninfo11.xlsx", sheet = sheet_names[1])

MAP_bayes_mixture_w_0.2_Ga_Robust <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/MAP_bayes_bayes_mixture_w_0.2_300_2000_Ninf11.xlsx", sheet = sheet_names[1])

MAP_bayes_mixture_w_0.25_Ga_Robust <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/MAP_bayes_bayes_mixture_w_0.25_300_2000_Ninfo11_HR_changing.xlsx", sheet = sheet_names[1])

MAP_bayes_mixture_w_0.3_Ga_Robust <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/MAP_bayes_bayes_mixture_w_0.3_300_2000_Ninfo11.xlsx", sheet = sheet_names[1])

MAP_bayes_mixture_w_0.35_Ga_Robust <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/MAP_bayes_bayes_mixture_w_0.35_300_2000_Ninf11.xlsx", sheet = sheet_names[1])

MAP_bayes_mixture_w_0.4_Ga_Robust <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/MAP_bayes_bayes_mixture_w_0.4_300_2000_Ninfo11.xlsx", sheet = sheet_names[1])

MAP_bayes_mixture_w_0.45_Ga_Robust <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/MAP_bayes_bayes_mixture_w_0.45_300_2000_Ninfo11.xlsx", sheet = sheet_names[1])

MAP_bayes_mixture_w_0.5_Ga_Robust <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/MAP_bayes_bayes_mixture_w_0.5_300_2000_Ninfo11.xlsx", sheet = sheet_names[1])


## Ahora juntamos los datos para graficarlos ##

# MAP Bayes Mixture prior with weight 0.05

data_map_bayes_mixture_w_0.05 <- MAP_bayes_mixture_w_0.05_Ga_Robust %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "MAP Bayes Mixture prior w weight of 0.05")

data_filtered_diff_not_zero_map_bayes_mixture_w_0.05 <- data_map_bayes_mixture_w_0.05 %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_map_bayes_mixture_w_0.05 <- data_map_bayes_mixture_w_0.05 %>%
  filter(median_control == median_treatment)

# MAP Bayes Mixture prior with weight 0.1

data_map_bayes_mixture_w_0.1 <- MAP_bayes_mixture_w_0.1_Ga_Robust %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "MAP Bayes Mixture prior w weight of 0.1")

data_filtered_diff_not_zero_map_bayes_mixture_w_0.1 <- data_map_bayes_mixture_w_0.1 %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_map_bayes_mixture_w_0.1 <- data_map_bayes_mixture_w_0.1 %>%
  filter(median_control == median_treatment)

# MAP Bayes Mixture prior with weight 0.15

data_map_bayes_mixture_w_0.15 <- MAP_bayes_mixture_w_0.15_Ga_Robust %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "MAP Bayes Mixture prior w weight of 0.15")

data_filtered_diff_not_zero_map_bayes_mixture_w_0.15 <- data_map_bayes_mixture_w_0.15 %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_map_bayes_mixture_w_0.15 <- data_map_bayes_mixture_w_0.15 %>%
  filter(median_control == median_treatment)

# MAP Bayes Mixture prior with weight 0.2

data_map_bayes_mixture_w_0.2 <- MAP_bayes_mixture_w_0.2_Ga_Robust %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "MAP Bayes Mixture prior w weight of 0.2")

data_filtered_diff_not_zero_map_bayes_mixture_w_0.2 <- data_map_bayes_mixture_w_0.2 %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_map_bayes_mixture_w_0.2 <- data_map_bayes_mixture_w_0.2 %>%
  filter(median_control == median_treatment)

# MAP Bayes Mixture prior with weight 0.25

data_map_bayes_mixture_w_0.25 <- MAP_bayes_mixture_w_0.25_Ga_Robust %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "MAP Bayes Mixture prior w weight of 0.25")

data_filtered_diff_not_zero_map_bayes_mixture_w_0.25 <- data_map_bayes_mixture_w_0.25 %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_map_bayes_mixture_w_0.25 <- data_map_bayes_mixture_w_0.25 %>%
  filter(median_control == median_treatment)

# MAP Bayes Mixture prior with weight 0.3

data_map_bayes_mixture_w_0.3 <- MAP_bayes_mixture_w_0.3_Ga_Robust %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "MAP Bayes Mixture prior w weight of 0.3")

data_filtered_diff_not_zero_map_bayes_mixture_w_0.3 <- data_map_bayes_mixture_w_0.3 %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_map_bayes_mixture_w_0.3 <- data_map_bayes_mixture_w_0.3 %>%
  filter(median_control == median_treatment)

# MAP Bayes Mixture prior with weight 0.35

data_map_bayes_mixture_w_0.35 <- MAP_bayes_mixture_w_0.35_Ga_Robust %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "MAP Bayes Mixture prior w weight of 0.35")

data_filtered_diff_not_zero_map_bayes_mixture_w_0.35 <- data_map_bayes_mixture_w_0.35 %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_map_bayes_mixture_w_0.35 <- data_map_bayes_mixture_w_0.35 %>%
  filter(median_control == median_treatment)

# MAP Bayes Mixture prior with weight 0.4

data_map_bayes_mixture_w_0.4 <- MAP_bayes_mixture_w_0.4_Ga_Robust %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "MAP Bayes Mixture prior w weight of 0.4")

data_filtered_diff_not_zero_map_bayes_mixture_w_0.4 <- data_map_bayes_mixture_w_0.4 %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_map_bayes_mixture_w_0.4 <- data_map_bayes_mixture_w_0.4 %>%
  filter(median_control == median_treatment)

# MAP Bayes Mixture prior with weight 0.45

data_map_bayes_mixture_w_0.45 <- MAP_bayes_mixture_w_0.45_Ga_Robust %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "MAP Bayes Mixture prior w weight of 0.45")

data_filtered_diff_not_zero_map_bayes_mixture_w_0.45 <- data_map_bayes_mixture_w_0.45 %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_map_bayes_mixture_w_0.45 <- data_map_bayes_mixture_w_0.45 %>%
  filter(median_control == median_treatment)

# MAP Bayes Mixture prior with weight 0.5

data_map_bayes_mixture_w_0.5 <- MAP_bayes_mixture_w_0.5_Ga_Robust %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "MAP Bayes Mixture prior w weight of 0.5")

data_filtered_diff_not_zero_map_bayes_mixture_w_0.5 <- data_map_bayes_mixture_w_0.5 %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_map_bayes_mixture_w_0.5 <- data_map_bayes_mixture_w_0.5 %>%
  filter(median_control == median_treatment)


combined_data_diff_not_zero <- bind_rows(data_filtered_diff_not_zero_frequentist,
                                         data_filtered_diff_not_zero_map_bayes_mixture_w_0.05,
                                         data_filtered_diff_not_zero_map_bayes_mixture_w_0.1,
                                         data_filtered_diff_not_zero_map_bayes_mixture_w_0.15,
                                         data_filtered_diff_not_zero_map_bayes_mixture_w_0.2,
                                         data_filtered_diff_not_zero_map_bayes_mixture_w_0.25,
                                         data_filtered_diff_not_zero_map_bayes_mixture_w_0.3,
                                         data_filtered_diff_not_zero_map_bayes_mixture_w_0.35,
                                         data_filtered_diff_not_zero_map_bayes_mixture_w_0.4,
                                         data_filtered_diff_not_zero_map_bayes_mixture_w_0.45,
                                         data_filtered_diff_not_zero_map_bayes_mixture_w_0.5)

combined_data_diff_zero <- bind_rows(data_filtered_diff_zero_frequentist,
                                     data_filtered_diff_zero_map_bayes_mixture_w_0.05,
                                     data_filtered_diff_zero_map_bayes_mixture_w_0.1,
                                     data_filtered_diff_zero_map_bayes_mixture_w_0.15,
                                     data_filtered_diff_zero_map_bayes_mixture_w_0.2,
                                     data_filtered_diff_zero_map_bayes_mixture_w_0.25,
                                     data_filtered_diff_zero_map_bayes_mixture_w_0.3,
                                     data_filtered_diff_zero_map_bayes_mixture_w_0.35,
                                     data_filtered_diff_zero_map_bayes_mixture_w_0.4,
                                     data_filtered_diff_zero_map_bayes_mixture_w_0.45,
                                     data_filtered_diff_zero_map_bayes_mixture_w_0.5)

## Ahora sacamos las gráficas de las características operantes usando como prior el MAP Bayesiano con pesos ##

# Este es el gráfico de las densidades de las prior que se han considerado 

# Parte informativa: MAP Bayes
gamma_density_1 <- function(x, alpha, beta) {
  dgamma(x, shape=alpha, rate=beta)
}

# Parte no informativa (robusta)
gamma_density_2 <- function(x) {
  dgamma(x, shape=1, rate=1/6)
}

# La unión de las dos prior con peso prespecificado
mixture_density <- function(x, w1, alpha, beta) {
  w1 * gamma_density_1(x, alpha, beta) + (1-w1) * gamma_density_2(x)
}

# Parámetros obtenidos del MAP frecuentista para la distribución Gamma
alpha = alpha_map_bayes
beta = beta_map_bayes

w1 = 0.05; w2 = 0.1; w3 = 0.15; w4 = 0.2; w5 = 0.25; w6 = 0.3; w7 = 0.35; w8 = 0.4; w9 = 0.45; w10 = 0.5

x_seq <- seq(0, 20, length.out = 400)
gamma1_densities <- gamma_density_1(x_seq, alpha, beta)
gamma2_densities <- gamma_density_2(x_seq)
mixture1_densities <- sapply(x_seq, function(x) mixture_density(x, w1, alpha, beta))
mixture2_densities <- sapply(x_seq, function(x) mixture_density(x, w2, alpha, beta))
mixture3_densities <- sapply(x_seq, function(x) mixture_density(x, w3, alpha, beta))
mixture4_densities <- sapply(x_seq, function(x) mixture_density(x, w4, alpha, beta))
mixture5_densities <- sapply(x_seq, function(x) mixture_density(x, w5, alpha, beta))
mixture6_densities <- sapply(x_seq, function(x) mixture_density(x, w6, alpha, beta))
mixture7_densities <- sapply(x_seq, function(x) mixture_density(x, w7, alpha, beta))
mixture8_densities <- sapply(x_seq, function(x) mixture_density(x, w8, alpha, beta))
mixture9_densities <- sapply(x_seq, function(x) mixture_density(x, w9, alpha, beta))
mixture10_densities <- sapply(x_seq, function(x) mixture_density(x, w10, alpha, beta))

df <- data.frame(x = x_seq, 
                 MAP_Bayes = gamma1_densities, 
                 Non_Informative = gamma2_densities,
                 Mixture_weight_0.05 = mixture1_densities,
                 Mixture_weight_0.1 = mixture2_densities,
                 Mixture_weight_0.15 = mixture3_densities,
                 Mixture_weight_0.2 = mixture4_densities,
                 Mixture_weight_0.25 = mixture5_densities,
                 Mixture_weight_0.3 = mixture6_densities,
                 Mixture_weight_0.35 = mixture7_densities,
                 Mixture_weight_0.4 = mixture8_densities,
                 Mixture_weight_0.45 = mixture9_densities,
                 Mixture_weight_0.5 = mixture10_densities)

ggplot(df, aes(x = x)) +  
  geom_line(size = 1.2, aes(y = MAP_Bayes, color = "Bayesian Meta-Analysis Prior")) + 
  geom_line(size = 1.2, aes(y = Non_Informative, color = "Non-Informative Prior")) +
  geom_line(size = 1.2, aes(y = Mixture_weight_0.05, color = "Robust MAP Prior w=0.05")) +
  geom_line(size = 1.2, aes(y = Mixture_weight_0.1, color = "Robust MAP Prior w=0.1")) +
  geom_line(size = 1.2, aes(y = Mixture_weight_0.15, color = "Robust MAP Prior w=0.15")) +
  geom_line(size = 1.2, aes(y = Mixture_weight_0.2, color = "Robust MAP Prior w=0.2")) +
  geom_line(size = 1.2, aes(y = Mixture_weight_0.25, color = "Robust MAP Prior w=0.25")) +
  geom_line(size = 1.2, aes(y = Mixture_weight_0.3, color = "Robust MAP Prior w=0.3")) +
  geom_line(size = 1.2, aes(y = Mixture_weight_0.35, color = "Robust MAP Prior w=0.35")) +
  geom_line(size = 1.2, aes(y = Mixture_weight_0.4, color = "Robust MAP Prior w=0.4")) +
  geom_line(size = 1.2, aes(y = Mixture_weight_0.45, color = "Robust MAP Prior w=0.45")) +
  geom_line(size = 1.2, aes(y = Mixture_weight_0.5, color = "Robust MAP Prior w=0.5")) +
  labs(title = "Gamma Pior Distributions", 
       x = "Scale Parameter for the Control Arm", 
       y = "Density", 
       color = "Scale Prior Distributions") + 
  theme_minimal()

# MSE

p6 <- ggplot(combined_data_diff_not_zero, aes(x = median_control, y = mean_MSE, color = Prior, linetype = Prior)) +
  geom_line() +
  geom_vline(xintercept = median_control_center, linetype = "dashed") +
  labs(title = "MSE", x = "Median Control", y = "Mean MSE") +
  theme_minimal()  + 
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 14, face = "bold"),
        axis.text = element_text(size = 12)) +
  scale_color_discrete(name = "Priors") +
  scale_linetype_discrete(name = "Priors") +
  scale_x_continuous(breaks = seq(min(combined_data_diff_not_zero$median_control), max(combined_data_diff_not_zero$median_control), by = 0.5)) +
  scale_y_continuous(limits = c(0, 0.075))
p6

# Power

p7 <- ggplot(combined_data_diff_not_zero, aes(x = median_control, y = prop_significant, color = Prior)) +
  geom_line() +
  geom_vline(xintercept = median_control_center, linetype = "dashed") +
  labs(title = "Power", x = "Median Control", y = "Prop. Significant") +
  theme_minimal() + 
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 14, face = "bold"),
        axis.text = element_text(size = 12)) +
  scale_color_discrete(name = "Priors") +
  scale_linetype_discrete(name = "Priors") +
  scale_x_continuous(breaks = seq(min(combined_data_diff_not_zero$median_control), max(combined_data_diff_not_zero$median_control), by = 0.5)) +
  scale_y_continuous(limits = c(0, 1))
p7

# ET1

p8 <- ggplot(combined_data_diff_zero, aes(x = median_control, y = prop_significant, color = Prior)) +
  geom_line() +
  geom_vline(xintercept = median_control_center, linetype = "dashed") +
  geom_hline(yintercept = 0.025, linetype = "dashed", color = "green") +
  geom_hline(yintercept = 0.05, linetype = "dashed", color = "purple") +
  labs(title = "Type I Error", x = "Median Control", y = "Prop. Significant") +
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 14, face = "bold"),
        axis.text = element_text(size = 12)) +
  scale_color_discrete(name = "Priors") +
  scale_linetype_discrete(name = "Priors") +
  scale_x_continuous(breaks = seq(min(combined_data_diff_zero$median_control), max(combined_data_diff_zero$median_control), by = 0.5)) +
  scale_y_continuous(limits = c(0, 0.2))
p8

```

En los resultados anteriores hemos visto un amplio rango de priors donde mediante una mixture, se ha propuesto una prior híbrida uniendo la parte informativa obtenida del MAP Bayesiano y la Parte no informativa con una Ga(1, 1/6). Para evaluar este rango, se han propuesto diferentes pesos que van desde el 0 (siendo esto simplemente una prior no informativa), hasta un peso del 0.5 yendo de 0.05 en 0.05. 

No se han valorado pesos más altos para la parte informativo porque no es algo que sea realista a la hora de hacer una propuesta seria, ya que no se aceptaría desde un punto de vista regulatorio. De todos modos, viendo valores de w con 0.45 y 0.5, vemos que el ET1 se infla en algunos puntos cuando la mediana es mayor de lo previsto en el tamaño muestral.

Con estos resultados, escoger una prior con pesos inferiores a 0.4 es realista ya que en estos escenarios cogiendo las asunciones del tamaño muestral, no se inflaría para un rango considerable.

Ahora hacemos lo mismo pero moviendo el HR en vez de la mediana del brazo control:
  
```{r `Mixture_Cambiando_HRs `, eval = T}

# Por ejemplo, con peso 0.15

shape_parameter <- 1 

desired_HRs <- c(1.3, 1.2, 1.1, 1, 0.95, 0.9, 0.85, 0.8, 0.775, 0.75, 0.725, 0.7, 0.675, 0.65, 0.625, 0.6, 0.575, 0.55, 0.525, 0.5, 0.45, 0.4, 0.35, 0.3)
control_medians <- rep(5.5, times = length(desired_HRs))

medians_control_fijo <- matrix(NA, nrow = length(desired_HRs), ncol = 2, dimnames = list(paste0("HR ", desired_HRs), c("Control", "Treatment")))

for (i in 1:length(desired_HRs)) {
  medians_control_fijo[i, "Treatment"] <- control_medians[i] / (desired_HRs[i]^(1/shape_parameter))
  medians_control_fijo[i, "Control"] <- control_medians[i]
}

sample_size <- 300  
ratio <- c(0.5,0.5)
rand_type <- "CR" 
scenarios_eff <- as.matrix(medians_control_fijo, nrow = dim(medians_control_fijo)[1], ncol = 2, byrow = TRUE)
censor <- c(0.1,0.1)
Tmax <- 20
alpha <- 0.05 
test.type <- 2
HR_1 <- FALSE
IA <- NULL
method_IA <- "bayes"
n_exp_events <- 175
Plot_Power <- FALSE
plot_pvalues = FALSE 
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = FALSE

analysis = "bayes"
n_sim <- 2000
seed <- 24
# 1) Shape control, 2) rate control, 3) Shape experimental y 4) rate experimental
prior_gamma <- matrix(c(alpha_map_bayes, beta_map_bayes, 1, 1/6), nrow = 2, ncol = 2, byrow = TRUE) 
prior_type <- c("Mixture prior with w 0.15") # Este vector es para que aparezca el nombre en las tablas
P_HR_data_Boundary <- 0.8 # P(HR < 0.8 | data)
modelo_weibull_sep <- rstan::stan_model("weibull_gamma_def.stan" ,verbose = F)
modelo = modelo_weibull_sep
modelo_bayes_test = "weibull"
w = 0.15

# sim16 <-  sim_trials(n_sim = n_sim,
#                      analysis = "bayes",
#                      sample_size = sample_size,
#                      ratio = ratio,
#                      rand_type = rand_type,
#                      Tmax = Tmax,
#                      scenarios_eff = scenarios_eff,
#                      shape_parameter = shape_parameter,
#                      censor = censor,
#                      test.type = test.type,
#                      alpha = alpha,
#                      method_IA = method_IA,
#                      IA = IA,
#                      n_exp_events = n_exp_events,
#                      HR_1 = HR_1,
#                      Plot_Power = Plot_Power,
#                      modelo = modelo,
#                      modelo_bayes_test = modelo_bayes_test,
#                      prior_type = prior_type,
#                      P_HR_data_Boundary = P_HR_data_Boundary,
#                      prior_gamma = prior_gamma,
#                      Plot_Power_scenarios = Plot_Power_scenarios,
#                      desired_HRs = desired_HRs,
#                      plot_pvalues = plot_pvalues,
#                      Plot_Control_Scenarios = Plot_Control_Scenarios,                     
#                      w = w,
#                      seed = seed)

## Leemos los datos de las tablas obtenidas con el ordenador de multicore ##

sheet_names <- c("Sheet1")

MAP_bayes_mixture_w_0.05_Ga_Robust_HR_changing <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/MAP_bayes_bayes_mixture_w_0.05_300_2000_Ninfo11_diferente_HR.xlsx", sheet = sheet_names[1])

MAP_bayes_mixture_w_0.1_Ga_Robust_HR_changing <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/MAP_bayes_bayes_mixture_w_0.1_300_2000_Ninfo11_diferente_HR.xlsx", sheet = sheet_names[1])

MAP_bayes_mixture_w_0.15_Ga_Robust_HR_changing <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/MAP_bayes_bayes_mixture_w_0.15_300_2000_Ninfo11_diferente_HR.xlsx", sheet = sheet_names[1])

MAP_bayes_mixture_w_0.2_Ga_Robust_HR_changing <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/MAP_bayes_bayes_mixture_w_0.2_300_2000_Ninfo11_diferente_HR.xlsx", sheet = sheet_names[1])

MAP_bayes_mixture_w_0.25_Ga_Robust_HR_changing <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/MAP_bayes_bayes_mixture_w_0.25_300_2000_Ninfo11_diferente_HR.xlsx", sheet = sheet_names[1])

MAP_bayes_mixture_w_0.3_Ga_Robust_HR_changing <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/MAP_bayes_bayes_mixture_w_0.3_300_2000_Ninfo11_diferente_HR.xlsx", sheet = sheet_names[1])

MAP_bayes_mixture_w_0.35_Ga_Robust_HR_changing <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/MAP_bayes_bayes_mixture_w_0.35_300_2000_Ninfo11_diferente_HR.xlsx", sheet = sheet_names[1])

MAP_bayes_mixture_w_0.4_Ga_Robust_HR_changing <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/MAP_bayes_bayes_mixture_w_0.4_300_2000_Ninfo11_diferente_HR.xlsx", sheet = sheet_names[1])

MAP_bayes_mixture_w_0.45_Ga_Robust_HR_changing <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/MAP_bayes_bayes_mixture_w_0.45_300_2000_Ninfo11_diferente_HR.xlsx", sheet = sheet_names[1])

MAP_bayes_mixture_w_0.5_Ga_Robust_HR_changing <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/MAP_bayes_bayes_mixture_w_0.5_300_2000_Ninfo11_diferente_HR.xlsx", sheet = sheet_names[1])

## Ahora juntamos los datos para graficarlos ##

# MAP Bayes Mixture prior with weight 0.05

data_map_bayes_mixture_w_0.05_HR_changing <- MAP_bayes_mixture_w_0.05_Ga_Robust_HR_changing %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "MAP Bayes Mixture prior w weight of 0.05")

# MAP Bayes Mixture prior with weight 0.1

data_map_bayes_mixture_w_0.1_HR_changing <- MAP_bayes_mixture_w_0.1_Ga_Robust_HR_changing %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "MAP Bayes Mixture prior w weight of 0.1")

# MAP Bayes Mixture prior with weight 0.15

data_map_bayes_mixture_w_0.15_HR_changing <- MAP_bayes_mixture_w_0.15_Ga_Robust_HR_changing %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "MAP Bayes Mixture prior w weight of 0.15")

# MAP Bayes Mixture prior with weight 0.2

data_map_bayes_mixture_w_0.2_HR_changing <- MAP_bayes_mixture_w_0.2_Ga_Robust_HR_changing %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "MAP Bayes Mixture prior w weight of 0.2")


# MAP Bayes Mixture prior with weight 0.25

data_map_bayes_mixture_w_0.25_HR_changing <- MAP_bayes_mixture_w_0.25_Ga_Robust_HR_changing %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "MAP Bayes Mixture prior w weight of 0.25")


# MAP Bayes Mixture prior with weight 0.3

data_map_bayes_mixture_w_0.3_HR_changing <- MAP_bayes_mixture_w_0.3_Ga_Robust_HR_changing %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "MAP Bayes Mixture prior w weight of 0.3")


# MAP Bayes Mixture prior with weight 0.35

data_map_bayes_mixture_w_0.35_HR_changing <- MAP_bayes_mixture_w_0.35_Ga_Robust_HR_changing %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "MAP Bayes Mixture prior w weight of 0.35")


# MAP Bayes Mixture prior with weight 0.4

data_map_bayes_mixture_w_0.4_HR_changing <- MAP_bayes_mixture_w_0.4_Ga_Robust_HR_changing %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "MAP Bayes Mixture prior w weight of 0.4")

# MAP Bayes Mixture prior with weight 0.45

data_map_bayes_mixture_w_0.45_HR_changing <- MAP_bayes_mixture_w_0.45_Ga_Robust_HR_changing %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "MAP Bayes Mixture prior w weight of 0.45")


# MAP Bayes Mixture prior with weight 0.5

data_map_bayes_mixture_w_0.5_HR_changing <- MAP_bayes_mixture_w_0.5_Ga_Robust_HR_changing %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "MAP Bayes Mixture prior w weight of 0.5")


combined_data_mixture_HR_changing <- bind_rows(data_sim3_results,
                                               data_informative_gamma_3.5, 
                                               data_informative_gamma_5.5, 
                                               data_informative_gamma_7.5,
                                               data_map_bayes_mixture_w_0.05_HR_changing,
                                               data_map_bayes_mixture_w_0.1_HR_changing,
                                               data_map_bayes_mixture_w_0.15_HR_changing,
                                               data_map_bayes_mixture_w_0.2_HR_changing,
                                               data_map_bayes_mixture_w_0.25_HR_changing,
                                               data_map_bayes_mixture_w_0.3_HR_changing,
                                               data_map_bayes_mixture_w_0.35_HR_changing,
                                               data_map_bayes_mixture_w_0.4_HR_changing,
                                               data_map_bayes_mixture_w_0.45_HR_changing,
                                               data_map_bayes_mixture_w_0.5_HR_changing)

combined_data_mixture_HR_changing <- combined_data_mixture_HR_changing %>%
  group_by(Prior) %>%
  mutate(desired_HRs = (desired_HRs))

combined_data_mixture_HR_changing <- combined_data_mixture_HR_changing %>%
  mutate(diff_HR = abs(mean_HR - desired_HRs))

## Ahora sacamos las gráficas de las características operantes usando como prior el MAP Bayesiano con pesos ##

p6 <- ggplot(combined_data_mixture_HR_changing, aes(x = desired_HRs, y = prop_significant, group = Prior, color = Prior)) +
  geom_point(size = 3) +
  geom_line(linewidth = 1) +
  geom_vline(xintercept = 1, linetype = "dashed", color = "red", size = 1) +
  geom_vline(xintercept = 0.55, linetype = "dashed", color = "red", size = 1) +
  geom_vline(xintercept = 0.5, linetype = "dashed", color = "red", size = 1) +
  geom_hline(yintercept = c(0.8, 0.9), linetype = "dotted", color = c("purple", "green"), size = 1) +
  scale_x_continuous(breaks = seq(min(combined_data_mixture_HR_changing$desired_HRs), max(combined_data_mixture_HR_changing$desired_HRs), 0.1), labels = sprintf("%.2f", seq(min(combined_data_mixture_HR_changing$desired_HRs), max(combined_data_mixture_HR_changing$desired_HRs), 0.1))) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Power vs Hazard Ratio w mixture prior",
       x = "Theoretical Hazard Ratio",
       y = "Power") +
  theme_minimal() +
  theme(plot.title = element_text(size = 12, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 10),
        legend.position = "right")

p6 <- p6 +
  annotate("text", x = max(combined_data_mixture_HR_changing$desired_HRs), y = 0.8, label = "80% power", hjust = 1, vjust = -0.5, size = 3.5, color = "purple") +
  annotate("text", x = max(combined_data_mixture_HR_changing$desired_HRs), y = 0.9, label = "90% power", hjust = 1, vjust = -0.5, size = 3.5, color = "green") +
  geom_label(aes(x = 1, y = Inf, label = "H0"), vjust = 2, color = "black", fill = "white", size = 3.5, label.size = 0, fontface = "bold") +
  geom_label(aes(x = 0.55, y = Inf, label = "H1"), vjust = 2, color = "black", fill = "white", size = 3.5, label.size = 0, fontface = "bold") +
  geom_label(aes(x = 0.5, y = Inf, label = "Real HR"), vjust = 2, color = "black", fill = "white", size = 3.5, label.size = 0, fontface = "bold")

p6

# Graficamos las diferencias

p7 <- ggplot(combined_data_mixture_HR_changing, aes(x = desired_HRs, y = diff_HR, color = Prior)) +
  geom_point(size = 3) +
  geom_line(aes(group = Prior), linewidth = 1) +
  scale_x_continuous(breaks = seq(min(combined_data_mixture_HR_changing$desired_HRs), max(combined_data_mixture_HR_changing$desired_HRs), 0.1), labels = sprintf("%.2f", seq(min(combined_data_mixture_HR_changing$desired_HRs), max(combined_data_mixture_HR_changing$desired_HRs), 0.1))) +
  labs(title = "Diff btw Simulated HR and Theoretical HRs w prior mixture",
       x = "Theoretical Hazard Ratio",
       y = "Difference") +
  theme_minimal() +
  theme(plot.title = element_text(size = 8, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 6, face = "bold"),
        axis.text = element_text(size = 6),
        legend.position = "right")

p7


```

Como era de esperar, todos los resultados son iguales porque estamos usando la misma prior moviendo los HRs a diferencia de los anteriores gráficos donde hacíamos la prior informativa en diferentes puntos de la mediana para el brazo control. Sólo se ve rosa porque es el último en dibujarse pero el resto están debajo porque todos los resultados son iguales.

Como nota, se ha investigado modificar los parámetros de la prior para el brazo tratamiento, usando ahora una Ga(1,1/6) en vez de la Ga(0.00001, 0.00001) como se ha hecho hasta ahora.

Por otro lado, he hecho los mismos análisis para todos los pesos usando una Ga(1,1/6) para los dos brazos para la parte no informativa y también, una distribución más robusta y realista del parametro shape. Ahora para el shape de la regresión Weibull usamos una Uniforme(0.1, 4) en vez de la Ga(0.00001, 0.00001). Esta distribución es mucho más robusta y facilita los cálculos disminuyendo hasta en 1h30 los cálculos. Recordar que todos los valores del shape van a estar en el 0.7 y el 1.3 por lo que es factible.

Las tablas para todos los pesos para ver cuál protege más el ET1 están en Excel en la carpeta "PEMBROLIZUMAB_NSCLC_TABLAS" de este entorno.

He comparado viendo los diferentes resultados para cada uno de los pesos y haciendo un análisis descriptivo. Las diferencias son mínimas (de 3-4 décimas) pero sale un poquito mejor en términos de ET1 con una pérdida pequeñísima de poder usando una Ga(1,1/6) para los dos brazos y una U(0.1, 4) para el shape. Sin embargo, como parte muy positiva es que tiene mucho mejor rendimiento en términos de tiempo estas nuevas priors (1h30 menos que es bastante).

A continuación muestro las características operantes usando estos parámetros para las 3 variables aleatorias que entran en juego, brazo control, experimental y shape parameter de la weibull.

```{r MAP_Bayes_Mixture_Prior_w_parametros_robustos , eval = T}

shape_parameter <- 1 

control_medians <- c(3.5,3.75,4,4.25,4.5,4.75,5,5.25,5.5,5.75,6,6.25,6.5,6.75,7,7.25,7.5)

medians <- matrix(NA, nrow = length(control_medians), ncol = 3, 
                  dimnames = list(NULL, c("Control", "Treatment", "Hazard Ratio")))

desired_HR = 0.55

for (i in 1:length(control_medians)) {
  medians[i, "Control"] <- control_medians[i]
  
  lambda_control = control_medians[i] / (log(2)^(1/shape_parameter))
  lambda_treatment = lambda_control / desired_HR^(1/shape_parameter)
  
  medians[i, "Treatment"] = lambda_treatment * (log(2)^(1/shape_parameter))
  medians[i, "Hazard Ratio"] = (lambda_control / lambda_treatment)^shape_parameter
}

medians <- medians[,1:2]
sample_size <- 300  
ratio <- c(0.5,0.5)
rand_type <- "CR" 
scenarios_eff <- as.matrix(medians, nrow = length(medians), ncol = 2, byrow = TRUE)
censor <- c(0.1,0.1)
Tmax <- 20
alpha <- 0.05 
test.type <- 2
HR_1 <- TRUE
IA <- NULL
method_IA <- "bayes"
n_exp_events <- 175
Plot_Power <- FALSE
plot_pvalues = FALSE 
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = TRUE

analysis = "bayes"
n_sim <- 2000
seed <- 24
# 1) Shape control, 2) rate control, 3) Shape experimental y 4) rate experimental
prior_gamma <- matrix(c(alpha_map_bayes, beta_map_bayes, 1, 1/6), nrow = 2, ncol = 2, byrow = TRUE) 
prior_type <- c("Mixture prior") # Este vector es para que aparezca el nombre en las tablas
P_HR_data_Boundary <- 0.8 # P(HR < 0.8 | data)
modelo_weibull_sep <- rstan::stan_model("weibull_mixture_gamma_sh_uniform.stan" ,verbose = F) # Este es el STAN con Ga(1, 1/6)
#modelo_weibull_sep <- rstan::stan_model("weibull_mixture_gamma_mult_def.stan" ,verbose = F) # Aquí evitamos el logmix


modelo = modelo_weibull_sep
modelo_bayes_test = "weibull"
w = 0.15

# sim14 <-  sim_trials(n_sim = n_sim,
#                      analysis = "bayes",
#                      sample_size = sample_size,
#                      ratio = ratio,
#                      rand_type = rand_type,
#                      Tmax = Tmax,
#                      scenarios_eff = scenarios_eff,
#                      shape_parameter = shape_parameter,
#                      censor = censor,
#                      test.type = test.type,
#                      alpha = alpha,
#                      method_IA = method_IA,
#                      IA = IA,
#                      n_exp_events = n_exp_events,
#                      HR_1 = HR_1,
#                      Plot_Power = Plot_Power,
#                      modelo = modelo,
#                      modelo_bayes_test = modelo_bayes_test,
#                      prior_type = prior_type,
#                      P_HR_data_Boundary = P_HR_data_Boundary,
#                      prior_gamma = prior_gamma,
#                      Plot_Power_scenarios = Plot_Power_scenarios,
#                      desired_HRs = desired_HRs,
#                      plot_pvalues = plot_pvalues,
#                      Plot_Control_Scenarios = Plot_Control_Scenarios,
#                      w = w,
#                      seed = seed)
# 
# sim14[[2]]
# sim14[[3]]
# sim14[[4]]
# 
# sim140 <- sim14[[1]]
# 
# wd <- createWorkbook()
# addWorksheet(wd, "Sheet1")
# writeData(wd, "Sheet1", sim140)
# saveWorkbook(wd, "MAP_bayes_bayes_mixture_w_0.15_300_2000_HR_changing.xlsx", overwrite = TRUE)

## Leemos los datos de las tablas obtenidas con el ordenador de multicore ##

sheet_names <- c("Sheet1")

# Tiempo = 08h36m43s
MAP_bayes_mixture_w_0.05_def <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/MAP_bayes_bayes_mixture_w_0.05_300_2000_Ninfo112_Shape_uni.xlsx", sheet = sheet_names[1])

# Tiempo = 09h48m28s
MAP_bayes_mixture_w_0.1_def <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/MAP_bayes_bayes_mixture_w_0.1_300_2000_Ninfo112_Shape_uni.xlsx", sheet = sheet_names[1])

# Tiempo = 08h23m03s
MAP_bayes_mixture_w_0.15_def <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/MAP_bayes_bayes_mixture_w_0.15_300_2000_Ninfo112_Shape_uni.xlsx", sheet = sheet_names[1])

# Tiempo = 08h41m02s
MAP_bayes_mixture_w_0.2_def <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/MAP_bayes_bayes_mixture_w_0.2_300_2000_Ninfo112_Shape_uni.xlsx", sheet = sheet_names[1])

# Tiempo = 09h50m23s
MAP_bayes_mixture_w_0.25_def <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/MAP_bayes_bayes_mixture_w_0.25_300_2000_Ninfo112_Shape_uni.xlsx", sheet = sheet_names[1])

# Tiempo = 08h31m59s
MAP_bayes_mixture_w_0.3_def <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/MAP_bayes_bayes_mixture_w_0.3_300_2000_Ninfo112_Shape_uni.xlsx", sheet = sheet_names[1])

# Tiempo = 08h34m33s
MAP_bayes_mixture_w_0.35_def <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/MAP_bayes_bayes_mixture_w_0.35_300_2000_Ninfo112_Shape_uni.xlsx", sheet = sheet_names[1])

# Tiempo = 09h50m57s
MAP_bayes_mixture_w_0.4_def <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/MAP_bayes_bayes_mixture_w_0.4_300_2000_Ninfo112_Shape_uni.xlsx", sheet = sheet_names[1])

# Tiempo = 08h25m10s
MAP_bayes_mixture_w_0.45_def <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/MAP_bayes_bayes_mixture_w_0.45_300_2000_Ninfo112_Shape_uni.xlsx", sheet = sheet_names[1])

# Tiempo = 06h45m04s
MAP_bayes_mixture_w_0.5_def <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/MAP_bayes_bayes_mixture_w_0.5_300_2000_Ninfo112_Shape_uni.xlsx", sheet = sheet_names[1])


## Ahora juntamos los datos para graficarlos ##

# MAP Bayes Mixture prior with weight 0.05

data_map_bayes_mixture_w_0.05_def <- MAP_bayes_mixture_w_0.05_def %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "Robust MAP Prior w=0.05")

data_filtered_diff_not_zero_map_bayes_mixture_w_0.05_def <- data_map_bayes_mixture_w_0.05_def %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_map_bayes_mixture_w_0.05_def <- data_map_bayes_mixture_w_0.05_def %>%
  filter(median_control == median_treatment)

# MAP Bayes Mixture prior with weight 0.1

data_map_bayes_mixture_w_0.1_def <- MAP_bayes_mixture_w_0.1_def %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "Robust MAP Prior w=0.1")

data_filtered_diff_not_zero_map_bayes_mixture_w_0.1_def <- data_map_bayes_mixture_w_0.1_def %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_map_bayes_mixture_w_0.1_def <- data_map_bayes_mixture_w_0.1_def %>%
  filter(median_control == median_treatment)

# MAP Bayes Mixture prior with weight 0.15

data_map_bayes_mixture_w_0.15_def <- MAP_bayes_mixture_w_0.15_def %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "Robust MAP Prior w=0.15")

data_filtered_diff_not_zero_map_bayes_mixture_w_0.15_def <- data_map_bayes_mixture_w_0.15_def %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_map_bayes_mixture_w_0.15_def <- data_map_bayes_mixture_w_0.15_def %>%
  filter(median_control == median_treatment)

# MAP Bayes Mixture prior with weight 0.2

data_map_bayes_mixture_w_0.2_def <- MAP_bayes_mixture_w_0.2_def %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "Robust MAP Prior w=0.2")

data_filtered_diff_not_zero_map_bayes_mixture_w_0.2_def <- data_map_bayes_mixture_w_0.2_def %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_map_bayes_mixture_w_0.2_def <- data_map_bayes_mixture_w_0.2_def %>%
  filter(median_control == median_treatment)

# MAP Bayes Mixture prior with weight 0.25

data_map_bayes_mixture_w_0.25_def <- MAP_bayes_mixture_w_0.25_def %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "Robust MAP Prior w=0.25")

data_filtered_diff_not_zero_map_bayes_mixture_w_0.25_def <- data_map_bayes_mixture_w_0.25_def %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_map_bayes_mixture_w_0.25_def <- data_map_bayes_mixture_w_0.25_def %>%
  filter(median_control == median_treatment)

# MAP Bayes Mixture prior with weight 0.3

data_map_bayes_mixture_w_0.3_def <- MAP_bayes_mixture_w_0.3_def %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "Robust MAP Prior w=0.3")

data_filtered_diff_not_zero_map_bayes_mixture_w_0.3_def <- data_map_bayes_mixture_w_0.3_def %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_map_bayes_mixture_w_0.3_def <- data_map_bayes_mixture_w_0.3_def %>%
  filter(median_control == median_treatment)

# MAP Bayes Mixture prior with weight 0.35

data_map_bayes_mixture_w_0.35_def <- MAP_bayes_mixture_w_0.35_def %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "Robust MAP Prior w=0.35")

data_filtered_diff_not_zero_map_bayes_mixture_w_0.35_def <- data_map_bayes_mixture_w_0.35_def %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_map_bayes_mixture_w_0.35_def <- data_map_bayes_mixture_w_0.35_def %>%
  filter(median_control == median_treatment)

# MAP Bayes Mixture prior with weight 0.4

data_map_bayes_mixture_w_0.4_def <- MAP_bayes_mixture_w_0.4_def %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "Robust MAP Prior w=0.4")

data_filtered_diff_not_zero_map_bayes_mixture_w_0.4_def <- data_map_bayes_mixture_w_0.4_def %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_map_bayes_mixture_w_0.4_def <- data_map_bayes_mixture_w_0.4_def %>%
  filter(median_control == median_treatment)

# MAP Bayes Mixture prior with weight 0.45

data_map_bayes_mixture_w_0.45_def <- MAP_bayes_mixture_w_0.45_def %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "Robust MAP Prior w=0.45")

data_filtered_diff_not_zero_map_bayes_mixture_w_0.45_def <- data_map_bayes_mixture_w_0.45_def %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_map_bayes_mixture_w_0.45_def <- data_map_bayes_mixture_w_0.45_def %>%
  filter(median_control == median_treatment)

# MAP Bayes Mixture prior with weight 0.5

data_map_bayes_mixture_w_0.5_def <- MAP_bayes_mixture_w_0.5_def %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "Robust MAP Prior w=0.5")

data_filtered_diff_not_zero_map_bayes_mixture_w_0.5_def <- data_map_bayes_mixture_w_0.5_def %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_map_bayes_mixture_w_0.5_def <- data_map_bayes_mixture_w_0.5_def %>%
  filter(median_control == median_treatment)


combined_data_diff_not_zero <- bind_rows(data_filtered_diff_not_zero_frequentist,
                                         data_filtered_diff_not_zero_map_bayes_mixture_w_0.05_def,
                                         data_filtered_diff_not_zero_map_bayes_mixture_w_0.1_def,
                                         data_filtered_diff_not_zero_map_bayes_mixture_w_0.15_def,
                                         data_filtered_diff_not_zero_map_bayes_mixture_w_0.2_def,
                                         data_filtered_diff_not_zero_map_bayes_mixture_w_0.25_def,
                                         data_filtered_diff_not_zero_map_bayes_mixture_w_0.3_def,
                                         data_filtered_diff_not_zero_map_bayes_mixture_w_0.35_def,
                                         data_filtered_diff_not_zero_map_bayes_mixture_w_0.4_def,
                                         data_filtered_diff_not_zero_map_bayes_mixture_w_0.45_def,
                                         data_filtered_diff_not_zero_map_bayes_mixture_w_0.5_def)

combined_data_diff_zero <- bind_rows(data_filtered_diff_zero_frequentist,
                                     data_filtered_diff_zero_map_bayes_mixture_w_0.05_def,
                                     data_filtered_diff_zero_map_bayes_mixture_w_0.1_def,
                                     data_filtered_diff_zero_map_bayes_mixture_w_0.15_def,
                                     data_filtered_diff_zero_map_bayes_mixture_w_0.2_def,
                                     data_filtered_diff_zero_map_bayes_mixture_w_0.25_def,
                                     data_filtered_diff_zero_map_bayes_mixture_w_0.3_def,
                                     data_filtered_diff_zero_map_bayes_mixture_w_0.35_def,
                                     data_filtered_diff_zero_map_bayes_mixture_w_0.4_def,
                                     data_filtered_diff_zero_map_bayes_mixture_w_0.45_def,
                                     data_filtered_diff_zero_map_bayes_mixture_w_0.5_def)

## Ahora sacamos las gráficas de las características operantes usando como prior el MAP Bayesiano con pesos ##

# MSE

p6 <- ggplot(combined_data_diff_not_zero, aes(x = median_control, y = mean_MSE, color = Prior, linetype = Prior)) +
  geom_line(size = 1.2) + 
  geom_line() +
  geom_vline(xintercept = median_control_center, linetype = "dashed") +
  labs(title = "Mean Square Error (MSE)", x = "Median Control Arm (in months)", y = "Mean MSE",
       color = "Bayesian Prior Distributions") +
  theme_minimal()  + 
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 12),
        axis.title.x = element_text(size = 12),
        axis.title.y = element_text(size = 12),
        legend.margin = margin(12, 12, 12, 12),
        legend.text = element_text(size = 11),
        legend.title = element_text(size = 12, face = "bold")) +
  scale_color_discrete(name = "Bayesian Prior Distributions") +
  scale_linetype_discrete(name = "Bayesian Prior Distributions") +
  scale_x_continuous(breaks = seq(min(combined_data_diff_not_zero$median_control), max(combined_data_diff_not_zero$median_control), by = 0.5)) +
  scale_y_continuous(limits = c(0, 0.075))
p6

# Power

p7 <- ggplot(combined_data_diff_not_zero, aes(x = median_control, y = prop_significant, color = Prior)) +
  geom_line(size = 1.2) + 
  geom_line() +
  geom_vline(xintercept = median_control_center, linetype = "dashed") +
  labs(title = "Power", x = "Median Control Arm (in months)", y = "Proportion of Significant Trials", color = "Bayesian Prior Distributions") +
  theme_minimal() + 
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 12),
        axis.title.x = element_text(size = 12),
        axis.title.y = element_text(size = 12),
        legend.margin = margin(12, 12, 12, 12),
        legend.text = element_text(size = 11),
        legend.title = element_text(size = 12, face = "bold")) +
  scale_color_discrete(name = "Bayesian Prior Distributions") +
  scale_linetype_discrete(name = "Bayesian Prior Distributions") +
  scale_x_continuous(breaks = seq(min(combined_data_diff_not_zero$median_control), max(combined_data_diff_not_zero$median_control), by = 0.5)) +
  scale_y_continuous(limits = c(0.8, 1))
p7

# ET1

p8 <- ggplot(combined_data_diff_zero, aes(x = median_control, y = prop_significant, color = Prior)) +
  geom_line(size = 1.2) + 
  geom_line() +
  geom_vline(xintercept = median_control_center, linetype = "dashed") +
  geom_hline(yintercept = 0.025, linetype = "dashed", color = "green") +
  geom_hline(yintercept = 0.05, linetype = "dashed", color = "purple") +
  labs(title = "Type I Error (T1E)", x = "Median Control (in months)", y = "Proportion of Significant Trials", color = "Bayesian Prior Distributions") +
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 12),
        axis.title.x = element_text(size = 12),
        axis.title.y = element_text(size = 12),
        legend.margin = margin(12, 12, 12, 12),
        legend.text = element_text(size = 11),
        legend.title = element_text(size = 12, face = "bold")) +
  scale_color_discrete(name = "Bayesian Prior Distributions") +
  scale_linetype_discrete(name = "Bayesian Prior Distributions") +
  scale_x_continuous(breaks = seq(min(combined_data_diff_zero$median_control), max(combined_data_diff_zero$median_control), by = 0.5)) +
  scale_y_continuous(limits = c(0, 0.2))
p8

```


```{r T1E_combined_RMAP, eval = T}

library(cowplot)

p66 <- p6 + scale_color_discrete(
  name = "Bayesian Prior Distributions", 
  labels = c(
        "Frequentist",
         "Robust MAP \nPrior w=0.05",
         "Robust MAP\nPrior w=0.1",
         "Robust MAP\nPrior w=0.15",
         "Robust MAP\nPrior w=0.2",
         "Robust MAP\nPrior w=0.25",
         "Robust MAP\nPrior w=0.3",
         "Robust MAP\nPrior w=0.35",
         "Robust MAP\nPrior w=0.4",
         "Robust MAP\nPrior w=0.45",
         "Robust MAP\nPrior w=0.5"
  )
) +
  guides(color = guide_legend(ncol = 11))  

legend <- get_legend(
  p66 +
    theme(
      # legend.box = "horizontal", 
      legend.justification = c(0, 1),
      # legend.margin = margin(8, 8, 8, 8),
      legend.text = element_text(size = 10), 
      legend.title = element_text(size = 11, face = "bold")
    )
)

# Remove individual legends from the plots
p66 <- p66 + theme(legend.position = "none")
p77 <- p7 + theme(legend.position = "none")
p88 <- p8 + theme(legend.position = "none")

p66 <- p66 + theme(plot.background = element_rect(colour = "black", size = 0.5, fill = NA))
p77 <- p77 + theme(plot.background = element_rect(colour = "black", size = 0.5, fill = NA))
p88 <- p88 + theme(plot.background = element_rect(colour = "black", size = 0.5, fill = NA))

plots_row <- plot_grid(p66, p77, p88, ncol = 3, labels = c("A", "B", "C"), label_size = 14)

combined_plot <- plot_grid(
  plots_row,
  legend,
  ncol = 1,                 
  rel_heights = c(3, 0.4)   
)

print(combined_plot)

```


A continuación, en vez de seleccionar el peso de antemano, dejamos la variable peso (w) como otra variable aleatoria más. De esto modo, se va a elegir un peso u otro en función de los datos que se van obteniendo.

Para testar lo de antes se han cogido 4 modelos diferentes:
  
  1) Brazo Control: Ga(1, 1/6), Brazo Tratamiento: Ga(0.00001, 0.00001) y Shape: Ga(0.00001, 0.00001). T=11h40min
  2) Brazo Control: Ga(1, 1/6), Brazo Tratamiento: Ga(1, 1/6) y Shape: Ga(0.00001, 0.00001). T=9h31min
  3) Brazo Control: Ga(1, 1/6), Brazo Tratamiento: Ga(0.00001, 0.00001) y Shape: U(0.1, 4). T=8h03min
  4) Brazo Control: Ga(1, 1/6), Brazo Tratamiento: Ga(1, 1/6) Y Shape:  U(0.1, 4). T=8h01min -> BUENO
  
  Como ha pasado arriba, protege mejor contra el ET1 una vez se pasa la mediana de 5.5 el modelo 4, ya que aunque se infla (sin pasar) en valores anteriores de 5.5, tiene mejor resultados una vez se pasa de 5.5 (que es lo preocupante). Aún así, las diferencias son mínimas entre los 4. Donde esta la mayor diferencia es en términos de tiempo como se ve arriba.
  
# Robust Mixture Prior with restricted and non-restricted random weight.
  
A continuación propongo 3 modelos más donde, en vez de prespecificar el peso que se va a usar para la parte informativa y la no informativa para cada uno de los ensayos simulados, se deja el peso como variable aleatoria. 
  
El peso va a seguir una distribución uniforme con valores que, como máximo, van a ir de 0 a 1. También se van a proponer modelos restringiendo el rango de valores de w que puede tomar esta variable en cada una de las simulaciones.
  
Los modelos son los siguientes:
    
1) Robust Mixture Prior con random weight siguiendo una Uniforme(0, 1)
2) Robust Mixture Prior con random weight siguiendo una Uniforme(0, 0.5)
3) Robust Mixture Prior con random weight siguiendo una Uniforme(0, 0.25)

Como puntualización, por simplicidad en este caso no se da una opción para el rango de pesos que se va a considerar para la variable aleatoria w. Es mucho más rápido cambiar el código STAN especificando estos rangos. Hay que fijarse cuándo uso un modelo STAN u otro para cada uno de los modelos.

```{r MAP_Bayes_Mixture_Prior_random_w , eval = T}

shape_parameter <- 1 

control_medians <- c(3.5,3.75,4,4.25,4.5,4.75,5,5.25,5.5,5.75,6,6.25,6.5,6.75,7,7.25,7.5)

medians <- matrix(NA, nrow = length(control_medians), ncol = 3, 
                  dimnames = list(NULL, c("Control", "Treatment", "Hazard Ratio")))

desired_HR = 0.55

for (i in 1:length(control_medians)) {
  medians[i, "Control"] <- control_medians[i]
  
  lambda_control = control_medians[i] / (log(2)^(1/shape_parameter))
  lambda_treatment = lambda_control / desired_HR^(1/shape_parameter)
  
  medians[i, "Treatment"] = lambda_treatment * (log(2)^(1/shape_parameter))
  medians[i, "Hazard Ratio"] = (lambda_control / lambda_treatment)^shape_parameter
}

medians <- medians[,1:2]
sample_size <- 300  
ratio <- c(0.5,0.5)
rand_type <- "CR" 
scenarios_eff <- as.matrix(medians, nrow = length(medians), ncol = 2, byrow = TRUE)
censor <- c(0.1,0.1)
Tmax <- 20
alpha <- 0.05 
test.type <- 2
HR_1 <- TRUE
IA <- NULL
method_IA <- "bayes"
n_exp_events <- 175
Plot_Power <- FALSE
plot_pvalues = FALSE 
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = TRUE

analysis = "bayes"
n_sim <- 2000
seed <- 24
# 1) Shape control, 2) rate control, 3) Shape experimental y 4) rate experimental
prior_gamma <- matrix(c(alpha_map_bayes, beta_map_bayes, 1, 1/6), nrow = 2, ncol = 2, byrow = TRUE) 
prior_type <- c("Mixture prior") # Este vector es para que aparezca el nombre en las tablas
P_HR_data_Boundary <- 0.8 # P(HR < 0.8 | data)
modelo_weibull_sep <- rstan::stan_model("weibull_mixture_gamma_random_w_def_ga_robust.stan" ,verbose = F)
# modelo_weibull_sep <- rstan::stan_model("weibull_mixture_gamma_random_w_0_0.5_shape_014_def.stan" ,verbose = F)
# modelo_weibull_sep <- rstan::stan_model("weibull_mixture_gamma_random_w_0_0.25_shape_014_def.stan" ,verbose = F)
modelo = modelo_weibull_sep
modelo_bayes_test = "weibull"
w = NULL

# sim16 <-  sim_trials(n_sim = n_sim,
#                      analysis = "bayes",
#                      sample_size = sample_size,
#                      ratio = ratio,
#                      rand_type = rand_type,
#                      Tmax = Tmax,
#                      scenarios_eff = scenarios_eff,
#                      shape_parameter = shape_parameter,
#                      censor = censor,
#                      test.type = test.type,
#                      alpha = alpha,
#                      method_IA = method_IA,
#                      IA = IA,
#                      n_exp_events = n_exp_events,
#                      HR_1 = HR_1,
#                      Plot_Power = Plot_Power,
#                      modelo = modelo,
#                      modelo_bayes_test = modelo_bayes_test,
#                      prior_type = prior_type,
#                      P_HR_data_Boundary = P_HR_data_Boundary,
#                      prior_gamma = prior_gamma,
#                      Plot_Power_scenarios = Plot_Power_scenarios,
#                      desired_HRs = desired_HRs,
#                      plot_pvalues = plot_pvalues,
#                      Plot_Control_Scenarios = Plot_Control_Scenarios,
#                      w = w,
#                      seed = seed)
# 
# sim16[[2]]
# sim16[[3]]
# sim16[[4]]
# 
# sim160 <- sim16[[1]]
# 
# wd <- createWorkbook()
# addWorksheet(wd, "Sheet1")
# writeData(wd, "Sheet1", sim140)
# saveWorkbook(wd, "MAP_bayes_bayes_mixture_w_0.15_300_2000_HR_changing.xlsx", overwrite = TRUE)

## Leemos los datos de las tablas obtenidas con el ordenador de multicore ##

sheet_names <- c("Sheet1")

# 1) Robust Mixture Prior con random weight siguiendo una Uniforme(0, 1)
# Tiempo = 08h38m10s
MAP_bayes_mixture_Random_w <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/MAP_bayes_bayes_mixture_Random_w_300_2000_Exp116_Shape014.xlsx", sheet = sheet_names[1])

# 2) Robust Mixture Prior con random weight siguiendo una Uniforme(0, 0.5)
# Tiempo = 14h41m58s
MAP_bayes_mixture_Random_w_restriccion_0.5 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/MAP_bayes_bayes_mixture_Random_w_restriccion_0.5_300_2000_Exp116_Shape014.xlsx", sheet = sheet_names[1])

# 3) Robust Mixture Prior con random weight siguiendo una Uniforme(0, 0.25)
# Tiempo = 16h01m23s
MAP_bayes_mixture_Random_w_restriccion_0.25 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/MAP_bayes_bayes_mixture_Random_w_restriccion_0.25_300_2000_Exp116_Shape014.xlsx", sheet = sheet_names[1])


# MAP Bayes Mixture prior with random weight

data_map_bayes_mixture_Random_w <- MAP_bayes_mixture_Random_w %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "Robust MAP Prior w ~ U(0, 1)")

data_filtered_diff_not_zero_map_bayes_mixture_random_w <- data_map_bayes_mixture_Random_w %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_map_bayes_mixture_random_w <- data_map_bayes_mixture_Random_w %>%
  filter(median_control == median_treatment)

# MAP Bayes Mixture prior with random weight restriction to 0.5

data_map_bayes_mixture_Random_w_0.5 <- MAP_bayes_mixture_Random_w_restriccion_0.5 %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "Robust MAP Prior w ~ U(0, 0.5)")

data_filtered_diff_not_zero_map_bayes_mixture_random_w_0.5 <- data_map_bayes_mixture_Random_w_0.5 %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_map_bayes_mixture_random_w_0.5 <- data_map_bayes_mixture_Random_w_0.5 %>%
  filter(median_control == median_treatment)

# MAP Bayes Mixture prior with random weight restriction to 0.25

data_map_bayes_mixture_Random_w_0.25 <- MAP_bayes_mixture_Random_w_restriccion_0.25 %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "Robust MAP Prior w ~ U(0, 0.25)")

data_filtered_diff_not_zero_map_bayes_mixture_random_w_0.25 <- data_map_bayes_mixture_Random_w_0.25 %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_map_bayes_mixture_random_w_0.25 <- data_map_bayes_mixture_Random_w_0.25 %>%
  filter(median_control == median_treatment)



combined_data_diff_not_zero <- bind_rows(data_filtered_diff_not_zero_frequentist,
                                         data_filtered_diff_not_zero_map_bayes_mixture_random_w,
                                         data_filtered_diff_not_zero_map_bayes_mixture_random_w_0.25,
                                         data_filtered_diff_not_zero_map_bayes_mixture_random_w_0.5)

combined_data_diff_zero <- bind_rows(data_filtered_diff_zero_frequentist,
                                     data_filtered_diff_zero_map_bayes_mixture_random_w,
                                     data_filtered_diff_zero_map_bayes_mixture_random_w_0.25,
                                     data_filtered_diff_zero_map_bayes_mixture_random_w_0.5)

## Ahora sacamos las gráficas de las características operantes usando como prior el MAP Bayesiano con pesos ##

# MSE

p6 <- ggplot(combined_data_diff_not_zero, aes(x = median_control, y = mean_MSE, color = Prior)) + 
  geom_line(size = 1.2) +
  geom_vline(xintercept = median_control_center, linetype = "solid") +
  labs(
    title = "Mean Square Error (MSE)",
    x = "Median Control Arm (in months)",
    y = "Mean MSE",
    color = "Bayesian Prior Distributions"
  ) +
  theme_minimal() + 
  theme(
    plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 10, face = "bold"),
    axis.text = element_text(size = 12),
    axis.title.x = element_text(size = 11),
    axis.title.y = element_text(size = 11),
    legend.margin = margin(9, 9, 9, 9),
    legend.text = element_text(size = 9),
    legend.title = element_text(size = 10, face = "bold")
  ) +
  scale_color_discrete(name = "Bayesian Prior Distributions") +
  scale_x_continuous(breaks = seq(min(combined_data_diff_not_zero$median_control), max(combined_data_diff_not_zero$median_control), by = 0.5)) +
  scale_y_continuous(limits = c(0, 0.075))

p6


# Power

p7 <- ggplot(combined_data_diff_not_zero, aes(x = median_control, y = prop_significant, color = Prior)) +
  geom_line(size = 1.2) + 
  geom_line() +
  geom_vline(xintercept = median_control_center, linetype = "dashed") +
  labs(title = "Power", x = "Median Control Arm (in months)", y = "Proportion of Significant Trials", color = "Bayesian Prior Distributions") +
  theme_minimal() + 
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 12),
        axis.title.x = element_text(size = 12),
        axis.title.y = element_text(size = 12),
        legend.margin = margin(12, 12, 12, 12),
        legend.text = element_text(size = 11),
        legend.title = element_text(size = 12, face = "bold")) +
  scale_color_discrete(name = "Bayesian Prior Distributions") +
  scale_linetype_discrete(name = "Bayesian Prior Distributions") +
  scale_x_continuous(breaks = seq(min(combined_data_diff_not_zero$median_control), max(combined_data_diff_not_zero$median_control), by = 0.5)) +
  scale_y_continuous(limits = c(0.8, 1))
p7

# ET1

p8 <- ggplot(combined_data_diff_zero, aes(x = median_control, y = prop_significant, color = Prior)) +
  geom_line(size = 1.2) + 
  geom_line() +
  geom_vline(xintercept = median_control_center, linetype = "dashed") +
  geom_hline(yintercept = 0.025, linetype = "dashed", color = "green") +
  geom_hline(yintercept = 0.05, linetype = "dashed", color = "purple") +
  labs(title = "Type I Error (T1E)", x = "Median Control (in months)", y = "Proportion of Significant Trials", color = "Bayesian Prior Distributions") +
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 12),
        axis.title.x = element_text(size = 12),
        axis.title.y = element_text(size = 12),
        legend.margin = margin(12, 12, 12, 12),
        legend.text = element_text(size = 11),
        legend.title = element_text(size = 12, face = "bold")) +
  scale_color_discrete(name = "Bayesian Prior Distributions") +
  scale_linetype_discrete(name = "Bayesian Prior Distributions") +
  scale_x_continuous(breaks = seq(min(combined_data_diff_zero$median_control), max(combined_data_diff_zero$median_control), by = 0.5)) +
  scale_y_continuous(limits = c(0, 0.2))
p8


```


```{r T1E_combined_RMAP, eval = T}

library(cowplot)

p66 <- p6 + scale_color_discrete(
  name = "Bayesian Prior Distributions", 
  labels = c(
        "Frequentist",
         "Robust MAP\nPrior w ~ U(0, 1)",
         "Robust MAP\nPrior w ~ U(0, 0.5)",
         "Robust MAP\nPrior w ~ U(0, 0.25)"
  )
) +
  guides(color = guide_legend(ncol = 4))  

legend <- get_legend(
  p66 +
    theme(
      # legend.box = "horizontal", 
      legend.justification = c(0, 1),
      # legend.margin = margin(8, 8, 8, 8),
      legend.text = element_text(size = 10), 
      legend.title = element_text(size = 11, face = "bold")
    )
)

# Remove individual legends from the plots
p66 <- p66 + theme(legend.position = "none")
p77 <- p7 + theme(legend.position = "none")
p88 <- p8 + theme(legend.position = "none")

p66 <- p66 + theme(plot.background = element_rect(colour = "black", size = 0.5, fill = NA))
p77 <- p77 + theme(plot.background = element_rect(colour = "black", size = 0.5, fill = NA))
p88 <- p88 + theme(plot.background = element_rect(colour = "black", size = 0.5, fill = NA))

plots_row <- plot_grid(p66, p77, p88, ncol = 3, labels = c("A", "B", "C"), label_size = 14)

combined_plot <- plot_grid(
  plots_row,
  legend,
  ncol = 1,                 
  rel_heights = c(3, 0.4)   
)

print(combined_plot)

```

El random w sin restriccines infla el ET1 en uno de los puntos. Por otro lado, los modelos restringidos tienen mejor comportamiento que con el peso preespecificado a 0.15. Son modelos a tener en cuenta.

Por último, repetimos lo de mover los HRs.

```{r `Mixture_Cambiando_HRs_random_w`, eval = T}

# Por ejemplo, con peso 0.15

shape_parameter <- 1 

desired_HRs <- c(1.3, 1.2, 1.1, 1, 0.95, 0.9, 0.85, 0.8, 0.775, 0.75, 0.725, 0.7, 0.675, 0.65, 0.625, 0.6, 0.575, 0.55, 0.525, 0.5, 0.45, 0.4, 0.35, 0.3)
control_medians <- rep(5.5, times = length(desired_HRs))

medians_control_fijo <- matrix(NA, nrow = length(desired_HRs), ncol = 2, dimnames = list(paste0("HR ", desired_HRs), c("Control", "Treatment")))

for (i in 1:length(desired_HRs)) {
  medians_control_fijo[i, "Treatment"] <- control_medians[i] / (desired_HRs[i]^(1/shape_parameter))
  medians_control_fijo[i, "Control"] <- control_medians[i]
}

sample_size <- 300  
ratio <- c(0.5,0.5)
rand_type <- "CR" 
scenarios_eff <- as.matrix(medians_control_fijo, nrow = dim(medians_control_fijo)[1], ncol = 2, byrow = TRUE)
censor <- c(0.1,0.1)
Tmax <- 20
alpha <- 0.05 
test.type <- 2
HR_1 <- FALSE
IA <- NULL
method_IA <- "bayes"
n_exp_events <- 175
Plot_Power <- FALSE
plot_pvalues = FALSE 
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = FALSE

analysis = "bayes"
n_sim <- 2000
seed <- 24
# 1) Shape control, 2) rate control, 3) Shape experimental y 4) rate experimental
prior_gamma <- matrix(c(alpha_map_bayes, beta_map_bayes, 1, 1/6), nrow = 2, ncol = 2, byrow = TRUE) 
prior_type <- c("Mixture prior with w 0.15") # Este vector es para que aparezca el nombre en las tablas
P_HR_data_Boundary <- 0.8 # P(HR < 0.8 | data)
modelo_weibull_sep <- rstan::stan_model("weibull_mixture_gamma_random_w_shape_014_def.stan" ,verbose = F)
modelo = modelo_weibull_sep
modelo_bayes_test = "weibull"
w = NULL

# sim16 <-  sim_trials(n_sim = n_sim,
#                      analysis = "bayes",
#                      sample_size = sample_size,
#                      ratio = ratio,
#                      rand_type = rand_type,
#                      Tmax = Tmax,
#                      scenarios_eff = scenarios_eff,
#                      shape_parameter = shape_parameter,
#                      censor = censor,
#                      test.type = test.type,
#                      alpha = alpha,
#                      method_IA = method_IA,
#                      IA = IA,
#                      n_exp_events = n_exp_events,
#                      HR_1 = HR_1,
#                      Plot_Power = Plot_Power,
#                      modelo = modelo,
#                      modelo_bayes_test = modelo_bayes_test,
#                      prior_type = prior_type,
#                      P_HR_data_Boundary = P_HR_data_Boundary,
#                      prior_gamma = prior_gamma,
#                      Plot_Power_scenarios = Plot_Power_scenarios,
#                      desired_HRs = desired_HRs,
#                      plot_pvalues = plot_pvalues,
#                      Plot_Control_Scenarios = Plot_Control_Scenarios,                     
#                      w = w,
#                      seed = seed)

## Leemos los datos de las tablas obtenidas con el ordenador de multicore ##

sheet_names <- c("Sheet1")

# 1) Robust Mixture Prior con random weight siguiendo una Uniforme(0, 1)

MAP_bayes_mixture_random_w_HR_changing <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/MAP_bayes_bayes_mixture_Random_w_300_2000_HR_changing.xlsx", sheet = sheet_names[1])

data_map_bayes_mixture_random_w_HR_changing <- MAP_bayes_mixture_random_w_HR_changing %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "MAP Bayes Mixture prior w random weight")

# 2) Robust Mixture Prior con random weight siguiendo una Uniforme(0, 0.5)
MAP_bayes_mixture_Random_w_restriccion_0.5_HR_changing <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/MAP_bayes_bayes_mixture_Random_w_restriccion_0.5_300_2000_HR_changing.xlsx", sheet = sheet_names[1])

data_map_bayes_mixture_random_w_restriccion_0.5_HR_changing <- MAP_bayes_mixture_Random_w_restriccion_0.5_HR_changing %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "MAP Bayes Mixture prior Random weight restricted to 0.5")

# 3) Robust Mixture Prior con random weight siguiendo una Uniforme(0, 0.25)
MAP_bayes_mixture_Random_w_restriccion_0.25_HR_changing <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/MAP_bayes_bayes_mixture_Random_w_restriccion_0.25_300_2000_HR_changing.xlsx", sheet = sheet_names[1])

data_map_bayes_mixture_random_w_restriccion_0.25_HR_changing <- MAP_bayes_mixture_Random_w_restriccion_0.25_HR_changing %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "MAP Bayes Mixture prior Random weight restricted to 0.25")

combined_data_mixture_HR_changing <- bind_rows(data_sim3_results,
                                               data_informative_gamma_3.5, 
                                               data_informative_gamma_5.5, 
                                               data_informative_gamma_7.5,
                                               data_map_bayes_mixture_w_0.5_HR_changing,
                                               data_map_bayes_mixture_random_w_HR_changing,
                                               data_map_bayes_mixture_random_w_restriccion_0.25_HR_changing,
                                               data_map_bayes_mixture_random_w_restriccion_0.5_HR_changing)

combined_data_mixture_HR_changing <- combined_data_mixture_HR_changing %>%
  group_by(Prior) %>%
  mutate(desired_HRs = (desired_HRs))

combined_data_mixture_HR_changing <- combined_data_mixture_HR_changing %>%
  mutate(diff_HR = abs(mean_HR - desired_HRs))

## Ahora sacamos las gráficas de las características operantes usando como prior el MAP Bayesiano con pesos ##

p6 <- ggplot(combined_data_mixture_HR_changing, aes(x = desired_HRs, y = prop_significant, group = Prior, color = Prior)) +
  geom_point(size = 3) +
  geom_line(linewidth = 1) +
  geom_vline(xintercept = 1, linetype = "dashed", color = "red", size = 1) +
  geom_vline(xintercept = 0.55, linetype = "dashed", color = "red", size = 1) +
  geom_vline(xintercept = 0.5, linetype = "dashed", color = "red", size = 1) +
  geom_hline(yintercept = c(0.8, 0.9), linetype = "dotted", color = c("purple", "green"), size = 1) +
  scale_x_continuous(breaks = seq(min(combined_data_mixture_HR_changing$desired_HRs), max(combined_data_mixture_HR_changing$desired_HRs), 0.1), labels = sprintf("%.2f", seq(min(combined_data_mixture_HR_changing$desired_HRs), max(combined_data_mixture_HR_changing$desired_HRs), 0.1))) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Power vs Hazard Ratio w mixture prior",
       x = "Theoretical Hazard Ratio",
       y = "Power") +
  theme_minimal() +
  theme(plot.title = element_text(size = 12, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 10),
        legend.position = "right")

p6 <- p6 +
  annotate("text", x = max(combined_data_mixture_HR_changing$desired_HRs), y = 0.8, label = "80% power", hjust = 1, vjust = -0.5, size = 3.5, color = "purple") +
  annotate("text", x = max(combined_data_mixture_HR_changing$desired_HRs), y = 0.9, label = "90% power", hjust = 1, vjust = -0.5, size = 3.5, color = "green") +
  geom_label(aes(x = 1, y = Inf, label = "H0"), vjust = 2, color = "black", fill = "white", size = 3.5, label.size = 0, fontface = "bold") +
  geom_label(aes(x = 0.55, y = Inf, label = "H1"), vjust = 2, color = "black", fill = "white", size = 3.5, label.size = 0, fontface = "bold") +
  geom_label(aes(x = 0.5, y = Inf, label = "Real HR"), vjust = 2, color = "black", fill = "white", size = 3.5, label.size = 0, fontface = "bold")

p6

# Graficamos las diferencias

p7 <- ggplot(combined_data_mixture_HR_changing, aes(x = desired_HRs, y = diff_HR, color = Prior)) +
  geom_point(size = 3) +
  geom_line(aes(group = Prior), linewidth = 1) +
  scale_x_continuous(breaks = seq(min(combined_data_mixture_HR_changing$desired_HRs), max(combined_data_mixture_HR_changing$desired_HRs), 0.1), labels = sprintf("%.2f", seq(min(combined_data_mixture_HR_changing$desired_HRs), max(combined_data_mixture_HR_changing$desired_HRs), 0.1))) +
  labs(title = "Diff btw Simulated HR and Theoretical HRs w prior mixture",
       x = "Theoretical Hazard Ratio",
       y = "Difference") +
  theme_minimal() +
  theme(plot.title = element_text(size = 8, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 6, face = "bold"),
        axis.text = element_text(size = 6),
        legend.position = "right")

p7


```

# Power prior: Incorporando IPD en el análisis

Me he inspirado en las ideas de Bayesian survival analysis for early detection of treatment effects in phase 3 clinical trials: Lucie Biard, Anne Bergeron,Vincent Lévy and Sylvie Chevreta (2021)

Para modificar mi código STAN, he cogido también la idea que se usa en el código del paper aunque no es para nada lo mismo: https://github.com/luciebiard/Bayesian_survival_analysis_phase_3_trials.

Este método es muy diferente al MAP, para empezar, aquí uso en el análisis datos de paciente a paciente de mi control externo directamente y no como antes, donde usamos el summary de un MAP o bien una creencia en función de las asunciones del Sponsor.

Por otro lado, aquí no modificamos la prior, de hecho sólo uso priors no informativas por lo que ahora, tanto para el control como para el experimental, uso priors no informativas de Ga(1, 1/6). En vez de esto, lo que hacemos es incorporar con un peso a0 (no lo llamo w como en el MAP para evitar confusión) que nos va a permitir usar este porcentaje de control externo dentro del análisis (en la función de verosimilitud, no en la prior). Esto es una manera de AUMENTAR el tamaño muestral para el brazo control.

Recordad que los controles externos sólo los he considerado para el brazo control por lo que en ningún caso se añade información a la asunción del tratamiento experimental.

En este caso, sólo uso una fuente de información externa, es el estudio nº3 llamado POSEIDÓN ya que son los datos más recientes que se podrían haber usado y además, tras comparar un número de simulaciones con estos parámetros, son los datos que más se parecen con diferencia por lo que puede ser un buen punto de partida.

Como en el MAP, he hecho simulaciones para estudiar las características operantes con diferentes pesos para a0: 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45 y 0.5.
  
```{r Power_Prior , eval = T}


control_medians <- c(3.5,3.75,4,4.25,4.5,4.75,5,5.25,5.5,5.75,6,6.25,6.5,6.75,7,7.25,7.5)

medians <- matrix(NA, nrow = length(control_medians), ncol = 3, 
                  dimnames = list(NULL, c("Control", "Treatment", "Hazard Ratio")))

desired_HR = 0.55

for (i in 1:length(control_medians)) {
  medians[i, "Control"] <- control_medians[i]
  
  lambda_control = control_medians[i] / (log(2)^(1/shape_parameter))
  lambda_treatment = lambda_control / desired_HR^(1/shape_parameter)
  
  medians[i, "Treatment"] = lambda_treatment * (log(2)^(1/shape_parameter))
  medians[i, "Hazard Ratio"] = (lambda_control / lambda_treatment)^shape_parameter
}

medians <- medians[,1:2]
shape_parameter <- 1 
sample_size <- 300  
ratio <- c(0.5,0.5)
rand_type <- "CR" 
#scenarios_eff <- as.matrix(medians, nrow = length(medians), ncol = 2, byrow = TRUE)
scenarios_eff <- matrix(c(5.5,10), nrow = 1, ncol = 2, byrow = TRUE) # HR=0.55
censor <- c(0.1,0.1)
Tmax <- 20
alpha <- 0.05 
test.type <- 2
HR_1 <- FALSE
IA <- NULL
method_IA <- "bayes"
n_exp_events <- 175
Plot_Power <- FALSE
plot_pvalues = FALSE 
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = TRUE
analysis = "bayes"
n_sim <- 2000
seed <- 24
# 1) Shape control, 2) rate control, 3) Shape experimental y 4) rate experimental
prior_gamma <- matrix(c(1, 1/6, 1, 1/6), nrow = 2, ncol = 2, byrow = TRUE) 
prior_type <- c("Power prior") # Este vector es para que aparezca el nombre en las tablas
P_HR_data_Boundary <- 0.8 # P(HR < 0.8 | data)
modelo_weibull_sep <- rstan::stan_model("weibull_power_prior.stan" ,verbose = F)
modelo = modelo_weibull_sep
w= NULL       
modelo_bayes_test = "weibull"
a0 = 0.05

#modelo_weibull_sep <- rstan::stan_model("weibull_power_prior_random_a0.stan" ,verbose = F)

# Este nuevo modelo es para evaluar la similitud de los datos actuales del ensayo con respecto a los datos del control externo. Cuanto más se parezca, más se va a tomar prestado con un máximo de 0.5 (gráfico abajo).

# Esto saca el HR para decidir cuánta fuerza para a0 se va a tomar prestado para el power prior.

# Sin embargo, aunque cargamos aquí el modelo, no lo vamos a usar. Esto clava los resultados del frecuentista pero por razones de tiempo de computación, vamos a usar la regresión de Cox frecuentista. Esto también es porque sólo estamos interesados en un valor para decidir que a0 usar, por lo que no es de tanto interés saber la distribución del HR obtenido.

#stan_model_cox_CPP <- stan_model("cox_borrowing_stregth.stan")


# Cogemos los datos que más se parecen

data_hist3$arm <- 1

external_data <- data_hist3
external_data$dataset <- 'external'
external_data$id <- seq(1, dim(external_data)[1], by = 1)
external_data$status <- ifelse(external_data$status==1, TRUE, FALSE)
w= NULL       

# sim16 <-  sim_trials(n_sim = n_sim,
#                       analysis = "bayes",
#                       sample_size = sample_size,
#                       ratio = ratio,
#                       rand_type = rand_type,
#                       Tmax = Tmax,
#                       scenarios_eff = scenarios_eff,
#                       shape_parameter = shape_parameter,
#                       censor = censor,
#                       test.type = test.type,
#                       alpha = alpha,
#                       method_IA = method_IA,
#                       IA = IA,
#                       n_exp_events = n_exp_events,
#                       HR_1 = HR_1,
#                       Plot_Power = Plot_Power,
#                       modelo = modelo,
#                       modelo_bayes_test = modelo_bayes_test,
#                       prior_type = prior_type,
#                       P_HR_data_Boundary = P_HR_data_Boundary,
#                       prior_gamma = prior_gamma,
#                       Plot_Power_scenarios = Plot_Power_scenarios,
#                       desired_HRs = desired_HRs,
#                       plot_pvalues = plot_pvalues,
#                       Plot_Control_Scenarios = Plot_Control_Scenarios,
#                       w = w,
#                       external_data = external_data,
#                       a0 = a0,
#                       seed = seed)

# sim105[[2]]
# sim105[[3]]
# sim105[[4]]
# 
# sim1050 <- sim105[[1]]
# 
# wd <- createWorkbook()
# addWorksheet(wd, "Sheet1")
# writeData(wd, "Sheet1", sim1050)
# saveWorkbook(wd, "Power_Prior_a0_=_0.05_300_2000.xlsx", overwrite = TRUE)

## Leemos los datos de las tablas obtenidas con el ordenador de multicore ##

sheet_names <- c("Sheet1")

# Tiempo = ??
Bayes_Power_Prior_a0_0 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/Power_Prior_a0_=_0_300_2000.xlsx", sheet = sheet_names[1])

# Tiempo = ??
Bayes_Power_Prior_a0_0.05 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/Power_Prior_a0_=_0.05_300_2000.xlsx", sheet = sheet_names[1])

# Tiempo = 16h41m08
Bayes_Power_Prior_a0_0.1 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/Power_Prior_a0_=_0.1_300_2000.xlsx", sheet = sheet_names[1])

# Tiempo = 13h05m29
Bayes_Power_Prior_a0_0.15 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/Power_Prior_a0_=_0.15_300_2000.xlsx", sheet = sheet_names[1])

# Tiempo = 12h59m58
Bayes_Power_Prior_a0_0.2 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/Power_Prior_a0_=_0.2_300_2000.xlsx", sheet = sheet_names[1])

# Tiempo = 12h57m02
Bayes_Power_Prior_a0_0.25 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/Power_Prior_a0_=_0.25_300_2000.xlsx", sheet = sheet_names[1])

# Tiempo = ??
Bayes_Power_Prior_a0_0.3 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/Power_Prior_a0_=_0.3_300_2000.xlsx", sheet = sheet_names[1])

# Tiempo = ??
Bayes_Power_Prior_a0_0.35 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/Power_Prior_a0_=_0.35_300_2000.xlsx", sheet = sheet_names[1])

# Tiempo = 16h01m26
Bayes_Power_Prior_a0_0.4 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/Power_Prior_a0_=_0.4_300_2000.xlsx", sheet = sheet_names[1])

# Tiempo = ??
Bayes_Power_Prior_a0_0.45 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/Power_Prior_a0_=_0.45_300_2000.xlsx", sheet = sheet_names[1])

# Tiempo = ??
Bayes_Power_Prior_a0_0.5 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/Power_Prior_a0_=_0.5_300_2000.xlsx", sheet = sheet_names[1])


## Ahora juntamos los datos para graficarlos ##

# Bayes_Power_Prior_a0_0 

data_Bayes_Power_Prior_a0_0 <- Bayes_Power_Prior_a0_0 %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "Power Prior a0 = 0")

data_filtered_diff_not_zero_Bayes_Power_Prior_a0_0 <- data_Bayes_Power_Prior_a0_0 %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_Bayes_Power_Prior_a0_0 <- data_Bayes_Power_Prior_a0_0 %>%
  filter(median_control == median_treatment)

# Bayes_Power_Prior_a0_0.05

data_Bayes_Power_Prior_a0_0.05 <- Bayes_Power_Prior_a0_0.05 %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "Power Prior a0 = 0.05")

data_filtered_diff_not_zero_Bayes_Power_Prior_a0_0.05 <- data_Bayes_Power_Prior_a0_0.05 %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_Bayes_Power_Prior_a0_0.05 <- data_Bayes_Power_Prior_a0_0.05 %>%
  filter(median_control == median_treatment)

# Bayes_Power_Prior_a0_0.1

data_Bayes_Power_Prior_a0_0.1 <- Bayes_Power_Prior_a0_0.1 %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "Power Prior a0 = 0.1")

data_filtered_diff_not_zero_Bayes_Power_Prior_a0_0.1 <- data_Bayes_Power_Prior_a0_0.1 %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_Bayes_Power_Prior_a0_0.1 <- data_Bayes_Power_Prior_a0_0.1 %>%
  filter(median_control == median_treatment)

# Bayes_Power_Prior_a0_0.15

data_Bayes_Power_Prior_a0_0.15 <- Bayes_Power_Prior_a0_0.15 %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "Power Prior a0 = 0.15")

data_filtered_diff_not_zero_Bayes_Power_Prior_a0_0.15 <- data_Bayes_Power_Prior_a0_0.15 %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_Bayes_Power_Prior_a0_0.15 <- data_Bayes_Power_Prior_a0_0.15 %>%
  filter(median_control == median_treatment)

# Bayes_Power_Prior_a0_0.2

data_Bayes_Power_Prior_a0_0.2 <- Bayes_Power_Prior_a0_0.2 %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "Power Prior a0 = 0.2")

data_filtered_diff_not_zero_Bayes_Power_Prior_a0_0.2 <- data_Bayes_Power_Prior_a0_0.2 %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_Bayes_Power_Prior_a0_0.2 <- data_Bayes_Power_Prior_a0_0.2 %>%
  filter(median_control == median_treatment)

# Bayes_Power_Prior_a0_0.25

data_Bayes_Power_Prior_a0_0.25 <- Bayes_Power_Prior_a0_0.25 %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "Power Prior a0 = 0.25")

data_filtered_diff_not_zero_Bayes_Power_Prior_a0_0.25 <- data_Bayes_Power_Prior_a0_0.25 %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_Bayes_Power_Prior_a0_0.25 <- data_Bayes_Power_Prior_a0_0.25 %>%
  filter(median_control == median_treatment)

# Bayes_Power_Prior_a0_0.3

data_Bayes_Power_Prior_a0_0.3 <- Bayes_Power_Prior_a0_0.3 %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "Power Prior a0 = 0.3")

data_filtered_diff_not_zero_Bayes_Power_Prior_a0_0.3 <- data_Bayes_Power_Prior_a0_0.3 %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_Bayes_Power_Prior_a0_0.3<- data_Bayes_Power_Prior_a0_0.3 %>%
  filter(median_control == median_treatment)

# Bayes_Power_Prior_a0_0.35

data_Bayes_Power_Prior_a0_0.35 <- Bayes_Power_Prior_a0_0.35 %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "Power Prior a0 = 0.35")

data_filtered_diff_not_zero_Bayes_Power_Prior_a0_0.35 <- data_Bayes_Power_Prior_a0_0.35 %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_Bayes_Power_Prior_a0_0.35 <- data_Bayes_Power_Prior_a0_0.35 %>%
  filter(median_control == median_treatment)

# Bayes_Power_Prior_a0_0.4

data_Bayes_Power_Prior_a0_0.4 <- Bayes_Power_Prior_a0_0.4 %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "Power Prior a0 = 0.4")

data_filtered_diff_not_zero_Bayes_Power_Prior_a0_0.4 <- data_Bayes_Power_Prior_a0_0.4 %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_Bayes_Power_Prior_a0_0.4 <- data_Bayes_Power_Prior_a0_0.4 %>%
  filter(median_control == median_treatment)

# Bayes_Power_Prior_a0_0.45

data_Bayes_Power_Prior_a0_0.45 <- Bayes_Power_Prior_a0_0.45 %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "Power Prior a0 = 0.45")

data_filtered_diff_not_zero_Bayes_Power_Prior_a0_0.45 <- data_Bayes_Power_Prior_a0_0.45 %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_Bayes_Power_Prior_a0_0.45 <- data_Bayes_Power_Prior_a0_0.45 %>%
  filter(median_control == median_treatment)

# Bayes_Power_Prior_a0_0.5

data_Bayes_Power_Prior_a0_0.5 <- Bayes_Power_Prior_a0_0.5 %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "Power Prior a0 = 0.5")

data_filtered_diff_not_zero_Bayes_Power_Prior_a0_0.5 <- data_Bayes_Power_Prior_a0_0.5 %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_Bayes_Power_Prior_a0_0.5 <- data_Bayes_Power_Prior_a0_0.5 %>%
  filter(median_control == median_treatment)


combined_data_diff_not_zero <- bind_rows(data_filtered_diff_not_zero_frequentist,
                                         data_filtered_diff_not_zero_Bayes_Power_Prior_a0_0,
                                         data_filtered_diff_not_zero_Bayes_Power_Prior_a0_0.05,
                                         data_filtered_diff_not_zero_Bayes_Power_Prior_a0_0.1,
                                         data_filtered_diff_not_zero_Bayes_Power_Prior_a0_0.15,
                                         data_filtered_diff_not_zero_Bayes_Power_Prior_a0_0.2,
                                         data_filtered_diff_not_zero_Bayes_Power_Prior_a0_0.25,
                                         data_filtered_diff_not_zero_Bayes_Power_Prior_a0_0.3,
                                         data_filtered_diff_not_zero_Bayes_Power_Prior_a0_0.35,
                                         data_filtered_diff_not_zero_Bayes_Power_Prior_a0_0.4,
                                         data_filtered_diff_not_zero_Bayes_Power_Prior_a0_0.45,
                                         data_filtered_diff_not_zero_Bayes_Power_Prior_a0_0.5)

combined_data_diff_zero <- bind_rows(data_filtered_diff_zero_frequentist,
                                     data_filtered_diff_zero_Bayes_Power_Prior_a0_0,
                                     data_filtered_diff_zero_Bayes_Power_Prior_a0_0.05,
                                     data_filtered_diff_zero_Bayes_Power_Prior_a0_0.1,
                                     data_filtered_diff_zero_Bayes_Power_Prior_a0_0.15,
                                     data_filtered_diff_zero_Bayes_Power_Prior_a0_0.2,
                                     data_filtered_diff_zero_Bayes_Power_Prior_a0_0.25,
                                     data_filtered_diff_zero_Bayes_Power_Prior_a0_0.3,
                                     data_filtered_diff_zero_Bayes_Power_Prior_a0_0.35,
                                     data_filtered_diff_zero_Bayes_Power_Prior_a0_0.4,
                                     data_filtered_diff_zero_Bayes_Power_Prior_a0_0.45,
                                     data_filtered_diff_zero_Bayes_Power_Prior_a0_0.5)

## Ahora sacamos las gráficas de las características operantes usando como prior el MAP Bayesiano con pesos ##

# MSE

p6 <- ggplot(combined_data_diff_not_zero, aes(x = median_control, y = mean_MSE, color = Prior)) + 
  geom_line(size = 1.2) +
  geom_vline(xintercept = median_control_center, linetype = "solid") +
  labs(
    title = "Mean Square Error (MSE)",
    x = "Median Control Arm (in months)",
    y = "Mean MSE",
    color = "Bayesian Prior Distributions"
  ) +
  theme_minimal() + 
  theme(
    plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 10, face = "bold"),
    axis.text = element_text(size = 12),
    axis.title.x = element_text(size = 11),
    axis.title.y = element_text(size = 11),
    legend.margin = margin(9, 9, 9, 9),
    legend.text = element_text(size = 9),
    legend.title = element_text(size = 10, face = "bold")
  ) +
  scale_color_discrete(name = "Bayesian Prior Distributions") +
  scale_x_continuous(breaks = seq(min(combined_data_diff_not_zero$median_control), max(combined_data_diff_not_zero$median_control), by = 0.5)) +
  scale_y_continuous(limits = c(0, 0.075))

p6

# Power

p7 <- ggplot(combined_data_diff_not_zero, aes(x = median_control, y = prop_significant, color = Prior)) +
  geom_line(size = 1.2) + 
  geom_line() +
  geom_vline(xintercept = median_control_center, linetype = "dashed") +
  labs(title = "Power", x = "Median Control Arm (in months)", y = "Proportion of Significant Trials", color = "Bayesian Prior Distributions") +
  theme_minimal() + 
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 12),
        axis.title.x = element_text(size = 12),
        axis.title.y = element_text(size = 12),
        legend.margin = margin(12, 12, 12, 12),
        legend.text = element_text(size = 11),
        legend.title = element_text(size = 12, face = "bold")) +
  scale_color_discrete(name = "Bayesian Prior Distributions") +
  scale_linetype_discrete(name = "Bayesian Prior Distributions") +
  scale_x_continuous(breaks = seq(min(combined_data_diff_not_zero$median_control), max(combined_data_diff_not_zero$median_control), by = 0.5)) +
  scale_y_continuous(limits = c(0.8, 1))
p7

# ET1

p8 <- ggplot(combined_data_diff_zero, aes(x = median_control, y = prop_significant, color = Prior)) +
  geom_line(size = 1.2) + 
  geom_line() +
  geom_vline(xintercept = median_control_center, linetype = "dashed") +
  geom_hline(yintercept = 0.025, linetype = "dashed", color = "green") +
  geom_hline(yintercept = 0.05, linetype = "dashed", color = "purple") +
  labs(title = "Type I Error (T1E)", x = "Median Control (in months)", y = "Proportion of Significant Trials", color = "Bayesian Prior Distributions") +
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 12),
        axis.title.x = element_text(size = 12),
        axis.title.y = element_text(size = 12),
        legend.margin = margin(12, 12, 12, 12),
        legend.text = element_text(size = 11),
        legend.title = element_text(size = 12, face = "bold")) +
  scale_color_discrete(name = "Bayesian Prior Distributions") +
  scale_linetype_discrete(name = "Bayesian Prior Distributions") +
  scale_x_continuous(breaks = seq(min(combined_data_diff_zero$median_control), max(combined_data_diff_zero$median_control), by = 0.5)) +
  scale_y_continuous(limits = c(0, 0.2))
p8

      
```


```{r T1E_combined_powerprior, eval = T}

library(cowplot)

p66 <- p6 + scale_color_discrete(
  name = "Bayesian Prior Distributions", 
  labels = c(
        "Frequentist",
         "Power Prior\na0=0",
         "Power Prior\na0=0.05",
         "Power Prior\na0=0.1",
         "Power Prior\na0=0.15",
         "Power Prior\na0=0.2",
         "Power Prior\na0=0.25",
         "Power Prior\na0=0.3",
         "Power Prior\na0=0.35",
         "Power Prior\na0=0.4",
         "Power Prior\na0=0.45",
         "Power Prior\na0=0.5")
) +
  guides(color = guide_legend(ncol = 12))  

legend <- get_legend(
  p66 +
    theme(
      # legend.box = "horizontal", 
      legend.justification = c(0, 1),
      # legend.margin = margin(8, 8, 8, 8),
      legend.text = element_text(size = 10), 
      legend.title = element_text(size = 11, face = "bold")
    )
)

# Remove individual legends from the plots
p66 <- p66 + theme(legend.position = "none")
p77 <- p7 + theme(legend.position = "none")
p88 <- p8 + theme(legend.position = "none")

p66 <- p66 + theme(plot.background = element_rect(colour = "black", size = 0.5, fill = NA))
p77 <- p77 + theme(plot.background = element_rect(colour = "black", size = 0.5, fill = NA))
p88 <- p88 + theme(plot.background = element_rect(colour = "black", size = 0.5, fill = NA))

plots_row <- plot_grid(p66, p77, p88, ncol = 3, labels = c("A", "B", "C"), label_size = 14)

combined_plot <- plot_grid(
  plots_row,
  legend,
  ncol = 1,                 
  rel_heights = c(3, 0.4)   
)

print(combined_plot)

```



Ahora cambiando los HRs para el power prior con diferentes pesos (a0)

```{r `Power_Prior_Cambiando_HRs`, eval = F}


shape_parameter <- 1 

desired_HRs <- c(1.3, 1.2, 1.1, 1, 0.95, 0.9, 0.85, 0.8, 0.775, 0.75, 0.725, 0.7, 0.675, 0.65, 0.625, 0.6, 0.575, 0.55, 0.525, 0.5, 0.45, 0.4, 0.35, 0.3)
control_medians <- rep(5.5, times = length(desired_HRs))

medians_control_fijo <- matrix(NA, nrow = length(desired_HRs), ncol = 2, dimnames = list(paste0("HR ", desired_HRs), c("Control", "Treatment")))

for (i in 1:length(desired_HRs)) {
  medians_control_fijo[i, "Treatment"] <- control_medians[i] / (desired_HRs[i]^(1/shape_parameter))
  medians_control_fijo[i, "Control"] <- control_medians[i]
}

sample_size <- 300  
ratio <- c(0.5,0.5)
rand_type <- "CR" 
scenarios_eff <- as.matrix(medians_control_fijo, nrow = dim(medians_control_fijo)[1], ncol = 2, byrow = TRUE)
censor <- c(0.1,0.1)
Tmax <- 20
alpha <- 0.05 
test.type <- 2
HR_1 <- FALSE
IA <- NULL
method_IA <- "bayes"
n_exp_events <- 175
Plot_Power <- FALSE
plot_pvalues = FALSE 
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = FALSE

analysis = "bayes"
n_sim <- 2000
seed <- 24
# 1) Shape control, 2) rate control, 3) Shape experimental y 4) rate experimental
prior_gamma <- matrix(c(1, 1/6, 1, 1/6), nrow = 2, ncol = 2, byrow = TRUE) 
prior_type <- c("Power prior") # Este vector es para que aparezca el nombre en las tablas
P_HR_data_Boundary <- 0.8 # P(HR < 0.8 | data)
modelo_weibull_sep <- rstan::stan_model("weibull_power_prior.stan" ,verbose = F)
modelo = modelo_weibull_sep
w= NULL       
modelo_bayes_test = "weibull"
a0 = 0.05

#modelo_weibull_sep <- rstan::stan_model("weibull_power_prior_random_a0.stan" ,verbose = F)

# Este nuevo modelo es para evaluar la similitud de los datos actuales del ensayo con respecto a los datos del control externo. Cuanto más se parezca, más se va a tomar prestado con un máximo de 0.5 (gráfico abajo).

# Esto saca el HR para decidir cuánta fuerza para a0 se va a tomar prestado para el power prior.

# Sin embargo, aunque cargamos aquí el modelo, no lo vamos a usar. Esto clava los resultados del frecuentista pero por razones de tiempo de computación, vamos a usar la regresión de Cox frecuentista. Esto también es porque sólo estamos interesados en un valor para decidir que a0 usar, por lo que no es de tanto interés saber la distribución del HR obtenido.

#stan_model_cox_CPP <- stan_model("cox_borrowing_stregth.stan")


# Cogemos los datos que más se parecen

data_hist3$arm <- 1

external_data <- data_hist3
external_data$dataset <- 'external'
external_data$id <- seq(1, dim(external_data)[1], by = 1)
external_data$status <- ifelse(external_data$status==1, TRUE, FALSE)
w= NULL       

# sim16 <-  sim_trials(n_sim = n_sim,
#                       analysis = "bayes",
#                       sample_size = sample_size,
#                       ratio = ratio,
#                       rand_type = rand_type,
#                       Tmax = Tmax,
#                       scenarios_eff = scenarios_eff,
#                       shape_parameter = shape_parameter,
#                       censor = censor,
#                       test.type = test.type,
#                       alpha = alpha,
#                       method_IA = method_IA,
#                       IA = IA,
#                       n_exp_events = n_exp_events,
#                       HR_1 = HR_1,
#                       Plot_Power = Plot_Power,
#                       modelo = modelo,
#                       modelo_bayes_test = modelo_bayes_test,
#                       prior_type = prior_type,
#                       P_HR_data_Boundary = P_HR_data_Boundary,
#                       prior_gamma = prior_gamma,
#                       Plot_Power_scenarios = Plot_Power_scenarios,
#                       desired_HRs = desired_HRs,
#                       plot_pvalues = plot_pvalues,
#                       Plot_Control_Scenarios = Plot_Control_Scenarios,
#                       w = w,
#                       external_data = external_data,
#                       a0 = a0,
#                       seed = seed)

# sim105[[2]]
# sim105[[3]]
# sim105[[4]]
# 
# sim1050 <- sim105[[1]]
# 
# wd <- createWorkbook()
# addWorksheet(wd, "Sheet1")
# writeData(wd, "Sheet1", sim1050)
# saveWorkbook(wd, "Power_Prior_a0_=_0.05_300_2000_HR_changing.xlsx", overwrite = TRUE)

## Leemos los datos de las tablas obtenidas con el ordenador de multicore ##

sheet_names <- c("Sheet1")

# 1) Power Prior a0=0.05

Bayes_Power_Prior_a0_0.05_HR_changing <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/Power_Prior_a0_=_0.05_300_2000_HR_changing.xlsx", sheet = sheet_names[1])

data_Bayes_Power_Prior_a0_0.05_HR_changing <- Bayes_Power_Prior_a0_0.05_HR_changing %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "Power Prior a0=0.05")

# 2) Power Prior a0=0.1

Bayes_Power_Prior_a0_0.1_HR_changing <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/Power_Prior_a0_=_0.1_300_2000_HR_changing.xlsx", sheet = sheet_names[1])

data_Bayes_Power_Prior_a0_0.1_HR_changing <- Bayes_Power_Prior_a0_0.1_HR_changing %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "Power Prior a0=0.1")

# 3) Power Prior a0=0.15

Bayes_Power_Prior_a0_0.15_HR_changing <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/Power_Prior_a0_=_0.15_300_2000_HR_changing.xlsx", sheet = sheet_names[1])

data_Bayes_Power_Prior_a0_0.15_HR_changing <- Bayes_Power_Prior_a0_0.15_HR_changing %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "Power Prior a0=0.15")

# 4) Power Prior a0=0.2

Bayes_Power_Prior_a0_0.2_HR_changing <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/Power_Prior_a0_=_0.2_300_2000_HR_changing.xlsx", sheet = sheet_names[1])

data_Bayes_Power_Prior_a0_0.2_HR_changing <- Bayes_Power_Prior_a0_0.2_HR_changing %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "Power Prior a0=0.2")

# 5) Power Prior a0=0.25

Bayes_Power_Prior_a0_0.25_HR_changing <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/Power_Prior_a0_=_0.25_300_2000_HR_changing.xlsx", sheet = sheet_names[1])

data_Bayes_Power_Prior_a0_0.25_HR_changing <- Bayes_Power_Prior_a0_0.25_HR_changing %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "Power Prior a0=0.25")

# 6) Power Prior a0=0.3

Bayes_Power_Prior_a0_0.3_HR_changing <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/Power_Prior_a0_=_0.3_300_2000_HR_changing.xlsx", sheet = sheet_names[1])

data_Bayes_Power_Prior_a0_0.3_HR_changing <- Bayes_Power_Prior_a0_0.3_HR_changing %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "Power Prior a0=0.3")

# 7) Power Prior a0=0.35

Bayes_Power_Prior_a0_0.35_HR_changing <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/Power_Prior_a0_=_0.35_300_2000_HR_changing.xlsx", sheet = sheet_names[1])

data_Bayes_Power_Prior_a0_0.35_HR_changing <- Bayes_Power_Prior_a0_0.35_HR_changing %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "Power Prior a0=0.35")

# 8) Power Prior a0=0.4

Bayes_Power_Prior_a0_0.4_HR_changing <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/Power_Prior_a0_=_0.4_300_2000_HR_changing.xlsx", sheet = sheet_names[1])

data_Bayes_Power_Prior_a0_0.4_HR_changing <- Bayes_Power_Prior_a0_0.4_HR_changing %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "Power Prior a0=0.4")

# 9) Power Prior a0=0.45

Bayes_Power_Prior_a0_0.45_HR_changing <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/Power_Prior_a0_=_0.45_300_2000_HR_changing.xlsx", sheet = sheet_names[1])

data_Bayes_Power_Prior_a0_0.45_HR_changing <- Bayes_Power_Prior_a0_0.45_HR_changing %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "Power Prior a0=0.45")

# 10) Power Prior a0=0.5

Bayes_Power_Prior_a0_0.5_HR_changing <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/Power_Prior_a0_=_0.5_300_2000_HR_changing.xlsx", sheet = sheet_names[1])

data_Bayes_Power_Prior_a0_0.5_HR_changing <- Bayes_Power_Prior_a0_0.5_HR_changing %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "Power Prior a0=0.5")

combined_data_mixture_HR_changing <- bind_rows(data_sim3_results,
                                               data_informative_gamma_3.5, 
                                               data_informative_gamma_5.5, 
                                               data_informative_gamma_7.5,
                                               data_Bayes_Power_Prior_a0_0.05_HR_changing,
                                               data_Bayes_Power_Prior_a0_0.1_HR_changing,
                                               data_Bayes_Power_Prior_a0_0.15_HR_changing,
                                               data_Bayes_Power_Prior_a0_0.2_HR_changing,
                                               data_Bayes_Power_Prior_a0_0.25_HR_changing,
                                               data_Bayes_Power_Prior_a0_0.3_HR_changing,
                                               data_Bayes_Power_Prior_a0_0.35_HR_changing,
                                               data_Bayes_Power_Prior_a0_0.4_HR_changing,
                                               data_Bayes_Power_Prior_a0_0.45_HR_changing,
                                               data_Bayes_Power_Prior_a0_0.5_HR_changing)

combined_data_mixture_HR_changing <- combined_data_mixture_HR_changing %>%
  group_by(Prior) %>%
  mutate(desired_HRs = (desired_HRs))

combined_data_mixture_HR_changing <- combined_data_mixture_HR_changing %>%
  mutate(diff_HR = abs(mean_HR - desired_HRs))

## Ahora sacamos las gráficas de las características operantes usando como prior el MAP Bayesiano con pesos ##

p6 <- ggplot(combined_data_mixture_HR_changing, aes(x = desired_HRs, y = prop_significant, group = Prior, color = Prior)) +
  geom_point(size = 3) +
  geom_line(linewidth = 1) +
  geom_vline(xintercept = 1, linetype = "dashed", color = "red", size = 1) +
  geom_vline(xintercept = 0.55, linetype = "dashed", color = "red", size = 1) +
  geom_vline(xintercept = 0.5, linetype = "dashed", color = "red", size = 1) +
  geom_hline(yintercept = c(0.8, 0.9), linetype = "dotted", color = c("purple", "green"), size = 1) +
  scale_x_continuous(breaks = seq(min(combined_data_mixture_HR_changing$desired_HRs), max(combined_data_mixture_HR_changing$desired_HRs), 0.1), labels = sprintf("%.2f", seq(min(combined_data_mixture_HR_changing$desired_HRs), max(combined_data_mixture_HR_changing$desired_HRs), 0.1))) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Power vs Hazard Ratio w mixture prior",
       x = "Theoretical Hazard Ratio",
       y = "Power") +
  theme_minimal() +
  theme(plot.title = element_text(size = 12, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 10),
        legend.position = "right")

p6 <- p6 +
  annotate("text", x = max(combined_data_mixture_HR_changing$desired_HRs), y = 0.8, label = "80% power", hjust = 1, vjust = -0.5, size = 3.5, color = "purple") +
  annotate("text", x = max(combined_data_mixture_HR_changing$desired_HRs), y = 0.9, label = "90% power", hjust = 1, vjust = -0.5, size = 3.5, color = "green") +
  geom_label(aes(x = 1, y = Inf, label = "H0"), vjust = 2, color = "black", fill = "white", size = 3.5, label.size = 0, fontface = "bold") +
  geom_label(aes(x = 0.55, y = Inf, label = "H1"), vjust = 2, color = "black", fill = "white", size = 3.5, label.size = 0, fontface = "bold") +
  geom_label(aes(x = 0.5, y = Inf, label = "Real HR"), vjust = 2, color = "black", fill = "white", size = 3.5, label.size = 0, fontface = "bold")

p6

# Graficamos las diferencias

p7 <- ggplot(combined_data_mixture_HR_changing, aes(x = desired_HRs, y = diff_HR, color = Prior)) +
  geom_point(size = 3) +
  geom_line(aes(group = Prior), linewidth = 1) +
  scale_x_continuous(breaks = seq(min(combined_data_mixture_HR_changing$desired_HRs), max(combined_data_mixture_HR_changing$desired_HRs), 0.1), labels = sprintf("%.2f", seq(min(combined_data_mixture_HR_changing$desired_HRs), max(combined_data_mixture_HR_changing$desired_HRs), 0.1))) +
  labs(title = "Diff btw Simulated HR and Theoretical HRs w prior mixture",
       x = "Theoretical Hazard Ratio",
       y = "Difference") +
  theme_minimal() +
  theme(plot.title = element_text(size = 8, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 6, face = "bold"),
        axis.text = element_text(size = 6),
        legend.position = "right")

p7


```

# Dynamic Power Prior

A continuación se propone el último modelo que me parece de mucho interés. Este es parte de la familia de los Power Prior y la diferencia con el anterior es que, en vez de prespecificar pesos para el descuento del control externo a0, vamos a crear unas reglas hechas de antemano para la elección automática del a0.

Aquí tenemos el diagrama de barras para entenderlo mucho más fácilmente para los dos modelos que he hecho, 1) con pesos más altos con un máximo de 0.5 y 2) el mismo esquema, pero los pesos considerados están a la mitad, siendo el máximo de 0.25.

```{r Tabla_condiciones_Dynamic_Power_Prior1 , eval = T}

# Dibujamos los esquemas dinámicos en los que se va a prestar información en función de cómo se parezca el brazo control y el control externo.

# 1) Pesos más altos


breakpoints <- c(0.775, 0.825, 0.875, 0.925, 0.975, 1.025, 1.075, 1.125, 1.175, 1.225)
strengths <- c(0.1, 0.2, 0.3, 0.4, 0.5, 0.4, 0.3, 0.2, 0.1, 0)

df <- data.frame(
  HR = breakpoints[-length(breakpoints)], 
  HR_next = breakpoints[-1], 
  Strength = strengths[-length(strengths)] 
)

p1 <- ggplot(df, aes(xmin = HR, xmax = HR_next, ymin = 0, ymax = Strength)) +
  geom_rect(color = "black", fill = "lightsteelblue1") +
  geom_vline(xintercept = 1, linetype = "dashed", color = "red") +
  scale_x_continuous(name = "Hazard Ratio", limits = c(0.7, 1.3), breaks = seq(0.6, 1.4, 0.05)) +
  scale_y_continuous(name = "Borrowing Strength", limits = c(0, 0.6), breaks = seq(0, 0.5, 0.05)) +
  theme_minimal() +
  theme(panel.grid.major.x = element_blank(), panel.grid.minor.x = element_blank()) 

p1

# 2) Pesos ma la mitad

breakpoints <- c(0.775, 0.825, 0.875, 0.925, 0.975, 1.025, 1.075, 1.125, 1.175, 1.225)
strengths <- c(0.05, 0.1, 0.15, 0.2, 0.25, 0.2, 0.15, 0.1, 0.05, 0)

df <- data.frame(
  HR = breakpoints[-length(breakpoints)], 
  HR_next = breakpoints[-1], 
  Strength = strengths[-length(strengths)] 
)

p2 <- ggplot(df, aes(xmin = HR, xmax = HR_next, ymin = 0, ymax = Strength)) +
  geom_rect(color = "black", fill = "lightsteelblue1") +
  geom_vline(xintercept = 1, linetype = "dashed", color = "red") +
  scale_x_continuous(name = "Hazard Ratio", limits = c(0.7, 1.3), breaks = seq(0.6, 1.4, 0.05)) +
  scale_y_continuous(name = "Borrowing Strength", limits = c(0, 0.3), breaks = seq(0, 0.5, 0.05)) +
  theme_minimal() +
  theme(panel.grid.major.x = element_blank(), panel.grid.minor.x = element_blank()) 

p2
      
```

```{r T1E_combined_all, eval = T}

library(cowplot)

p11 <- p1 + theme(plot.background = element_rect(colour = "black", size = 0.5, fill = NA))
p22 <- p2 + theme(plot.background = element_rect(colour = "black", size = 0.5, fill = NA))

plots_row <- plot_grid(p11, p22, ncol = 2, labels = c("A", "B"), label_size = 14)

combined_plot <- plot_grid(
  plots_row,
  #legend,
  ncol = 1,                 
  rel_heights = c(3, 0.4)   
)

print(combined_plot)

```

Para que se decida de manera dinámica el peso para a0, vamos a hacer para cada uno de los ensayos simulados en cada uno de los escenarios una comparación en los datos obtenidos de esa simulación para el brazo control vs los datos del brazo control externo (POSEIDON).

Como podemos observar, si los datos se parecen (i.e., HR=1), entonces se va a prestar más información y a0 tendrá el máximo valor que es 0.5, de lo contrario, si se va diferenciando progresivamente el peso para a0 va a ir disminuyendo. Si el HR entre el brazo control y el brazo control externo es menor de 0.7 o mayor de 1.3, entonces no se va a el power prior y se hará un análisis normal (a0 = 0).

Para estudiar esta similitud, he hecho un código STAN adhoc usando una regresión de Cox para compararlo, sin embargo, el tiempo de simulación tarda el doble. Es por eso, que para comparar estos 2 brazos control, lo he hecho con una regresión de Cox frecuentista. Simplemente para ahorrar tiempo ya que lo he comprobado y sale exactamente lo mismo al usar en el Bayesiano priors no informativas N(0,10).

La condición que se ve en el gráfico de barras lo he puesto directamente en la función madre para no complicarme, así que por eso no está como input. Pero ya con más tiempo se puede hacer especificarlo desde la llamada de la función. 

Esto es muy útil porque no es una caja negra como si usáramos el peso como otra variable aleatoria más, si no que sabemos de antemano las condiciones y esto podemos verlo desde un punto de vista regulatorio.

```{r Dynamic_Power_Prior , eval = T}

shape_parameter <- 1 

control_medians <- c(3.5,3.75,4,4.25,4.5,4.75,5,5.25,5.5,5.75,6,6.25,6.5,6.75,7,7.25,7.5)

medians <- matrix(NA, nrow = length(control_medians), ncol = 3, 
                  dimnames = list(NULL, c("Control", "Treatment", "Hazard Ratio")))

desired_HR = 0.55

for (i in 1:length(control_medians)) {
  medians[i, "Control"] <- control_medians[i]
  
  lambda_control = control_medians[i] / (log(2)^(1/shape_parameter))
  lambda_treatment = lambda_control / desired_HR^(1/shape_parameter)
  
  medians[i, "Treatment"] = lambda_treatment * (log(2)^(1/shape_parameter))
  medians[i, "Hazard Ratio"] = (lambda_control / lambda_treatment)^shape_parameter
}

medians <- medians[,1:2]
sample_size <- 300  
ratio <- c(0.5,0.5)
rand_type <- "CR" 
scenarios_eff <- as.matrix(medians, nrow = length(medians), ncol = 2, byrow = TRUE)
censor <- c(0.1,0.1)
Tmax <- 20
alpha <- 0.05 
test.type <- 2
HR_1 <- TRUE
IA <- NULL
method_IA <- "bayes"
n_exp_events <- 175
Plot_Power <- FALSE
plot_pvalues = FALSE 
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = TRUE
analysis = "bayes"
n_sim <- 2000
seed <- 24
# 1) Shape control, 2) rate control, 3) Shape experimental y 4) rate experimental
prior_gamma <- matrix(c(1, 1/6, 1, 1/6), nrow = 2, ncol = 2, byrow = TRUE) 
prior_type <- c("Power prior") # Este vector es para que aparezca el nombre en las tablas
P_HR_data_Boundary <- 0.8 # P(HR < 0.8 | data)
modelo_weibull_sep <- rstan::stan_model("weibull_power_prior.stan" ,verbose = F)
modelo = modelo_weibull_sep
w= NULL       
modelo_bayes_test = "weibull"
a0 = NULL

# Cogemos los datos que más se parecen

data_hist3 <- read.csv("IPD_POSEIDON_NSCLC_PFS_pem_bsc.csv")

data_hist3$arm <- 1

external_data <- data_hist3
external_data$dataset <- 'external'
external_data$id <- seq(1, dim(external_data)[1], by = 1)
external_data$status <- ifelse(external_data$status==1, TRUE, FALSE)

Dynamic_Borrowing_PP = TRUE

# sim103 <-  sim_trials(n_sim = n_sim,
#                       analysis = "bayes",
#                       sample_size = sample_size,
#                       ratio = ratio,
#                       rand_type = rand_type,
#                       Tmax = Tmax,
#                       scenarios_eff = scenarios_eff,
#                       shape_parameter = shape_parameter,
#                       censor = censor,
#                       test.type = test.type,
#                       alpha = alpha,
#                       method_IA = method_IA,
#                       IA = IA,
#                       n_exp_events = n_exp_events,
#                       HR_1 = HR_1,
#                       Plot_Power = Plot_Power,
#                       modelo = modelo,
#                       modelo_bayes_test = modelo_bayes_test,
#                       prior_type = prior_type,
#                       P_HR_data_Boundary = P_HR_data_Boundary,
#                       prior_gamma = prior_gamma,
#                       Plot_Power_scenarios = Plot_Power_scenarios,
#                       desired_HRs = desired_HRs,
#                       plot_pvalues = plot_pvalues,
#                       Plot_Control_Scenarios = Plot_Control_Scenarios,
#                       w = w,
#                       external_data = external_data,
#                       a0 = a0,
#                       Dynamic_Borrowing_PP = Dynamic_Borrowing_PP,
#                       seed = seed)
# 
# sim103[[2]]
# sim103[[3]]
# sim103[[4]]
# 
# sim1030 <- sim103[[1]]
# 
# wd <- createWorkbook()
# addWorksheet(wd, "Sheet1")
# writeData(wd, "Sheet1", sim1030)
# saveWorkbook(wd, "Dynamic_Power_Prior_4_300_2000.xlsx", overwrite = TRUE)

## Leemos los datos de las tablas obtenidas con el ordenador de multicore ##

sheet_names <- c("Sheet1")

# 1) Dynamic Power Prior 1: Pesos altos
# Tiempo = ??

Bayes_Dynamic_Power_Prior_1 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/Dynamic_Power_Prior_4_300_2000.xlsx", sheet = sheet_names[1])

# 1) Dynamic Power Prior 2: Pesos bajos
# Tiempo = 16h19m24s

Bayes_Dynamic_Power_Prior_2 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/Dynamic_Power_Prior_3_300_2000.xlsx", sheet = sheet_names[1])


# Bayes_Dynamic_Power_Prior_1

data_Bayes_Dynamic_Power_Prior_1 <- Bayes_Dynamic_Power_Prior_1 %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "Dynamic Power Prior HW")

data_filtered_diff_not_zero_Bayes_Dynamic_Power_Prior_1 <- data_Bayes_Dynamic_Power_Prior_1 %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_Bayes_Dynamic_Power_Prior_1 <- data_Bayes_Dynamic_Power_Prior_1 %>%
  filter(median_control == median_treatment)

# Bayes_Dynamic_Power_Prior_2

data_Bayes_Dynamic_Power_Prior_2 <- Bayes_Dynamic_Power_Prior_2 %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "Dynamic Power Prior LW")

data_filtered_diff_not_zero_Bayes_Dynamic_Power_Prior_2 <- data_Bayes_Dynamic_Power_Prior_2 %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_Bayes_Dynamic_Power_Prior_2 <- data_Bayes_Dynamic_Power_Prior_2 %>%
  filter(median_control == median_treatment)


combined_data_diff_not_zero <- bind_rows(data_filtered_diff_not_zero_frequentist,
                                         data_filtered_diff_not_zero_Bayes_Dynamic_Power_Prior_1,
                                         data_filtered_diff_not_zero_Bayes_Dynamic_Power_Prior_2)

combined_data_diff_not_zero$Prior <- factor(
  combined_data_diff_not_zero$Prior,
  levels = c(
    "Frequentist",
     "Dynamic Power Prior HW",
     "Dynamic Power Prior LW"
  )
)

combined_data_diff_zero <- bind_rows(data_filtered_diff_zero_frequentist,
                                     data_filtered_diff_zero_Bayes_Dynamic_Power_Prior_1,
                                     data_filtered_diff_zero_Bayes_Dynamic_Power_Prior_2)

combined_data_diff_zero$Prior <- factor(
  combined_data_diff_not_zero$Prior,
  levels = c(
    "Frequentist",
     "Dynamic Power Prior HW",
     "Dynamic Power Prior LW"
  )
)

## Ahora sacamos las gráficas de las características operantes usando como prior el MAP Bayesiano con pesos ##

# MSE

p6 <- ggplot(combined_data_diff_not_zero, aes(x = median_control, y = mean_MSE, color = Prior)) + 
  geom_line(size = 1.2) +
  geom_vline(xintercept = median_control_center, linetype = "solid") +
  labs(
    title = "Mean Square Error (MSE)",
    x = "Median Control Arm (in months)",
    y = "Mean MSE",
    color = "Bayesian Prior Distributions"
  ) +
  theme_minimal() + 
  theme(
    plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 10, face = "bold"),
    axis.text = element_text(size = 12),
    axis.title.x = element_text(size = 11),
    axis.title.y = element_text(size = 11),
    legend.margin = margin(9, 9, 9, 9),
    legend.text = element_text(size = 9),
    legend.title = element_text(size = 10, face = "bold")
  ) +
  scale_color_discrete(name = "Bayesian Prior Distributions") +
  scale_x_continuous(breaks = seq(min(combined_data_diff_not_zero$median_control), max(combined_data_diff_not_zero$median_control), by = 0.5)) +
  scale_y_continuous(limits = c(0, 0.075))

p6

# Power

p7 <- ggplot(combined_data_diff_not_zero, aes(x = median_control, y = prop_significant, color = Prior)) +
  geom_line(size = 1.2) + 
  geom_line() +
  geom_vline(xintercept = median_control_center, linetype = "dashed") +
  labs(title = "Power", x = "Median Control Arm (in months)", y = "Proportion of Significant Trials", color = "Bayesian Prior Distributions") +
  theme_minimal() + 
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 12),
        axis.title.x = element_text(size = 12),
        axis.title.y = element_text(size = 12),
        legend.margin = margin(12, 12, 12, 12),
        legend.text = element_text(size = 11),
        legend.title = element_text(size = 12, face = "bold")) +
  scale_color_discrete(name = "Bayesian Prior Distributions") +
  scale_linetype_discrete(name = "Bayesian Prior Distributions") +
  scale_x_continuous(breaks = seq(min(combined_data_diff_not_zero$median_control), max(combined_data_diff_not_zero$median_control), by = 0.5)) +
  scale_y_continuous(limits = c(0.8, 1))
p7


# ET1

p8 <- ggplot(combined_data_diff_zero, aes(x = median_control, y = prop_significant, color = Prior)) +
  geom_line(size = 1.2) + 
  geom_line() +
  geom_vline(xintercept = median_control_center, linetype = "dashed") +
  geom_hline(yintercept = 0.025, linetype = "dashed", color = "green") +
  geom_hline(yintercept = 0.05, linetype = "dashed", color = "purple") +
  labs(title = "Type I Error (T1E)", x = "Median Control (in months)", y = "Proportion of Significant Trials", color = "Bayesian Prior Distributions") +
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 12),
        axis.title.x = element_text(size = 12),
        axis.title.y = element_text(size = 12),
        legend.margin = margin(12, 12, 12, 12),
        legend.text = element_text(size = 11),
        legend.title = element_text(size = 12, face = "bold")) +
  scale_color_discrete(name = "Bayesian Prior Distributions") +
  scale_linetype_discrete(name = "Bayesian Prior Distributions") +
  scale_x_continuous(breaks = seq(min(combined_data_diff_zero$median_control), max(combined_data_diff_zero$median_control), by = 0.5)) +
  scale_y_continuous(limits = c(0, 0.2))
p8
      
```

```{r T1E_combined_powerprior2, eval = T}

library(cowplot)

p66 <- p6 + scale_color_discrete(
  name = "Bayesian Prior Distributions", 
  labels = c(
        "Frequentist",
        "Dynamic Power Prior with High Weights (0, 0.5)",
        "Dynamic Power Prior with Low Weights (0, 0.25)"
  )
) +
  guides(color = guide_legend(ncol = 3))  

legend <- get_legend(
  p66 +
    theme(
      # legend.box = "horizontal", 
      legend.justification = c(0, 1),
      # legend.margin = margin(8, 8, 8, 8),
      legend.text = element_text(size = 10), 
      legend.title = element_text(size = 11, face = "bold")
    )
)

# Remove individual legends from the plots
p66 <- p66 + theme(legend.position = "none")
p77 <- p7 + theme(legend.position = "none")
p88 <- p8 + theme(legend.position = "none")

p66 <- p66 + theme(plot.background = element_rect(colour = "black", size = 0.5, fill = NA))
p77 <- p77 + theme(plot.background = element_rect(colour = "black", size = 0.5, fill = NA))
p88 <- p88 + theme(plot.background = element_rect(colour = "black", size = 0.5, fill = NA))

plots_row <- plot_grid(p66, p77, p88, ncol = 3, labels = c("A", "B", "C"), label_size = 14)

combined_plot <- plot_grid(
  plots_row,
  legend,
  ncol = 1,                 
  rel_heights = c(3, 0.4)   
)

print(combined_plot)

```


Ahora evaluamos cuando variamos los hazard ratios.

```{r `Dynamic_Power_Prior_Cambiando_HRs`, eval = T}

shape_parameter <- 1 

desired_HRs <- c(1.3, 1.2, 1.1, 1, 0.95, 0.9, 0.85, 0.8, 0.775, 0.75, 0.725, 0.7, 0.675, 0.65, 0.625, 0.6, 0.575, 0.55, 0.525, 0.5, 0.45, 0.4, 0.35, 0.3)
control_medians <- rep(5.5, times = length(desired_HRs))

medians_control_fijo <- matrix(NA, nrow = length(desired_HRs), ncol = 2, dimnames = list(paste0("HR ", desired_HRs), c("Control", "Treatment")))

for (i in 1:length(desired_HRs)) {
  medians_control_fijo[i, "Treatment"] <- control_medians[i] / (desired_HRs[i]^(1/shape_parameter))
  medians_control_fijo[i, "Control"] <- control_medians[i]
}

sample_size <- 300  
ratio <- c(0.5,0.5)
rand_type <- "CR" 
scenarios_eff <- as.matrix(medians_control_fijo, nrow = dim(medians_control_fijo)[1], ncol = 2, byrow = TRUE)
censor <- c(0.1,0.1)
Tmax <- 20
alpha <- 0.05 
test.type <- 2
HR_1 <- FALSE
IA <- NULL
method_IA <- "bayes"
n_exp_events <- 175
Plot_Power <- FALSE
plot_pvalues = FALSE 
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = FALSE
analysis = "bayes"
n_sim <- 2000
seed <- 24
# 1) Shape control, 2) rate control, 3) Shape experimental y 4) rate experimental
prior_gamma <- matrix(c(1, 1/6, 1, 1/6), nrow = 2, ncol = 2, byrow = TRUE) 
prior_type <- c("Power prior") # Este vector es para que aparezca el nombre en las tablas
P_HR_data_Boundary <- 0.8 # P(HR < 0.8 | data)
modelo_weibull_sep <- rstan::stan_model("weibull_power_prior.stan" ,verbose = F)
modelo = modelo_weibull_sep
w= NULL       
modelo_bayes_test = "weibull"
a0 = NULL

# Cogemos los datos que más se parecen

data_hist3 <- read.csv("IPD_POSEIDON_NSCLC_PFS_pem_bsc.csv")

data_hist3$arm <- 1

external_data <- data_hist3
external_data$dataset <- 'external'
external_data$id <- seq(1, dim(external_data)[1], by = 1)
external_data$status <- ifelse(external_data$status==1, TRUE, FALSE)

Dynamic_Borrowing_PP = TRUE


# sim111 <-  sim_trials(n_sim = n_sim,
#                       analysis = "bayes",
#                       sample_size = sample_size,
#                       ratio = ratio,
#                       rand_type = rand_type,
#                       Tmax = Tmax,
#                       scenarios_eff = scenarios_eff,
#                       shape_parameter = shape_parameter,
#                       censor = censor,
#                       test.type = test.type,
#                       alpha = alpha,
#                       method_IA = method_IA,
#                       IA = IA,
#                       n_exp_events = n_exp_events,
#                       HR_1 = HR_1,
#                       Plot_Power = Plot_Power,
#                       modelo = modelo,
#                       modelo_bayes_test = modelo_bayes_test,
#                       prior_type = prior_type,
#                       P_HR_data_Boundary = P_HR_data_Boundary,
#                       prior_gamma = prior_gamma,
#                       Plot_Power_scenarios = Plot_Power_scenarios,
#                       desired_HRs = desired_HRs,
#                       plot_pvalues = plot_pvalues,
#                       Plot_Control_Scenarios = Plot_Control_Scenarios,
#                       w = w,
#                       external_data = external_data,
#                       a0 = a0,
#                       seed = seed,
#                       Dynamic_Borrowing_PP = Dynamic_Borrowing_PP)
# 
# wd <- createWorkbook()
# addWorksheet(wd, "Sheet1")
# writeData(wd, "Sheet1", sim111)
# saveWorkbook(wd, "Dynamic_Power_Prior_4_300_2000_HR_changing.xlsx", overwrite = TRUE)


sheet_names <- c("Sheet1")

# 1) Dynamic Power Prior 1: Higher weights

Bayes_Dynamic_Power_Prior_1_HR_changing <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/Dynamic_Power_Prior_4_300_2000_HR_changing.xlsx", sheet = sheet_names[1])

data_Bayes_Dynamic_Power_Prior_1_HR_changing <- Bayes_Dynamic_Power_Prior_1_HR_changing %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "Dynamic Power Prior 1: Higher weights")

# 2) Dynamic Power Prior 2: Lower weights

Bayes_Dynamic_Power_Prior_2_HR_changing <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/Dynamic_Power_Prior_3_300_2000_HR_changing.xlsx", sheet = sheet_names[1])

data_Bayes_Dynamic_Power_Prior_2_HR_changing <- Bayes_Dynamic_Power_Prior_2_HR_changing %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "Dynamic Power Prior 2: Lower weights")


combined_data_mixture_HR_changing <- bind_rows(data_sim3_results,
                                               data_informative_gamma_3.5, 
                                               data_informative_gamma_5.5, 
                                               data_informative_gamma_7.5,
                                               Bayes_Dynamic_Power_Prior_1_HR_changing,
                                               Bayes_Dynamic_Power_Prior_2_HR_changing)

combined_data_mixture_HR_changing <- combined_data_mixture_HR_changing %>%
  group_by(Prior) %>%
  mutate(desired_HRs = (desired_HRs))

combined_data_mixture_HR_changing <- combined_data_mixture_HR_changing %>%
  mutate(diff_HR = abs(mean_HR - desired_HRs))

## Ahora sacamos las gráficas de las características operantes usando como prior el MAP Bayesiano con pesos ##

p6 <- ggplot(combined_data_mixture_HR_changing, aes(x = desired_HRs, y = prop_significant, group = Prior, color = Prior)) +
  geom_point(size = 3) +
  geom_line(linewidth = 1) +
  geom_vline(xintercept = 1, linetype = "dashed", color = "red", size = 1) +
  geom_vline(xintercept = 0.55, linetype = "dashed", color = "red", size = 1) +
  geom_vline(xintercept = 0.5, linetype = "dashed", color = "red", size = 1) +
  geom_hline(yintercept = c(0.8, 0.9), linetype = "dotted", color = c("purple", "green"), size = 1) +
  scale_x_continuous(breaks = seq(min(combined_data_mixture_HR_changing$desired_HRs), max(combined_data_mixture_HR_changing$desired_HRs), 0.1), labels = sprintf("%.2f", seq(min(combined_data_mixture_HR_changing$desired_HRs), max(combined_data_mixture_HR_changing$desired_HRs), 0.1))) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Power vs Hazard Ratio w mixture prior",
       x = "Theoretical Hazard Ratio",
       y = "Power") +
  theme_minimal() +
  theme(plot.title = element_text(size = 12, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 10),
        legend.position = "right")

p6 <- p6 +
  annotate("text", x = max(combined_data_mixture_HR_changing$desired_HRs), y = 0.8, label = "80% power", hjust = 1, vjust = -0.5, size = 3.5, color = "purple") +
  annotate("text", x = max(combined_data_mixture_HR_changing$desired_HRs), y = 0.9, label = "90% power", hjust = 1, vjust = -0.5, size = 3.5, color = "green") +
  geom_label(aes(x = 1, y = Inf, label = "H0"), vjust = 2, color = "black", fill = "white", size = 3.5, label.size = 0, fontface = "bold") +
  geom_label(aes(x = 0.55, y = Inf, label = "H1"), vjust = 2, color = "black", fill = "white", size = 3.5, label.size = 0, fontface = "bold") +
  geom_label(aes(x = 0.5, y = Inf, label = "Real HR"), vjust = 2, color = "black", fill = "white", size = 3.5, label.size = 0, fontface = "bold")

p6

# Graficamos las diferencias

p7 <- ggplot(combined_data_mixture_HR_changing, aes(x = desired_HRs, y = diff_HR, color = Prior)) +
  geom_point(size = 3) +
  geom_line(aes(group = Prior), linewidth = 1) +
  scale_x_continuous(breaks = seq(min(combined_data_mixture_HR_changing$desired_HRs), max(combined_data_mixture_HR_changing$desired_HRs), 0.1), labels = sprintf("%.2f", seq(min(combined_data_mixture_HR_changing$desired_HRs), max(combined_data_mixture_HR_changing$desired_HRs), 0.1))) +
  labs(title = "Diff btw Simulated HR and Theoretical HRs w prior mixture",
       x = "Theoretical Hazard Ratio",
       y = "Difference") +
  theme_minimal() +
  theme(plot.title = element_text(size = 8, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 6, face = "bold"),
        axis.text = element_text(size = 6),
        legend.position = "right")

p7


```



# Selección de Modelos para calcular el tamaño muestral con diferentes efectos de tratamiento.

Ahora vamos a elegir modelos tipos para ver cuántos pacientes nos ahorramos seleccionando algunos de los modelos anteriormente vistos. En todos los modelos se han hecho 5K simulaciones por cada tamaño muestral, mientras que en el frecuentista se ha hecho 100K (también hay otro de 5K pero ya que hecho el otro lo dejo):
  
  1) Frecuentista (100K) -> T = 15h42m48s
  2) Prior poco informativa centered at median 5.5 months:  Gamma(7.213475, 1) -> T = 44h07m59s
  3) Robust Mixture Prior: 0.15 Prior MAP + 0.85 Prior no informativa -> T = 41h32m37s
  4) Robust Mixture Prior: 0.25 Prior MAP + 0.75 Prior no informativa -> T = 38h00m50s
  5) Robust Mixture Prior: 0.35 Prior MAP + 0.6 Prior no informativa -> T = 37h53m44s
  6) Robust Mixture Prior: Random weight restringido (0-0.5) -> T = 70h19m01s
  7) Power Prior: a0 = 0.05
  8) Dynamic Power Prior: Lower weights
  
Usando estos modelos, vamos a ver cuántos pacientes son necesarios para obtener un poder del 80%, 85% y 90% de poder. Como para evaluar estos modelos se han usado diferentes asunciones para el efecto del brazo control, vamos a asumir 2 tipos de efectos para cada uno de los modelos a la hora de generar los datos:
    
1) Efecto que se especificó en el SAP para el brazo experimental y control
2) Efecto obtenido al final del estudio para el brazo experimental y control. Para este, tengo que modificar el código para poder tener 2 shapes diferentes a la hora de general los datos para cada uno de los brazos. Primero hago una regresión weibull para cada uno de los brazos por separado y ahí, lo incorporo en el código.

Luego hay que crear una tabla resumen con cada uno de los modelos y los números de pacientes necesarios para cada uno de los 3 poderes para cada uno de los efectos diferentes. Así mismo, se especificarán los valores de MSE, poder y T1E obtenidos anteriormente.

Sin necesidad de poner los inputs para todos los modelos ya que se han hecho anteriormente, aquí sólo muestro como son los inputs para el modelo frecuentista y uno de los modelos Bayesianos.

Como esto es para los resultados finales, el nº de simulaciones por escenario ha aumentado de 3.000 a 5.000.

Como ya se han ejecutado, voy a leer los resultados directamente de todos los modelos moviendo todos los tamaños muestrales.

1) Frecuentista - SAP

```{r `Final models: Frequentist - SAP`, eval = T, echo = T}

shape_parameter <- 1
sample_size <- seq(from = 50, to= 300, by = 5)
ratio <- c(0.5,0.5)
rand_type <- "CR" 
scenarios_eff <- matrix(c(5.5,10), nrow = 1, ncol = 2, byrow = TRUE) # HR=0.55
censor <- c(0.1,0.1)
Tmax <- 20
alpha <- 0.05 
test.type <- 2
HR_1 <- TRUE
IA <- NULL
Plot_Power = TRUE
plot_pvalues = FALSE
analysis = "freq" 
n_sim <- 100000
seed <- 24

# sim2 <- sim_trials(n_sim = n_sim, 
#                    analysis = "freq",
#                    sample_size = sample_size,
#                    ratio = ratio,
#                    rand_type = rand_type,
#                    Tmax = Tmax, 
#                    shape_parameter = shape_parameter,
#                    scenarios_eff = scenarios_eff,
#                    censor = censor,
#                    alpha = alpha,
#                    test.type = test.type,
#                    IA = IA,
#                    method_IA = method_IA,
#                    n_exp_events = n_exp_events,
#                    HR_1 = HR_1,
#                    seed=seed,
#                    Plot_Power = Plot_Power,
#                    plot_pvalues = plot_pvalues)
# 
# sim2_power <- sim2[[2]]
# sim2_power_T1E <- sim2[[3]]
# sim2_power_MSE <- sim2[[4]]
# sim2_results <- sim2[[1]]

# Aquí los datos se leen del Excel con los datos simulados en el ordenador de multicore.

sheet_names <- c("Sheet1")
SAP_Freq_5K_SampleSizes <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/DEF_SAP_Freq_5K_SampleSizes.xlsx", sheet = sheet_names[1])


```


2) Bayes: Weak Prior centered at median 5.5 months, Gamma(7.213475, 1) - SAP

```{r `Final models: Bayes - Weak prior Gamma(7.213475, 1) - SAP`, eval = T}

sample_size <- seq(from = 50, to= 300, by = 5)
ratio <- c(0.5,0.5)
rand_type <- "CR" 
scenarios_eff <- matrix(c(5.5,10), nrow = 1, ncol = 2, byrow = TRUE) # HR=0.55
censor <- c(0.1,0.1)
Tmax <- 20
alpha <- 0.05 
test.type <- 2
HR_1 <- TRUE
IA <- NULL
method_IA <- "bayes"
n_exp_events <- 175
Plot_Power <- TRUE
plot_pvalues = FALSE 
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = FALSE

analysis = "bayes"
n_sim <- 5000
seed <- 24
# 1) Shape control, 2) rate control, 3) Shape experimental y 4) rate experimental
prior_gamma <- matrix(c(7.213475, 1, 1, 1/6), nrow = 2, ncol = 2, byrow = TRUE) 
prior_type <- c("Weak informative prior") # Este vector es para que aparezca el nombre en las tablas
P_HR_data_Boundary <- 0.8 # P(HR < 0.8 | data)
modelo_weibull_sep <- rstan::stan_model("weibull_gamma_def.stan" ,verbose = F)
modelo = modelo_weibull_sep
modelo_bayes_test = "weibull"

# sim6 <-  sim_trials(n_sim = n_sim,  
#                     analysis = "bayes",
#                     sample_size = sample_size, 
#                     ratio = ratio,
#                     rand_type = rand_type,
#                     Tmax = Tmax, 
#                     scenarios_eff = scenarios_eff,
#                     shape_parameter = shape_parameter,
#                     censor = censor,
#                     test.type = test.type,
#                     alpha = alpha,
#                     method_IA = method_IA,
#                     IA = IA,
#                     n_exp_events = n_exp_events,
#                     HR_1 = HR_1,
#                     Plot_Power = Plot_Power,
#                     modelo = modelo,
#                     modelo_bayes_test = modelo_bayes_test,
#                     prior_type = prior_type,
#                     P_HR_data_Boundary = P_HR_data_Boundary,
#                     prior_gamma = prior_gamma,
#                     Plot_Power_scenarios = Plot_Power_scenarios,
#                     desired_HRs = desired_HRs,
#                     plot_pvalues = plot_pvalues,
#                     Plot_Control_Scenarios = Plot_Control_Scenarios,
#                     seed = seed)
# sim6[[2]]
# sim6[[3]]
# sim6[[4]]
# 
# sim66 <- sim6[[1]]
# 
# wd <- createWorkbook()
# addWorksheet(wd, "Sheet1")
# writeData(wd, "Sheet1", sim66)
# saveWorkbook(wd, "weak_informative_gamma_300_2000_HR_055.xlsx", overwrite = TRUE)


sheet_names <- c("Sheet1")
weak_informative_gamma <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/weak_informative_gamma_300_2000_HR_055.xlsx", sheet = sheet_names[1])


```

# LECTURA RESULTADOS TAMAÑOS MUESTRALES DEL SAP

```{r `Final models: Lectura datos SAP`, eval = T}

sheet_names <- c("Sheet1")

# 1) Frecuentista (100K) -> T = 15h42m48s
DEF_SAP_Freq <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/DEF_SAP_Freq_5K_SampleSizes.xlsx", sheet = sheet_names[1])
DEF_SAP_Freq_Power <- subset(DEF_SAP_Freq, scenario == 1,
                             select = c(scenario, sample_size, prop_significant)) %>%
  mutate(Prior = "Frequentist")
DEF_SAP_Freq_T1E <- subset(DEF_SAP_Freq, scenario == 2,
                           select = c(scenario, sample_size, prop_significant)) %>%
  mutate(Prior = "Frequentist")

# 2) Prior weak informative centered at median 5.5 months:  Gamma(7.213475, 1) -> T = 44h07m59s
DEF_SAP_Weak_informative <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/DEF_SAP_Bayes_Weak_informative_5K_SampleSizes.xlsx", sheet = sheet_names[1])
DEF_SAP_Weak_informative_Power <- subset(DEF_SAP_Weak_informative, scenario == 1,
                                         select = c(scenario, sample_size, Prior, prop_significant)) %>%
  mutate(Prior = "Weak Informative Prior centered at 5.5 months")

DEF_SAP_Weak_informative_T1E <- subset(DEF_SAP_Weak_informative, scenario == 2,
                                       select = c(scenario, sample_size, Prior, prop_significant)) %>%
  mutate(Prior = "Weak Informative Prior centered at 5.5 months")

# 3) Robust Mixture Prior: 0.15 Prior MAP + 0.85 Prior no informativa -> T = 41h32m37s
DEF_SAP_Mixture_0.15 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/DEF_SAP_Bayes_Mixture_0.15_5K_SampleSizes.xlsx", sheet = sheet_names[1])
DEF_SAP_Mixture_0.15_Power <- subset(DEF_SAP_Mixture_0.15, scenario == 1,
                                     select = c(scenario, sample_size, Prior, prop_significant)) %>%
  mutate(Prior = "Robust MAP Prior w=0.15")
DEF_SAP_Mixture_0.15_T1E <- subset(DEF_SAP_Mixture_0.15, scenario == 2,
                                   select = c(scenario, sample_size, Prior, prop_significant)) %>%
  mutate(Prior = "Robust MAP Prior w=0.15")

# 4) Robust Mixture Prior: 0.25 Prior MAP + 0.75 Prior no informativa -> T = 38h00m50s
DEF_SAP_Mixture_0.25 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/DEF_SAP_Bayes_Mixture_0.25_5K_SampleSizes.xlsx", sheet = sheet_names[1])
DEF_SAP_Mixture_0.25_Power <- subset(DEF_SAP_Mixture_0.25, scenario == 1,
                                     select = c(scenario, sample_size, Prior, prop_significant)) %>%
  mutate(Prior = "Robust MAP Prior w=0.25")
DEF_SAP_Mixture_0.25_T1E <- subset(DEF_SAP_Mixture_0.25, scenario == 2,
                                   select = c(scenario, sample_size, Prior, prop_significant)) %>%
  mutate(Prior = "Robust MAP Prior w=0.25")

# 5) Robust Mixture Prior: 0.4 Prior MAP + 0.6 Prior no informativa -> T = 37h53m44s
DEF_SAP_Mixture_0.35 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/DEF_SAP_Bayes_Mixture_0.35_5K_SampleSizes.xlsx", sheet = sheet_names[1])
DEF_SAP_Mixture_0.35_Power <- subset(DEF_SAP_Mixture_0.35, scenario == 1,
                                    select = c(scenario, sample_size, Prior, prop_significant)) %>%
  mutate(Prior = "Robust MAP Prior w=0.35")
DEF_SAP_Mixture_0.35_T1E <- subset(DEF_SAP_Mixture_0.35, scenario == 2,
                                  select = c(scenario, sample_size, Prior, prop_significant)) %>%
  mutate(Prior = "Robust MAP Prior w=0.35")

# 6) Robust Mixture Prior: Random weight restringido (0-0.5) -> T = 70h19m01s
DEF_SAP_Mixture_Restricted_Random_W <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/DEF_SAP_Bayes_Mixture_Random_w_0_a_0.5_5K_SampleSizes.xlsx", sheet = sheet_names[1])
DEF_SAP_Mixture_Restricted_Random_W_Power <- subset(DEF_SAP_Mixture_Restricted_Random_W, scenario == 1,
                                                    select = c(scenario, sample_size, Prior, prop_significant)) %>%
  mutate(Prior = "Robust MAP Prior with w (0, 0.5)")
DEF_SAP_Mixture_Restricted_Random_W_T1E <- subset(DEF_SAP_Mixture_Restricted_Random_W, scenario == 2,
                                                  select = c(scenario, sample_size, Prior, prop_significant)) %>%
  mutate(Prior = "Robust Mixture MAP Prior with w (0, 0.5)")

# 7)   7) Power Prior: a0 = 0.05
DEF_SAP_Bayes_Power_Prior_a0_0.05_5K_SampleSizes <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/DEF_SAP_Bayes_Mixture_Random_w_0_a_0.5_5K_SampleSizes.xlsx", sheet = sheet_names[1])

DEF_SAP_Bayes_Power_Prior_a0_0.05_5K_SampleSizes_Power <- subset(DEF_SAP_Bayes_Power_Prior_a0_0.05_5K_SampleSizes, scenario == 1,
                                                    select = c(scenario, sample_size, Prior, prop_significant)) %>%
  mutate(Prior = "Power Prior a0=0.05")
DEF_SAP_Bayes_Power_Prior_a0_0.05_5K_SampleSizes_T1E <- subset(DEF_SAP_Bayes_Power_Prior_a0_0.05_5K_SampleSizes, scenario == 2,
                                                  select = c(scenario, sample_size, Prior, prop_significant)) %>%
  mutate(Prior = "Power Prior a0=0.05")

# 8) Dynamic Power Prior: Lower weights
DEF_SAP_Bayes_Dynamic_Power_Prior_2_5K_SampleSizes <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/DEF_SAP_Bayes_Dynamic_Power_Prior_3_5K_SampleSizes.xlsx", sheet = sheet_names[1])
DEF_SAP_Bayes_Dynamic_Power_Prior_2_5K_SampleSizes_Power <- subset(DEF_SAP_Bayes_Dynamic_Power_Prior_2_5K_SampleSizes, scenario == 1,
                                                    select = c(scenario, sample_size, Prior, prop_significant)) %>%
  mutate(Prior = "Dynamic Power Prior with Low Weights (0, 0.25)")
DEF_SAP_Bayes_Dynamic_Power_Prior_3_5K_SampleSizes_T1E <- subset(DEF_SAP_Bayes_Dynamic_Power_Prior_2_5K_SampleSizes, scenario == 2,
                                                  select = c(scenario, sample_size, Prior, prop_significant)) %>%
  mutate(Prior = "Dynamic Power Prior with Low Weights (0, 0.25)")


# Combinamos los datos 



combined_data_DEF_SAP_Power <- bind_rows(DEF_SAP_Freq_Power,
                                         DEF_SAP_Weak_informative_Power,
                                         DEF_SAP_Mixture_0.15_Power,
                                         DEF_SAP_Mixture_0.25_Power,
                                         DEF_SAP_Mixture_0.35_Power,
                                         DEF_SAP_Mixture_Restricted_Random_W_Power,
                                         DEF_SAP_Bayes_Power_Prior_a0_0.05_5K_SampleSizes_Power,
                                         DEF_SAP_Bayes_Dynamic_Power_Prior_2_5K_SampleSizes_Power)

combined_data_DEF_SAP_T1E <- bind_rows(DEF_SAP_Freq_T1E,
                                       DEF_SAP_Weak_informative_T1E,
                                       DEF_SAP_Mixture_0.15_T1E,
                                       DEF_SAP_Mixture_0.25_T1E,
                                       DEF_SAP_Mixture_0.35_T1E,
                                       DEF_SAP_Mixture_Restricted_Random_W_T1E,
                                       DEF_SAP_Bayes_Power_Prior_a0_0.05_5K_SampleSizes_T1E,
                                       DEF_SAP_Bayes_Dynamic_Power_Prior_3_5K_SampleSizes_T1E)

# Dibujamos el plot del poder:
# Dibujamos el plot del poder:

desired_powers <- c(0.8, 0.85, 0.9, 0.95)
colors_for_dotted_lines <- c("purple", "blue", "green", "red") 

p1 <- ggplot(combined_data_DEF_SAP_Power, aes(x = sample_size, y = prop_significant, group = Prior, color = Prior)) +
  geom_point(size = 3) +  
  geom_line(linewidth = 1) +  
  geom_hline(yintercept = desired_powers, linetype = "dotted", color = colors_for_dotted_lines, size = 1) + 
  scale_x_continuous(breaks = seq(min(combined_data_DEF_SAP_Power$sample_size)-5, max(combined_data_DEF_SAP_Power$sample_size)+5, 25)) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Power for Selected Bayesian Models",
       x = "Sample Size",
       y = "Power") +
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 12),
        axis.title.x = element_text(size = 11),
        axis.title.y = element_text(size = 11),
        legend.margin = margin(12, 12, 12, 12),
        legend.text = element_text(size = 11),
        legend.title = element_text(size = 12, face = "bold")) +
  scale_color_discrete(name = "Bayesian Prior Distributions") +
  scale_linetype_discrete(name = "Bayesian Prior Distributions") 

rightmost_x <- max(combined_data_DEF_SAP_Power$sample_size) - 5  
for (i in 1:length(desired_powers)) {
  p1 <- p1 + annotate("text", 
                      x = rightmost_x, 
                      y = desired_powers[i], 
                      label = sprintf("%.0f%% power", desired_powers[i] * 100), 
                      hjust = 1,  
                      vjust = -0.3,  
                      size = 3.5, 
                      color = colors_for_dotted_lines[i])
}

p1

#Ahora hacemos una tabla para identificar cuál alcanza el poder antes.

desired_powers <- c(0.8, 0.85, 0.9, 0.95)

tabla <- function(df, target) {
  df %>%
    group_by(Prior) %>%
    filter(prop_significant >= target) %>%
    arrange(sample_size) %>%
    slice(1) %>%
    summarize(sample_size = first(sample_size), .groups = 'drop') %>%
    mutate(Power = as.character(target))  
}

results <- lapply(desired_powers, function(p) tabla(combined_data_DEF_SAP_Power, p))
results_df <- do.call(rbind, results)

Table_Power <- pivot_wider(
  results_df, 
  names_from = Prior, 
  values_from = sample_size, 
  id_cols = Power,
  values_fill = list(sample_size = NA)
)

Table_Power_df <- as.data.frame(Table_Power)

Table_Power_df <- Table_Power_df[c("Power", "Frequentist", "Weak Informative Prior centered at 5.5 months", "Robust MAP Prior w=0.15", "Robust MAP Prior w=0.25", "Robust MAP Prior w=0.35", "Robust MAP Prior with w (0, 0.5)", "Power Prior a0=0.05", "Dynamic Power Prior with Low Weights (0, 0.25)")]


table5 <- gt(Table_Power_df) %>%
  #tab_header(title = "Sample Sizes achieving target Power with different Prior Distributions") %>%
  cols_label(
  ) %>%
  fmt_number(
    columns = c(-Power),
    decimals = 0  
  ) %>%
  tab_style(
    style = cell_text(weight = "bold", align = "center"),
    locations = cells_column_labels(columns = everything())
  ) %>%
  tab_options(
    column_labels.background.color = "lightsteelblue1",
    table.font.size = px(20),
    table.background.color = "white"
  ) %>%
  tab_style(
    style = cell_fill(color = "lightsteelblue1"),
    locations = cells_body(rows = seq(2, nrow(Table_Power_df), by = 2))
  ) %>%
  tab_style(
    style = cell_fill(color = "white"),
    locations = cells_body(rows = seq(1, nrow(Table_Power_df), by = 2))
  ) %>%
  tab_style(
    style = cell_text(align = "center"),
    locations = cells_body(columns = everything())
  ) %>% 
  tab_style(
    style = cell_fill(color = "lightsteelblue1"),  
    locations = cells_body(columns = "Power")
  ) %>%
  tab_style(
    style = cell_borders(sides = "bottom", color = "black", weight = px(2)),
    locations = cells_column_labels(columns = names(Table_Power_df)[names(Table_Power_df) != "Power"])
  ) %>%
  tab_style(
    style = cell_borders(sides = "right", color = "black", weight = px(2)),
    locations = cells_body(columns = "Power")
  ) %>%
  tab_style(
    style = cell_text(weight = "bold"),  
    locations = cells_body(columns = "Power")
  ) 

table5

# Ahora tamaños muestrales para datos reales.

sample_sizes <- c(110, 115, 120, 125, 130, 135, 140, 150, 155, 160, 180, 185, 190, 200, 220, 300, 305)

# Dibujamos el plot del ET1:

desired_powers <- c(0.025, 0.05)
colors_for_dotted_lines <- c("green", "red") 

p2 <- ggplot(combined_data_DEF_SAP_T1E, aes(x = sample_size, y = prop_significant, group = Prior, color = Prior)) +
  geom_point(size = 3) +  
  geom_line(linewidth = 1) +  
  geom_hline(yintercept = desired_powers, linetype = "dotted", color = colors_for_dotted_lines, size = 1) + 
  scale_x_continuous(breaks = seq(min(combined_data_DEF_SAP_T1E$sample_size)-5, max(combined_data_DEF_SAP_T1E$sample_size)+5, 25)) +
  scale_y_continuous(limits = c(0, 0.15)) +  
  labs(title = "T1E vs. Sample Size",
       x = "Sample Size",
       y = "T1E") +
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 14, face = "bold"),
        axis.text = element_text(size = 12))


p2


```

# Datos Reales obtenidos en el ensayo

Se han evaluado los resultados finales de este estudio para hacernos una idea de los parámetros necesarios para los modelos parámetricos que se va a utilizar. Para ello es necesario tener los datos paciente a paciente para poder usar estos datos en R y poder hacer inferencias. Ya que por temas de confidencialidad no ha sido posible, lo que se ha hecho ha sido digitalizar las curvas de Kaplan-Meier para el resultado de PFS (variable principal). 

Esta digitalización se ha hecho usando las funciones propuestas por Lui et al 2021.

Link paper: https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/s12874-021-01308-8#availability-of-data-and-materials

Link shiny app: https://www.trialdesign.org/one-page-shell.html#IPDfromKM

Cuando se escriba la tesis pondré el resto de referencias y como funciona esto.

A continuación tenemos el resultado final de PFS:
  

```{r `Results using pseudo-IPD in both arms`, eval = T, echo = T}

# Leemos los datos obtenidos a través de las coordenadas de cada uno de los puntos seleccionados de las dos curvas:

trt <- read.csv("IPD_KEYNOTE026_NSCLC_PFS_Pembro.csv")
trt$arm <- "Pembro"
soc <- read.csv("IPD_KEYNOTE026_NSCLC_PFS_SOC.csv")
soc$arm <- "soc"

# Juntamos los datasets para hacer la regresion de Cox
data <- rbind(trt,soc)

# Estimacion Cox (lo que se hace en la simulacion de momento)
fit <- coxph(Surv(time, status) ~ arm, data = data)
Estimate <- c(1/exp(confint(fit))[2], 1/summary(fit)$coefficients[2], 1/exp(confint(fit))[1])

fit_soc <- survfit(Surv(time, status) ~ 1, data = soc)
fit_trt <- survfit(Surv(time, status) ~ 1, data = trt)

time_seq <- seq(min(data$time), max(data$time), length.out = 100)

plot(fit_soc, col = "blue", main = "Kaplan-Meier Plot with pseudo IPD", xlab = "Time", ylab = "Survival Probability", lty = 1, conf.int = FALSE)
lines(fit_trt, col = "red", lty = 1, conf.int = FALSE)

```

Podemos observar que las dos curvas son prácticamente iguales usando los pseudo-datos de paciente a paciente estimado con la digitalización. Así mismo, los resultados son muy similares ya que en el estudio real se obtuvo un HR en PFS de 0.5 (0.37, 0.68) con medianas de 10.3 (6.7, -) y 6 (4.2, 6.2) para el brazo experimental y el control respectivamente. Por otro lado, usando los datos digitalizados tenemos un HR de 0.489 (0.363, 0.657) y medianas de 10.335 (6.957, -) y 6.047 (4.207, 6.310).

# Parametric survival model applied to a pseudo IPD from the Keynote024

Una vez que tenemos unos datos que se aproximan bastante bien a los reales, vamos a hacer un fit paramétrico. Para ello, vamos a ver que modelo se aproximan mejor a estos datos. La elección para el modelo en cuestión se va a hacer en función del AIC (cuanto más bajo el valor, mejor modelo es comparado con el resto)

```{r `Fitting of parametric models`, eval = T, echo = T}
# Se van a considerar 4 modelos: Exponencial, Weibull, Gompertz y Log-normal
exp_mod <- flexsurvreg(Surv(time, status) ~ arm, data = data, dist = "exp")
weibull_mod <- flexsurvreg(Surv(time, status) ~ arm, data = data, dist = "weibull")
gompertz_mod <- flexsurvreg(Surv(time, status) ~ arm, data = data, dist = "gompertz")
lognormal_mod <- flexsurvreg(Surv(time, status) ~ arm, data = data, dist = "lnorm")

# Comparamos los modelos
model_list <- list(Exponential = exp_mod, Weibull = weibull_mod, Gompertz = gompertz_mod, LogNormal = lognormal_mod)
#sapply(model_list, AIC)

```

Podemos ver que la distribución Weibull es la que mejor se aproxima bien.

```{r `Weibull Fit`, eval = T, echo = T}

weibull_surv <- survreg(Surv(time, status) ~ arm, dist = "weibull", data = data)

# El shape parameter común es 1.13017  (1/Scale)
# El scale parameter para el brazo experimental es 13.03967 (exp(Intercept))
# El scale parameter para el brazo control es 6.725033 (exp(Intercept+armsoc))
# El HR es 0.516 (exp(-armsoc))

# Por último, dibujar las curvas con el pseudo-IPD y el fit paramétrico del Weibull

time_seq <- seq(min(data$time), max(data$time), length.out = 100)

# P de supervivencia usando el modelo Weibull
weibull_soc_surv <- 1 - pweibull(time_seq, shape = 1/weibull_surv$scale, scale = exp(2.5679960-0.6621592))
weibull_trt_surv <- 1 - pweibull(time_seq, shape = 1/weibull_surv$scale, scale = exp(2.5679960))

plot(fit_soc, col = "blue", main = "Kaplan-Meier Plot with Weibull", xlab = "Time", ylab = "Survival Probability", lty = 1, conf.int = FALSE)
lines(fit_trt, col = "red", lty = 1, conf.int = FALSE)
lines(time_seq, weibull_soc_surv, col = "green", lty = 2)
lines(time_seq, weibull_trt_surv, col = "black", lty = 2)



```

Ahora vamos a hacer lo mismo pero brazo a brazo para simular los datos reales y obtener los parámetros de interés para la generación de datos.

```{r `Weibull Fit arm by arm`, eval = T, echo = T}

pembro_data <- subset(data, arm == "Pembro")
soc_data <- subset(data, arm == "soc")

fit_pembro_data <- coxph(Surv(time, status) ~ 1, data = pembro_data)
weibull_pembro_data <- survreg(Surv(time, status) ~ 1, dist = "weibull", data = pembro_data)

# El shape parameter común es 0.8690831  (1/Scale)
# El scale parameter para el brazo experimental es 14.88501 (exp(Intercept))

fit_soc_data <- survfit(Surv(time, status) ~ 1, data = soc_data)
weibull_soc_data <- survreg(Surv(time, status) ~ 1, dist = "weibull", data = soc_data)

# El shape parameter común es 1.369615  (1/Scale)
# El scale parameter para el brazo experimental es 6.761968 (exp(Intercept))

fit_soc <- survfit(Surv(time, status) ~ 1, data = soc)
fit_trt <- survfit(Surv(time, status) ~ 1, data = trt)

time_seq <- seq(min(data$time), max(data$time), length.out = 100)

# P de supervivencia usando el modelo Weibull
weibull_pembro_surv <- 1 - pweibull(time_seq, shape = 1/weibull_pembro_data$scale, scale = 14.88501)
weibull_socc_surv <- 1 - pweibull(time_seq, shape = 1/weibull_soc_data$scale, scale = 6.761968)

# Kaplan-Meier survival data preparation for ggplot
fit_trt_df <- data.frame(time = fit_trt$time, surv = fit_trt$surv, group = "Pembrolizumab (Pseudo-IPD)")
fit_soc_df <- data.frame(time = fit_soc$time, surv = fit_soc$surv, group = "SoC (Pseudo-IPD)")

# Weibull survival data preparation for ggplot
weibull_Pembrolizumab_df <- data.frame(time = time_seq, surv = weibull_pembro_surv, group = "Pembrolizumab (Weibull Model)")
weibull_soc_df <- data.frame(time = time_seq, surv = weibull_socc_surv, group = "SoC (Weibull Model)")

# Combine all data
combined_surv_df <- rbind(fit_trt_df, fit_soc_df, weibull_Pembrolizumab_df, weibull_soc_df)

# Plot using ggplot2
ggplot(combined_surv_df, aes(x = time, y = surv, color = group, linetype = group)) +
  geom_line(size = 1.2) +
  labs(
    title = "Kaplan-Meier of Pseudo-IPD with Weibull Model",
    x = "Months",
    y = "Survival Probability",
    color = "Group",
    linetype = "Group"
  ) +
  scale_color_manual(values = c("blue", "red", "green", "black")) +
  scale_linetype_manual(values = c("solid", "dashed", "solid", "dashed")) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 10, face = "bold"),
    axis.text = element_text(size = 12),
    axis.title.x = element_text(size = 11),
    axis.title.y = element_text(size = 11),
    legend.position = "bottom",
    legend.text = element_text(size = 10)
  )





plot(fit_trt, col = "blue", main = "Kaplan-Meier Plot with Weibull", xlab = "Time", ylab = "Survival Probability", lty = 1, conf.int = FALSE)
lines(fit_soc, col = "red", lty = 1, conf.int = FALSE)
lines(time_seq, weibull_pembro_surv, col = "green", lty = 2)
lines(time_seq, weibull_socc_surv, col = "black", lty = 2)

# A ver, tengo que cambiar el shape para que se puedan generar diferentes shapes y scales. Muy a tener en cuenta, cuando tengamos un vector las comparaciones de MSE y coverage probability ya no son válidas por que le HR teórico no se puede calcular al necesitar un punto en concreto. No pasa nada, lo importante es que salga sifnificativo o no.


# Dibujo para asegurarme las líneas con sus scales y shapes de la weibull de los datos reales

weibull_survival <- function(time_seq, shape, scale) {
  return(exp(- (time_seq / scale)^shape))
}

# Parametros del soc
shape1 <- 1.369615
scale1 <- 6.761968

# Parametros del pembro
shape2 <- 0.8690831
scale2 <- 14.88501

surv1 <- weibull_survival(time_seq, shape1, scale1)
surv2 <- weibull_survival(time_seq, shape2, scale2)

# Plot
# plot(time_seq, surv1, type = "l", col = "red", xlab = "Time", ylab = "Survival Probability", 
#      main = "Weibull Survival Curves")
# lines(time_seq, surv2, col = "blue")
# legend("topright", legend = c("SoC", "Pembro"), col = c("red", "blue"), lty = 1)

# Están bien los valores
```

Para entender qué hubiera pasado si se hubieran aplicado estos modelos en el momento del diseño del estudio, es interesante analizar los datos reales obtenidos y ver cómo estos modelos se comportan con los datos obtenidos.

Tengo que mirar publicaciones de otros paquetes que se han hecho para ver qué más resultados puedo tener

Para ello se van a cambiar los parámetros necesarios, por ejemplo el tamaño muestral, el efecto obtenido finalmente, etc.

En los datos reales mirando los resultados en OS. Aquí está el resumen:
  
1) HR: 0.50 (95% CI: 0.37, 0.68)
2) Mediana real en meses del brazo control: 6.0 (4.2, 6.2) 
3) Mediana real en meses del brazo experimental: 10.3 (6.7, -) 

Por otro lado, para generar los datos simulados lo más realistas posibles se ha hecho lo siguiente:
  
1) Se han obtenido los datos paciente a paciente digitalizando las curvas para cada uno de los brazos
2) Se han sacado el fit para obtener los parámetros Shape y Scala de cada uno de los brazos.
3) Sólo se modifica el código de la función gen_surv_data.r común tanto para la simulación frecuentista como      Bayesiana. Hay que tener en cuenta que estoy forzando de manera artifical al poner estos parámetros dentro     de la función ya que el parámetro shape común y el parámetro de las eficacias se usan para diferentes    c     cosas y métricas, por lo que iba a ser muy jaleo modificar todo esto para ponerlo como input.
4) En el ordenador de multicore también se actualiza ya que de ahí es de donde saco los resultados finales.
5) Se obtienen los resultados como siempre, la diferencia radica en que cada uno de los dataset obtenidos por     cada simulación van a ser mucho más realistas a los obtenidos finalemente.

Por último, dado que estos son los resultados definitivos aproximando lo mejor posible a resultados reales, se han incrementado las simulaciones en cada escenario de 5.000 a 10.000 simulaciones.

Ahora tenemos un ejemplo de los nuevos parámetros que se van a considerar para la simulación frecuentista:
  
```{r `Freq ejemplo con datos reales`, eval = T}

shape_parameter <- 1 # Esto está obsoleto porque he puesto el bueno en la función de gen_surv_data.r
sample_size <- c(110, 115, 130, 140, 150, 155, 160, 170, 180, 195, 200, 215, 220, 300, 305)
ratio <- c(0.5,0.5)
rand_type <- "CR" 
scenarios_eff <- matrix(c(6, 10.3), nrow = 1, ncol = 2, byrow = TRUE) # Esto quedará obsoleto por la incorporación en la función de gen_surv_data.r
censor <- c(0.15,0.2) # Las censuras se han hecho mirando la Tabla 10-2 de la disposición de los pacientes del CSR de este ensayo. He mirado las reglas de censura para el análisis primario y la tabla y sumando las siguientes discontinuaciones sin contar con las administrativas porque estas no son "aleatorias" que se han censurado según las normas: Adverse Event + Physician Decision + Withdrawal by subject. Se supone que Status Not Recorded son las administrativas porque tienen 74 en Pembro y 15 en SoC.


Tmax <- 17 # Esto cambió al final
alpha <- 0.05 
test.type <- 2
HR_1 <- FALSE
IA <- NULL
Plot_Power = FALSE
plot_pvalues = FALSE
analysis = "freq" 
n_sim <- 100000
seed <- 24

# sim2 <- sim_trials(n_sim = n_sim,
#                    analysis = "freq",
#                    sample_size = sample_size,
#                    ratio = ratio,
#                    rand_type = rand_type,
#                    Tmax = Tmax,
#                    shape_parameter = shape_parameter,
#                    scenarios_eff = scenarios_eff,
#                    censor = censor,
#                    alpha = alpha,
#                    test.type = test.type,
#                    IA = IA,
#                    method_IA = method_IA,
#                    n_exp_events = n_exp_events,
#                    HR_1 = HR_1,
#                    seed=seed,
#                    Plot_Power = Plot_Power,
#                    plot_pvalues = plot_pvalues)
# 
# 
# # sim45_power <- sim45[[2]]
# # sim45_power_T1E <- sim45[[3]]
# # sim45_power_MSE <- sim45[[4]]
# # sim45_results <- sim45[[1]]
# 
# wd <- createWorkbook()
# addWorksheet(wd, "Sheet1")
# writeData(wd, "Sheet1", sim2)
# saveWorkbook(wd, "DEF_DEF_REAL_Freq_100K_SampleSizes_DEF.xlsx", overwrite = TRUE)

```

Y un ejemplo de un Bayesiano, en este caso el Weak:
  
```{r `Final models: Bayes - Weak prior Gamma(7.213475, 1) - SAP2`, eval = T}


# 1) # ESTE ES EL WEAK PRIOR

shape_parameter <- 1 # Esto está obsoleto porque he puesto el bueno en la función de gen_surv_data.r
sample_size <- c(110, 115, 130, 140, 150, 155, 160, 170, 180, 195, 200, 215, 220, 300, 305)

ratio <- c(0.5,0.5)
rand_type <- "CR" 
scenarios_eff <- matrix(c(6, 10.3), nrow = 1, ncol = 2, byrow = TRUE) 


Tmax <- 17 # Esto cambió al final
alpha <- 0.05 
test.type <- 2
HR_1 <- FALSE
IA <- NULL
method_IA <- "bayes"
n_exp_events <- 175
Plot_Power = FALSE
plot_pvalues = FALSE 
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = FALSEanalysis = "bayes"
n_sim <- 10000
seed <- 24
# 1) Shape control, 2) rate control, 3) Shape experimental y 4) rate experimental
prior_gamma <- matrix(c(6.223775, 1, 1, 1/6), nrow = 2, ncol = 2, byrow = TRUE) 

prior_type <- c("Non informative prior") # Este vector es para que aparezca el nombre en las tablas
P_HR_data_Boundary <- 0.8 # P(HR < 0.8 | data)
modelo_weibull_sep <- rstan::stan_model("weibull_gamma_def.stan" ,verbose = F) # Este es el STAN con Ga(1, 1/6)
modelo = modelo_weibull_sep
modelo_bayes_test = "weibull"
w = NULL

# sim51 <-  sim_trials(n_sim = n_sim,
#                      analysis = "bayes",
#                      sample_size = sample_size,
#                      ratio = ratio,
#                      rand_type = rand_type,
#                      Tmax = Tmax,
#                      scenarios_eff = scenarios_eff,
#                      shape_parameter = shape_parameter,
#                      censor = censor,
#                      test.type = test.type,
#                      alpha = alpha,
#                      method_IA = method_IA,
#                      IA = IA,
#                      n_exp_events = n_exp_events,
#                      HR_1 = HR_1,
#                      Plot_Power = Plot_Power,
#                      modelo = modelo,
#                      modelo_bayes_test = modelo_bayes_test,
#                      prior_type = prior_type,
#                      P_HR_data_Boundary = P_HR_data_Boundary,
#                      prior_gamma = prior_gamma,
#                      Plot_Power_scenarios = Plot_Power_scenarios,
#                      desired_HRs = desired_HRs,
#                      plot_pvalues = plot_pvalues,
#                      Plot_Control_Scenarios = Plot_Control_Scenarios,                     
#                      w = w,
#                      seed = seed)
# 
# # sim45_power <- sim45[[2]]
# # sim45_power_T1E <- sim45[[3]]
# # sim45_power_MSE <- sim45[[4]]
# # sim45_results <- sim45[[1]]
# 
# wd <- createWorkbook()
# addWorksheet(wd, "Sheet1")
# writeData(wd, "Sheet1", sim51)
# saveWorkbook(wd, "DEF_DEF_REAL_Bayes_Weak_10K_SampleSizes_DEF.xlsx", overwrite = TRUE)


```


# LECTURA RESULTADOS TAMAÑOS MUESTRALES DEL REAL

```{r `Final models: Lectura datos REAL`, eval = T}

sheet_names <- c("Sheet1")

# 1) Frecuentista (100K) -> T = 15h42m48s
DEF_REAL_Freq <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/DEF_DEF_REAL_Freq_100K_SampleSizes_DEF.xlsx", sheet = sheet_names[1])
DEF_REAL_Freq_Power <- subset(DEF_REAL_Freq, scenario == 1,
                              select = c(scenario, sample_size, prop_significant)) %>%
  mutate(Prior = "Frequentist")

colnames(DEF_REAL_Freq)[colnames(DEF_REAL_Freq) == "mean_Lower_IC"] <- "mean_Lower_ICrI"
colnames(DEF_REAL_Freq)[colnames(DEF_REAL_Freq) == "mean_Upper_IC"] <- "mean_Upper_CrI"

DEF_REAL_Freq_HRs <- subset(DEF_REAL_Freq, scenario == 1,
                              select = c(scenario, sample_size, mean_HR, mean_Lower_ICrI, mean_Upper_CrI)) %>%
  mutate(Prior = "Frequentist") 


# 2) Prior weak informative centered at median 5.5 months:  Gamma(7.213475, 1) -> T = 44h07m59s
DEF_REAL_Weak_informative <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/DEF_DEF_REAL_Bayes_Weak_10K_SampleSizes_DEF.xlsx", sheet = sheet_names[1])
DEF_REAL_Weak_informative_Power <- subset(DEF_REAL_Weak_informative, scenario == 1,
                                          select = c(scenario, sample_size, Prior, prop_significant)) %>%
  mutate(Prior = "Weak Informative Prior centered at 5.5 months")

DEF_REAL_Weak_informative_HRs <- subset(DEF_REAL_Weak_informative, scenario == 1,
                              select = c(scenario, sample_size, Prior, mean_HR, mean_Upper_CrI, mean_Lower_ICrI)) %>%
  mutate(Prior = "Weak Informative Prior\ncentered at 5.5 months") 


# # 3) MAP Bayesiano -> T = 44h04m30s
# DEF_REAL_MAP <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/DEF_REAL_Bayes_MAP_10K_SampleSizes.xlsx", sheet = sheet_names[1])
# DEF_REAL_MAP_Power <- subset(DEF_REAL_MAP, scenario == 1,
#                              select = c(scenario, sample_size, Prior, prop_significant)) %>%
#   mutate(Prior = "Meta-Analytic Prior (MAP)")

# 3) Robust Mixture Prior: 0.15 Prior MAP + 0.85 Prior no informativa -> T = 41h32m37s
DEF_REAL_Mixture_0.15 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/DEF_DEF_REAL_Bayes_Mixture_0.15_10K_SampleSizes_DEF.xlsx", sheet = sheet_names[1])
DEF_REAL_Mixture_0.15_Power <- subset(DEF_REAL_Mixture_0.15, scenario == 1,
                                      select = c(scenario, sample_size, Prior, prop_significant)) %>%
  mutate(Prior = "Robust MAP Prior w=0.15")

DEF_REAL_MAP_0.15_HRs <- subset(DEF_REAL_Mixture_0.15, scenario == 1,
                              select = c(scenario, sample_size, Prior, mean_HR, mean_Upper_CrI, mean_Lower_ICrI)) %>%
  mutate(Prior = "Robust MAP Prior w=0.15") 



# 4) Robust Mixture Prior: 0.25 Prior MAP + 0.75 Prior no informativa -> T = 38h00m50s
DEF_REAL_Mixture_0.25 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/DEF_DEF_REAL_Bayes_Mixture_0.25_10K_SampleSizes_DEF.xlsx", sheet = sheet_names[1])
DEF_REAL_Mixture_0.25_Power <- subset(DEF_REAL_Mixture_0.25, scenario == 1,
                                      select = c(scenario, sample_size, Prior, prop_significant)) %>%
  mutate(Prior = "Robust MAP Prior w=0.25")

DEF_REAL_MAP_0.25_HRs <- subset(DEF_REAL_Mixture_0.25, scenario == 1,
                              select = c(scenario, sample_size, Prior, mean_HR, mean_Upper_CrI, mean_Lower_ICrI)) %>%
  mutate(Prior = "Robust MAP Prior w=0.25") 


# 5) Robust Mixture Prior: 0.35 Prior MAP + 0.65 Prior no informativa -> T = 37h53m44s
DEF_REAL_Mixture_0.35 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/DEF_DEF_REAL_Bayes_Mixture_0.35_10K_SampleSizes_DEF.xlsx", sheet = sheet_names[1])
DEF_REAL_Mixture_0.35_Power <- subset(DEF_REAL_Mixture_0.35, scenario == 1,
                                     select = c(scenario, sample_size, Prior, prop_significant)) %>%
  mutate(Prior = "Robust MAP Prior w=0.35")

DEF_REAL_MAP_0.35_HRs <- subset(DEF_REAL_Mixture_0.35, scenario == 1,
                              select = c(scenario, sample_size, Prior, mean_HR, mean_Upper_CrI, mean_Lower_ICrI)) %>%
  mutate(Prior = "Robust MAP Prior w=0.35") 


# # 7) Robust Mixture Prior: Random weight -> T = 46m02m32s
# DEF_REAL_Mixture_Random_W <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/DEF_REAL_Bayes_Mixture_Random_w_10K_SampleSizes.xlsx", sheet = sheet_names[1])
# DEF_REAL_Mixture_Random_W_Power <- subset(DEF_REAL_Mixture_Random_W, scenario == 1,
#                                           select = c(scenario, sample_size, Prior, prop_significant)) %>%
#   mutate(Prior = "Robust Mixture Prior Random w")

# 6) Robust Mixture Prior: Random weight restringido (0-0.5) -> T = 70h19m01s
DEF_REAL_Mixture_Restricted_Random_W <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/DEF_DEF_REAL_Bayes_Mixture_Random_w_0_A_0.05_10K_SampleSizes_DEF.xlsx", sheet = sheet_names[1])
DEF_REAL_Mixture_Restricted_Random_W_Power <- subset(DEF_REAL_Mixture_Restricted_Random_W, scenario == 1,
                                                     select = c(scenario, sample_size, Prior, prop_significant)) %>%
  mutate(Prior = "Robust MAP Prior with w (0, 0.5)")

DEF_REAL_Mixture_Restricted_Random_W_HRs <- subset(DEF_REAL_Mixture_Restricted_Random_W, scenario == 1,
                              select = c(scenario, sample_size, Prior, mean_HR, mean_Upper_CrI, mean_Lower_ICrI)) %>%
  mutate(Prior = "Robust MAP Prior with w (0, 0.5)") 

# 7) Power Prior con a0 = 0.05

DEF_REAL_Power_Prior_a0_0.05 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/DEF_DEF_REAL_Bayes_Power_Prior_a0_0.05_5K_SampleSizes.xlsx", sheet = sheet_names[1])
DEF_REAL_Power_Prior_a0_0.05_Power <- subset(DEF_REAL_Power_Prior_a0_0.05, scenario == 1,
                                                     select = c(scenario, sample_size, Prior, prop_significant)) %>%
   mutate(Prior = "Power Prior with a0=0.05")

DEF_REAL_Power_Prior_a0_0.05_HRs <- subset(DEF_REAL_Power_Prior_a0_0.05, scenario == 1,
                              select = c(scenario, sample_size, Prior, mean_HR, mean_Upper_CrI, mean_Lower_ICrI)) %>%
  mutate(Prior = "Power Prior with a0=0.05") 

# 8) Dynamic Power Prior: Low weights
DEF_REAL_Dynamic_Power_Prior <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Pembro_NSCLC/PEMBROLIZUMAB_NSCLC_TABLAS/DEF_DEF_REAL_Dyn_Power_Prior_10K_SampleSizes_DEF.xlsx", sheet = sheet_names[1])
DEF_REAL_Dynamic_Power_Prior_Power <- subset(DEF_REAL_Dynamic_Power_Prior, scenario == 1,
                                                     select = c(scenario, sample_size, Prior, prop_significant)) %>%
  mutate(Prior = "Dynamic Power Prior with Low Weights (0, 0.25)")

DEF_REAL_Dynamic_Power_Prior_HRs <- subset(DEF_REAL_Dynamic_Power_Prior, scenario == 1,
                              select = c(scenario, sample_size, Prior, mean_HR, mean_Upper_CrI, mean_Lower_ICrI)) %>%
  mutate(Prior = "Dynamic Power Prior with Low Weights (0, 0.25)") 

# Combinamos los datos 



combined_data_DEF_REAL_Power <- bind_rows(DEF_REAL_Freq_Power,
                                          DEF_REAL_Weak_informative_Power,
                                          DEF_REAL_Mixture_0.15_Power,
                                          DEF_REAL_Mixture_0.25_Power,
                                          DEF_REAL_Mixture_0.35_Power,
                                          DEF_REAL_Mixture_Restricted_Random_W_Power,
                                          DEF_REAL_Power_Prior_a0_0.05_Power,
                                          DEF_REAL_Dynamic_Power_Prior)

combined_data_DEF_REAL_HRs <- bind_rows(DEF_REAL_Freq_HRs,
                                          DEF_REAL_Weak_informative_HRs,
                                          DEF_REAL_MAP_0.15_HRs,
                                          DEF_REAL_MAP_0.25_HRs,
                                          DEF_REAL_MAP_0.35_HRs,
                                          DEF_REAL_Mixture_Restricted_Random_W_HRs,
                                          DEF_REAL_Power_Prior_a0_0.05_HRs,
                                          DEF_REAL_Dynamic_Power_Prior_HRs)


# Dibujamos el plot del poder:

desired_powers <- c(0.8, 0.85, 0.9, 0.95)
colors_for_dotted_lines <- c("purple", "blue", "green", "red") 

p1 <- ggplot(combined_data_DEF_REAL_Power, aes(x = sample_size, y = prop_significant, group = Prior, color = Prior)) +
  geom_point(size = 3) +  
  geom_line(linewidth = 1) +  
  geom_hline(yintercept = desired_powers, linetype = "dotted", color = colors_for_dotted_lines, size = 1) + 
  scale_x_continuous(breaks = seq(min(combined_data_DEF_REAL_Power$sample_size)-5, max(combined_data_DEF_REAL_Power$sample_size)+5, 25)) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Power vs. Sample Size",
       x = "Sample Size",
       y = "Power") +
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 14, face = "bold"),
        axis.text = element_text(size = 12))

rightmost_x <- max(combined_data_DEF_REAL_Power$sample_size) - 5  

for (i in 1:length(desired_powers)) {
  p1 <- p1 + annotate("text", 
                      x = rightmost_x, 
                      y = desired_powers[i], 
                      label = sprintf("%.0f%% power", desired_powers[i] * 100), 
                      hjust = 1,  
                      vjust = -0.3,  
                      size = 3.5, 
                      color = colors_for_dotted_lines[i])
}

p1

#Ahora hacemos una tabla para identificar cuál alcanza el poder antes.

combined_data_DEF_REAL_Power <- combined_data_DEF_REAL_Power %>%
  mutate(sample_size = as.integer(sample_size)) %>%
  select(-scenario)

Table_Power <- combined_data_DEF_REAL_Power %>%
  pivot_wider(
    names_from = Prior,
    values_from = prop_significant,
    id_cols = sample_size,
    values_fill = list(prop_significant = NA))
  # ) %>%
  # slice(-1:-2)  # Quito los valores de 75 y 90 porque ya no voy a considerar el MAP para los modelos finales

Table_Power_df <- as.data.frame(Table_Power)

library(gt)

table6 <- gt(Table_Power_df) %>%
  #tab_header(title = "Proportion Significant by Sample Size and Prior Type") %>%
  cols_label(
    sample_size = "Sample Size" 
  ) %>%
  fmt_number(
    columns = c(-sample_size),  
    decimals = 4  
  ) %>%
  tab_style(
    style = cell_text(weight = "bold", align = "center"),
    locations = cells_column_labels(columns = everything())
  ) %>%
  tab_options(
    column_labels.background.color = "lightsteelblue1",
    table.font.size = px(25),
    table.background.color = "white"
  ) %>%
  tab_style(
    style = cell_fill(color = "lightsteelblue1"),
    locations = cells_body(rows = seq(2, nrow(Table_Power_df), by = 2))
  ) %>%
  tab_style(
    style = cell_fill(color = "white"),
    locations = cells_body(rows = seq(1, nrow(Table_Power_df), by = 2))
  ) %>%
  tab_style(
    style = cell_text(align = "center"),
    locations = cells_body(columns = everything())
  ) %>%
  tab_style(
    style = cell_fill(color = "lightsteelblue1"),  
    locations = cells_body(columns = vars(sample_size))
  ) %>%
  tab_style(
    style = cell_borders(sides = "bottom", color = "black", weight = px(2)),
    locations = cells_column_labels(columns = names(Table_Power_df)[names(Table_Power_df) != "sample_size"])
  ) %>%
  tab_style(
    style = cell_borders(sides = "right", color = "black", weight = px(2)),
    locations = cells_body(columns = vars(sample_size))
  ) %>%
  tab_style(
    style = cell_text(weight = "bold"),  
    locations = cells_body(columns = vars(sample_size))
  ) 

table6



```



```{r `Final models: Lectura datos REAL2`, eval = T}

library(highcharter)
library(dplyr)

custom_prior_order <- c(
  "Frequentist",
  "Weak Informative Prior\ncentered at 5.5 months",
  "Weak Informative Prior\ncentered at 19 months (Seddon)",
  "Robust MAP Prior w=0.15",
  "Robust MAP Prior w=0.25",
  "Robust MAP Prior w=0.35",
  "Robust MAP Prior with w (0, 0.5)",
  "Power Prior with a0=0.05",
  "Dynamic Power Prior with Low Weights (0, 0.25)"
)

custom_colors <- c(
  "#e31a1c",  
  "#1f78b4",  
  "#b15928", 
  "#B57BA2",
  "#C2A43C",
  "#1E1E1E",
  "#33a02c",  
  "#ff7f00",
  "#8DB9D7"
)

combined_data_DEF_REAL_HRs <- combined_data_DEF_REAL_HRs %>%
  mutate(
    sample_size = as.factor(sample_size),  
    Prior = factor(Prior, levels = custom_prior_order)  
  )

combined_data_DEF_REAL_HRs2 <- combined_data_DEF_REAL_HRs %>%
  mutate(
    mean_HR = as.numeric(mean_HR),
    mean_Lower_ICrI = as.numeric(mean_Lower_ICrI),
    mean_Upper_CrI = as.numeric(mean_Upper_CrI),
    sample_size = as.character(sample_size) 
  )

p <- hchart(
  combined_data_DEF_REAL_HRs2,
  type = "columnrange",  
  hcaes(
    x = sample_size,        
    low = mean_Lower_ICrI,  
    high = mean_Upper_CrI,  
    group = Prior           
  )
) %>%
  hc_chart(polar = TRUE) %>% 
  hc_colors(custom_colors) %>%  
  hc_yAxis(
    max = 0.75,    
    min = 0.25,    
    labels = list(
      formatter = JS("function() { return 'HR = ' + this.value; }"),  
      style = list(fontSize = "13px", fontWeight = "bold")
    ),
    title = NULL
  ) %>%
  hc_xAxis(
    title = NULL,  
    categories = levels(combined_data_DEF_REAL_HRs2$sample_size),  
    labels = list(format = "{value}", style = list(fontSize = "14px", fontWeight = "bold")),
    gridLineWidth = 0.5
  ) %>%
  hc_exporting(enabled = TRUE, buttons = list(contextButton = list(enabled = FALSE))) %>%
  hc_add_theme(hc_theme_elementary()) 


p <- p %>% 
  hc_legend(
    align = "center",
    verticalAlign = "bottom",
    layout = "horizontal",
    title = list(
      text = "Bayesian Prior Distributions",
      style = list(fontSize = "16px", fontWeight = "bold")  
    ),
    itemStyle = list(fontSize = "13px") 
  )

p


```



La siguiente tabla nos muestra lo mismo pero con mucho más detalle y clasificándolo

```{r `Final models: Lectura datos REAL guay`, eval = T}

combined_data_DEF_REAL_Power <- bind_rows(DEF_REAL_Freq_Power,
                                          DEF_REAL_Weak_informative_Power,
                                          DEF_REAL_Mixture_0.15_Power,
                                          DEF_REAL_Mixture_0.25_Power,
                                          DEF_REAL_Mixture_0.35_Power,
                                          DEF_REAL_Mixture_Restricted_Random_W_Power,
                                          DEF_REAL_Power_Prior_a0_0.05_Power,
                                          DEF_REAL_Dynamic_Power_Prior)

combined_data_DEF_REAL_Power <- combined_data_DEF_REAL_Power %>%
  mutate(sample_size = as.integer(sample_size)) %>%
  select(-scenario)

Table_Power <- combined_data_DEF_REAL_Power %>%
  pivot_wider(
    names_from = Prior,
    values_from = prop_significant,
    id_cols = sample_size,
    values_fill = list(prop_significant = NA))
  # ) %>%
  # slice(-1:-2)  # Quito los valores de 75 y 90 porque ya no voy a considerar el MAP para los modelos finales

Table_Power_df <- as.data.frame(Table_Power)

# Aplicamos el ranking para cada modelo en cada tamaño muestral
ranked_df <- Table_Power_df %>%
  select(-sample_size) %>%
  apply(1, function(row) rank(-row, ties.method = "random")) %>% #En este metodo para empates usaría average pero esta da problemas a la hora de colorear las tablas cuando hay empates por lo que pongo random.
  t() %>%
  as.data.frame()

names(ranked_df) <- paste0(names(ranked_df), "_rank")

ranked_df <- ranked_df[1:nrow(Table_Power_df), ]

# Juntamos los datos de poder con los rankings
Table_Power_df <- Table_Power_df %>%
  bind_cols(ranked_df)

# Colores como las olimpiadas: oro, plata y bronce
colors <- c("gold", "grey70", "darkorange")

# Crear la tabla de interés
table7 <- gt(Table_Power_df) %>%
  tab_header(title = "Power achieved by each model for the whole set of sample sizes considered") %>%
  cols_label(sample_size = "Sample Size") %>%
    fmt_number(
    columns = c("sample_size"),  # Aquí detallamos cuántos decimales queremos para los valores de estas columnas
    decimals = 0
  ) %>%
  fmt_number(
    columns = names(medians)[!names(medians) %in% c("sample_size")],  # Aplicamos estos decimales para los valores de todas las columnas menos las especificadas aquí
    decimals = 4
  ) %>%
  cols_align(align = "center", columns = everything()) %>%
  cols_hide(vars(ends_with("_rank"))) %>%
  tab_style(
    style = cell_text(weight = "bold", align = "center"),
    locations = cells_column_labels(columns = everything())
  ) %>%
  tab_options(
    column_labels.background.color = "lightsteelblue1",
    table.font.size = px(12),
    table.background.color = "white"
  ) %>%
  tab_style(
    style = cell_fill(color = "lightsteelblue1"),
    locations = cells_body(rows = seq(2, nrow(Table_Power_df), by = 2))
  ) %>%
  tab_style(
    style = cell_fill(color = "white"),
    locations = cells_body(rows = seq(1, nrow(Table_Power_df), by = 2))
  ) %>%
  tab_style(
    style = cell_text(align = "center"),
    locations = cells_body(columns = everything())
  ) %>%
  tab_style(
    style = cell_fill(color = "lightsteelblue1"),  
    locations = cells_body(columns = vars(sample_size))
  ) %>%
  tab_style(
    style = cell_borders(sides = "bottom", color = "black", weight = px(2)),
    locations = cells_column_labels(columns = names(Table_Power_df)[names(Table_Power_df) != "sample_size"])
  ) %>%
  tab_style(
    style = cell_borders(sides = "right", color = "black", weight = px(2)),
    locations = cells_body(columns = vars(sample_size))
  ) %>%
  tab_style(
    style = cell_text(weight = "bold"),  
    locations = cells_body(columns = vars(sample_size))
  ) 

# En este bucle aplicamos el color correspondiente al top-3 para cada tamaño muestral
for (row_index in 1:nrow(Table_Power_df)) {
  for (col_name in names(Table_Power_df)[!grepl("_rank$", names(Table_Power_df)) & names(Table_Power_df) != "sample_size"]) {
    rank_col_name <- paste0(col_name, "_rank")
    rank_value <- Table_Power_df[[rank_col_name]][row_index]

    if (rank_value %in% 1:3) {
      color_value <- colors[rank_value]
      
      table7 <- table7 %>%
        tab_style(
          style = cell_fill(color = color_value),
          locations = cells_body(
            columns = col_name,
            rows = row_index
          )
        )
    }
  }
}

# Ponemos la nota a pie de página para aclarar en qué consiste cada color
table7 <- table7 %>%
  tab_source_note(
    source_note = "1. A golden cell indicates the highest power achieved by a model for a specific sample size."
  ) %>%
  tab_source_note(
    source_note = "2. A silver cell indicates the second highest power achieved by a model for a specific sample size."
  ) %>%
  tab_source_note(
    source_note = "3. A copper-colored cell indicates the third highest power achieved by a model for a specific sample size."
  )

table7


```


