---
title: "Assessment of the TOWER trial (study 00103311) for the Blinatumomab in Philadelphia chromosome negative relapsed or refractory B-precursor ALL"
author: "Borja G. López-Rey"
date: "`r Sys.Date()`"
output: 
  rmarkdown::html_vignette:
    code_folding: hide
vignette: >
  %\VignetteIndexEntry{Model checking with simulated data (survival model example)}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, eval = T, results = 'hide', echo = F}
knitr::opts_chunk$set(message = FALSE,
                      warning = FALSE,
                      fig.width = 8.5,  
                      fig.height = 6,
                      echo = TRUE)
```


```{r load-packages, eval = T, echo = F}

library(ggplot2)
library(survival)
library(tidyr)
library(gsDesign)
library(gsDesign2)
library(dplyr)
library(stringr)
library(tibble)
library(rstan)
rstan_options(auto_write = TRUE)
options(mc.cores = min(8, parallel::detectCores()))
library(loo)
library(openxlsx)
library(readxl)
options(digits=7)
library(flexsurv)
library(stringr)
library(SurvRegCensCov)
library(metafor)
library(knitr)
library(flexmix)
library(brms)
library(meta)
library(tidybayes)
library(ggdist)
library(forcats)
library(ggridges)
library(glue)
library(stats4)
library(kableExtra)
library(gt)

```

```{r load-functions, eval = T, echo = F}

source("sim_trials.r")
source("sim_freq.r")
source("sim_bayes.r")
source("surv_analysis_freq.r")
source("surv_analysis_bayes.r")
source("rand.r")
source("gen_surv_data.r")
source("get_boundaries_IA.r")
source("analysis_surv_data_freq.r")
source("analysis_surv_data_bayes.r")
source("plot_bayes.r")
source("plot_bayes_sep.r")

```

# Ejercicio de simulación

Partimos de la hipótesis que el uso de diseños Bayesianos podría haber optimizado el desarrollo de los ensayos clínicos oncológicos en aquellos donde se ha usado una diseño frecuentista. Para ello, se van a evaluar las características operantes de diferentes diseños Bayesianos con respecto al frecuentista para comprobar que podríamos haber necesitado un menor número de pacientes asegurando que no se infle el Error de Tipo I (ET1) a lo largo de diferntes escenarios.

Para ello, se van a usar 3 ensayos reales y vamos a simular los datos cogiendo como parámetros lo que el Sponsor tuvo en cuenta cuando justificó su tamaño muestral en el Statistical Analysis Plan (SAP). Así mismo, como los resultados de esos ensayos ya están disponibles, también se van como parámetros los datos reales obtenidos de estos ensayos usando como análisis los modelos escogidos anteriormente en la primera parte para ver el poder que hubiéramos tenido.

El segundo ensayo tipo, es un ensayo con resultados muy limítrofes, siendo estadísticamente significativo. Este es el Blincyto indicado en pacientes adultos con R/R B-precursor Acute Lymphoblastic Leukemia (ALL). 

# TOWER Study -> Blinatumomab indicado en R/R B-precursos ALL

Este estudio se hizo como condición para poder obtener la autorización completa. La autorización condicional se hizo con el SAT en fase 2 en esta misma indicación.

A continuación hay un párrafo que explica la situación de este ensayo, se aprobó de manera condicional en 23/11/2015 con resultados de Fase 2 single-arm trial con NCT NCT01466179 (https://clinicaltrials.gov/study/NCT01466179#study-plan). La condición era hacer el ensayo que vamos a simular para poder dar una autorización completa, cosa que se dio con los resultados de OS.

Texto de la EMA:

Blincyto (blinatumomab) was granted a conditional MA on 23/11/2015 in the indication of “Treatment of adult patients with Philadelphia chromosome-negative relapsed/refractory B-cell precursor acute lymphoblastic leukaemia (ALL)” based upon a phase 2 single arm study (MT103-211). As the Specific Obligation (SO) of the conditional approval, additional efficacy and safety data from the following phase 3 study were required to confirm the clinical B/R of blinatumomab, to better quantify the magnitude of its treatment effect and to help better differentiate between the AEs associated with blinatumomab and
those associated with cytotoxic chemotherapy:

“Post-authorisation efficacy study (PAES): Study 00103311 (TOWER): A Study of BITE antibody blinatumomab versus standard of care chemotherapy in adult subjects with relapsed/refractory b-precursor acute lymphoblastic leukaemia (ALL).”

The purpose of this type II variation is therefore to present the final efficacy and safety data from Study 00103311, propose updates to the product information to reflect the study data and request the CHMP to adopt the granting of a MA no longer subject to SO for Blincyto.

FUENTE: "https://www.ema.europa.eu/en/documents/variation-report/blincyto-h-c-3731-ii-0009-epar-assessment-report-variation_en.pdf"

Con los resultados obtenidos, se le concedió la autorización completa el 25/01/2018.

La variable primaria del estudio fue la supervivencia global (SG), como variables secundarias están la respuesta hematológica, EFS o MRD.

Un total de 400 sujetos fueron aleatorizados en proporción 2:1 a recibir tratamiento con blinatumomab 200 mg cada 3 semanas administrado en perfusión intravenosa de 30 minutos (n=154) o bien el estándar de tratamiento elegido por el investigador (n=151). Este tamaño muestral se consideró

El kaplan-Meier de los resultados primarios (IA2) en PFS a fecha del data cut-off de 04/01/2016 y del report a 26/08/2016 con un total de 251 muertes (251/330=76.06%) son los siguientes:

```{r `Final primary results on OS`, eval = T, echo = F}

knitr::include_graphics("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/Blincyto_PhALL_Graficos/Blincyto_OS.png")

```

Un año después aproximadamente, con fecha del data cut-off a 14/03/2017 y del report a 29/08/2017, se actualizan los resultados teniendo en ese momento un total de 274 muertes (23 muertes más). En el SAP se planearon un total de 330 muertes (83.03% de madurez).

```{r `Final results on OS`, eval = T, echo = F}

knitr::include_graphics("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/Blincyto_PhALL_Graficos/Blincyto_OS_updated.png")

```


## Frequentist simulation

Como se ha especificado anteriormente, vamos a considerar los parámetros que ha usado la compañía en el SAP para el diseño de este estudio. Cabe destacar que todo el ejercicio de simulación tanto para la generación de datos simulados como para el análisis bayesiano se va a usar la distribución Weibull.

1) Shape parameter = 1. La Cy usa una exponencial para el diseño por lo que el parámetro es =1. Una Weibull con shape = 1 es una exponencial.
2) Sample size = 400.
3) ratio = 2:1.
4) rand_type = CR. Esto es la manera que se asigna grupo a cada paciente, esto es complete randomization.
5) Tmax = 32. En el SAP se dice esto: "an enrollment period of 14 months and at least 6 months PFS follow-up after enrollment completion"
6) Censor = 0.05/0.05. Se han escogido estos valores por lo que se dice en el SAP "a dropout rate of 10% per year". 
7) Alpha = 0.05.
8) test.type = 2. Esto es que el test es de dos colas.
9) Power = 85% 
10) IA = TRUE. Hay 2 IAs planeados, con el 50% (165/330) y con el 75% (248/330) de los eventos de OS planeados. Para controlar el ET1, la función de gasto de alfa de O'Brien-Fleming se ha usado con los boundaries de IA1=0.0031, IA2=0.0183 y el FA=0.044. Los resultados primarios corresponden a un IA hecho al 76.1% de eventos en OS (251/330) usando un boundary de 0.0194.
11) seed = 24. A lo largo de este estudio en casi todas las simulaciones se usará esta semilla.

Con respecto a los efectos esperados, en el SAP está lo siguiente: 
  
"If the study observes 330 deaths in the Full Analysis Set, it will be powered at approximately 85% for a 2-sided log-rank test with an overall alpha of 0.05 under a 2:1 randomization ratio and an assumed hazard ratio of 0.70. To observe 330 deaths
the study will randomize approximately 400 subjects which further assumes a control arm median of 4.2 months (a conservative approximation based on 2 published reports in patients meeting the key entry criterion of the study: O´Brien et al, 2008 report a median OS of 3.0 months in 288 patients after 2nd salvage and Kantarjian et al, 2010 report a median OS of 4.7 months in 245 patients after 1st salvage with a CR1 duration < 1 year), a staggered 25-month enrollment period (8% of total enrollment in months 1 to 7, 22% in months 8 to 14, and 70% in months 15 to 25), a 7-month follow-up period after the last subject is enrolled, and a 10% drop-out (ie, loss to follow-up) rate over the 32-month study (calculations performed using East 5.3 and adjust for the alpha and beta spent for the interim analyses described in Section 8). If the study observes only
300 deaths then the unconditional power is approximately 80%."

A modo de introducción para la herramienta de simulación que he hecho, vamos a usar los parámetros considerados en el SAP, incluyendo las asunciones de que HR=0.7 y las medianas para el brazo control y experimental son 4.2 y 6 meses respectivamente. 

Para el cálculo de la mediana del experimental, he asumido una exponencial (no lo dicen pero se sobreentiende), poniendo el shape_parameter=1 y usando la siguiente fórmula:

median_control <- 4.2  
hazard_ratio <- 0.7  
shape_parameter <- 1  

# Lambda_control w the median of the control group
lambda_control <- median_control / (log(2))^(1 / shape_parameter)

# Lambda_experimental 
lambda_experimental <- lambda_control / hazard_ratio^(1 / shape_parameter)

# Median of the experimental group
median_experimental <- lambda_experimental * (log(2))^(1 / shape_parameter)

Los resultados comprenden 10.000 simulaciones para este escenario.

```{r `Simulation of the trial with the parameters from the protocol`, eval = T, echo = T}

shape_parameter <- 1
sample_size <- 400
ratio <- c(2/3,1/3)
rand_type <- "CR" 
scenarios_eff <- matrix(c(4.2,6), nrow = 1, ncol = 2, byrow = TRUE) # HR=0.7
censor <- c(0.05,0.05) # 10% drop-out
Tmax <- 32 
alpha <- 0.05 
test.type <- 2
HR_1 <- FALSE
IA <- c(0.5, 0.75)
#IA <- NULL
method_IA <- "OF"
n_exp_events <- 330
Plot_Power = TRUE
plot_pvalues = FALSE
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = FALSE
analysis = "freq" 
n_sim <- 10000
seed <- 24

# Efectivamente, en el real hicieron el IA1, no pararon y salió significativo en el IA2.

# sim1 <- sim_trials(n_sim = n_sim,
#                    analysis = "freq",
#                    sample_size = sample_size,
#                    ratio = ratio,
#                    rand_type = rand_type,
#                    Tmax = Tmax,
#                    shape_parameter = shape_parameter,
#                    scenarios_eff = scenarios_eff,
#                    censor = censor,
#                    alpha = alpha,
#                    test.type = test.type,
#                    IA = IA,
#                    method_IA = method_IA,
#                    n_exp_events = n_exp_events,
#                    HR_1 = HR_1,
#                    seed=seed,
#                    Plot_Power = Plot_Power,
#                    plot_pvalues = plot_pvalues)
# 
# sim11 <- as.data.frame(sim1)
# 
# sim11 <- sim11 %>%
#   rename(IA1 = `IA 1`, IA2 = `IA 2`) %>%
#   mutate(IA1 = round(IA1), IA2 = round(IA2), FA = round(FA))
# 
# sim11 <- sim11 %>%
#   select(-scenario) %>%
#   mutate(sample_size = as.integer(sample_size))
# 
# table1 <- gt(sim11) %>%
#   tab_header(title = "Frequentist simulation considering the parameters from the SAP") %>%
#   fmt_number(columns = names(sim11)[-which(names(sim11) %in% c("sample_size", "count_significant", "count_not_significant", "IA1", "IA2", "FA"))], decimals = 4) %>%
#   tab_style(style = cell_text(weight = "bold", align = "center"),locations = cells_column_labels(columns = everything())) %>%
#   tab_options( column_labels.background.color = "lightsteelblue1",
#     table.font.size = px(11),
#     table.background.color = "white") %>%
#   tab_style(style = cell_fill(color = "white"),
#     locations = cells_body(rows = everything(), columns = everything())) %>%
#   tab_style( style = cell_text(align = "center"),
#     locations = cells_body(columns = everything()))
# 
# table1

```

Como podemos ver, la media del HR es 0.6839 (0.52, 0.90) y el % de estudios que han salido significativos es el 82.13% y donde el 95% de las veces el valor verdadero del HR (0.7) está contenido en los intervalos de confianza (Coverage Probability). 

Así mismo, de los 8213 ensayos que han salido significativos (son 1787 los negativos), el nº de ensayos que han salido significativos en el IA1 es el 27.78% (2282/8213), en el IA2 es 44.95% (3692/8213) y en el análisis final (FA) representa el 27.26% (2239/8213).

# Evaluación del tamaño muestral con un efecto dado

Lo siguiente es evaluar mediante simulaciones como varían las características operantes en función de diferentes tamaños muestrales (así también se confirmará que 400 pacientes tiene un poder aprox del 85% usando un 5% 2-sided).

Para asegurar qué es más apropiado para evaluar el poder, vamos a hacer las siguientes simulaciones frecuentistas tanto en la situación en la que no hay IAs, como en la situación donde sí hay IAs.

Nota: A partir de ahora cuando debajo de la función principal para simular aparezcan unas líneas para leer un Excel es porque las simulaciones de mucha carga computacional se han hecho con el ordenador de multicore. 

Aquí están las simulaciones de poder sin IAs

```{r `Simulation of the trial with the parameters from the SAP w different sample size`, eval = T, echo = T}

shape_parameter <- 1
sample_size <- seq(from = 50, to= 500, by = 5)
ratio <- c(2/3,1/3)
rand_type <- "CR" 
scenarios_eff <- matrix(c(4.2,6), nrow = 1, ncol = 2, byrow = TRUE) # HR=0.7
censor <- c(0.05,0.05) # 10% drop-out
Tmax <- 32 
alpha <- 0.05 
test.type <- 2
IA <- NULL 
method_IA <- "OF"
n_exp_events <- 330
HR_1 <- TRUE
Plot_Power = TRUE
plot_pvalues = FALSE
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = FALSE
analysis = "freq" 
n_sim <- 10000
seed <- 24

# sim2 <- sim_trials(n_sim = n_sim,
#                    analysis = analysis,
#                    sample_size = sample_size,
#                    HR_1 = HR_1,
#                    rand_type = rand_type,
#                    Tmax = Tmax,
#                    shape_parameter = shape_parameter,
#                    scenarios_eff = scenarios_eff,
#                    IA = IA,
#                    alpha = alpha,
#                    test.type = test.type,
#                    IA = IA,
#                    method_IA = method_IA,
#                    n_exp_events = n_exp_events,
#                    HR_1 = HR_1,
#                    seed=seed,
#                    Plot_Power = Plot_Power,
#                    plot_pvalues = plot_pvalues,
#                    Plot_Power_scenarios = Plot_Power_scenarios,
#                    Plot_Control_Scenarios = Plot_Control_Scenarios)
# 
# sim2_power <- sim2[[2]]
# sim2_power_T1E <- sim2[[3]]
# sim2_power_MSE <- sim2[[4]]
# sim2_results <- sim2[[1]]

# Aquí los datos se leen del Excel con los datos simulados en el ordenador de multicore.

sheet_names <- c("Sheet1")
sim2_results <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/Blincyto_PhALL_Tablas/Freq_dif_sample_sizes_power_10K_NO_IA.xlsx", sheet = sheet_names[1])

# Dibujamos el plot del poder:

data <- subset(sim2_results, scenario == 1)

desired_powers <- c(0.75, 0.8, 0.85, 0.9, 0.95)
sample_sizes_for_desired_powers <- sapply(desired_powers, function(x) 
  min(data$sample_size[data$prop_significant >= x]))

p1 <- ggplot(data, aes(x = sample_size, y = prop_significant)) +
  geom_point(size = 3, color = "steelblue") +  
  geom_line(linewidth = 1, color = "steelblue") +  
  geom_hline(yintercept = desired_powers, linetype = "dotted", color = c("purple", "orange", "green", "turquoise", "gold"), size = 0.65) + 
  scale_x_continuous(breaks = seq(min(data$sample_size)-5, max(data$sample_size)+5, 25)) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Power vs. Sample Size",
       x = "Sample Size",
       y = "Power") +
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 14, face = "bold"),
        axis.text = element_text(size = 12))

colors_for_annotation <- c("purple", "orange", "green", "turquoise", "gold")  
leftmost_x <- min(data$sample_size) + 5  
for (i in 1:length(desired_powers)) {
  p1 <- p1 + annotate("text", 
                      x = leftmost_x, 
                      y = desired_powers[i], 
                      label = sprintf("%.0f%% power", desired_powers[i] * 100), 
                      hjust = 0,  
                      vjust = -0.3,  
                      size = 3.5, 
                      color = colors_for_annotation[i])
}

p1

```

Como se puede ver, efectivamente con 300 pacientes se tiene un poder por encima del 98% (98.87%). También se identifica que con estos datos simulados, 130 pacientes son suficientes para obtener un poder del 80%, 150 pacientes para tener un poder del 85% y 175 pacientes para un poder del 90%.

La compañía fue bastante conservadora a la hora de diseñar este estudio aunque el tamaño muestral se puede deducir que se diseñó para OS por lo que necesitan más eventos que para PFS.

Ahora miramos los datos para el poder junto al Error de Tipo I:
  
```{r `Simulation of sample sizes: T1E`, eval = T, echo = T}

df <- data.frame(
  sample_size = sim2_results$sample_size,
  HR = sim2_results$scenario,
  power_and_T1E = sim2_results$prop_significant)

# Nueva columna para indicar a partir de cuándo se hace el zoom para el ET1

df$zoom <- ifelse(df$power_and_T1E <= 0.1, "Zoomed", "Regular")

suppressWarnings(
  p2 <- ggplot(data = df) +
    geom_line(aes(x = sample_size, y = power_and_T1E, color = as.factor(HR))) +
    labs(title = "Power and Type I Error by Sample Size",
         x = "Sample Size",
         y = "%",
         color = "scenarios") +
    scale_color_discrete(labels = c("HR = 0.55", "HR = 1")) +
    scale_linetype_discrete(labels = c("Power", "Type I Error")) +
    theme_minimal() +
    facet_grid(zoom ~ ., scales = "free_y") + 
    geom_hline(yintercept = 0.1, linetype = "dashed", color = "black", data = subset(df, zoom == "Zoomed"))
)
p2


```

Así mismo podemos ver que el error de tipo I se mantiene por debajo del valor especificado (5%, 2-sided) por lo que se demuestra que no se infla el ET1 (como era de esperar en un estudio frecuentista si está bien hecho).

Por último, se puede ver valores del MSE como varían en valores más pequeños según se aumenta el tamaño muestral.

```{r `Simulation sample sizes: MSE`, eval = T, echo = T}


p4 <-  ggplot(data, aes(x = sample_size, y = MSE)) +
  geom_point(size = 3, color = "steelblue") +  
  geom_line(linewidth = 1, color = "steelblue") +
  labs(title = "MSE vs. Sample Size",
                      x = "Sample Size",
                      y = "MSE") +
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 14, face = "bold"),
        axis.text = element_text(size = 12))
p4

```

Ahora tenemos los resultados de Poder y del Error de Tipo I teniendo en cuenta los diferentes IAs:

```{r `Simulation of the trial with the parameters from the SAP w different sample size_IAs`, eval = T, echo = T}

shape_parameter <- 1
sample_size <- seq(from = 50, to= 500, by = 5)
ratio <- c(2/3,1/3)
rand_type <- "CR" 
scenarios_eff <- matrix(c(4.2,6), nrow = 1, ncol = 2, byrow = TRUE) # HR=0.7
censor <- c(0.05,0.05) # 10% drop-out
Tmax <- 32 
alpha <- 0.05 
test.type <- 2
IA <- c(0.5, 0.75)
method_IA <- "OF"
n_exp_events <- 330
HR_1 <- TRUE
Plot_Power = TRUE
plot_pvalues = FALSE
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = FALSE
analysis = "freq" 
n_sim <- 10000
seed <- 24

# sim2 <- sim_trials(n_sim = n_sim,
#                    analysis = analysis,
#                    sample_size = sample_size,
#                    HR_1 = HR_1,
#                    rand_type = rand_type,
#                    Tmax = Tmax,
#                    shape_parameter = shape_parameter,
#                    scenarios_eff = scenarios_eff,
#                    IA = IA,
#                    alpha = alpha,
#                    test.type = test.type,
#                    IA = IA,
#                    method_IA = method_IA,
#                    n_exp_events = n_exp_events,
#                    HR_1 = HR_1,
#                    seed=seed,
#                    Plot_Power = Plot_Power,
#                    plot_pvalues = plot_pvalues,
#                    Plot_Power_scenarios = Plot_Power_scenarios,
#                    Plot_Control_Scenarios = Plot_Control_Scenarios)
# 
# sim2_power <- sim2[[2]]
# sim2_power_T1E <- sim2[[3]]
# sim2_power_MSE <- sim2[[4]]
# sim2_results <- sim2[[1]]

# Aquí los datos se leen del Excel con los datos simulados en el ordenador de multicore.

sheet_names <- c("Sheet1")
sim2_results <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/Blincyto_PhALL_Tablas/Freq_dif_sample_sizes_power_10K_CON_IA.xlsx", sheet = sheet_names[1])

# Dibujamos el plot del poder:

data <- subset(sim2_results, scenario == 1)

desired_powers <- c(0.75, 0.8, 0.85, 0.9, 0.95)
sample_sizes_for_desired_powers <- sapply(desired_powers, function(x) 
  min(data$sample_size[data$prop_significant >= x]))

p1 <- ggplot(data, aes(x = sample_size, y = prop_significant)) +
  geom_point(size = 3, color = "steelblue") +  
  geom_line(linewidth = 1, color = "steelblue") +  
  geom_hline(yintercept = desired_powers, linetype = "dotted", color = c("purple", "orange", "green", "turquoise", "gold"), size = 0.65) + 
  scale_x_continuous(breaks = seq(min(data$sample_size)-5, max(data$sample_size)+5, 25)) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Power vs. Sample Size",
       x = "Sample Size",
       y = "Power") +
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 14, face = "bold"),
        axis.text = element_text(size = 12))

colors_for_annotation <- c("purple", "orange", "green", "turquoise", "gold")  
leftmost_x <- min(data$sample_size) + 5  
for (i in 1:length(desired_powers)) {
  p1 <- p1 + annotate("text", 
                      x = leftmost_x, 
                      y = desired_powers[i], 
                      label = sprintf("%.0f%% power", desired_powers[i] * 100), 
                      hjust = 0,  
                      vjust = -0.3,  
                      size = 3.5, 
                      color = colors_for_annotation[i])
}

p1

```

Como se puede ver, efectivamente con 300 pacientes se tiene un poder por encima del 98% (98.87%). También se identifica que con estos datos simulados, 130 pacientes son suficientes para obtener un poder del 80%, 150 pacientes para tener un poder del 85% y 175 pacientes para un poder del 90%.

La compañía fue bastante conservadora a la hora de diseñar este estudio aunque el tamaño muestral se puede deducir que se diseñó para OS por lo que necesitan más eventos que para PFS.

Ahora miramos los datos para el poder junto al Error de Tipo I:
  
```{r `Simulation of sample sizes: T1E_IAs`, eval = T, echo = T}

df <- data.frame(
  sample_size = sim2_results$sample_size,
  HR = sim2_results$scenario,
  power_and_T1E = sim2_results$prop_significant)

# Nueva columna para indicar a partir de cuándo se hace el zoom para el ET1

df$zoom <- ifelse(df$power_and_T1E <= 0.1, "Zoomed", "Regular")

suppressWarnings(
  p2 <- ggplot(data = df) +
    geom_line(aes(x = sample_size, y = power_and_T1E, color = as.factor(HR))) +
    labs(title = "Power and Type I Error by Sample Size",
         x = "Sample Size",
         y = "%",
         color = "scenarios") +
    scale_color_discrete(labels = c("HR = 0.55", "HR = 1")) +
    scale_linetype_discrete(labels = c("Power", "Type I Error")) +
    theme_minimal() +
    facet_grid(zoom ~ ., scales = "free_y") + 
    geom_hline(yintercept = 0.1, linetype = "dashed", color = "black", data = subset(df, zoom == "Zoomed"))
)
p2


```

Así mismo podemos ver que el error de tipo I se mantiene por debajo del valor especificado (5%, 2-sided) por lo que se demuestra que no se infla el ET1 (como era de esperar en un estudio frecuentista si está bien hecho).

Por último, se puede ver valores del MSE como varían en valores más pequeños según se aumenta el tamaño muestral.

```{r `Simulation sample sizes: MSE_IAs`, eval = T, echo = T}


p4 <-  ggplot(data, aes(x = sample_size, y = MSE)) +
  geom_point(size = 3, color = "steelblue") +  
  geom_line(linewidth = 1, color = "steelblue") +
  labs(title = "MSE vs. Sample Size",
                      x = "Sample Size",
                      y = "MSE") +
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 14, face = "bold"),
        axis.text = element_text(size = 12))
p4

```

Estos son los valores del tamaño muestral necesario para alcanzar los poderes de interés para las dos simulaciones: 1) Sin tener en cuenta los IAs y 2) Teniendo en cuenta los IAs.

Sin IA

1) Poder: 95% -> 620
2) Poder: 90% -> 500
3) Poder: 85% -> 425
4) Poder: 80% -> 375
5) Poder: 75% -> 330

Con IA

1) Poder: 95% -> 635
2) Poder: 90% -> 515
3) Poder: 85% -> 435
4) Poder: 80% -> 390
5) Poder: 75% -> 335

# Evaluación de diferentes de efecto 

Ahora vamos a evaluar cómo afectan los compartamientos del efecto para cada uno de los brazos a un tamaño muestral dado. No sólo se va a hacer con los 400 pacientes planeados, si no también para X, Y y Z.

Ya que el tamaño del efecto depende de dos variables diferentes, efecto del brazo control y efecto del brazo experimental, tenemos que ver los dos escenarios de interés en base a un factor común, el HR.

Para ello, primero vamos a evaluar los diferentes escenarios en términos de medianas. Vamos a dejar fijo primero la mediana para el brazo control como está definido en el SAP (4.2) y luego dejamos fija la mediana para el brazo experimental (6). De esto modo, vemos cómo evoluciona todo el rango de Hazard Ratios relevantes a lo largo de los diferentes escenarios.

```{r `Medians w control arm at 4.2` , eval = T, echo = T}

shape_parameter <- 1

desired_HRs <- c(1.6, 1.5, 1.4, 1.3, 1.2, 1.1, 1, 0.95, 0.9, 0.85, 0.8, 0.775, 0.75, 0.725, 0.7, 0.675, 0.65, 0.625, 0.6, 0.575, 0.55, 0.525, 0.5, 0.45, 0.4, 0.35, 0.3)
control_medians <- rep(4.2, times = length(desired_HRs))

medians_control_fijo <- matrix(NA, nrow = length(desired_HRs), ncol = 2, dimnames = list(paste0("HR ", desired_HRs), c("Control", "Treatment")))

for (i in 1:length(desired_HRs)) {
  medians_control_fijo[i, "Treatment"] <- control_medians[i] / (desired_HRs[i]^(1/shape_parameter))
  medians_control_fijo[i, "Control"] <- control_medians[i]
}

medians_control_fijo <- as.data.frame(medians_control_fijo)

medians_control_fijo <- medians_control_fijo %>%
  mutate(HR = desired_HRs) %>%
  select(HR, everything())

# Creamos la tabla
table2 <- gt(medians_control_fijo) %>%
  tab_header(title = "Effect Based on Different HR w Median control = 4.2") %>%
  fmt_number(
    columns = c("Control"),  # Aquí detallamos cuántos decimales queremos para los valores de estas columnas
    decimals = 1
  ) %>%
  fmt_number(
    columns = names(medians_control_fijo)[!names(medians_control_fijo) %in% c("Control")],  # Aplicamos estos decimales para los valores de todas las columnas menos las especificadas aquí
    decimals = 3
  ) %>%
  tab_style(
    style = cell_text(weight = "bold", align = "center"),
    locations = cells_column_labels(columns = everything())
  ) %>%
  tab_options(
    column_labels.background.color = "lightsteelblue1",
    table.font.size = px(12),
    table.background.color = "white"
  ) %>%
  tab_style(
    style = cell_fill(color = "lightsteelblue1"),
    locations = cells_body(rows = seq(2, nrow(medians_control_fijo), by = 2), columns = everything())
  ) %>%
  tab_style(
    style = cell_fill(color = "white"),
    locations = cells_body(rows = seq(1, nrow(medians_control_fijo), by = 2), columns = everything())
  ) %>% # En las tres sentencias anteriores es cómo hacemos que se alternen los colores
  tab_style(
    style = cell_fill(color = "lightsteelblue1"),  # Esto es para aplicar el color azul para valores de la primera columna
    locations = cells_body(columns = "HR")
  ) %>%
  tab_style(
    style = cell_text(weight = "bold"),  
    locations = cells_body(columns = "HR")
  ) %>%
  tab_style(
    style = cell_text(align = "center"),
    locations = cells_body(columns = everything())
  ) %>%
  tab_style(
    style = cell_borders(sides = "bottom", color = "black", weight = px(2)),
    locations = cells_column_labels(columns = names(medians_control_fijo)[names(medians_control_fijo) != "HR"])
  ) %>%
  tab_style(
    style = cell_borders(sides = "right", color = "black", weight = px(2)),
    locations = cells_body(columns = "HR")
  )

table2

```

Ahora dejando fija la mediana del brazo experimental a 6.

```{r `Medians w experimental arm at 6` , eval = T, echo = T}

shape_parameter <- 1

desired_HRs <- c(1.5, 1.6, 1.5, 1.4, 1.3, 1.2, 1.1, 1, 0.95, 0.9, 0.85, 0.8, 0.775, 0.75, 0.725, 0.7, 0.675, 0.65, 0.625, 0.6, 0.575, 0.55, 0.525, 0.5, 0.45, 0.4, 0.35, 0.3)
medians_experimiental_fijo <- rep(6, times = length(desired_HRs))

treatment_medians <- matrix(NA, nrow = length(desired_HRs), ncol = 2, 
                            dimnames = list(paste0("HR ", desired_HRs), c("Control", "Treatment")))

for (i in 1:length(desired_HRs)) {
  treatment_medians[i, "Control"] <- medians_experimiental_fijo[i] * (desired_HRs[i]^(1/shape_parameter))
  treatment_medians[i, "Treatment"] <- medians_experimiental_fijo[i]
}

treatment_medians <- as.data.frame(treatment_medians)

treatment_medians <- treatment_medians %>%
  mutate(HR = desired_HRs) %>%
  select(HR, everything())

# Creamos la tabla
table3 <- gt(treatment_medians) %>%
  tab_header(title = "Effect Based on Different HR w Median Treatment = 6") %>%
  fmt_number(
    columns = c("Treatment"),  # Aquí detallamos cuántos decimales queremos para los valores de estas columnas
    decimals = 0
  ) %>%
  fmt_number(
    columns = names(treatment_medians)[!names(treatment_medians) %in% c("Treatment")],  # Aplicamos estos decimales para los valores de todas las columnas menos las especificadas aquí
    decimals = 3
  ) %>%
  tab_style(
    style = cell_text(weight = "bold", align = "center"),
    locations = cells_column_labels(columns = everything())
  ) %>%
  tab_options(
    column_labels.background.color = "lightsteelblue1",
    table.font.size = px(12),
    table.background.color = "white"
  ) %>%
  tab_style(
    style = cell_fill(color = "lightsteelblue1"),
    locations = cells_body(rows = seq(2, nrow(treatment_medians), by = 2), columns = everything())
  ) %>%
  tab_style(
    style = cell_fill(color = "white"),
    locations = cells_body(rows = seq(1, nrow(treatment_medians), by = 2), columns = everything())
  ) %>% # En las tres sentencias anteriores es cómo hacemos que se alternen los colores
  tab_style(
    style = cell_fill(color = "lightsteelblue1"),  # Esto es para aplicar el color azul para valores de la primera columna
    locations = cells_body(columns = "HR")
  ) %>%
  tab_style(
    style = cell_text(weight = "bold"),  
    locations = cells_body(columns = "HR")
  ) %>%
  tab_style(
    style = cell_text(align = "center"),
    locations = cells_body(columns = everything())
  ) %>%
  tab_style(
    style = cell_borders(sides = "bottom", color = "black", weight = px(2)),
    locations = cells_column_labels(columns = names(treatment_medians)[names(treatment_medians) != "HR"])
  ) %>%
  tab_style(
    style = cell_borders(sides = "right", color = "black", weight = px(2)),
    locations = cells_body(columns = "HR")
  )

table3

```

Ahora vamos a simular ensayos clínicos yendo de un rango a otro tanto dejando la mediana del control fija  para los siguientes tamaños muestrales (si fijamos la mediana del tratamiento sale exactamente igual que fijando la mediana del control, por lo que lo obviamos).

Como hemos hecho anteriormente con el poder y el ET1, vamos a diferenciar este análisis viendo el tamaño muestral necesario para el análisis con y sin IAs.

## 1) Análisis sin IAs

### 1) Tamaño muestral original del SAP: 400 Pacientes

```{r `Simulation scenarios w fixed control`, eval = T, echo = T}

shape_parameter <- 1

desired_HRs <- c(1.6, 1.5, 1.4, 1.3, 1.2, 1.1, 1, 0.95, 0.9, 0.85, 0.8, 0.775, 0.75, 0.725, 0.7, 0.675, 0.65, 0.625, 0.6, 0.575, 0.55, 0.525, 0.5, 0.45, 0.4, 0.35, 0.3)
control_medians <- rep(4.2, times = length(desired_HRs))

medians_control_fijo <- matrix(NA, nrow = length(desired_HRs), ncol = 2, dimnames = list(paste0("HR ", desired_HRs), c("Control", "Treatment")))

for (i in 1:length(desired_HRs)) {
  medians_control_fijo[i, "Treatment"] <- control_medians[i] / (desired_HRs[i]^(1/shape_parameter))
  medians_control_fijo[i, "Control"] <- control_medians[i]
}

sample_size <- 400
ratio <- c(2/3,1/3)
rand_type <- "CR" 
scenarios_eff <- as.matrix(medians_control_fijo, nrow = length(medians_control_fijo), ncol = 2, byrow = TRUE)
censor <- c(0.05,0.05) # 10% drop-out
Tmax <- 32 
alpha <- 0.05 
test.type <- 2
HR_1 <- FALSE
IA <- NULL # No IAs de momento
method_IA <- "OF"
n_exp_events <- 330
Plot_Power = FALSE
plot_pvalues = FALSE
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = FALSE
analysis = "freq"
n_sim <- 10000
seed <- 24

# sim3 <- sim_trials(n_sim = n_sim,
#                    analysis = "freq",
#                    sample_size = sample_size,
#                    ratio = ratio,
#                    rand_type = rand_type,
#                    Tmax = Tmax,
#                    shape_parameter = shape_parameter,
#                    scenarios_eff = scenarios_eff,
#                    censor = censor,
#                    alpha = alpha,
#                    test.type = test.type,
#                    IA = IA,
#                    method_IA = method_IA,
#                    n_exp_events = n_exp_events,
#                    HR_1 = HR_1,
#                    seed=seed,
#                    Plot_Power = Plot_Power,
#                    plot_pvalues = plot_pvalues,
#                    Plot_Power_scenarios = Plot_Power_scenarios,
#                    Plot_Control_Scenarios = Plot_Control_Scenarios)

sheet_names <- c("Sheet1")
sim3_results <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/Blincyto_PhALL_Tablas/power_esc_10K_SAP_400.xlsx", sheet = sheet_names[1])

data <- sim3_results %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE))

data$desired_HRs <- desired_HRs[1:nrow(data)]

p3 <- ggplot(data, aes(x = desired_HRs, y = prop_significant)) +
  geom_point(size = 3, color = "steelblue") +
  geom_line(linewidth = 1, color = "steelblue") +
  geom_vline(xintercept = 1, linetype = "dashed", color = "red", size = 1) +
  geom_hline(yintercept = c(0.8, 0.9), linetype = "dotted", color = c("purple", "green"), size = 1) +
  scale_x_continuous(breaks = seq(min(desired_HRs), max(desired_HRs), 0.1), labels = sprintf("%.2f", seq(min(desired_HRs), max(desired_HRs), 0.1))) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Power vs Hazard Ratio",
       x = "Theoretical Hazard Ratio",
       y = "Power") +
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 14, face = "bold"),
        axis.text = element_text(size = 12))

p3 <- p3 +
  annotate("text", x = max(desired_HRs), y = 0.8, label = "80% power", hjust = 1, vjust = -0.5, size = 3.5, color = "purple") +
  annotate("text", x = max(desired_HRs), y = 0.9, label = "90% power", hjust = 1, vjust = -0.5, size = 3.5, color = "green")

for (i in 1:nrow(data)) {
  p3 <- p3 + annotate("text", x = data$desired_HRs[i], y = data$prop_significant[i],
                      label = sprintf("%.2f", data$mean_HR[i]), hjust = 1, vjust = 1.5, size = 4, color = "black")
}

p3

```

Recordemos que los tamaño muestrales requeridos para alcanzar los poder objetivos de acuerdo con mis simulaciones son:

1) Poder: 95% -> 620
2) Poder: 90% -> 500
3) Poder: 85% -> 425
4) Poder: 80% -> 375
5) Poder: 75% -> 330


### 2) Tamaño muestral con poder del 95%: 620 Pacientes


```{r `Simulation scenarios w fixed experimental_620_no_IA`, eval = T, echo = T}

sheet_names <- c("Sheet1")
sim3_results <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/Blincyto_PhALL_Tablas/power_esc_10K_620.xlsx", sheet = sheet_names[1])

data <- sim3_results %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE))

data$desired_HRs <- desired_HRs[1:nrow(data)]

p4 <- ggplot(data, aes(x = desired_HRs, y = prop_significant)) +
  geom_point(size = 3, color = "steelblue") +
  geom_line(linewidth = 1, color = "steelblue") +
  geom_vline(xintercept = 1, linetype = "dashed", color = "red", size = 1) +
  geom_hline(yintercept = c(0.8, 0.9), linetype = "dotted", color = c("purple", "green"), size = 1) +
  scale_x_continuous(breaks = seq(min(desired_HRs), max(desired_HRs), 0.1), labels = sprintf("%.2f", seq(min(desired_HRs), max(desired_HRs), 0.1))) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Power vs Hazard Ratio",
       x = "Theoretical Hazard Ratio",
       y = "Power") +
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 14, face = "bold"),
        axis.text = element_text(size = 12))

p4 <- p4 +
  annotate("text", x = max(desired_HRs), y = 0.8, label = "80% power", hjust = 1, vjust = -0.5, size = 3.5, color = "purple") +
  annotate("text", x = max(desired_HRs), y = 0.9, label = "90% power", hjust = 1, vjust = -0.5, size = 3.5, color = "green")

for (i in 1:nrow(data)) {
  p4 <- p4 + annotate("text", x = data$desired_HRs[i], y = data$prop_significant[i],
                      label = sprintf("%.3f", data$mean_HR[i]), hjust = 1, vjust = 1.5, size = 3, color = "black")
}
p4
```


### 3) Tamaño muestral con poder del 90%: 500 Pacientes


```{r `Simulation scenarios w fixed experimental_500_no_IA`, eval = T, echo = T}

sheet_names <- c("Sheet1")
sim3_results <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/Blincyto_PhALL_Tablas/power_esc_10K_500.xlsx", sheet = sheet_names[1])

data <- sim3_results %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE))

data$desired_HRs <- desired_HRs[1:nrow(data)]

p4 <- ggplot(data, aes(x = desired_HRs, y = prop_significant)) +
  geom_point(size = 3, color = "steelblue") +
  geom_line(linewidth = 1, color = "steelblue") +
  geom_vline(xintercept = 1, linetype = "dashed", color = "red", size = 1) +
  geom_hline(yintercept = c(0.8, 0.9), linetype = "dotted", color = c("purple", "green"), size = 1) +
  scale_x_continuous(breaks = seq(min(desired_HRs), max(desired_HRs), 0.1), labels = sprintf("%.2f", seq(min(desired_HRs), max(desired_HRs), 0.1))) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Power vs Hazard Ratio",
       x = "Theoretical Hazard Ratio",
       y = "Power") +
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 14, face = "bold"),
        axis.text = element_text(size = 12))

p4 <- p4 +
  annotate("text", x = max(desired_HRs), y = 0.8, label = "80% power", hjust = 1, vjust = -0.5, size = 3.5, color = "purple") +
  annotate("text", x = max(desired_HRs), y = 0.9, label = "90% power", hjust = 1, vjust = -0.5, size = 3.5, color = "green")

for (i in 1:nrow(data)) {
  p4 <- p4 + annotate("text", x = data$desired_HRs[i], y = data$prop_significant[i],
                      label = sprintf("%.3f", data$mean_HR[i]), hjust = 1, vjust = 1.5, size = 3, color = "black")
}
p4
```

### 4) Tamaño muestral con poder del 85%: 425 Pacientes


```{r `Simulation scenarios w fixed experimental_425_no_IA`, eval = T, echo = T}

sheet_names <- c("Sheet1")
sim3_results <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/Blincyto_PhALL_Tablas/power_esc_10K_425.xlsx", sheet = sheet_names[1])

data <- sim3_results %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE))

data$desired_HRs <- desired_HRs[1:nrow(data)]

p4 <- ggplot(data, aes(x = desired_HRs, y = prop_significant)) +
  geom_point(size = 3, color = "steelblue") +
  geom_line(linewidth = 1, color = "steelblue") +
  geom_vline(xintercept = 1, linetype = "dashed", color = "red", size = 1) +
  geom_hline(yintercept = c(0.8, 0.9), linetype = "dotted", color = c("purple", "green"), size = 1) +
  scale_x_continuous(breaks = seq(min(desired_HRs), max(desired_HRs), 0.1), labels = sprintf("%.2f", seq(min(desired_HRs), max(desired_HRs), 0.1))) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Power vs Hazard Ratio",
       x = "Theoretical Hazard Ratio",
       y = "Power") +
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 14, face = "bold"),
        axis.text = element_text(size = 12))

p4 <- p4 +
  annotate("text", x = max(desired_HRs), y = 0.8, label = "80% power", hjust = 1, vjust = -0.5, size = 3.5, color = "purple") +
  annotate("text", x = max(desired_HRs), y = 0.9, label = "90% power", hjust = 1, vjust = -0.5, size = 3.5, color = "green")

for (i in 1:nrow(data)) {
  p4 <- p4 + annotate("text", x = data$desired_HRs[i], y = data$prop_significant[i],
                      label = sprintf("%.3f", data$mean_HR[i]), hjust = 1, vjust = 1.5, size = 3, color = "black")
}
p4
```

### 5) Tamaño muestral con poder del 80%: 375 Pacientes


```{r `Simulation scenarios w fixed experimental_375_no_IA`, eval = T, echo = T}

sheet_names <- c("Sheet1")
sim3_results <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/Blincyto_PhALL_Tablas/power_esc_10K_375.xlsx", sheet = sheet_names[1])

data <- sim3_results %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE))

data$desired_HRs <- desired_HRs[1:nrow(data)]

p4 <- ggplot(data, aes(x = desired_HRs, y = prop_significant)) +
  geom_point(size = 3, color = "steelblue") +
  geom_line(linewidth = 1, color = "steelblue") +
  geom_vline(xintercept = 1, linetype = "dashed", color = "red", size = 1) +
  geom_hline(yintercept = c(0.8, 0.9), linetype = "dotted", color = c("purple", "green"), size = 1) +
  scale_x_continuous(breaks = seq(min(desired_HRs), max(desired_HRs), 0.1), labels = sprintf("%.2f", seq(min(desired_HRs), max(desired_HRs), 0.1))) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Power vs Hazard Ratio",
       x = "Theoretical Hazard Ratio",
       y = "Power") +
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 14, face = "bold"),
        axis.text = element_text(size = 12))

p4 <- p4 +
  annotate("text", x = max(desired_HRs), y = 0.8, label = "80% power", hjust = 1, vjust = -0.5, size = 3.5, color = "purple") +
  annotate("text", x = max(desired_HRs), y = 0.9, label = "90% power", hjust = 1, vjust = -0.5, size = 3.5, color = "green")

for (i in 1:nrow(data)) {
  p4 <- p4 + annotate("text", x = data$desired_HRs[i], y = data$prop_significant[i],
                      label = sprintf("%.3f", data$mean_HR[i]), hjust = 1, vjust = 1.5, size = 3, color = "black")
}
p4
```

### 6) Tamaño muestral con poder del 75%: 330 Pacientes


```{r `Simulation scenarios w fixed experimental_330_no_IA`, eval = T, echo = T}

sheet_names <- c("Sheet1")
sim3_results <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/Blincyto_PhALL_Tablas/power_esc_10K_330.xlsx", sheet = sheet_names[1])

data <- sim3_results %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE))

data$desired_HRs <- desired_HRs[1:nrow(data)]

p4 <- ggplot(data, aes(x = desired_HRs, y = prop_significant)) +
  geom_point(size = 3, color = "steelblue") +
  geom_line(linewidth = 1, color = "steelblue") +
  geom_vline(xintercept = 1, linetype = "dashed", color = "red", size = 1) +
  geom_hline(yintercept = c(0.8, 0.9), linetype = "dotted", color = c("purple", "green"), size = 1) +
  scale_x_continuous(breaks = seq(min(desired_HRs), max(desired_HRs), 0.1), labels = sprintf("%.2f", seq(min(desired_HRs), max(desired_HRs), 0.1))) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Power vs Hazard Ratio",
       x = "Theoretical Hazard Ratio",
       y = "Power") +
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 14, face = "bold"),
        axis.text = element_text(size = 12))

p4 <- p4 +
  annotate("text", x = max(desired_HRs), y = 0.8, label = "80% power", hjust = 1, vjust = -0.5, size = 3.5, color = "purple") +
  annotate("text", x = max(desired_HRs), y = 0.9, label = "90% power", hjust = 1, vjust = -0.5, size = 3.5, color = "green")

for (i in 1:nrow(data)) {
  p4 <- p4 + annotate("text", x = data$desired_HRs[i], y = data$prop_significant[i],
                      label = sprintf("%.3f", data$mean_HR[i]), hjust = 1, vjust = 1.5, size = 3, color = "black")
}
p4
```

## 1) Análisis con IAs

### 1) Tamaño muestral original del SAP: 400 Pacientes

```{r `Simulation scenarios w fixed control`, eval = T, echo = T}

shape_parameter <- 1

desired_HRs <- c(1.6, 1.5, 1.4, 1.3, 1.2, 1.1, 1, 0.95, 0.9, 0.85, 0.8, 0.775, 0.75, 0.725, 0.7, 0.675, 0.65, 0.625, 0.6, 0.575, 0.55, 0.525, 0.5, 0.45, 0.4, 0.35, 0.3)
control_medians <- rep(4.2, times = length(desired_HRs))

medians_control_fijo <- matrix(NA, nrow = length(desired_HRs), ncol = 2, dimnames = list(paste0("HR ", desired_HRs), c("Control", "Treatment")))

for (i in 1:length(desired_HRs)) {
  medians_control_fijo[i, "Treatment"] <- control_medians[i] / (desired_HRs[i]^(1/shape_parameter))
  medians_control_fijo[i, "Control"] <- control_medians[i]
}

sample_size <- 400
ratio <- c(2/3,1/3)
rand_type <- "CR" 
scenarios_eff <- as.matrix(medians_control_fijo, nrow = length(medians_control_fijo), ncol = 2, byrow = TRUE)
censor <- c(0.05,0.05) # 10% drop-out
Tmax <- 32 
alpha <- 0.05 
test.type <- 2
HR_1 <- FALSE
IA <- c(0.5, 0.75)
method_IA <- "OF"
n_exp_events <- 330
Plot_Power = FALSE
plot_pvalues = FALSE
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = FALSE
analysis = "freq"
n_sim <- 10000
seed <- 24

# sim3 <- sim_trials(n_sim = n_sim,
#                    analysis = "freq",
#                    sample_size = sample_size,
#                    ratio = ratio,
#                    rand_type = rand_type,
#                    Tmax = Tmax,
#                    shape_parameter = shape_parameter,
#                    scenarios_eff = scenarios_eff,
#                    censor = censor,
#                    alpha = alpha,
#                    test.type = test.type,
#                    IA = IA,
#                    method_IA = method_IA,
#                    n_exp_events = n_exp_events,
#                    HR_1 = HR_1,
#                    seed=seed,
#                    Plot_Power = Plot_Power,
#                    plot_pvalues = plot_pvalues,
#                    Plot_Power_scenarios = Plot_Power_scenarios,
#                    Plot_Control_Scenarios = Plot_Control_Scenarios)

sheet_names <- c("Sheet1")
sim3_results <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/Blincyto_PhALL_Tablas/power_esc_10K_SAP_400_Con_IAs.xlsx", sheet = sheet_names[1])

data <- sim3_results %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE))

data$desired_HRs <- desired_HRs[1:nrow(data)]

p3 <- ggplot(data, aes(x = desired_HRs, y = prop_significant)) +
  geom_point(size = 3, color = "steelblue") +
  geom_line(linewidth = 1, color = "steelblue") +
  geom_vline(xintercept = 1, linetype = "dashed", color = "red", size = 1) +
  geom_hline(yintercept = c(0.8, 0.9), linetype = "dotted", color = c("purple", "green"), size = 1) +
  scale_x_continuous(breaks = seq(min(desired_HRs), max(desired_HRs), 0.1), labels = sprintf("%.2f", seq(min(desired_HRs), max(desired_HRs), 0.1))) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Power vs Hazard Ratio",
       x = "Theoretical Hazard Ratio",
       y = "Power") +
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 14, face = "bold"),
        axis.text = element_text(size = 12))

p3 <- p3 +
  annotate("text", x = max(desired_HRs), y = 0.8, label = "80% power", hjust = 1, vjust = -0.5, size = 3.5, color = "purple") +
  annotate("text", x = max(desired_HRs), y = 0.9, label = "90% power", hjust = 1, vjust = -0.5, size = 3.5, color = "green")

for (i in 1:nrow(data)) {
  p3 <- p3 + annotate("text", x = data$desired_HRs[i], y = data$prop_significant[i],
                      label = sprintf("%.2f", data$mean_HR[i]), hjust = 1, vjust = 1.5, size = 4, color = "black")
}

p3

```

Recordemos que los tamaño muestrales requeridos para alcanzar los poder objetivos de acuerdo con mis simulaciones son:

1) Poder: 95% -> 635
2) Poder: 90% -> 515
3) Poder: 85% -> 435
4) Poder: 80% -> 390
5) Poder: 75% -> 335


### 2) Tamaño muestral con poder del 95%: 635 Pacientes


```{r `Simulation scenarios w fixed experimental_635_IA`, eval = T, echo = T}

sheet_names <- c("Sheet1")
sim3_results <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/Blincyto_PhALL_Tablas/power_esc_10K_635_Con_IAs.xlsx", sheet = sheet_names[1])

data <- sim3_results %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE))

data$desired_HRs <- desired_HRs[1:nrow(data)]

p4 <- ggplot(data, aes(x = desired_HRs, y = prop_significant)) +
  geom_point(size = 3, color = "steelblue") +
  geom_line(linewidth = 1, color = "steelblue") +
  geom_vline(xintercept = 1, linetype = "dashed", color = "red", size = 1) +
  geom_hline(yintercept = c(0.8, 0.9), linetype = "dotted", color = c("purple", "green"), size = 1) +
  scale_x_continuous(breaks = seq(min(desired_HRs), max(desired_HRs), 0.1), labels = sprintf("%.2f", seq(min(desired_HRs), max(desired_HRs), 0.1))) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Power vs Hazard Ratio",
       x = "Theoretical Hazard Ratio",
       y = "Power") +
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 14, face = "bold"),
        axis.text = element_text(size = 12))

p4 <- p4 +
  annotate("text", x = max(desired_HRs), y = 0.8, label = "80% power", hjust = 1, vjust = -0.5, size = 3.5, color = "purple") +
  annotate("text", x = max(desired_HRs), y = 0.9, label = "90% power", hjust = 1, vjust = -0.5, size = 3.5, color = "green")

for (i in 1:nrow(data)) {
  p4 <- p4 + annotate("text", x = data$desired_HRs[i], y = data$prop_significant[i],
                      label = sprintf("%.3f", data$mean_HR[i]), hjust = 1, vjust = 1.5, size = 3, color = "black")
}
p4
```


### 3) Tamaño muestral con poder del 90%: 515 Pacientes


```{r `Simulation scenarios w fixed experimental_515_IA`, eval = T, echo = T}

sheet_names <- c("Sheet1")
sim3_results <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/Blincyto_PhALL_Tablas/power_esc_10K_515_CON_IAs.xlsx", sheet = sheet_names[1])

data <- sim3_results %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE))

data$desired_HRs <- desired_HRs[1:nrow(data)]

p4 <- ggplot(data, aes(x = desired_HRs, y = prop_significant)) +
  geom_point(size = 3, color = "steelblue") +
  geom_line(linewidth = 1, color = "steelblue") +
  geom_vline(xintercept = 1, linetype = "dashed", color = "red", size = 1) +
  geom_hline(yintercept = c(0.8, 0.9), linetype = "dotted", color = c("purple", "green"), size = 1) +
  scale_x_continuous(breaks = seq(min(desired_HRs), max(desired_HRs), 0.1), labels = sprintf("%.2f", seq(min(desired_HRs), max(desired_HRs), 0.1))) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Power vs Hazard Ratio",
       x = "Theoretical Hazard Ratio",
       y = "Power") +
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 14, face = "bold"),
        axis.text = element_text(size = 12))

p4 <- p4 +
  annotate("text", x = max(desired_HRs), y = 0.8, label = "80% power", hjust = 1, vjust = -0.5, size = 3.5, color = "purple") +
  annotate("text", x = max(desired_HRs), y = 0.9, label = "90% power", hjust = 1, vjust = -0.5, size = 3.5, color = "green")

for (i in 1:nrow(data)) {
  p4 <- p4 + annotate("text", x = data$desired_HRs[i], y = data$prop_significant[i],
                      label = sprintf("%.3f", data$mean_HR[i]), hjust = 1, vjust = 1.5, size = 3, color = "black")
}
p4
```

### 4) Tamaño muestral con poder del 85%: 435 Pacientes


```{r `Simulation scenarios w fixed experimental_435_IA`, eval = T, echo = T}

sheet_names <- c("Sheet1")
sim3_results <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/Blincyto_PhALL_Tablas/power_esc_10K_435_Con_IAs.xlsx", sheet = sheet_names[1])

data <- sim3_results %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE))

data$desired_HRs <- desired_HRs[1:nrow(data)]

p4 <- ggplot(data, aes(x = desired_HRs, y = prop_significant)) +
  geom_point(size = 3, color = "steelblue") +
  geom_line(linewidth = 1, color = "steelblue") +
  geom_vline(xintercept = 1, linetype = "dashed", color = "red", size = 1) +
  geom_hline(yintercept = c(0.8, 0.9), linetype = "dotted", color = c("purple", "green"), size = 1) +
  scale_x_continuous(breaks = seq(min(desired_HRs), max(desired_HRs), 0.1), labels = sprintf("%.2f", seq(min(desired_HRs), max(desired_HRs), 0.1))) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Power vs Hazard Ratio",
       x = "Theoretical Hazard Ratio",
       y = "Power") +
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 14, face = "bold"),
        axis.text = element_text(size = 12))

p4 <- p4 +
  annotate("text", x = max(desired_HRs), y = 0.8, label = "80% power", hjust = 1, vjust = -0.5, size = 3.5, color = "purple") +
  annotate("text", x = max(desired_HRs), y = 0.9, label = "90% power", hjust = 1, vjust = -0.5, size = 3.5, color = "green")

for (i in 1:nrow(data)) {
  p4 <- p4 + annotate("text", x = data$desired_HRs[i], y = data$prop_significant[i],
                      label = sprintf("%.3f", data$mean_HR[i]), hjust = 1, vjust = 1.5, size = 3, color = "black")
}
p4
```

### 5) Tamaño muestral con poder del 80%: 390 Pacientes


```{r `Simulation scenarios w fixed experimental_390_IA`, eval = T, echo = T}

sheet_names <- c("Sheet1")
sim3_results <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/Blincyto_PhALL_Tablas/power_esc_10K_390_Con_IAs.xlsx", sheet = sheet_names[1])

data <- sim3_results %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE))

data$desired_HRs <- desired_HRs[1:nrow(data)]

p4 <- ggplot(data, aes(x = desired_HRs, y = prop_significant)) +
  geom_point(size = 3, color = "steelblue") +
  geom_line(linewidth = 1, color = "steelblue") +
  geom_vline(xintercept = 1, linetype = "dashed", color = "red", size = 1) +
  geom_hline(yintercept = c(0.8, 0.9), linetype = "dotted", color = c("purple", "green"), size = 1) +
  scale_x_continuous(breaks = seq(min(desired_HRs), max(desired_HRs), 0.1), labels = sprintf("%.2f", seq(min(desired_HRs), max(desired_HRs), 0.1))) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Power vs Hazard Ratio",
       x = "Theoretical Hazard Ratio",
       y = "Power") +
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 14, face = "bold"),
        axis.text = element_text(size = 12))

p4 <- p4 +
  annotate("text", x = max(desired_HRs), y = 0.8, label = "80% power", hjust = 1, vjust = -0.5, size = 3.5, color = "purple") +
  annotate("text", x = max(desired_HRs), y = 0.9, label = "90% power", hjust = 1, vjust = -0.5, size = 3.5, color = "green")

for (i in 1:nrow(data)) {
  p4 <- p4 + annotate("text", x = data$desired_HRs[i], y = data$prop_significant[i],
                      label = sprintf("%.3f", data$mean_HR[i]), hjust = 1, vjust = 1.5, size = 3, color = "black")
}
p4
```

### 6) Tamaño muestral con poder del 75%: 335 Pacientes


```{r `Simulation scenarios w fixed experimental_335_IA`, eval = T, echo = T}

sheet_names <- c("Sheet1")
sim3_results <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/Blincyto_PhALL_Tablas/power_esc_10K_335_Con_IAs.xlsx", sheet = sheet_names[1])

data <- sim3_results %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE))

data$desired_HRs <- desired_HRs[1:nrow(data)]

p4 <- ggplot(data, aes(x = desired_HRs, y = prop_significant)) +
  geom_point(size = 3, color = "steelblue") +
  geom_line(linewidth = 1, color = "steelblue") +
  geom_vline(xintercept = 1, linetype = "dashed", color = "red", size = 1) +
  geom_hline(yintercept = c(0.8, 0.9), linetype = "dotted", color = c("purple", "green"), size = 1) +
  scale_x_continuous(breaks = seq(min(desired_HRs), max(desired_HRs), 0.1), labels = sprintf("%.2f", seq(min(desired_HRs), max(desired_HRs), 0.1))) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Power vs Hazard Ratio",
       x = "Theoretical Hazard Ratio",
       y = "Power") +
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 14, face = "bold"),
        axis.text = element_text(size = 12))

p4 <- p4 +
  annotate("text", x = max(desired_HRs), y = 0.8, label = "80% power", hjust = 1, vjust = -0.5, size = 3.5, color = "purple") +
  annotate("text", x = max(desired_HRs), y = 0.9, label = "90% power", hjust = 1, vjust = -0.5, size = 3.5, color = "green")

for (i in 1:nrow(data)) {
  p4 <- p4 + annotate("text", x = data$desired_HRs[i], y = data$prop_significant[i],
                      label = sprintf("%.3f", data$mean_HR[i]), hjust = 1, vjust = 1.5, size = 3, color = "black")
}
p4
```


Es de interés evaluar diferentes escenarios en medianas tanta de un brazo como de otro en función de HR dado. Esto será útil más adelante cuando evaluemos los Bayesianos ya que en principio, se van a comparar los modelos para diferentes tamaños muestrales y en función de diferentes escenarios de HR.

Esto se va a calcular para evaluar las características operantes de Poder, Error de Tipo I y MSE. Los que cumplan buenas condiciones para los escenarios plausibles se calculará el tamaño muestral y el poder para seleccionar el ahorro que ofrecen con respecto al frecuentista.

```{r `Medians W HR fixed`, eval = T, echo = T}


control_medians <- c(2,2.25,2.5,2.75,3,3.25,3.5,3.75,4,4.2,4.25,4.5,4.75,5,5.25,5.5,5.75,6,6.25,6.5,6.75,7,7.25,7.5,7.75,8,8.25,8.5,8.75,9)

medians <- matrix(NA, nrow = length(control_medians), ncol = 3, 
                  dimnames = list(NULL, c("Control", "Treatment", "HR")))

desired_HR = 0.7

for (i in 1:length(control_medians)) {
  medians[i, "Control"] <- control_medians[i]
  
  lambda_control = control_medians[i] / (log(2)^(1/shape_parameter))
  lambda_treatment = lambda_control / desired_HR^(1/shape_parameter)
  
  medians[i, "Treatment"] = lambda_treatment * (log(2)^(1/shape_parameter))
  medians[i, "HR"] = (lambda_control / lambda_treatment)^shape_parameter
}

#medians <- medians[,1:2]

medians <- as.data.frame(medians)

medians <- medians %>%
  select(HR, everything())

# Creamos la tabla
table4 <- gt(medians) %>%
  tab_header(title = "Effect in medians when HR = 0.70") %>%
  fmt_number(
    columns = c("HR", "Control"),  # Aquí detallamos cuántos decimales queremos para los valores de estas columnas
    decimals = 2
  ) %>%
  fmt_number(
    columns = names(medians)[!names(medians) %in% c("HR", "Control")],  # Aplicamos estos decimales para los valores de todas las columnas menos las especificadas aquí
    decimals = 2
  ) %>%
  tab_style(
    style = cell_text(weight = "bold", align = "center"),
    locations = cells_column_labels(columns = everything())
  ) %>%
  tab_options(
    column_labels.background.color = "lightsteelblue1",
    table.font.size = px(9),
    table.background.color = "white"
  ) %>%
  tab_style(
    style = cell_fill(color = "lightsteelblue1"),
    locations = cells_body(rows = seq(2, nrow(medians), by = 2), columns = everything())
  ) %>%
  tab_style(
    style = cell_fill(color = "white"),
    locations = cells_body(rows = seq(1, nrow(medians), by = 2), columns = everything())
  ) %>% # En las tres sentencias anteriores es cómo hacemos que se alternen los colores
  tab_style(
    style = cell_fill(color = "lightsteelblue1"),  # Esto es para aplicar el color azul para valores de la primera columna
    locations = cells_body(columns = "HR")
  ) %>%
  tab_style(
    style = cell_text(weight = "bold"),  
    locations = cells_body(columns = "HR")
  ) %>%
  tab_style(
    style = cell_text(align = "center"),
    locations = cells_body(columns = everything())
  ) %>%
  tab_style(
    style = cell_borders(sides = "bottom", color = "black", weight = px(2)),
    locations = cells_column_labels(columns = names(medians)[names(medians) != "HR"])
  ) %>%
  tab_style(
    style = cell_borders(sides = "right", color = "black", weight = px(2)),
    locations = cells_body(columns = "HR")
  )

table4


```

# Análisis Bayesiano

Se usa para la variable de tipo-hasta un modelo Weibull para la inferencia de los datos.
He cambiado el código para, en vez de calcular el tamaño efecto como variable aleatoria, ahora calculo cada uno de los brazos por separado como variables aleatorias; de este modo podré especificar prior distributions para cada uno de los brazos por separado ya que vamos a asumir siempre que el brazo tratamiento va a tener una prior no informativa.

A continuación muestro el modelo STAN que tenía como efectos conjuntos (variable aleatorio diferencia de tratamiento en función de la pendiente de la regresión):
  
```{r `stan-file slope`, eval = T}

cat(readLines("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/weibull_model_def.stan"), sep = "\n")

```

Y este es el modelo que uso a partir de ahora evaluando el efecto de cada uno de los brazos por separado.

Tenemos tres parámetros a estimar en el modelo.

1. Shape: Este es común para los dos brazos.
2. Scale_control: Es es el parámetro escala para el brazo control en el modelo Weibull.
3. Scale_treatment: Es es el parámetro escala para el brazo tratamiento en el modelo Weibull.

Para las 3 variables se usa una distribución a prior gamma. 

Estas distribuciones a priori son proper ya que integra 1 en todo su dominio, ya que todas las prior son gamma y están parametrizadas para tener sólo valores positivos en los parámetros. Esto tiene sentido ya que en análisis de supervivencia sólo valores positivos son considerados. Una ejemplo común de improper es escoger una dist. uniforme sobre todos los valores reales por una media ya que esta dist. tiene valores infinitos bajo la curva.

Así mismo, estas prior son commensurate. Esto se refiere a que si puede tomar valores lógicos con el análisis de supervivencia. Estos priors lo son porque sólo pueden tomar valores positivos respetando la naturaleza y la escala de los datos. 

```{r `stan-file separate arms`, eval = T, echo = T}

cat(readLines("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/weibull_gamma_def.stan"), sep = "\n")

```

Antes de continuar, merece la pena evaluar la comparabilidad entre un ensayo frecuentista y Bayesiano en términos no sólo de decision (rechazar o no rechazar una hipótesis) si no que la fuerza con que se rechaza tiene que ser similar para el mismo dataset de cada uno de los ensayos simulados. Hay que tener en cuenta que los resultados no son para nada lo mismo (el concepto de p-valores y 1-Posterior son totalmente diferentes) y que para el frecuentista se hace una regresión de Cox y en el Bayesiano una regresión de Weibull.

Cabe destacar que aunque aquí no lo muestro, también he comparado los resultados de una regresión Weibull con mi frecuentista con el Weibull de Bayesiano y arroja resultados similares.

Como hasta ahora he estado dividiendo los resultados con y sin los IAs planeados, aquí igual, voy a mostrar estos análisis por cada uno:


## 1) Sin tener en cuenta los IAs: Frecuentista usando Weibull

```{r `pvalues freq_NO_IAs`, eval = T, echo = T}

# Calculo de los p-valores NO IAs

shape_parameter <- 1
sample_size <- 400
ratio <- c(2/3,1/3)
rand_type <- "CR" 
scenarios_eff <- matrix(c(4.2,6), nrow = 1, ncol = 2, byrow = TRUE) # HR=0.7
censor <- c(0.05,0.05) # 10% drop-out
Tmax <- 32 
alpha <- 0.025 
test.type <- 1
HR_1 <- FALSE
IA <- NULL
method_IA <- "OF"
n_exp_events <- 330
HR_1 <- FALSE
Plot_Power = FALSE
plot_pvalues = TRUE
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = FALSE
analysis = "freq"
n_sim <- 10000
seed <- 24

#  sim7 <- sim_trials(n_sim = n_sim,
#                     analysis = "freq",
#                     sample_size = sample_size,
#                     ratio = ratio,
#                     rand_type = rand_type,
#                     Tmax = Tmax,
#                     shape_parameter = shape_parameter,
#                     scenarios_eff = scenarios_eff,
#                     censor = censor,
#                     alpha = alpha,
#                     test.type = test.type,
#                     IA = IA,
#                     method_IA = method_IA,
#                     n_exp_events = n_exp_events,
#                     HR_1 = HR_1,
#                     seed=seed,
#                     Plot_Power = Plot_Power,
#                     plot_pvalues = plot_pvalues)
# 
# pvalues2 <- sim7[[2]]
# sim77 <- sim7[[1]]
# 
# wd <- createWorkbook()
# addWorksheet(wd, "Sheet1")
# writeData(wd, "Sheet1", pvalues2)
# saveWorkbook(wd, "freq_pvalues_NO_IAs_1sided_cox.xlsx", overwrite = TRUE)

# wd <- createWorkbook()
# addWorksheet(wd, "Sheet1")
# writeData(wd, "Sheet1", pvalues6)
# saveWorkbook(wd, "freq_pvalues_NO_IAs.xlsx", overwrite = TRUE)

# sheet_names <- c("Sheet1")
# pvalues1 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/Blincyto_PhALL_Tablas/freq_pvalues_NO_IAs.xlsx", sheet = sheet_names[1])

#sheet_names <- c("Sheet1")
#pvalues1 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/freq_pvalues_Weibull_NO_IAs.xlsx", sheet = sheet_names[1])

# sheet_names <- c("Sheet1")
# pvalues1 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/Blincyto_PhALL_Tablas/freq_pvalues_CON_IAs.xlsx", sheet = sheet_names[1])


```

Ahora muestro el código que se ha usado para el Bayesiano con una distribución a priori no informativa para los dos brazos:
  
```{r `1-Posterior values_NO_IAs`, eval = T}

# P-VALUES BAYESIANO NO INFORMATIVO SIN IAs

shape_parameter <- 1
sample_size <- 400
ratio <- c(2/3,1/3)
rand_type <- "CR" 
scenarios_eff <- matrix(c(4.2,6), nrow = 1, ncol = 2, byrow = TRUE) # HR=0.7
censor <- c(0.05,0.05) # 10% drop-out
Tmax <- 32 
alpha <- 0.025 
test.type <- 1
# alpha <- 0.05 
# test.type <- 2
HR_1 <- FALSE
IA <- NULL
method_IA <- "OF"
n_exp_events <- 330
HR_1 <- FALSE
Plot_Power = FALSE
plot_pvalues = TRUE
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = FALSE
analysis = "bayes"
n_sim <- 10000
seed <- 24
# 1) Shape control, 2) rate control, 3) Shape experimental y 4) rate experimental
#prior_gamma <- matrix(c(0.00001, 0.00001, 0.00001, 0.00001), nrow = 2, ncol = 2, byrow = TRUE) 
prior_gamma <- matrix(c(1, 1/16, 1, 1/16), nrow = 2, ncol = 2, byrow = TRUE) 
prior_type <- c("Non informative prior") # Este vector es para que aparezca el nombre en las tablas
P_HR_data_Boundary <- 0.8 # P(HR < 0.8 | data)
modelo_weibull_sep <- rstan::stan_model("weibull_gamma_def.stan" ,verbose = F)
modelo = modelo_weibull_sep
modelo_bayes_test = "weibull"

 # sim5 <- sim_trials(n_sim = n_sim,
 #                    analysis = "bayes",
 #                    sample_size = sample_size,
 #                    ratio = ratio,
 #                    rand_type = rand_type,
 #                    Tmax = Tmax,
 #                    scenarios_eff = scenarios_eff,
 #                    shape_parameter = shape_parameter,
 #                    censor = censor,
 #                    test.type = test.type,
 #                    alpha = alpha,
 #                    method_IA = method_IA,
 #                    IA = IA,
 #                    n_exp_events = n_exp_events,
 #                    HR_1 = HR_1,
 #                    Plot_Power = Plot_Power,
 #                    #prior = prior,
 #                    modelo = modelo,
 #                    modelo_bayes_test = modelo_bayes_test,
 #                    prior_type = prior_type,
 #                    P_HR_data_Boundary = P_HR_data_Boundary,
 #                    prior_gamma = prior_gamma,
 #                    Plot_Power_scenarios = Plot_Power_scenarios,
 #                    desired_HRs = desired_HRs,
 #                    plot_pvalues = plot_pvalues,
 #                    Plot_Control_Scenarios = Plot_Control_Scenarios,
 #                    seed = seed)
 # 
 # pvalues5 <- sim5[[2]]
 # sim55 <- sim5[[1]]
 # 
 # wd <- createWorkbook()
 # addWorksheet(wd, "Sheet1")
 # writeData(wd, "Sheet1", pvalues5)
 # saveWorkbook(wd, "bayes_pvalues_NO_IAs_prior_robust_1sided_def.xlsx", overwrite = TRUE)


# Leemos los datos porque la simulación es de muchas horas:

# sheet_names <- c("Sheet1")
# pvalues4 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/bayes_pvalues_NO_IAs.xlsx", sheet = sheet_names[1])

# sheet_names <- c("Sheet1")
# pvalues4 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/bayes_pvalues_NO_IAs_prior_robust.xlsx", sheet = sheet_names[1])

sheet_names <- c("Sheet1")
pvalues4 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/bayes_pvalues_NO_IAs_prior_robust_1sided_def.xlsx", sheet = sheet_names[1])

# sheet_names <- c("Sheet1")
# pvalues4 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/bayes_pvalues_Con_IAs.xlsx", sheet = sheet_names[1])





```

Las características del Bayes que se ha hecho anteriormente:

f <- rstan::sampling(object  = modelo,
                     data    = lista_prior,
                     chains  = 3,       
                     thin    = 3,
                     iter    = 3400,   
                     warmup  = 1900,
                     refresh = 0,
                     seed = 12)
        
        
Juntamos los datos de los dos enfoques para los mismos resultados de cada uno de los ensayos clínicos y se enseña un plot donde se muestra que todos los puntos están alineados alrededor de la línea identidad, mostrando una gran consistencia entre el enfoque frecuentista y el Bayesiano con priors no informativas.

```{r `Comparison pvalues vs 1-Posterior 1_NO_IAs`, eval = F}

pvalues1$p_value <- pvalues1$p_value/2
pvalues4$`1-post_prob` <- pvalues4$`1-post_prob`*2

plot_pvalues <- inner_join(pvalues1, pvalues4, by = "n_sim") # Si solo cogemos los de Cox y Bayes

# Cuando el "p-valor" Bayesiano supera el 50% hay que hacer 1-(1-post_prob) para hacer este valor
# comparable con el p-valor frecuentista
plot_pvalues <- plot_pvalues %>%
  mutate(`1-post_prob` = ifelse(`1-post_prob` > 0.5, (1 - `1-post_prob`), `1-post_prob`))

ggplot(plot_pvalues, aes(x = p_value, y = `1-post_prob`)) +
  geom_point() +
  geom_abline(slope = 1, intercept = 0, color = "red") +
  xlab("P-value") +
  ylab("1 - Posterior Probability") +
  ggtitle("Frequentist P-value vs Bayesian 1 - Posterior Probability") +
  theme_minimal()

```

Además, en la siguiente figura (donde se ha hecho zoom en la zona entre 0 y 0.05) se muestra que en la mayoría de los casos simulados, el frecuentista y Bayesiano llegan a la misma conclusión con respecto a la significancia de los datos.

```{r `Comparison pvalues vs 1-Posterior 2_NO_IAs`, eval = F}

plot_pvalues_table <- plot_pvalues %>%
  mutate(
    p_value_significant = ifelse(p_value < 0.05, 1, 0),
    post_prob_significant = ifelse(`1-post_prob` < 0.05, 1, 0)
  )

agreement_proportion <- mean(plot_pvalues_table$p_value_significant == plot_pvalues_table$post_prob_significant)

disagree_trials <- plot_pvalues_table %>%
  filter(p_value_significant != post_prob_significant)

n_disagree <- nrow(disagree_trials)

frequentist_only <- disagree_trials %>%
  filter(p_value_significant == 1 & post_prob_significant == 0)

bayesian_only <- disagree_trials %>%
  filter(p_value_significant == 0 & post_prob_significant == 1)

freq_only_prop <- nrow(frequentist_only) / n_disagree
bayes_only_prop <- nrow(bayesian_only) / n_disagree

ggplot(plot_pvalues, aes(x = p_value, y = `1-post_prob`)) +
  geom_point() +
  geom_abline(slope = 1, intercept = 0, color = "black") +
  geom_vline(xintercept = 0.025, linetype = "dashed", color = "red") +
  geom_hline(yintercept = 0.025, linetype = "dashed", color = "red") +
  annotate("text", x = 0.0375, y = 0.0125, label = "Only Bayesian test is significant") +
  annotate("text", x = 0.0125, y = 0.0375, label = "Only frequentist test is significant") +
  xlim(c(0, 0.05)) +
  ylim(c(0, 0.05)) +
  xlab("P-value") +
  ylab("1- Posterior Probability") +
  ggtitle("P-value vs 1-Posterior Probability") +
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 14, face = "bold"),
        axis.text = element_text(size = 12))

```
Por ultimo, aquí muestro la comparación entre los dos enfoques con el porcentaje total de "fallos", lo que se ve que es muy residual.

```{r `Comparison pvalues vs 1-Posterior 3_NO_IAs`, eval = F}

freq_only_prop <- nrow(frequentist_only) / nrow(plot_pvalues_table)
bayes_only_prop <- nrow(bayesian_only) / nrow(plot_pvalues_table)

ggplot(plot_pvalues_table, aes(x = p_value, y = `1-post_prob`)) +
  geom_point() +
  geom_abline(slope = 1, intercept = 0, color = "red") +
  geom_vline(xintercept = 0.05, linetype = "dashed", color = "red") +
  geom_hline(yintercept = 0.05, linetype = "dashed", color = "red") +
  annotate("text", x = 0.3, y = 0.02, label = paste("Only Bayesian test is significant (", round(bayes_only_prop*100, 2), "%)", sep = "")) +
  annotate("text", x = 0.15, y = 0.4, label = paste("Only frequentist test is significant (", round(freq_only_prop*100, 2), "%)", sep = "")) +
  xlim(c(0, 0.55)) +
  ylim(c(0, 0.55)) +
  xlab("P-value") +
  ylab("1-Posterior Probability") +
  ggtitle("P-value vs 1-Posterior Probability") +
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 14, face = "bold"),
        axis.text = element_text(size = 12))

```

## 1) Sin tener en cuenta los IAs: Frecuentista usando Cox

```{r `pvalues freq_IAs`, eval = T, echo = T}

# Calculo de los p-valores NO IAs

shape_parameter <- 1
sample_size <- 400
ratio <- c(2/3,1/3)
rand_type <- "CR" 
scenarios_eff <- matrix(c(4.2,6), nrow = 1, ncol = 2, byrow = TRUE) # HR=0.7
censor <- c(0.05,0.05) # 10% drop-out
Tmax <- 32 
alpha <- 0.05 
test.type <- 2
HR_1 <- FALSE
IA <- NULL
method_IA <- "OF"
n_exp_events <- 330
HR_1 <- FALSE
Plot_Power = FALSE
plot_pvalues = TRUE
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = FALSE
analysis = "freq"
n_sim <- 10000
seed <- 24

# sim6 <- sim_trials(n_sim = n_sim, 
#                    analysis = "freq",
#                    sample_size = sample_size,
#                    ratio = ratio,
#                    rand_type = rand_type,
#                    Tmax = Tmax, 
#                    shape_parameter = shape_parameter,
#                    scenarios_eff = scenarios_eff,
#                    censor = censor,
#                    alpha = alpha,
#                    test.type = test.type,
#                    IA = IA,
#                    method_IA = method_IA,
#                    n_exp_events = n_exp_events,
#                    HR_1 = HR_1,
#                    seed=seed,
#                    Plot_Power = Plot_Power,
#                    plot_pvalues = plot_pvalues)

# pvalues6 <- sim6[[2]]
# sim66 <- sim6[[1]]
# 
# wd <- createWorkbook()
# addWorksheet(wd, "Sheet1")
# writeData(wd, "Sheet1", pvalues6)
# saveWorkbook(wd, "freq_pvalues_NO_IAs.xlsx", overwrite = TRUE)

# sheet_names <- c("Sheet1")
# pvalues1 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/Blincyto_PhALL_Tablas/freq_pvalues_NO_IAs.xlsx", sheet = sheet_names[1])

# sheet_names <- c("Sheet1")
# pvalues1 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/Blincyto_PhALL_Tablas/freq_pvalues_Weibull_NO_IAs.xlsx", sheet = sheet_names[1])

# sheet_names <- c("Sheet1")
# pvalues1 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/Blincyto_PhALL_Tablas/freq_pvalues_CON_IAs.xlsx", sheet = sheet_names[1])


sheet_names <- c("Sheet1")
pvalues1 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/freq_pvalues_NO_IAs_1sided_cox.xlsx", sheet = sheet_names[1])

sheet_names <- c("Sheet1")
pvalues2 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/freq_pvalues_NO_IAs_1sided_weibull.xlsx", sheet = sheet_names[1])

```

Ahora muestro el código que se ha usado para el Bayesiano con una distribución a priori no informativa para los dos brazos:
  
```{r `1-Posterior values_IAs`, eval = T}

# P-VALUES BAYESIANO NO INFORMATIVO SIN IAs

shape_parameter <- 1
sample_size <- 400
ratio <- c(2/3,1/3)
rand_type <- "CR" 
scenarios_eff <- matrix(c(4.2,6), nrow = 1, ncol = 2, byrow = TRUE) # HR=0.7
censor <- c(0.05,0.05) # 10% drop-out
Tmax <- 32 
alpha <- 0.05 
test.type <- 2
HR_1 <- FALSE
IA <- NULL
method_IA <- "OF"
n_exp_events <- 330
HR_1 <- FALSE
Plot_Power = FALSE
plot_pvalues = TRUE
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = FALSE
analysis = "bayes"
n_sim <- 10000
seed <- 24
# 1) Shape control, 2) rate control, 3) Shape experimental y 4) rate experimental
prior_gamma <- matrix(c(1, 1/16, 1, 1/16), nrow = 2, ncol = 2, byrow = TRUE) 
prior_type <- c("Non informative prior") # Este vector es para que aparezca el nombre en las tablas
P_HR_data_Boundary <- 0.8 # P(HR < 0.8 | data)
modelo_weibull_sep <- rstan::stan_model("weibull_gamma_def.stan" ,verbose = F)
modelo = modelo_weibull_sep
modelo_bayes_test = "weibull"

# sim5 <- sim_trials(n_sim = n_sim,
#                    analysis = "bayes",
#                    sample_size = sample_size,
#                    ratio = ratio,
#                    rand_type = rand_type,
#                    Tmax = Tmax,
#                    scenarios_eff = scenarios_eff,
#                    shape_parameter = shape_parameter,
#                    censor = censor,
#                    test.type = test.type,
#                    alpha = alpha,
#                    method_IA = method_IA,
#                    IA = IA,
#                    n_exp_events = n_exp_events,
#                    HR_1 = HR_1,
#                    Plot_Power = Plot_Power,
#                    #prior = prior,
#                    modelo = modelo,
#                    modelo_bayes_test = modelo_bayes_test,
#                    prior_type = prior_type,
#                    P_HR_data_Boundary = P_HR_data_Boundary,
#                    prior_gamma = prior_gamma,
#                    Plot_Power_scenarios = Plot_Power_scenarios,
#                    desired_HRs = desired_HRs,
#                    plot_pvalues = plot_pvalues,
#                    Plot_Control_Scenarios = Plot_Control_Scenarios,
#                    seed = seed)
# 
# pvalues5 <- sim5[[2]]
# sim55 <- sim5[[1]]

# wd <- createWorkbook()
# addWorksheet(wd, "Sheet1")
# writeData(wd, "Sheet1", pvalues5)
# saveWorkbook(wd, "bayes_pvalues_NO_IAs.xlsx", overwrite = TRUE)


# Leemos los datos porque la simulación es de muchas horas:
# 
# sheet_names <- c("Sheet1")
# pvalues4 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/bayes_pvalues_NO_IAs.xlsx", sheet = sheet_names[1])

# sheet_names <- c("Sheet1")
# pvalues4 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/bayes_pvalues_NO_IAs_prior_robust_def.xlsx", sheet = sheet_names[1])


# sheet_names <- c("Sheet1")
# pvalues4 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/bayes_pvalues_Con_IAs.xlsx", sheet = sheet_names[1])


```

        
Juntamos los datos de los dos enfoques para los mismos resultados de cada uno de los ensayos clínicos y se enseña un plot donde se muestra que todos los puntos están alineados alrededor de la línea identidad, mostrando una gran consistencia entre el enfoque frecuentista y el Bayesiano con priors no informativas.

```{r `Comparison pvalues vs 1-Posterior 1_IAs`, eval = T}

#pvalues1$p_value <- pvalues1$p_value/2
#pvalues2$p_value <- pvalues2$p_value/2

plot_pvalues <- inner_join(pvalues1, pvalues4, by = "n_sim") # Si solo cogemos los de Cox y Bayes

# Cuando el "p-valor" Bayesiano supera el 50% hay que hacer 1-(1-post_prob) para hacer este valor
# comparable con el p-valor frecuentista
plot_pvalues <- plot_pvalues %>%
  mutate(`1-post_prob` = ifelse(`1-post_prob` > 0.5, (1 - `1-post_prob`), `1-post_prob`))

ggplot(plot_pvalues, aes(x = p_value, y = `1-post_prob`)) +
  geom_point() +
  geom_abline(slope = 1, intercept = 0, color = "red") +
  xlab("P-value") +
  ylab("1 - Posterior Probability") +
  ggtitle("Frequentist P-value vs Bayesian 1 - Posterior Probability") +
  theme_minimal()

```

Además, en la siguiente figura (donde se ha hecho zoom en la zona entre 0 y 0.05) se muestra que en la mayoría de los casos simulados, el frecuentista y Bayesiano llegan a la misma conclusión con respecto a la significancia de los datos.

```{r `Comparison pvalues vs 1-Posterior 2_IAs`, eval = T}

plot_pvalues_table <- plot_pvalues %>%
  mutate(
    p_value_significant = ifelse(p_value < 0.025, 1, 0),
    post_prob_significant = ifelse(`1-post_prob` < 0.025, 1, 0)
  )

agreement_proportion <- mean(plot_pvalues_table$p_value_significant == plot_pvalues_table$post_prob_significant)

disagree_trials <- plot_pvalues_table %>%
  filter(p_value_significant != post_prob_significant)

n_disagree <- nrow(disagree_trials)

frequentist_only <- disagree_trials %>%
  filter(p_value_significant == 1 & post_prob_significant == 0)

bayesian_only <- disagree_trials %>%
  filter(p_value_significant == 0 & post_prob_significant == 1)

freq_only_prop <- nrow(frequentist_only) / n_disagree
bayes_only_prop <- nrow(bayesian_only) / n_disagree

p1 <- ggplot(plot_pvalues, aes(x = p_value, y = `1-post_prob`)) +
  geom_point() +
  geom_abline(slope = 1, intercept = 0, color = "black") +
  geom_vline(xintercept = 0.025, linetype = "dashed", color = "red") +
  geom_hline(yintercept = 0.025, linetype = "dashed", color = "red") +
  annotate("text", x = 0.0375, y = 0.0125, label = "Only Bayesian test is significant") +
  annotate("text", x = 0.0125, y = 0.0375, label = "Only frequentist test is significant") +
  xlim(c(0, 0.05)) +
  ylim(c(0, 0.05)) +
  xlab("P-value") +
  ylab("1- Posterior Probability") +
  ggtitle("P-value vs 1-Posterior Probability") +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 13, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 10, face = "bold"),
    axis.text = element_text(size = 9)
  )

p1
```
Por ultimo, aquí muestro la comparación entre los dos enfoques con el porcentaje total de "fallos", lo que se ve que es muy residual.

```{r `Comparison pvalues vs 1-Posterior 3_IAs`, eval = T}

freq_only_prop <- nrow(frequentist_only) / nrow(plot_pvalues_table)
bayes_only_prop <- nrow(bayesian_only) / nrow(plot_pvalues_table)

p2 <- ggplot(plot_pvalues_table, aes(x = p_value, y = `1-post_prob`)) +
  geom_point() +
  geom_abline(slope = 1, intercept = 0, color = "red") +
  geom_vline(xintercept = 0.05, linetype = "dashed", color = "red") +
  geom_hline(yintercept = 0.05, linetype = "dashed", color = "red") +
  annotate("text", x = 0.3, y = 0.02, label = paste("Only Bayesian test is significant (", round(bayes_only_prop*100, 2), "%)", sep = "")) +
  annotate("text", x = 0.15, y = 0.4, label = paste("Only frequentist test is significant (", round(freq_only_prop*100, 2), "%)", sep = "")) +
  xlim(c(0, 0.55)) +
  ylim(c(0, 0.55)) +
  xlab("P-value") +
  ylab("1-Posterior Probability") +
  ggtitle("P-value vs 1-Posterior Probability") +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 13, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 10, face = "bold"),
    axis.text = element_text(size = 9)
  )
p2
```


```{r T1E_combined_all1, eval = T}

library(cowplot)

p11 <- p1 + theme(plot.background = element_rect(colour = "black", size = 0.5, fill = NA))
p22 <- p2 + theme(plot.background = element_rect(colour = "black", size = 0.5, fill = NA))

plots_row <- plot_grid(p22, p11, ncol = 2, labels = c("A", "B"), label_size = 14)

combined_plot <- plot_grid(
  plots_row,
  #legend,
  ncol = 1,                 
  rel_heights = c(3, 0.4)   
)

print(combined_plot)

```

## 2) Sin tener en cuenta los IAs: Frecuentista usando Weibull

```{r `Comparison pvalues vs 1-Posterior 1_IAs2`, eval = T}

# Freq Weibull
sheet_names <- c("Sheet1")
pvalues1 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/freq_pvalues_Weibull_NO_IAs.xlsx", sheet = sheet_names[1])

# # Bayes
# sheet_names <- c("Sheet1")
# pvalues4 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/bayes_pvalues_NO_IAs.xlsx", sheet = sheet_names[1])

sheet_names <- c("Sheet1")
pvalues4 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/bayes_pvalues_NO_IAs_prior_robust_def.xlsx", sheet = sheet_names[1])

pvalues1$p_value <- pvalues1$p_value/2
plot_pvalues <- inner_join(pvalues1, pvalues4, by = "n_sim") # Si solo cogemos los de Cox y Bayes

# Cuando el "p-valor" Bayesiano supera el 50% hay que hacer 1-(1-post_prob) para hacer este valor
# comparable con el p-valor frecuentista
plot_pvalues <- plot_pvalues %>%
  mutate(`1-post_prob` = ifelse(`1-post_prob` > 0.5, (1 - `1-post_prob`), `1-post_prob`))

ggplot(plot_pvalues, aes(x = p_value, y = `1-post_prob`)) +
  geom_point() +
  geom_abline(slope = 1, intercept = 0, color = "red") +
  xlab("P-value") +
  ylab("1 - Posterior Probability") +
  ggtitle("Frequentist P-value vs Bayesian 1 - Posterior Probability") +
  theme_minimal()

```

Además, en la siguiente figura (donde se ha hecho zoom en la zona entre 0 y 0.05) se muestra que en la mayoría de los casos simulados, el frecuentista y Bayesiano llegan a la misma conclusión con respecto a la significancia de los datos.

```{r `Comparison pvalues vs 1-Posterior 2_IAs2`, eval = T}

plot_pvalues_table <- plot_pvalues %>%
  mutate(
    p_value_significant = ifelse(p_value < 0.025, 1, 0),
    post_prob_significant = ifelse(`1-post_prob` < 0.025, 1, 0)
  )

agreement_proportion <- mean(plot_pvalues_table$p_value_significant == plot_pvalues_table$post_prob_significant)

disagree_trials <- plot_pvalues_table %>%
  filter(p_value_significant != post_prob_significant)

n_disagree <- nrow(disagree_trials)

frequentist_only <- disagree_trials %>%
  filter(p_value_significant == 1 & post_prob_significant == 0)

bayesian_only <- disagree_trials %>%
  filter(p_value_significant == 0 & post_prob_significant == 1)

freq_only_prop <- nrow(frequentist_only) / n_disagree
bayes_only_prop <- nrow(bayesian_only) / n_disagree

p1 <- ggplot(plot_pvalues, aes(x = p_value, y = `1-post_prob`)) +
  geom_point() +
  geom_abline(slope = 1, intercept = 0, color = "black") +
  geom_vline(xintercept = 0.025, linetype = "dashed", color = "red") +
  geom_hline(yintercept = 0.025, linetype = "dashed", color = "red") +
  annotate("text", x = 0.0375, y = 0.0125, label = "Only Bayesian test is significant") +
  annotate("text", x = 0.0125, y = 0.0375, label = "Only frequentist test is significant") +
  xlim(c(0, 0.05)) +
  ylim(c(0, 0.05)) +
  xlab("P-value") +
  ylab("1- Posterior Probability") +
  ggtitle("P-value vs 1-Posterior Probability") +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 13, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 10, face = "bold"),
    axis.text = element_text(size = 9)
  )

p1
```
Por ultimo, aquí muestro la comparación entre los dos enfoques con el porcentaje total de "fallos", lo que se ve que es muy residual.

```{r `Comparison pvalues vs 1-Posterior 3_IAs2`, eval = T}

freq_only_prop <- nrow(frequentist_only) / nrow(plot_pvalues_table)
bayes_only_prop <- nrow(bayesian_only) / nrow(plot_pvalues_table)

p2 <- ggplot(plot_pvalues_table, aes(x = p_value, y = `1-post_prob`)) +
  geom_point() +
  geom_abline(slope = 1, intercept = 0, color = "red") +
  geom_vline(xintercept = 0.05, linetype = "dashed", color = "red") +
  geom_hline(yintercept = 0.05, linetype = "dashed", color = "red") +
  annotate("text", x = 0.3, y = 0.02, label = paste("Only Bayesian test is significant (", round(bayes_only_prop*100, 2), "%)", sep = "")) +
  annotate("text", x = 0.15, y = 0.4, label = paste("Only frequentist test is significant (", round(freq_only_prop*100, 2), "%)", sep = "")) +
  xlim(c(0, 0.55)) +
  ylim(c(0, 0.55)) +
  xlab("P-value") +
  ylab("1-Posterior Probability") +
  ggtitle("P-value vs 1-Posterior Probability") +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 13, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 10, face = "bold"),
    axis.text = element_text(size = 9)
  )

p2
```


```{r T1E_combined_all2, eval = T}

library(cowplot)

p11 <- p1 + theme(plot.background = element_rect(colour = "black", size = 0.5, fill = NA))
p22 <- p2 + theme(plot.background = element_rect(colour = "black", size = 0.5, fill = NA))

plots_row <- plot_grid(p22, p11, ncol = 2, labels = c("A", "B"), label_size = 14)

combined_plot <- plot_grid(
  plots_row,
  #legend,
  ncol = 1,                 
  rel_heights = c(3, 0.4)   
)

print(combined_plot)

```

De manera preliminar (y sin detallar nada a modo de resumen). Se van a considerar 3 modelos Bayesianos diferentes donde se van a considerar 3 prior distribution diferentes para el brazo control considerando siempre una prior no informativa para el brazo tratamiento.
Esta información a priori sigue una distribución beta y aunque los resultados a partir de ahora se muestran en términos de medianas, las prior se van a especificar en términos de la escala weibull para este tratamiento.

La fórmula para transformar las medianas en parámetro escala para la Weibull es la siguiente (asumiendo un shape=1 que es exponencial):
  
parameters <- medians / (log(2)^(1/shape_parameter))


  
Control: Mediana de 4.2 es 7.934823
Experimental: Mediana de 6 es 14.42695

Control: Mediana de 4.2 es 6.059319
Experimental: Mediana de 6 es 8.65617

A continuación muestro los 3 plots de densidad para la prior del brazo control.

1) Prior no informativa: 

Equivalente al frecuentista porque "dejamos que los datos hablen por sí mismos" a través de la función de verosimilitud. Anteriormente, los parámetros para la distribución Gamma había sido una súper no informativa (1/1000, 1/1000), el problema con estos valores tan cercanos al 0 provoca que sea una distribución impropia, además de que tarda muchísimo más (muchos más puntos que evaluar) ya que esta distribución coincide con los ejes de las coordenadas.

Por eso, voy a considerar una distribución no informativa pero acotada al tiempo máximo del estudio de 32 meses. Para ello el 1º parámetro es 1, y el 2º va a ser 1/16 para que esta distribución tenga como media la mitad de la duración total (media=1/(1/16)=16), esto es muy conservador porque el valor que coincide con la mediana del control es 6.

2) Prior débil: 

Damos una idea de en qué rangos debería estar el parámetro para la mediana pero es información muy vaga y que no aporta gran conocimiento. La media de una gamma es 6.059319/1 por lo que está bien (aunque parezca que no está muy centrado)

3) Prior muy informativa: 

Tenemos una certeza absoluta de qué valor es el valor real de la mediana y dejamos poco espacio a la incertidumbre (muy poca variabilidad). Por eso ajustamos los dos parámetros para obtener valores de 605.9319 (6.059319/100) y 100.

```{r `Gamma priors`, eval = T}


parameters_gamma <- data.frame(shape = c(1, 6.059319, 605.9319),
                               rate = c( 1/16, 1, 100),
                               label = c("Non-informative: Gamma(1, 1/16)", "Weak: Gamma(6.059319, 1)", "Informative: Gamma(605.9319, 100)"))


gamma_density <- function(shape, rate, label) {
  data.frame(x = seq(0, 32, length.out = 100)) %>%
    mutate(density = dgamma(x, shape = shape, rate = rate),
           parameter = label)
}

densities <- purrr::pmap_df(parameters_gamma, gamma_density)

ggplot(densities, aes(x, density, color = parameter)) +
  geom_line() +
  labs(title = "Gamma Prior Distributions",
       x = "Median control in months",
       y = "Density") +
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 14, face = "bold"),
        axis.text = element_text(size = 12))

```

De ahora en adelante, todas las simulaciones hechas con Bayesiano va a tener las siguientes características (a continuación el link de Stan dode te puede cuál está por defecto)

f <- rstan::sampling(object  = modelo,
                     data    = lista_prior,
                     chains  = 3,       
                     thin    = 1,
                     iter    = 10000,   
                     warmup  = 5000,
                     refresh = 0,
                     seed = 24)

A continuación, pasamos a evaluar las características operantes para los 3 modelos Bayesianos propuestos. Se va a estudiar como anteriormente, el Poder, el Error de Tipo I y el MSE.

Se va a evaluar un escenario donde el HR = 0.7 y se asume una exponencial. Se van a considerar los parámetros del SAP como si no tuviéramos conocimiento de los resultados finales.

A continuación está el Bayesiano con prior no informativa:

```{r `Bayes: Non informative prior distribution`, eval = T}

shape_parameter <- 1 

control_medians <- c(2,2.25,2.5,2.75,3,3.25,3.5,3.75,4,4.2,4.25,4.5,4.75,5,5.25,5.5,5.75,6,6.25,6.5,6.75,7,7.25,7.5,7.75,8,8.25,8.5,8.75,9)

medians <- matrix(NA, nrow = length(control_medians), ncol = 3, 
                  dimnames = list(NULL, c("Control", "Treatment", "Hazard Ratio")))

desired_HR = 0.7

for (i in 1:length(control_medians)) {
  medians[i, "Control"] <- control_medians[i]
  
  lambda_control = control_medians[i] / (log(2)^(1/shape_parameter))
  lambda_treatment = lambda_control / desired_HR^(1/shape_parameter)
  
  medians[i, "Treatment"] = lambda_treatment * (log(2)^(1/shape_parameter))
  medians[i, "Hazard Ratio"] = (lambda_control / lambda_treatment)^shape_parameter
}

medians <- medians[,1:2]
sample_size <- 400
ratio <- c(2/3,1/3)
rand_type <- "CR" 
scenarios_eff <- as.matrix(medians, nrow = length(control_medians), ncol = 2, byrow = TRUE)
censor <- c(0.05,0.05) # 10% drop-out
Tmax <- 32 # Aquí tengo dudas, muy pocos pacientes llegan al final pero parece que es lo que pone en el SAP
alpha <- 0.05 
test.type <- 2
HR_1 <- TRUE
IA <- c(0.5, 0.75)
method_IA <- "OF"
n_exp_events <- 330
Plot_Power <- FALSE
plot_pvalues = FALSE 
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = TRUE
analysis = "bayes"
n_sim <- 3000
seed <- 24
# 1) Shape control, 2) rate control, 3) Shape experimental y 4) rate experimental
prior_gamma <- matrix(c(1, 1/16, 1, 1/16), nrow = 2, ncol = 2, byrow = TRUE) 
prior_type <- c("Non Informative prior ~ Ga(1, 1/16)") 
P_HR_data_Boundary <- 0.8 # P(HR < 0.8 | data)
modelo_weibull_sep <- rstan::stan_model("weibull_gamma_def.stan" ,verbose = F)
modelo = modelo_weibull_sep
modelo_bayes_test = "weibull"
w = NULL
a0 = NULL

# sim14 <-  sim_trials(n_sim = n_sim,
#                      analysis = "bayes",
#                      sample_size = sample_size,
#                      ratio = ratio,
#                      rand_type = rand_type,
#                      Tmax = Tmax,
#                      scenarios_eff = scenarios_eff,
#                      shape_parameter = shape_parameter,
#                      censor = censor,
#                      test.type = test.type,
#                      alpha = alpha,
#                      method_IA = method_IA,
#                      IA = IA,
#                      n_exp_events = n_exp_events,
#                      HR_1 = HR_1,
#                      Plot_Power = Plot_Power,
#                      modelo = modelo,
#                      modelo_bayes_test = modelo_bayes_test,
#                      prior_type = prior_type,
#                      P_HR_data_Boundary = P_HR_data_Boundary,
#                      prior_gamma = prior_gamma,
#                      Plot_Power_scenarios = Plot_Power_scenarios,
#                      desired_HRs = desired_HRs,
#                      plot_pvalues = plot_pvalues,
#                      Plot_Control_Scenarios = Plot_Control_Scenarios,
#                      seed = seed)
# sim14[[2]]
# sim14[[3]]
# sim14[[4]]
# 
# sim1414 <- sim14[[1]]
# 
# wd <- createWorkbook()
# addWorksheet(wd, "Sheet1")
# writeData(wd, "Sheet1", sim1414)
# saveWorkbook(wd, "Bayes_Non_Informative_400_3000.xlsx", overwrite = TRUE)

sheet_names <- c("Sheet1")
non_informative_gamma <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/Blincyto_PhALL_Tablas/Bayes_Non_Informative_400_3000.xlsx", sheet = sheet_names[1])


```

El Bayesiano con una prior muy poco informativa (débil):
  
```{r `Bayes: Weak informative prior distribution`, eval = T}


shape_parameter <- 1 

control_medians <- c(2,2.25,2.5,2.75,3,3.25,3.5,3.75,4,4.2,4.25,4.5,4.75,5,5.25,5.5,5.75,6,6.25,6.5,6.75,7,7.25,7.5,7.75,8,8.25,8.5,8.75,9)

medians <- matrix(NA, nrow = length(control_medians), ncol = 3, 
                  dimnames = list(NULL, c("Control", "Treatment", "Hazard Ratio")))

desired_HR = 0.7

for (i in 1:length(control_medians)) {
  medians[i, "Control"] <- control_medians[i]
  
  lambda_control = control_medians[i] / (log(2)^(1/shape_parameter))
  lambda_treatment = lambda_control / desired_HR^(1/shape_parameter)
  
  medians[i, "Treatment"] = lambda_treatment * (log(2)^(1/shape_parameter))
  medians[i, "Hazard Ratio"] = (lambda_control / lambda_treatment)^shape_parameter
}

medians <- medians[,1:2]
sample_size <- 400
ratio <- c(2/3,1/3)
rand_type <- "CR" 
scenarios_eff <- as.matrix(medians, nrow = length(control_medians), ncol = 2, byrow = TRUE)
censor <- c(0.05,0.05) # 10% drop-out
Tmax <- 32 # Aquí tengo dudas, muy pocos pacientes llegan al final pero parece que es lo que pone en el SAP
alpha <- 0.05 
test.type <- 2
HR_1 <- TRUE
IA <- c(0.5, 0.75)
method_IA <- "OF"
n_exp_events <- 330
Plot_Power <- FALSE
plot_pvalues = FALSE 
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = TRUE
analysis = "bayes"
n_sim <- 3000
seed <- 24
# 1) Shape control, 2) rate control, 3) Shape experimental y 4) rate experimental
prior_gamma <- matrix(c(6.059319, 1, 1, 1/16), nrow = 2, ncol = 2, byrow = TRUE) 
prior_type <- c("Weak Informative prior ~ Ga(6.059319, 1)") 
P_HR_data_Boundary <- 0.8 # P(HR < 0.8 | data)
modelo_weibull_sep <- rstan::stan_model("weibull_gamma_def.stan" ,verbose = F)
modelo = modelo_weibull_sep
modelo_bayes_test = "weibull"
w = NULL
a0 = NULL

# sim15 <-  sim_trials(n_sim = n_sim,
#                      analysis = "bayes",
#                      sample_size = sample_size,
#                      ratio = ratio,
#                      rand_type = rand_type,
#                      Tmax = Tmax,
#                      scenarios_eff = scenarios_eff,
#                      shape_parameter = shape_parameter,
#                      censor = censor,
#                      test.type = test.type,
#                      alpha = alpha,
#                      method_IA = method_IA,
#                      IA = IA,
#                      n_exp_events = n_exp_events,
#                      HR_1 = HR_1,
#                      Plot_Power = Plot_Power,
#                      modelo = modelo,
#                      modelo_bayes_test = modelo_bayes_test,
#                      prior_type = prior_type,
#                      P_HR_data_Boundary = P_HR_data_Boundary,
#                      prior_gamma = prior_gamma,
#                      Plot_Power_scenarios = Plot_Power_scenarios,
#                      desired_HRs = desired_HRs,
#                      plot_pvalues = plot_pvalues,
#                      Plot_Control_Scenarios = Plot_Control_Scenarios,
#                      seed = seed)
# sim15[[2]]
# sim15[[3]]
# sim15[[4]]
# 
# sim1515 <- sim15[[1]]
# 
# wd <- createWorkbook()
# addWorksheet(wd, "Sheet1")
# writeData(wd, "Sheet1", sim1515)
# saveWorkbook(wd, "Bayes_Weak_Informative_400_3000.xlsx", overwrite = TRUE)


sheet_names <- c("Sheet1")
weak_informative_gamma <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/Blincyto_PhALL_Tablas/Bayes_Weak_Informative_400_3000.xlsx", sheet = sheet_names[1])

```


Y el Bayesiano con prior muy informativa:
  
```{r `Bayes: Strong informative prior distribution`, eval = T}

shape_parameter <- 1 

control_medians <- c(2,2.25,2.5,2.75,3,3.25,3.5,3.75,4,4.2,4.25,4.5,4.75,5,5.25,5.5,5.75,6,6.25,6.5,6.75,7,7.25,7.5,7.75,8,8.25,8.5,8.75,9)

medians <- matrix(NA, nrow = length(control_medians), ncol = 3, 
                  dimnames = list(NULL, c("Control", "Treatment", "Hazard Ratio")))

desired_HR = 0.7

for (i in 1:length(control_medians)) {
  medians[i, "Control"] <- control_medians[i]
  
  lambda_control = control_medians[i] / (log(2)^(1/shape_parameter))
  lambda_treatment = lambda_control / desired_HR^(1/shape_parameter)
  
  medians[i, "Treatment"] = lambda_treatment * (log(2)^(1/shape_parameter))
  medians[i, "Hazard Ratio"] = (lambda_control / lambda_treatment)^shape_parameter
}

medians <- medians[,1:2]
sample_size <- 400
ratio <- c(2/3,1/3)
rand_type <- "CR" 
scenarios_eff <- as.matrix(medians, nrow = length(control_medians), ncol = 2, byrow = TRUE)
censor <- c(0.05,0.05) # 10% drop-out
Tmax <- 32 # Aquí tengo dudas, muy pocos pacientes llegan al final pero parece que es lo que pone en el SAP
alpha <- 0.05 
test.type <- 2
HR_1 <- TRUE
IA <- c(0.5, 0.75)
method_IA <- "OF"
n_exp_events <- 330
Plot_Power <- FALSE
plot_pvalues = FALSE 
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = TRUE
analysis = "bayes"
n_sim <- 3000
seed <- 24
# 1) Shape control, 2) rate control, 3) Shape experimental y 4) rate experimental
prior_gamma <- matrix(c(605.9319, 100, 1, 1/16), nrow = 2, ncol = 2, byrow = TRUE) 
prior_type <- c("Strong Informative prior ~ Ga(605.9319, 100)") 
P_HR_data_Boundary <- 0.8 # P(HR < 0.8 | data)
modelo_weibull_sep <- rstan::stan_model("weibull_gamma_def.stan" ,verbose = F)
modelo = modelo_weibull_sep
modelo_bayes_test = "weibull"
w = NULL
a0 = NULL

# sim16 <-  sim_trials(n_sim = n_sim,
#                      analysis = "bayes",
#                      sample_size = sample_size,
#                      ratio = ratio,
#                      rand_type = rand_type,
#                      Tmax = Tmax,
#                      scenarios_eff = scenarios_eff,
#                      shape_parameter = shape_parameter,
#                      censor = censor,
#                      test.type = test.type,
#                      alpha = alpha,
#                      method_IA = method_IA,
#                      IA = IA,
#                      n_exp_events = n_exp_events,
#                      HR_1 = HR_1,
#                      Plot_Power = Plot_Power,
#                      modelo = modelo,
#                      modelo_bayes_test = modelo_bayes_test,
#                      prior_type = prior_type,
#                      P_HR_data_Boundary = P_HR_data_Boundary,
#                      prior_gamma = prior_gamma,
#                      Plot_Power_scenarios = Plot_Power_scenarios,
#                      desired_HRs = desired_HRs,
#                      plot_pvalues = plot_pvalues,
#                      Plot_Control_Scenarios = Plot_Control_Scenarios,
#                      seed = seed)
# sim16[[2]]
# sim16[[3]]
# sim16[[4]]
# 
# sim1616 <- sim16[[1]]
# 
# wd <- createWorkbook()
# addWorksheet(wd, "Sheet1")
# writeData(wd, "Sheet1", sim1616)
# saveWorkbook(wd, "Bayes_Strong_Informative_400_3000.xlsx", overwrite = TRUE)


sheet_names <- c("Sheet1")
strong_informative_gamma <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/Blincyto_PhALL_Tablas/Bayes_Strong_Informative_400_3000.xlsx", sheet = sheet_names[1])

```

Por último, leemos los datos del frecuentista para HR=0.7:
  
```{r `Bayes: freq HR=0.7`, eval = T}

shape_parameter <- 1 

control_medians <- c(2,2.25,2.5,2.75,3,3.25,3.5,3.75,4,4.2,4.25,4.5,4.75,5,5.25,5.5,5.75,6,6.25,6.5,6.75,7,7.25,7.5,7.75,8,8.25,8.5,8.75,9)

medians <- matrix(NA, nrow = length(control_medians), ncol = 3, 
                  dimnames = list(NULL, c("Control", "Treatment", "Hazard Ratio")))

desired_HR = 0.7

for (i in 1:length(control_medians)) {
  medians[i, "Control"] <- control_medians[i]
  
  lambda_control = control_medians[i] / (log(2)^(1/shape_parameter))
  lambda_treatment = lambda_control / desired_HR^(1/shape_parameter)
  
  medians[i, "Treatment"] = lambda_treatment * (log(2)^(1/shape_parameter))
  medians[i, "Hazard Ratio"] = (lambda_control / lambda_treatment)^shape_parameter
}

medians <- medians[,1:2]
sample_size <- 400
ratio <- c(2/3,1/3)
rand_type <- "CR" 
scenarios_eff <- as.matrix(medians, nrow = length(control_medians), ncol = 2, byrow = TRUE)
censor <- c(0.05,0.05) # 10% drop-out
Tmax <- 32 # Aquí tengo dudas, muy pocos pacientes llegan al final pero parece que es lo que pone en el SAP
alpha <- 0.05 
test.type <- 2
HR_1 <- TRUE
IA <- c(0.5, 0.75)
method_IA <- "OF"
n_exp_events <- 330
Plot_Power <- FALSE
plot_pvalues = FALSE 
Plot_Power_scenarios = FALSE
#Plot_Control_Scenarios = TRUE
Plot_Control_Scenarios = FALSE
analysis = "freq"
n_sim <- 3000
seed <- 24

# sim17 <-  sim_trials(n_sim = n_sim,
#                      analysis = analysis,
#                      sample_size = sample_size,
#                      ratio = ratio,
#                      rand_type = rand_type,
#                      Tmax = Tmax,
#                      scenarios_eff = scenarios_eff,
#                      shape_parameter = shape_parameter,
#                      censor = censor,
#                      test.type = test.type,
#                      alpha = alpha,
#                      method_IA = method_IA,
#                      IA = IA,
#                      n_exp_events = n_exp_events,
#                      HR_1 = HR_1,
#                      Plot_Power = Plot_Power,
#                      modelo = modelo,
#                      modelo_bayes_test = modelo_bayes_test,
#                      prior_type = prior_type,
#                      P_HR_data_Boundary = P_HR_data_Boundary,
#                      prior_gamma = prior_gamma,
#                      Plot_Power_scenarios = Plot_Power_scenarios,
#                      desired_HRs = desired_HRs,
#                      plot_pvalues = plot_pvalues,
#                      Plot_Control_Scenarios = Plot_Control_Scenarios,
#                      seed = seed)
# # sim17[[2]]
# # sim17[[3]]
# # sim17[[4]]
# # 
# # sim1717 <- sim17[[1]]
# 
# wd <- createWorkbook()
# addWorksheet(wd, "Sheet1")
# writeData(wd, "Sheet1", sim17)
# saveWorkbook(wd, "Frequentist_400_3000.xlsx", overwrite = TRUE)


sheet_names <- c("Sheet1")
frequentist <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/Frequentist_400_3000.xlsx", sheet = sheet_names[1])


```

Una vez que hemos recogido los resultados de la simulación vamos a comparar en los mismos gráficos el rendimiento de cada uno de los modelos. También se incorpora el frecuentista para tenerlo como referencia.

A continuación recogemos los datos para poder dibujarlos

```{r `Data gathering `, eval = T}

if(HR_1 == TRUE){hr_1 <- replicate(n = ncol(scenarios_eff), scenarios_eff[, 1])
scenarios_eff <- rbind(scenarios_eff, hr_1)}

scenarios_eff_df <- as.data.frame(scenarios_eff)
colnames(scenarios_eff_df) <- c("median_control", "median_treatment")

scenarios_eff_df$scenario <- seq_len(nrow(scenarios_eff_df))

# Frequentist
data_frequentist <- frequentist %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "Frequentist")

data_filtered_diff_not_zero_frequentist <- data_frequentist %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_frequentist <- data_frequentist %>%
  filter(median_control == median_treatment)

# Non-informative
data_non_informative <- non_informative_gamma %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "Non-informative")

data_filtered_diff_not_zero_non_informative <- data_non_informative %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_non_informative <- data_non_informative %>%
  filter(median_control == median_treatment)

# Very informative
data_informative <- strong_informative_gamma %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "Strongly Informative")

data_filtered_diff_not_zero_informative <- data_informative %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_informative <- data_informative %>%
  filter(median_control == median_treatment)

# Mid informative
data_mid_informative <- weak_informative_gamma %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "Weakly informative")

data_filtered_diff_not_zero_mid_informative <- data_mid_informative %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_mid_informative <- data_mid_informative %>%
  filter(median_control == median_treatment)

median_control_center <- median(data_filtered_diff_not_zero_informative$median_control)
median_control_center_zero_diff <- median(data_filtered_diff_zero_informative$median_control)

combined_data_diff_not_zero <- bind_rows(data_filtered_diff_not_zero_frequentist,
                                         data_filtered_diff_not_zero_non_informative, 
                                         data_filtered_diff_not_zero_informative, 
                                         data_filtered_diff_not_zero_mid_informative)

combined_data_diff_zero <- bind_rows(data_filtered_diff_zero_frequentist,
                                     data_filtered_diff_zero_non_informative, 
                                     data_filtered_diff_zero_informative, 
                                     data_filtered_diff_zero_mid_informative)

```

Primero observamos cómo de bien se ajustan las inferencias a los datos verdaderos (poblacionales dentro de la simulación). 

Los resultados de MSE son prácticamente iguales para el modelo frecuentista como el bayesiano con las priors no informativas. Con respecto a la Weak, 

Por último la informativa tiene un comportamiento espectacular en escenarios donde la mediana real para el control son muy cercanos a 5.5 pero muy malos según se van alejando del valores central de esta prior.

```{r MSE, eval = T}

p6 <- ggplot(combined_data_diff_not_zero, aes(x = median_control, y = mean_MSE, color = Prior)) + 
  geom_line(size = 1.2) +
  geom_vline(xintercept = median_control_center, linetype = "solid") +
  labs(
    title = "Mean Square Error (MSE)",
    x = "Median Control Arm (in months)",
    y = "Mean MSE",
    color = "Bayesian Prior Distributions"
  ) +
  theme_minimal() + 
  theme(
    plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 10, face = "bold"),
    axis.text = element_text(size = 12),
    axis.title.x = element_text(size = 11),
    axis.title.y = element_text(size = 11),
    legend.margin = margin(9, 9, 9, 9),
    legend.text = element_text(size = 9),
    legend.title = element_text(size = 10, face = "bold")
  ) +
  scale_color_discrete(name = "Bayesian Prior Distributions") +
  scale_x_continuous(breaks = seq(min(combined_data_diff_not_zero$median_control), max(combined_data_diff_not_zero$median_control), by = 0.5)) +
  scale_y_continuous(limits = c(0, 0.075))

p6

```

Con respecto al poder...

```{r Power, eval = T}

p7 <- ggplot(combined_data_diff_not_zero, aes(x = median_control, y = prop_significant, color = Prior)) +
  geom_line(size = 1.2) + 
  geom_line() +
  geom_vline(xintercept = median_control_center, linetype = "dashed") +
  labs(title = "Power", x = "Median Control Arm (in months)", y = "Proportion of Significant Trials", color = "Bayesian Prior Distributions") +
  theme_minimal() + 
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 12),
        axis.title.x = element_text(size = 11),
        axis.title.y = element_text(size = 11),
        legend.margin = margin(12, 12, 12, 12),
        legend.text = element_text(size = 11),
        legend.title = element_text(size = 12, face = "bold")) +
  scale_color_discrete(name = "Bayesian Prior Distributions") +
  scale_linetype_discrete(name = "Bayesian Prior Distributions") +
  scale_x_continuous(breaks = seq(min(combined_data_diff_not_zero$median_control), max(combined_data_diff_not_zero$median_control), by = 0.5)) +
  scale_y_continuous(limits = c(0.5, 1))
p7

```

Por último, el error de Tipo I vemos que se controla para el bayesiano no informativo y el weak. Sin embargo, en el bayesiano informativo para valores mayores de 5.5 el error de tipo I se infla de una manera exponencial. Esto demuestra que este modelo no debería usarse a no ser que exista un consenso de que estos valores son "seguros".

```{r T1E, eval = T}

p8 <- ggplot(combined_data_diff_zero, aes(x = median_control, y = prop_significant, color = Prior)) +
  geom_line(size = 1.2) + 
  geom_line() +
  geom_vline(xintercept = median_control_center, linetype = "dashed") +
  geom_hline(yintercept = 0.025, linetype = "dashed", color = "green") +
  geom_hline(yintercept = 0.05, linetype = "dashed", color = "purple") +
  labs(title = "Type I Error (T1E)", x = "Median Control (in months)", y = "Proportion of Significant Trials", color = "Bayesian Prior Distributions") +
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 12),
        axis.title.x = element_text(size = 11),
        axis.title.y = element_text(size = 11),
        legend.margin = margin(12, 12, 12, 12),
        legend.text = element_text(size = 11),
        legend.title = element_text(size = 12, face = "bold")) +
  scale_color_discrete(name = "Bayesian Prior Distributions") +
  scale_linetype_discrete(name = "Bayesian Prior Distributions") +
  scale_x_continuous(breaks = seq(min(combined_data_diff_zero$median_control), max(combined_data_diff_zero$median_control), by = 0.5)) +
  scale_y_continuous(limits = c(0, 0.2))
p8

```

```{r T1E_combined_all, eval = T}

library(cowplot)

p66 <- p6 + scale_color_discrete(
  name = "Bayesian Prior Distributions:", 
  labels = c(
    "Frequentist",
    "Non-informative Prior",
    "Informative Prior\ncentered at 5.5 months",
    "Weak Informative Prior\ncentered at 5.5 months"
  )
) +
  guides(color = guide_legend(ncol = 4))  

legend <- get_legend(
  p66 +
    theme(
      # legend.box = "horizontal", 
      legend.justification = c(0, 1),
      # legend.margin = margin(8, 8, 8, 8),
      legend.text = element_text(size = 10), 
      legend.title = element_text(size = 11, face = "bold")
    )
)

# Remove individual legends from the plots
p66 <- p66 + theme(legend.position = "none")
p77 <- p7 + theme(legend.position = "none")
p88 <- p8 + theme(legend.position = "none")

p66 <- p66 + theme(plot.background = element_rect(colour = "black", size = 0.5, fill = NA))
p77 <- p77 + theme(plot.background = element_rect(colour = "black", size = 0.5, fill = NA))
p88 <- p88 + theme(plot.background = element_rect(colour = "black", size = 0.5, fill = NA))

plots_row <- plot_grid(p66, p77, p88, ncol = 3, labels = c("A", "B", "C"), label_size = 14)

combined_plot <- plot_grid(
  plots_row,
  legend,
  ncol = 1,                 
  rel_heights = c(3, 0.4)   
)

print(combined_plot)

```


También resulta valioso cómo afectan diferentes asunciones para la prior informativa en el brazo control si vamos moviendo el HR. Esto nos va a permitir ver cómo asunciones demasiado pesimistas para el brazo control favorece que sea más fácil ver diferencias entre brazos y por lo tanto, considerar el estudio como significativo. Por otro lado, es relativamente común ver cuando un estudio sale fallido achacar la culpa a que la mediana del brazo control ha sido más buena de lo esperado y por lo tanto, es más difícil demostrar eficacia.

Ahora vamos a usar el gráfico que ya se presentó anteriormente sólo para el frecuentista con priors muy informativas y comparar cómo afectan estas asunciones informativas a la facilidad o dificultad para declarar eficacia. Esto también se puede ver traducido a la importancia de elegir un threshold para demostrar eficacia ya que esto es totalmente comparable a usar un prior muy muy informativa a un valor determinado.

Recordar que siempre se usa un prior no informativa para el brazo experimental.

Se va a hacer sólo para los parámetros que la compañía usó en el SAP, i.e., distribución exponencial (shape parameter = 1), tamaño muestral de 400 y mediana de control de 4.2


A continuación se cogen los datos del frecuentista para los que se hizo en la gráfica original:
  
```{r `Bayes: freq HR=0.7 Power changing HRs`, eval = T}

shape_parameter <- 1

desired_HRs <- c(1.6, 1.5, 1.4, 1.3, 1.2, 1.1, 1, 0.95, 0.9, 0.85, 0.8, 0.775, 0.75, 0.725, 0.7, 0.675, 0.65, 0.625, 0.6, 0.575, 0.55, 0.525, 0.5, 0.45, 0.4, 0.35, 0.3)
control_medians <- rep(4.2, times = length(desired_HRs))

medians_control_fijo <- matrix(NA, nrow = length(desired_HRs), ncol = 2, dimnames = list(paste0("HR ", desired_HRs), c("Control", "Treatment")))

for (i in 1:length(desired_HRs)) {
  medians_control_fijo[i, "Treatment"] <- control_medians[i] / (desired_HRs[i]^(1/shape_parameter))
  medians_control_fijo[i, "Control"] <- control_medians[i]
}

sample_size <- 400
ratio <- c(2/3,1/3)
rand_type <- "CR" 
scenarios_eff <- as.matrix(medians_control_fijo, nrow = length(medians_control_fijo), ncol = 2, byrow = TRUE)
censor <- c(0.05,0.05) # 10% drop-out
Tmax <- 32 
alpha <- 0.05 
test.type <- 2
HR_1 <- FALSE
IA <- c(0.5, 0.75)
method_IA <- "OF"
n_exp_events <- 330
Plot_Power = FALSE
plot_pvalues = FALSE
Plot_Power_scenarios = FALSE
analysis = "freq" 
n_sim <- 3000
seed <- 24

 # sim3 <- sim_trials(n_sim = n_sim,
 #                    analysis = "freq",
 #                    sample_size = sample_size,
 #                    ratio = ratio,
 #                    rand_type = rand_type,
 #                    Tmax = Tmax,
 #                    shape_parameter = shape_parameter,
 #                    scenarios_eff = scenarios_eff,
 #                    censor = censor,
 #                    alpha = alpha,
 #                    test.type = test.type,
 #                    IA = IA,
 #                    method_IA = method_IA,
 #                    n_exp_events = n_exp_events,
 #                    HR_1 = HR_1,
 #                    seed=seed,
 #                    Plot_Power = Plot_Power,
 #                    plot_pvalues = plot_pvalues)

#
# wd <- createWorkbook()
# addWorksheet(wd, "Sheet1")
# writeData(wd, "Sheet1", sim3)
# saveWorkbook(wd, "freq_3000_HR_changing.xlsx", overwrite = TRUE)

sheet_names <- c("Sheet1")
sim3_results <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/Blincyto_PhALL_Tablas/freq_3000_HR_changing.xlsx", sheet = sheet_names[1])

```

Vamos a ver la densidad para cada una de las distribuciones informativas del control forzando valores de 2.2, 4.2 y 6.2

```{r `Gamma priors informatives`, eval = T}

# Vamos a presentarlo en términos de medianas en vez de escala Weibull (aunque luego sea esto lo que se meta como input en el model STAN)

# En términos del parámetro escala
# parameters <- medians / (log(2)^(1/shape_parameter))
# En términos de mediana
# medians <- parameters * (log(2))^(1/shape_parameter)

parameters_gamma <- data.frame(shape = c(317.3929, 605.9319, 894.4709),
                               rate = c( 100, 100, 100),
                               label = c("Informative: Gamma(317.3929, 100)", "Informative: Gamma(605.9319, 100)", "Informative: Gamma(894.4709, 100)"))

gamma_density <- function(shape, rate, label) {
  data.frame(x = seq(0, 20, length.out = 100)) %>%
    mutate(density = dgamma(x, shape = shape, rate = rate),
           parameter = label)
}

densities <- purrr::pmap_df(parameters_gamma, gamma_density)

ggplot(densities, aes(x, density, color = parameter)) +
  geom_line() +
  labs(title = "Gamma Prior Distributions",
       x = "Median control in months",
       y = "Density") +
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 14, face = "bold"),
        axis.text = element_text(size = 12))

```

Simulamos los resultados forzando a la prior informativa del control a ser de 2.2

```{r `Bayes: Bayes infor med: 2.2 HR=0.7 Power changing HRs`, eval = T}

shape_parameter <- 1

desired_HRs <- c(1.6, 1.5, 1.4, 1.3, 1.2, 1.1, 1, 0.95, 0.9, 0.85, 0.8, 0.775, 0.75, 0.725, 0.7, 0.675, 0.65, 0.625, 0.6, 0.575, 0.55, 0.525, 0.5, 0.45, 0.4, 0.35, 0.3)
control_medians <- rep(4.2, times = length(desired_HRs))

medians_control_fijo <- matrix(NA, nrow = length(desired_HRs), ncol = 2, dimnames = list(paste0("HR ", desired_HRs), c("Control", "Treatment")))

for (i in 1:length(desired_HRs)) {
  medians_control_fijo[i, "Treatment"] <- control_medians[i] / (desired_HRs[i]^(1/shape_parameter))
  medians_control_fijo[i, "Control"] <- control_medians[i]
}

sample_size <- 400
ratio <- c(2/3,1/3)
rand_type <- "CR" 
scenarios_eff <- as.matrix(medians_control_fijo, nrow = length(medians_control_fijo), ncol = 2, byrow = TRUE)
censor <- c(0.05,0.05) # 10% drop-out
Tmax <- 32 
alpha <- 0.05 
test.type <- 2
HR_1 <- FALSE
IA <- c(0.5, 0.75)
method_IA <- "OF"
n_exp_events <- 330
Plot_Power <- FALSE
plot_pvalues = FALSE 
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = FALSE

analysis = "bayes"
n_sim <- 3000
seed <- 24
# 1) Shape control, 2) rate control, 3) Shape experimental y 4) rate experimental
prior_gamma <- matrix(c(317.3929, 100,  1, 1/16), nrow = 2, ncol = 2, byrow = TRUE) 
prior_type <- c("Non informative prior") # Este vector es para que aparezca el nombre en las tablas
P_HR_data_Boundary <- 0.8 # P(HR < 0.8 | data)
modelo_weibull_sep <- rstan::stan_model("weibull_gamma_def.stan" ,verbose = F)
modelo = modelo_weibull_sep
modelo_bayes_test = "weibull"

# sim5 <-  sim_trials(n_sim = n_sim,  
#                     analysis = "bayes",
#                     sample_size = sample_size, 
#                     ratio = ratio,
#                     rand_type = rand_type,
#                     Tmax = Tmax, 
#                     scenarios_eff = scenarios_eff,
#                     shape_parameter = shape_parameter,
#                     censor = censor,
#                     test.type = test.type,
#                     alpha = alpha,
#                     method_IA = method_IA,
#                     IA = IA,
#                     n_exp_events = n_exp_events,
#                     HR_1 = HR_1,
#                     Plot_Power = Plot_Power,
#                     modelo = modelo,
#                     modelo_bayes_test = modelo_bayes_test,
#                     prior_type = prior_type,
#                     P_HR_data_Boundary = P_HR_data_Boundary,
#                     prior_gamma = prior_gamma,
#                     Plot_Power_scenarios = Plot_Power_scenarios,
#                     desired_HRs = desired_HRs,
#                     plot_pvalues = plot_pvalues,
#                     Plot_Control_Scenarios = Plot_Control_Scenarios,
#                     seed = seed)
# 
# wd <- createWorkbook()
# addWorksheet(wd, "Sheet1")
# writeData(wd, "Sheet1", sim5)
# saveWorkbook(wd, "informative_gamma22_400_3000_HR_changing.xlsx", overwrite = TRUE)
# 


sheet_names <- c("Sheet1")
informative_gamma_2.2 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/Blincyto_PhALL_Tablas/informative_gamma22_400_3000_HR_changing.xlsx", sheet = sheet_names[1])

```

Simulamos los resultados forzando a la prior informativa del control a ser de 4.2

```{r `Bayes: Bayes infor med: 4.2 HR=0.7 Power changing HRs`, eval = T}

shape_parameter <- 1

desired_HRs <- c(1.6, 1.5, 1.4, 1.3, 1.2, 1.1, 1, 0.95, 0.9, 0.85, 0.8, 0.775, 0.75, 0.725, 0.7, 0.675, 0.65, 0.625, 0.6, 0.575, 0.55, 0.525, 0.5, 0.45, 0.4, 0.35, 0.3)
control_medians <- rep(4.2, times = length(desired_HRs))

medians_control_fijo <- matrix(NA, nrow = length(desired_HRs), ncol = 2, dimnames = list(paste0("HR ", desired_HRs), c("Control", "Treatment")))

for (i in 1:length(desired_HRs)) {
  medians_control_fijo[i, "Treatment"] <- control_medians[i] / (desired_HRs[i]^(1/shape_parameter))
  medians_control_fijo[i, "Control"] <- control_medians[i]
}

sample_size <- 400
ratio <- c(2/3,1/3)
rand_type <- "CR" 
scenarios_eff <- as.matrix(medians_control_fijo, nrow = length(medians_control_fijo), ncol = 2, byrow = TRUE)
censor <- c(0.05,0.05) # 10% drop-out
Tmax <- 32 
alpha <- 0.05 
test.type <- 2
HR_1 <- FALSE
IA <- c(0.5, 0.75)
method_IA <- "OF"
n_exp_events <- 330
Plot_Power <- FALSE
plot_pvalues = FALSE 
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = FALSE

analysis = "bayes"
n_sim <- 3000
seed <- 24
# 1) Shape control, 2) rate control, 3) Shape experimental y 4) rate experimental
prior_gamma <- matrix(c(605.9319, 100, 1, 1/16), nrow = 2, ncol = 2, byrow = TRUE) 
prior_type <- c("Non informative prior") # Este vector es para que aparezca el nombre en las tablas
P_HR_data_Boundary <- 0.8 # P(HR < 0.8 | data)
modelo_weibull_sep <- rstan::stan_model("weibull_gamma_def.stan" ,verbose = F)
modelo = modelo_weibull_sep
modelo_bayes_test = "weibull"

# sim5 <-  sim_trials(n_sim = n_sim,  
#                     analysis = "bayes",
#                     sample_size = sample_size, 
#                     ratio = ratio,
#                     rand_type = rand_type,
#                     Tmax = Tmax, 
#                     scenarios_eff = scenarios_eff,
#                     shape_parameter = shape_parameter,
#                     censor = censor,
#                     test.type = test.type,
#                     alpha = alpha,
#                     method_IA = method_IA,
#                     IA = IA,
#                     n_exp_events = n_exp_events,
#                     HR_1 = HR_1,
#                     Plot_Power = Plot_Power,
#                     modelo = modelo,
#                     modelo_bayes_test = modelo_bayes_test,
#                     prior_type = prior_type,
#                     P_HR_data_Boundary = P_HR_data_Boundary,
#                     prior_gamma = prior_gamma,
#                     Plot_Power_scenarios = Plot_Power_scenarios,
#                     desired_HRs = desired_HRs,
#                     plot_pvalues = plot_pvalues,
#                     Plot_Control_Scenarios = Plot_Control_Scenarios,
#                     seed = seed)
# 
# wd <- createWorkbook()
# addWorksheet(wd, "Sheet1")
# writeData(wd, "Sheet1", sim5)
# saveWorkbook(wd, "informative_gamma42_400_3000_HR_changing.xlsx", overwrite = TRUE)
# 


sheet_names <- c("Sheet1")
informative_gamma_4.2 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/Blincyto_PhALL_Tablas/informative_gamma42_400_3000_HR_changing.xlsx", sheet = sheet_names[1])

```

Simulamos los resultados forzando a la prior informativa del control a ser de 6.2 

```{r `Bayes: Bayes infor med: 6.2 HR=0.7 Power changing HRs`, eval = T}

shape_parameter <- 1

desired_HRs <- c(1.6, 1.5, 1.4, 1.3, 1.2, 1.1, 1, 0.95, 0.9, 0.85, 0.8, 0.775, 0.75, 0.725, 0.7, 0.675, 0.65, 0.625, 0.6, 0.575, 0.55, 0.525, 0.5, 0.45, 0.4, 0.35, 0.3)
control_medians <- rep(4.2, times = length(desired_HRs))

medians_control_fijo <- matrix(NA, nrow = length(desired_HRs), ncol = 2, dimnames = list(paste0("HR ", desired_HRs), c("Control", "Treatment")))

for (i in 1:length(desired_HRs)) {
  medians_control_fijo[i, "Treatment"] <- control_medians[i] / (desired_HRs[i]^(1/shape_parameter))
  medians_control_fijo[i, "Control"] <- control_medians[i]
}

sample_size <- 400
ratio <- c(2/3,1/3)
rand_type <- "CR" 
scenarios_eff <- as.matrix(medians_control_fijo, nrow = length(medians_control_fijo), ncol = 2, byrow = TRUE)
censor <- c(0.05,0.05) # 10% drop-out
Tmax <- 32 
alpha <- 0.05 
test.type <- 2
HR_1 <- FALSE
IA <- c(0.5, 0.75)
method_IA <- "OF"
n_exp_events <- 330
Plot_Power <- FALSE
plot_pvalues = FALSE 
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = FALSE

analysis = "bayes"
n_sim <- 3000
seed <- 24
# 1) Shape control, 2) rate control, 3) Shape experimental y 4) rate experimental
prior_gamma <- matrix(c(894.4709, 100, 1, 1/16), nrow = 2, ncol = 2, byrow = TRUE) 
prior_type <- c("Non informative prior") # Este vector es para que aparezca el nombre en las tablas
P_HR_data_Boundary <- 0.8 # P(HR < 0.8 | data)
modelo_weibull_sep <- rstan::stan_model("weibull_gamma_def.stan" ,verbose = F)
modelo = modelo_weibull_sep
modelo_bayes_test = "weibull"

# sim5 <-  sim_trials(n_sim = n_sim,  
#                     analysis = "bayes",
#                     sample_size = sample_size, 
#                     ratio = ratio,
#                     rand_type = rand_type,
#                     Tmax = Tmax, 
#                     scenarios_eff = scenarios_eff,
#                     shape_parameter = shape_parameter,
#                     censor = censor,
#                     test.type = test.type,
#                     alpha = alpha,
#                     method_IA = method_IA,
#                     IA = IA,
#                     n_exp_events = n_exp_events,
#                     HR_1 = HR_1,
#                     Plot_Power = Plot_Power,
#                     modelo = modelo,
#                     modelo_bayes_test = modelo_bayes_test,
#                     prior_type = prior_type,
#                     P_HR_data_Boundary = P_HR_data_Boundary,
#                     prior_gamma = prior_gamma,
#                     Plot_Power_scenarios = Plot_Power_scenarios,
#                     desired_HRs = desired_HRs,
#                     plot_pvalues = plot_pvalues,
#                     Plot_Control_Scenarios = Plot_Control_Scenarios,
#                     seed = seed)
# 
# wd <- createWorkbook()
# addWorksheet(wd, "Sheet1")
# writeData(wd, "Sheet1", sim5)
# saveWorkbook(wd, "informative_gamma62_400_3000_HR_changing.xlsx", overwrite = TRUE)
# 


sheet_names <- c("Sheet1")
informative_gamma_6.2 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/Blincyto_PhALL_Tablas/informative_gamma62_400_3000_HR_changing.xlsx", sheet = sheet_names[1])

```


Aquí juntamos los datos:
  
```{r `Simulation scenarios w fixed experimental & bayes w data`, eval = T, echo = T}


data_sim3_results <- sim3_results %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE))%>%
  mutate(Prior = "Frequentist")

data_informative_gamma_2.2 <- informative_gamma_2.2 %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  mutate(Prior = "Informative: Median control at 2.2")

data_informative_gamma_4.2 <- informative_gamma_4.2 %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  mutate(Prior = "Informative:  Median control at 4.2")

data_informative_gamma_6.2 <- informative_gamma_6.2 %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  mutate(Prior = "Informative:  Median control at 6.2")  


combined_data <- bind_rows(data_sim3_results,
                           data_informative_gamma_2.2, 
                           data_informative_gamma_4.2
                           ,data_informative_gamma_6.2)


combined_data <- combined_data %>%
  group_by(Prior) %>%
  mutate(desired_HRs = (desired_HRs))

# La diferencia la he considerado en valor absoluto (se podría también al cuadrado para que salgan siempre positivos)
combined_data <- combined_data %>%
  mutate(diff_HR = abs(mean_HR - desired_HRs))

```

Ahora los dibujamos juntos: 
  
```{r `Simulation scenarios w fixed experimental & bayes w plot`, eval = T, echo = T}


p4 <- ggplot(combined_data, aes(x = desired_HRs, y = prop_significant, group = Prior, color = Prior)) +
  geom_point(size = 3) +
  geom_line(linewidth = 1) +
  geom_vline(xintercept = 1, linetype = "dashed", color = "red", size = 1) +
  geom_vline(xintercept = 0.7, linetype = "dashed", color = "red", size = 1) +
  geom_vline(xintercept = 0.7, linetype = "dashed", color = "red", size = 1) +
  geom_hline(yintercept = c(0.8, 0.9), linetype = "dotted", color = c("purple", "green"), size = 1) +
  scale_x_continuous(breaks = seq(min(combined_data$desired_HRs), max(combined_data$desired_HRs), 0.1), labels = sprintf("%.2f", seq(min(combined_data$desired_HRs), max(combined_data$desired_HRs), 0.1))) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Power vs Hazard Ratio",
       x = "Theoretical Hazard Ratio",
       y = "Power") +
  theme_minimal() +
  theme(plot.title = element_text(size = 12, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 10),
        legend.position = "right")


p4 <- p4 +
  annotate("text", x = max(combined_data$desired_HRs), y = 0.8, label = "80% power", hjust = 1, vjust = -0.5, size = 3.5, color = "purple") +
  annotate("text", x = max(combined_data$desired_HRs), y = 0.9, label = "90% power", hjust = 1, vjust = -0.5, size = 3.5, color = "green") +
  geom_label(aes(x = 1, y = Inf, label = "H0"), vjust = 2, color = "black", fill = "white", size = 3.5, label.size = 0, fontface = "bold") +
  geom_label(aes(x = 0.55, y = Inf, label = "H1"), vjust = 2, color = "black", fill = "white", size = 3.5, label.size = 0, fontface = "bold") +
  geom_label(aes(x = 0.5, y = Inf, label = "Real HR"), vjust = 2, color = "black", fill = "white", size = 3.5, label.size = 0, fontface = "bold")

p4

p5 <- ggplot(combined_data, aes(x = desired_HRs, y = diff_HR, color = Prior)) +
  geom_point(size = 3) +
  geom_line(aes(group = Prior), linewidth = 1) +
  scale_x_continuous(breaks = seq(min(combined_data$desired_HRs), max(combined_data$desired_HRs), 0.1), labels = sprintf("%.2f", seq(min(combined_data$desired_HRs), max(combined_data$desired_HRs), 0.1))) +
  labs(title = "Diff btw Simulated HR and Theoretical HRs",
       x = "Theoretical Hazard Ratio",
       y = "Difference") +
  theme_minimal() +
  theme(plot.title = element_text(size = 10, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 8, face = "bold"),
        axis.text = element_text(size = 8),
        legend.position = "right")

p5
```


También es interesante en vez de dibujar todas las prior muy informativas con diferentes asunciones para la mediana del control (e.g., 2.2, 4.2 y 6.2) es ver cómo se comportan diferentes priors (i.e., no informativa, weak informative y strong informative) para la misma asunción del efecto de mediana 2.2, 4.2 y 6.2.

Como ya tenemos estos valores para las strong informative para cada uno de los escenarios, vamos a poner ahora los parámetros para la no informativa (son los mismos datos para todos los escenarios) y la weak.


Ahora dibujamos las densidades para las weak prior que estarán centradas en los valores de 2.2, 4.2 y 6.2:
  
```{r `Gamma priors weak informatives`, eval = T}

# Vamos a presentarlo en términos de medianas en vez de escala Weibull (aunque luego sea esto lo que se meta como input en el model STAN)

# En términos del parámetro escala
# parameters <- medians / (log(2)^(1/shape_parameter))
# En términos de mediana
# medians <- parameters * (log(2))^(1/shape_parameter)

# parameters_gamma <- data.frame(shape = c(3.50, 5.50, 7.50),
#                          rate = c( 1, 1, 1),
#                          label = c("Informative: Gamma(5.049433, 1)", "Informative: Gamma(7.934823, 1)", "Informative: Gamma(10.82021, 1)"))

parameters_gamma <- data.frame(shape = c(3.173929, 6.059319, 8.944709),
                               rate = c( 1, 1, 1),
                               label = c("Weak: Gamma(3.173929, 1)", "Weak: Gamma(6.059319, 1)", "Weak: Gamma(8.944709, 1)"))


gamma_density <- function(shape, rate, label) {
  data.frame(x = seq(0, 20, length.out = 100)) %>%
    mutate(density = dgamma(x, shape = shape, rate = rate),
           parameter = label)
}

densities <- purrr::pmap_df(parameters_gamma, gamma_density)

ggplot(densities, aes(x, density, color = parameter)) +
  geom_line() +
  labs(title = "Gamma Prior Distributions",
       x = "Median control in months",
       y = "Density") +
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 14, face = "bold"),
        axis.text = element_text(size = 12))

```

Parámetros weak para mediana del 2.2

```{r `Bayes: Bayes weak infor med: 2.2 HR=0.7 Power changing HRs`, eval = T}

shape_parameter <- 1

desired_HRs <- c(1.6, 1.5, 1.4, 1.3, 1.2, 1.1, 1, 0.95, 0.9, 0.85, 0.8, 0.775, 0.75, 0.725, 0.7, 0.675, 0.65, 0.625, 0.6, 0.575, 0.55, 0.525, 0.5, 0.45, 0.4, 0.35, 0.3)
control_medians <- rep(4.2, times = length(desired_HRs))

medians_control_fijo <- matrix(NA, nrow = length(desired_HRs), ncol = 2, dimnames = list(paste0("HR ", desired_HRs), c("Control", "Treatment")))

for (i in 1:length(desired_HRs)) {
  medians_control_fijo[i, "Treatment"] <- control_medians[i] / (desired_HRs[i]^(1/shape_parameter))
  medians_control_fijo[i, "Control"] <- control_medians[i]
}

sample_size <- 400
ratio <- c(2/3,1/3)
rand_type <- "CR" 
scenarios_eff <- as.matrix(medians_control_fijo, nrow = length(medians_control_fijo), ncol = 2, byrow = TRUE)
censor <- c(0.05,0.05) # 10% drop-out
Tmax <- 32 
alpha <- 0.05 
test.type <- 2
HR_1 <- FALSE
IA <- c(0.5, 0.75)
method_IA <- "OF"
n_exp_events <- 330
Plot_Power <- FALSE
plot_pvalues = FALSE 
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = FALSE

analysis = "bayes"
n_sim <- 3000
seed <- 24
# 1) Shape control, 2) rate control, 3) Shape experimental y 4) rate experimental
prior_gamma <- matrix(c(3.173929, 1, 1, 1/16), nrow = 2, ncol = 2, byrow = TRUE) 
prior_type <- c("Non informative prior") # Este vector es para que aparezca el nombre en las tablas
P_HR_data_Boundary <- 0.8 # P(HR < 0.8 | data)
modelo_weibull_sep <- rstan::stan_model("weibull_gamma_def.stan" ,verbose = F)
modelo = modelo_weibull_sep
modelo_bayes_test = "weibull"

# sim5 <-  sim_trials(n_sim = n_sim,  
#                     analysis = "bayes",
#                     sample_size = sample_size, 
#                     ratio = ratio,
#                     rand_type = rand_type,
#                     Tmax = Tmax, 
#                     scenarios_eff = scenarios_eff,
#                     shape_parameter = shape_parameter,
#                     censor = censor,
#                     test.type = test.type,
#                     alpha = alpha,
#                     method_IA = method_IA,
#                     IA = IA,
#                     n_exp_events = n_exp_events,
#                     HR_1 = HR_1,
#                     Plot_Power = Plot_Power,
#                     modelo = modelo,
#                     modelo_bayes_test = modelo_bayes_test,
#                     prior_type = prior_type,
#                     P_HR_data_Boundary = P_HR_data_Boundary,
#                     prior_gamma = prior_gamma,
#                     Plot_Power_scenarios = Plot_Power_scenarios,
#                     desired_HRs = desired_HRs,
#                     plot_pvalues = plot_pvalues,
#                     Plot_Control_Scenarios = Plot_Control_Scenarios,
#                     seed = seed)
# 
# wd <- createWorkbook()
# addWorksheet(wd, "Sheet1")
# writeData(wd, "Sheet1", sim5)
# saveWorkbook(wd, "weak_informative_gamma_2.2_400_3000_HR_changing.xlsx", overwrite = TRUE)
# 

sheet_names <- c("Sheet1")
weak_informative_gamma_2.2 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/Blincyto_PhALL_Tablas/weak_informative_gamma_2.2_400_3000_HR_changing.xlsx", sheet = sheet_names[1])

```

Parámetros weak informative de 4.2

```{r `Bayes: Bayes weak infor med: 4.2 HR=0.7 Power changing HRs`, eval = T}

shape_parameter <- 1

desired_HRs <- c(1.6, 1.5, 1.4, 1.3, 1.2, 1.1, 1, 0.95, 0.9, 0.85, 0.8, 0.775, 0.75, 0.725, 0.7, 0.675, 0.65, 0.625, 0.6, 0.575, 0.55, 0.525, 0.5, 0.45, 0.4, 0.35, 0.3)
control_medians <- rep(4.2, times = length(desired_HRs))

medians_control_fijo <- matrix(NA, nrow = length(desired_HRs), ncol = 2, dimnames = list(paste0("HR ", desired_HRs), c("Control", "Treatment")))

for (i in 1:length(desired_HRs)) {
  medians_control_fijo[i, "Treatment"] <- control_medians[i] / (desired_HRs[i]^(1/shape_parameter))
  medians_control_fijo[i, "Control"] <- control_medians[i]
}

sample_size <- 400
ratio <- c(2/3,1/3)
rand_type <- "CR" 
scenarios_eff <- as.matrix(medians_control_fijo, nrow = length(medians_control_fijo), ncol = 2, byrow = TRUE)
censor <- c(0.05,0.05) # 10% drop-out
Tmax <- 32 
alpha <- 0.05 
test.type <- 2
HR_1 <- FALSE
IA <- c(0.5, 0.75)
method_IA <- "OF"
n_exp_events <- 330
Plot_Power <- FALSE
plot_pvalues = FALSE 
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = FALSE

analysis = "bayes"
n_sim <- 3000
seed <- 24
# 1) Shape control, 2) rate control, 3) Shape experimental y 4) rate experimental
prior_gamma <- matrix(c(6.059319, 1, 1, 1/16), nrow = 2, ncol = 2, byrow = TRUE) 
prior_type <- c("Non informative prior") # Este vector es para que aparezca el nombre en las tablas
P_HR_data_Boundary <- 0.8 # P(HR < 0.8 | data)
modelo_weibull_sep <- rstan::stan_model("weibull_gamma_def.stan" ,verbose = F)
modelo = modelo_weibull_sep
modelo_bayes_test = "weibull"

# sim5 <-  sim_trials(n_sim = n_sim,  
#                     analysis = "bayes",
#                     sample_size = sample_size, 
#                     ratio = ratio,
#                     rand_type = rand_type,
#                     Tmax = Tmax, 
#                     scenarios_eff = scenarios_eff,
#                     shape_parameter = shape_parameter,
#                     censor = censor,
#                     test.type = test.type,
#                     alpha = alpha,
#                     method_IA = method_IA,
#                     IA = IA,
#                     n_exp_events = n_exp_events,
#                     HR_1 = HR_1,
#                     Plot_Power = Plot_Power,
#                     modelo = modelo,
#                     modelo_bayes_test = modelo_bayes_test,
#                     prior_type = prior_type,
#                     P_HR_data_Boundary = P_HR_data_Boundary,
#                     prior_gamma = prior_gamma,
#                     Plot_Power_scenarios = Plot_Power_scenarios,
#                     desired_HRs = desired_HRs,
#                     plot_pvalues = plot_pvalues,
#                     Plot_Control_Scenarios = Plot_Control_Scenarios,
#                     seed = seed)
# 
# wd <- createWorkbook()
# addWorksheet(wd, "Sheet1")
# writeData(wd, "Sheet1", sim5)
# saveWorkbook(wd, "weak_informative_gamma_4.2_400_3000_HR_changing.xlsx", overwrite = TRUE)
# 

sheet_names <- c("Sheet1")
weak_informative_gamma_4.2 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/Blincyto_PhALL_Tablas/weak_informative_gamma_4.2_400_3000_HR_changing.xlsx", sheet = sheet_names[1])
```


Parámetros weak informative de 6.2

```{r `Bayes: Bayes weak infor med: 6.2 HR=0.7 Power changing HRs`, eval = T}

shape_parameter <- 1

desired_HRs <- c(1.6, 1.5, 1.4, 1.3, 1.2, 1.1, 1, 0.95, 0.9, 0.85, 0.8, 0.775, 0.75, 0.725, 0.7, 0.675, 0.65, 0.625, 0.6, 0.575, 0.55, 0.525, 0.5, 0.45, 0.4, 0.35, 0.3)
control_medians <- rep(4.2, times = length(desired_HRs))

medians_control_fijo <- matrix(NA, nrow = length(desired_HRs), ncol = 2, dimnames = list(paste0("HR ", desired_HRs), c("Control", "Treatment")))

for (i in 1:length(desired_HRs)) {
  medians_control_fijo[i, "Treatment"] <- control_medians[i] / (desired_HRs[i]^(1/shape_parameter))
  medians_control_fijo[i, "Control"] <- control_medians[i]
}

sample_size <- 400
ratio <- c(2/3,1/3)
rand_type <- "CR" 
scenarios_eff <- as.matrix(medians_control_fijo, nrow = length(medians_control_fijo), ncol = 2, byrow = TRUE)
censor <- c(0.05,0.05) # 10% drop-out
Tmax <- 32 
alpha <- 0.05 
test.type <- 2
HR_1 <- FALSE
IA <- c(0.5, 0.75)
method_IA <- "OF"
n_exp_events <- 330
Plot_Power <- FALSE
plot_pvalues = FALSE 
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = FALSE

analysis = "bayes"
n_sim <- 3000
seed <- 24
# 1) Shape control, 2) rate control, 3) Shape experimental y 4) rate experimental
prior_gamma <- matrix(c(8.944709, 1, 1, 1/16), nrow = 2, ncol = 2, byrow = TRUE) 
prior_type <- c("Non informative prior") # Este vector es para que aparezca el nombre en las tablas
P_HR_data_Boundary <- 0.8 # P(HR < 0.8 | data)
modelo_weibull_sep <- rstan::stan_model("weibull_gamma_def.stan" ,verbose = F)
modelo = modelo_weibull_sep
modelo_bayes_test = "weibull"

# sim5 <-  sim_trials(n_sim = n_sim,  
#                     analysis = "bayes",
#                     sample_size = sample_size, 
#                     ratio = ratio,
#                     rand_type = rand_type,
#                     Tmax = Tmax, 
#                     scenarios_eff = scenarios_eff,
#                     shape_parameter = shape_parameter,
#                     censor = censor,
#                     test.type = test.type,
#                     alpha = alpha,
#                     method_IA = method_IA,
#                     IA = IA,
#                     n_exp_events = n_exp_events,
#                     HR_1 = HR_1,
#                     Plot_Power = Plot_Power,
#                     modelo = modelo,
#                     modelo_bayes_test = modelo_bayes_test,
#                     prior_type = prior_type,
#                     P_HR_data_Boundary = P_HR_data_Boundary,
#                     prior_gamma = prior_gamma,
#                     Plot_Power_scenarios = Plot_Power_scenarios,
#                     desired_HRs = desired_HRs,
#                     plot_pvalues = plot_pvalues,
#                     Plot_Control_Scenarios = Plot_Control_Scenarios,
#                     seed = seed)
# 
# wd <- createWorkbook()
# addWorksheet(wd, "Sheet1")
# writeData(wd, "Sheet1", sim5)
# saveWorkbook(wd, "weak_informative_gamma_6.2_400_3000_HR_changing.xlsx", overwrite = TRUE)
# 

sheet_names <- c("Sheet1")
weak_informative_gamma_6.2 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/Blincyto_PhALL_Tablas/weak_informative_gamma_6.2_400_3000_HR_changing.xlsx", sheet = sheet_names[1])
```


Ahora juntamos los datos para dibujar cada uno de los escenarios.

```{r `Simulation scenarios w fixed experimental & bayes w data 2`, eval = T, echo = T}


data_sim3_results <- sim3_results %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE))%>%
  mutate(Prior = "Frequentist")

# data_non_informative <- non_informative_gamma %>%
#   group_by(scenario) %>%
#   summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
#             mean_HR = mean(mean_HR), mean_MSE = mean(MSE))%>%
#   mutate(Prior = "Non informative")

data_weak_informative_gamma_2.2 <- weak_informative_gamma_2.2 %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE))%>%
  mutate(Prior = "Weak Informative: Median control at 2.2")


data_informative_gamma_4.2 <- informative_gamma_4.2 %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  mutate(Prior = "Informative: Median control at 4.2")

data_weak_informative_gamma_6.2 <- weak_informative_gamma_6.2 %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE))%>%
  mutate(Prior = "Weak Informative: Median control at 6.2")

data_informative_gamma_2.2 <- informative_gamma_2.2 %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  mutate(Prior = "Informative:  Median control at 2.2")

data_weak_informative_gamma_4.2 <- weak_informative_gamma_4.2 %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE))%>%
  mutate(Prior = "Weak Informative: Median control at 4.2")      

data_informative_gamma_6.2 <- informative_gamma_6.2 %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  mutate(Prior = "Informative:  Median control at 6.2")  

# 2.2
combined_data_2.2 <- bind_rows(data_sim3_results,
                               # data_non_informative, 
                               data_weak_informative_gamma_2.2, 
                               data_informative_gamma_2.2)

combined_data_2.2 <- combined_data_2.2 %>%
  group_by(Prior) %>%
  mutate(desired_HRs = (desired_HRs))

combined_data_2.2 <- combined_data_2.2 %>%
  mutate(diff_HR = abs(mean_HR - desired_HRs))

# 4.2
combined_data_4.2 <- bind_rows(data_sim3_results,
                               #data_non_informative, 
                               data_weak_informative_gamma_4.2, 
                               data_informative_gamma_4.2)


combined_data_4.2 <- combined_data_4.2 %>%
  group_by(Prior) %>%
  mutate(desired_HRs = (desired_HRs))

combined_data_4.2 <- combined_data_4.2 %>%
  mutate(diff_HR = abs(mean_HR - desired_HRs))

# 6.2

combined_data_6.2 <- bind_rows(data_sim3_results,
                               #data_non_informative, 
                               data_weak_informative_gamma_6.2, 
                               data_informative_gamma_6.2)

combined_data_6.2 <- combined_data_6.2 %>%
  group_by(Prior) %>%
  mutate(desired_HRs = (desired_HRs))

combined_data_6.2 <- combined_data_6.2 %>%
  mutate(diff_HR = abs(mean_HR - desired_HRs))

```

Dibujamos los de la mediana de 2.2

```{r `Simulation scenarios w fixed experimental & bayes w plot 2.2`, eval = T, echo = T}

p6 <- ggplot(combined_data_2.2, aes(x = desired_HRs, y = prop_significant, group = Prior, color = Prior)) +
  geom_point(size = 3) +
  geom_line(linewidth = 1) +
  geom_vline(xintercept = 1, linetype = "dashed", color = "red", size = 1) +
  geom_vline(xintercept = 0.7, linetype = "dashed", color = "red", size = 1) +
  #geom_vline(xintercept = 0.5, linetype = "dashed", color = "red", size = 1) +
  geom_hline(yintercept = c(0.8, 0.9), linetype = "dotted", color = c("purple", "green"), size = 1) +
  scale_x_continuous(breaks = seq(min(data$desired_HRs), max(data$desired_HRs), 0.1), labels = sprintf("%.2f", seq(min(data$desired_HRs), max(data$desired_HRs), 0.1))) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Power Varying Hazard Ratios with Prior Median Control at 2.2 Months",
       x = "Theoretical Hazard Ratios",
       y = "Power",
    color = "Scale Prior Distributions") +
  theme_minimal() +
  theme(plot.title = element_text(size = 9, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 9, face = "bold"),
    axis.text = element_text(size = 8),
    axis.title.x = element_text(size = 9),
    axis.title.y = element_text(size = 9),
    legend.margin = margin(12, 12, 12, 12),
    legend.text = element_text(size = 11),
    legend.title = element_text(size = 9, face = "bold"),
        legend.position = "right")

p6 <- p6 +
  annotate("text", x = max(data$desired_HRs), y = 0.8, label = "80% power", hjust = 1, vjust = -0.5, size = 3.5, color = "purple") +
  annotate("text", x = max(data$desired_HRs), y = 0.9, label = "90% power", hjust = 1, vjust = -0.5, size = 3.5, color = "green") +
  geom_label(aes(x = 1, y = Inf, label = "H0"), vjust = 2, color = "black", fill = "white", size = 3.5, label.size = 0, fontface = "bold") +
  geom_label(aes(x = 0.7, y = Inf, label = "H1"), vjust = 2, color = "black", fill = "white", size = 3.5, label.size = 0, fontface = "bold") 
# +
#   geom_label(aes(x = 0.5, y = Inf, label = "Real HR"), vjust = 2, color = "black", fill = "white", size = 3.5, label.size = 0, fontface = "bold")

# Graficamos las diferencias

p7 <- ggplot(combined_data_2.2, aes(x = desired_HRs, y = diff_HR, color = Prior)) +
  geom_point(size = 3) +
  geom_line(aes(group = Prior), linewidth = 1) +
  scale_x_continuous(breaks = seq(min(combined_data_2.2$desired_HRs), max(combined_data_2.2$desired_HRs), 0.1), labels = sprintf("%.2f", seq(min(combined_data_2.2$desired_HRs), max(combined_data_2.2$desired_HRs), 0.1))) +
  labs(title = "Diff btw Simulated HR and Theoretical HRs w prior median control = 2.2",
       x = "Theoretical Hazard Ratio",
       y = "Difference") +
  theme_minimal() +
  theme(plot.title = element_text(size = 10, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 8, face = "bold"),
        axis.text = element_text(size = 8),
        legend.position = "right")

p7
```

Dibujamos los de la mediana de 4.2

```{r `Simulation scenarios w fixed experimental & bayes w plot 5.5`, eval = T, echo = T}


p8 <- ggplot(combined_data_4.2, aes(x = desired_HRs, y = prop_significant, group = Prior, color = Prior)) +
  geom_point(size = 3) +
  geom_line(linewidth = 1) +
  geom_vline(xintercept = 1, linetype = "dashed", color = "red", size = 1) +
  geom_vline(xintercept = 0.7, linetype = "dashed", color = "red", size = 1) +
  #geom_vline(xintercept = 0.5, linetype = "dashed", color = "red", size = 1) +
  geom_hline(yintercept = c(0.8, 0.9), linetype = "dotted", color = c("purple", "green"), size = 1) +
  scale_x_continuous(breaks = seq(min(data$desired_HRs), max(data$desired_HRs), 0.1), labels = sprintf("%.2f", seq(min(data$desired_HRs), max(data$desired_HRs), 0.1))) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Power Varying Hazard Ratios with Prior Median Control at 4.2 Months",
       x = "Theoretical Hazard Ratios",
       y = "Power",
    color = "Scale Prior Distributions") +
  theme_minimal() +
  theme(plot.title = element_text(size = 9, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 9, face = "bold"),
    axis.text = element_text(size = 8),
    axis.title.x = element_text(size = 9),
    axis.title.y = element_text(size = 9),
    legend.margin = margin(12, 12, 12, 12),
    legend.text = element_text(size = 11),
    legend.title = element_text(size = 9, face = "bold"),
        legend.position = "right")

p8 <- p8 +
  annotate("text", x = max(data$desired_HRs), y = 0.8, label = "80% power", hjust = 1, vjust = -0.5, size = 3.5, color = "purple") +
  annotate("text", x = max(data$desired_HRs), y = 0.9, label = "90% power", hjust = 1, vjust = -0.5, size = 3.5, color = "green") +
  geom_label(aes(x = 1, y = Inf, label = "H0"), vjust = 2, color = "black", fill = "white", size = 3.5, label.size = 0, fontface = "bold") +
  geom_label(aes(x = 0.7, y = Inf, label = "H1"), vjust = 2, color = "black", fill = "white", size = 3.5, label.size = 0, fontface = "bold") 
# +
#   geom_label(aes(x = 0.5, y = Inf, label = "Real HR"), vjust = 2, color = "black", fill = "white", size = 3.5, label.size = 0, fontface = "bold")

# Graficamos las diferencias

p9 <- ggplot(combined_data_4.2, aes(x = desired_HRs, y = diff_HR, color = Prior)) +
  geom_point(size = 3) +
  geom_line(aes(group = Prior), linewidth = 1) +
  scale_x_continuous(breaks = seq(min(combined_data_4.2$desired_HRs), max(combined_data_4.2$desired_HRs), 0.1), labels = sprintf("%.2f", seq(min(combined_data_4.2$desired_HRs), max(combined_data_4.2$desired_HRs), 0.1))) +
  scale_y_continuous(limits = c(NA, 0.4)) + # Setting the y-axis max limit here
  labs(title = "Diff btw Simulated HR and Theoretical HRs w prior median control = 4.2",
       x = "Theoretical Hazard Ratio",
       y = "Difference") +
  theme_minimal() +
  theme(plot.title = element_text(size = 12, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 10),
        legend.position = "right")

p9

```

Dibujamos los de la mediana de 6.2

```{r `Simulation scenarios w fixed experimental & bayes w plot 6.2`, eval = T, echo = T}


p10 <- ggplot(combined_data_6.2, aes(x = desired_HRs, y = prop_significant, group = Prior, color = Prior)) +
  geom_point(size = 3) +
  geom_line(linewidth = 1) +
  geom_vline(xintercept = 1, linetype = "dashed", color = "red", size = 1) +
  geom_vline(xintercept = 0.7, linetype = "dashed", color = "red", size = 1) +
  #geom_vline(xintercept = 0.5, linetype = "dashed", color = "red", size = 1) +
  geom_hline(yintercept = c(0.8, 0.9), linetype = "dotted", color = c("purple", "green"), size = 1) +
  scale_x_continuous(breaks = seq(min(data$desired_HRs), max(data$desired_HRs), 0.1), labels = sprintf("%.2f", seq(min(data$desired_HRs), max(data$desired_HRs), 0.1))) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Power Varying Hazard Ratios with Prior Median Control at 6.2 Months",
       x = "Theoretical Hazard Ratios",
       y = "Power",
    color = "Scale Prior Distributions") +
  theme_minimal() +
  theme(plot.title = element_text(size = 9, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 9, face = "bold"),
    axis.text = element_text(size = 8),
    axis.title.x = element_text(size = 9),
    axis.title.y = element_text(size = 9),
    legend.margin = margin(12, 12, 12, 12),
    legend.text = element_text(size = 11),
    legend.title = element_text(size = 9, face = "bold"),
        legend.position = "right")

p10 <- p10 +
  annotate("text", x = max(data$desired_HRs), y = 0.8, label = "80% power", hjust = 1, vjust = -0.5, size = 3.5, color = "purple") +
  annotate("text", x = max(data$desired_HRs), y = 0.9, label = "90% power", hjust = 1, vjust = -0.5, size = 3.5, color = "green") +
  geom_label(aes(x = 1, y = Inf, label = "H0"), vjust = 2, color = "black", fill = "white", size = 3.5, label.size = 0, fontface = "bold") +
  geom_label(aes(x = 0.7, y = Inf, label = "H1"), vjust = 2, color = "black", fill = "white", size = 3.5, label.size = 0, fontface = "bold") 
# +
#   geom_label(aes(x = 0.5, y = Inf, label = "Real HR"), vjust = 2, color = "black", fill = "white", size = 3.5, label.size = 0, fontface = "bold")

p10

# Graficamos las diferencias

p11 <- ggplot(combined_data_6.2, aes(x = desired_HRs, y = diff_HR, color = Prior)) +
  geom_point(size = 3) +
  geom_line(aes(group = Prior), linewidth = 1) +
  scale_x_continuous(breaks = seq(min(combined_data_6.2$desired_HRs), max(combined_data_6.2$desired_HRs), 0.1), labels = sprintf("%.2f", seq(min(combined_data_6.2$desired_HRs), max(combined_data_6.2$desired_HRs), 0.1))) +
  labs(title = "Diff btw Simulated HR and Theoretical HRs w prior median control = 6.2",
       x = "Theoretical Hazard Ratio",
       y = "Difference") +
  theme_minimal() +
  theme(plot.title = element_text(size = 12, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 10),
        legend.position = "right")

p11
```


```{r Changing_HRs_combined_all, eval = T}

library(cowplot)

p66 <- p6 + scale_color_discrete(
  name = "Bayesian Prior Distributions:", 
  labels = c(
    "Frequentist",
    "Informative Prior",
    "Weak Informative Prior"
  )
) +
  guides(color = guide_legend(ncol = 4))  

legend <- get_legend(
  p66 +
    theme(
      # legend.box = "horizontal", 
      legend.justification = c(0, 1),
      # legend.margin = margin(8, 8, 8, 8),
      legend.text = element_text(size = 10), 
      legend.title = element_text(size = 11, face = "bold")
    )
)

# Remove individual legends from the plots
p66 <- p66 + theme(legend.position = "none")
p88 <- p8 + theme(legend.position = "none")
p100 <- p10 + theme(legend.position = "none")

p66 <- p66 + theme(plot.background = element_rect(colour = "black", size = 0.5, fill = NA))
p88 <- p88 + theme(plot.background = element_rect(colour = "black", size = 0.5, fill = NA))
p100 <- p100 + theme(plot.background = element_rect(colour = "black", size = 0.5, fill = NA))

plots_row <- plot_grid(p66, p88, p100, ncol = 3, labels = c("A", "B", "C"), label_size = 13)

combined_plot <- plot_grid(
  plots_row,
  legend,
  ncol = 1,                 
  rel_heights = c(3, 0.4)   
)

print(combined_plot)


```


# Incorporación de información externa para el brazo control de otros estudios.

Según la descripción hecha para elegir el brazo control hecho por la compañía, se van a tener en cuenta 2 publicaciones de ensayos:

1) O´Brien et al, 2008: median OS de 3 meses en 288 pacientes después del 2º salvage.

2) Kantarjian et al, 2010: median OS de 4,7 meses en 245 pacientes después del primer salvage con un CR1 duración menor de 1 año.

Para el MAP vamos a tener en cuenta la dos publicaciones. Para el Power Prior donde hay que elegir sólo un ensayo para incorporarlo en la función de verosimilitud, se va a elegir el 2 al ser el más cercano a lo que asumió la Cy en el SAP y el más reciente.


Como brazo control usand el best standard of care (BSC), entre los que se encuentran 4 regimenes diferentes a elección del investigador (pg 35 del primary CSR). La disposición final del análisis primario para el brazo SOC es la siguiente:

FLAG ± anthracycline -> 56 pacientes (41.8%)
High-dose methotrexate -> 30 pacientes (22.4%)
Clofarabine -> 29 pacientes (19.4%)
HIDAC -> 22 pacientes (16.4%)

Aquí he usado la digitalización de las curvas KM para obtener un dataset con datos pseudo-IPD

1) O´Brien et al, 2008: Salvage study, median OS of 3 months.

```{r `O´Brien et al, 2008: Salvage study, median OS of 3 months` , eval = T}

data_hist1 <- read.csv("IPD_Externo_1.csv")

fit_hist1 <- coxph(Surv(Survival.time, Status) ~ 1, data = data_hist1)

fit_soc_1 <- survfit(Surv(Survival.time, Status) ~ 1, data = data_hist1)

# Regresión de Weibull para sacar los parametros de interes
weibull_soc_1 <- survreg(Surv(Survival.time, Status) ~ 1, dist = "weibull", data = data_hist1)

time_seq <- seq(min(data_hist1$Survival.time), max(data_hist1$Survival.time), length.out = 100)

# P de supervivencia usando el modelo Weibull
weibull_soc_1_surv <- 1 - pweibull(time_seq, shape = 1/weibull_soc_1$scale, scale = exp(weibull_soc_1$coefficients))

# Comparamos
plot(fit_soc_1, col = "blue", main = "Kaplan-Meier Plot with Weibull Fits", xlab = "Time", ylab = "Survival Probability", lty = 1, conf.int = FALSE)
lines(time_seq, weibull_soc_1_surv, col = "green", lty = 2)

# Vemos que modelos se ajustan mejor
weibull_mod <- flexsurvreg(Surv(Survival.time, Status) ~ 1, data = data_hist1, dist = "weibull")
exp_mod <- flexsurvreg(Surv(Survival.time, Status) ~ 1, data = data_hist1, dist = "exp")
gompertz_mod <- flexsurvreg(Surv(Survival.time, Status) ~ 1, data = data_hist1, dist = "gompertz")
lognormal_mod <- flexsurvreg(Surv(Survival.time, Status) ~ 1, data = data_hist1, dist = "lnorm")

# Compare models
model_list <- list(Weibull = weibull_mod, Exponential = exp_mod, Gompertz = gompertz_mod, LogNormal = lognormal_mod)
#sapply(model_list, AIC)


```

2) Kantarjian et al, 2010: median OS de 4,7 meses en 245 pacientes después del primer salvage con un CR1 duración menor de 1 año.

```{r `2) Kantarjian et al, 2010: median OS de 4,7 meses` , eval = T}

data_hist2 <- read.csv("IPD_Externo_2_bueno.csv")

fit_hist2 <- coxph(Surv(Survival.time, Status) ~ 1, data = data_hist2)

fit_soc_2 <- survfit(Surv(Survival.time, Status) ~ 1, data = data_hist2)

# Regresión de Weibull para sacar los parametros de interes
weibull_soc_2 <- survreg(Surv(Survival.time, Status) ~ 1, dist = "weibull", data = data_hist2)

time_seq <- seq(min(data_hist2$Survival.time), max(data_hist2$Survival.time), length.out = 100)

# P de supervivencia usando el modelo Weibull
weibull_soc_2_surv <- 1 - pweibull(time_seq, shape = 1/weibull_soc_2$scale, scale = exp(weibull_soc_2$coefficients))

# Comparamos
plot(fit_soc_2, col = "blue", main = "Kaplan-Meier Plot with Weibull Fits", xlab = "Time", ylab = "Survival Probability", lty = 1, conf.int = FALSE)
lines(time_seq, weibull_soc_2_surv, col = "green", lty = 2)

# Vemos que modelos se ajustan mejor
weibull_mod <- flexsurvreg(Surv(Survival.time, Status) ~ 1, data = data_hist2, dist = "weibull")
exp_mod <- flexsurvreg(Surv(Survival.time, Status) ~ 1, data = data_hist2, dist = "exp")
gompertz_mod <- flexsurvreg(Surv(Survival.time, Status) ~ 1, data = data_hist2, dist = "gompertz")
lognormal_mod <- flexsurvreg(Surv(Survival.time, Status) ~ 1, data = data_hist2, dist = "lnorm")

# Compare models
model_list <- list(Weibull = weibull_mod, Exponential = exp_mod, Gompertz = gompertz_mod, LogNormal = lognormal_mod)
#sapply(model_list, AIC)


```


# Análisis Bayesiano incorporando información externa

El primer método que se va a considerar es el MAP donde incorpora en la Prior información top-level externa para el brazo control.

Primer paper de referencia es "Robust Meta-Analytic-Predictive Priors in Clinical Trials with
Historical Control Information". Aquí discuten el uso de una mezcla entre MAP y no informativo o weak en caso de que haya un conflicto entre los datos del control con el histórico. 

Al tener varios estudios históricos se van a hacer los siguientes modelos:
  
1) MAP -> Varios ensayos históricos
2) Conjugate MAP w weak prior info -> Varios ensayos históricos. (Pesos desde 0.1 hasta 0.5 para la parte informativa)
3) Conjugate MAP w weak prior info -> Varios ensayos históricos. (Peso como variable aleatoria) -> NO DE MOMENTO

A continuación se va a seguir un procedimiento para la incorporación de información externa a través de la pre-especificación de una prior con parámetros sacados de un meta-análisis (MAP).

Hay muchas maneras de hacer esto pero vamos a centrarnos en la siguiente metodología:
  
1- Obtener la información externa para el brazo control: Me he centrado principalmente en coger los ensayos especificados por el promotor para justificar la asunción para el tamaño muestral del brazo control.

2- Obtener los parámetros para la dist exponencial/weibull de los ensayos históricos: Al ser datos de supervivencia (con binario no existe este problema), es necesario tener los datos paciente a paciente para poder sacar los valores de la distribución paramétrica que consideremos, ya sea exponencial/weibull. Al no ser posible, se digitalizan las curvas para poder hacer esta regresión paramétrica.

3- Una vez tengamos estos valores de la regresión paramétrica, lambda para la exponencial, y lambda y shape para la weibull, en todos los ensayos históricos, vamos a realizar el meta-análisis.

4- El meta-análisis aquí se va a considerar de dos maneras, frecuentista y Bayesiano. Para el enfoque frecuentista se va a utilizar el paquete ampliamente usado "metafor" y para el Bayesiano el "brms". Se van a comparar los dos en este informe y ya vemos si usamos uno, otro o los dos.

5- El MAP se va a hacer para la propuesta de una prior usando sólo 1 ensayo clínico y varios.

6- Una vez tengamos la media y SD del MAP, se transformarán estos valores en términos de la distribución Gamma para el modelo STAN.

# Meta-Analytic Prior

1) MAP -> Varios ensayos históricos

A continuación se muestra el resultado del meta-análisis desde un punto de vista frecuentista utilizando los resultados globales de los estudios anteriormente descritos. 


```{r MAP_Multiple_Historical_Data , eval = T, fig.width=12, fig.height=8}

# Ensayo Externo 1

soc_externo_1 <- survreg(Surv(Survival.time, Status) ~ 1, dist = "exponential", data = data_hist1)

n_soc_externo_1 <- dim(data_hist1)[1]
scale_soc_externo_1 <- exp(soc_externo_1$coefficients[1])
se_soc_externo_1 <- sqrt(vcov(soc_externo_1)[1])


# Ensayo Externo 2 

soc_externo_2 <- survreg(Surv(Survival.time, Status) ~ 1, dist = "exponential", data = data_hist2)

n_soc_externo_2 <- dim(data_hist2)[1]
scale_soc_externo_2 <- exp(soc_externo_2$coefficients[1])
se_soc_externo_2 <- sqrt(vcov(soc_externo_2)[1])


# Juntamos los datos

df <- data.frame(
  study = c('O´Brien et al, (2008)', 'Kantarjian et al, (2010)'),
  year = c(2008, 2010),
  ni = c(n_soc_externo_1, n_soc_externo_2),
  yi = c(scale_soc_externo_1, scale_soc_externo_2),
  vi = c(se_soc_externo_1^2, se_soc_externo_2^2),
  sei = c(se_soc_externo_1, se_soc_externo_2)
)


map_meta <- metagen(TE = df$yi, seTE = df$sei, studlab = df$study, data = df, prediction = TRUE, method.tau = "PM",test = "knha")           



```

A continuación se muestra el resultado del meta-análisis desde un punto de vista Bayesiano utilizando los resultados globales de los estudios anteriormente descritos. 

```{r MAP_Multiple_Historical_Data_Bayes , eval = T, echo = F}

#https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/bayesian-ma.html

# Estas priors son muy comunes para los meta-análisis

df <- data.frame(
  study = c('O´Brien et al, (2008)', 'Kantarjian et al, (2010)'),
  year = c(2008, 2010),
  ni = c(n_soc_externo_1, n_soc_externo_2),
  yi = c(scale_soc_externo_1, scale_soc_externo_2),
  vi = c(se_soc_externo_1^2, se_soc_externo_2^2),
  sei = c(se_soc_externo_1, se_soc_externo_2)
)

priors <- c(prior(normal(0,1), class = Intercept),
            prior(cauchy(0,0.5), class = sd))

brm_out <- brm( yi | se(sei) ~ 1 + (1 | study),
                data = df,
                prior = priors,
                iter = 4000)

out_f <- spread_draws(brm_out, b_Intercept) %>% 
  mutate(study = "Average")

out_r <- spread_draws(brm_out, r_study[study,term], b_Intercept) %>% 
  mutate(b_Intercept = r_study + b_Intercept)

avg_effects <- out_r %>% group_by(.iteration) %>% summarise(avg_r_study = mean(r_study, na.rm = TRUE))

out_f <- out_f %>%
  left_join(avg_effects, by = ".iteration") %>%
  mutate(b_Intercept = b_Intercept + avg_r_study)

out_all <- bind_rows(out_r, out_f) %>% 
  ungroup() %>%
  mutate(study = fct_relevel(study, "Average"),
         study = str_replace_all(study, "\\.", " "))

out_all_sum <- group_by(out_all, study) %>% 
  mean_qi(b_Intercept)

out_all %>%   
  ggplot(aes(b_Intercept, study)) +
  geom_vline(xintercept = 6.5, size = .25, lty = 2) +
  stat_halfeye(.width = c(.8, .95), fill = "dodgerblue") +
  geom_text(
    data = mutate_if(out_all_sum, is.numeric, round, 2),
    aes(label = str_glue("{b_Intercept} [{.lower}, {.upper}]"), x = 4.1),  
    hjust = "inward"
  ) +
  geom_point(
    data = df %>% mutate(study = str_replace_all(study, "\\.", " ")), 
    aes(x=yi), position = position_nudge(y = -.05), shape = 1
  ) +
  coord_cartesian(xlim = c(0, 13)) +
  scale_y_discrete(name = "External Control Studies") +
  theme(
    panel.background = element_rect(fill = "white")
)

```

Ahora vamos a extraer los parámetros para especificar nuestras prior informativas basado en los MAPs.

```{r MAP_Multiple_Historical_Data_Bayes_Freq , eval = T}

# MAP Frecuentista

# Esto cuanta con toda la variabilidad, intra y externa


yi <- map_meta$TE
vi <- map_meta$seTE^2 
tau2 <- map_meta$tau2  
mu <- map_meta$TE.random  

# Los efectos estimados para cada estudio
#Borenstein, M., Hedges, L. V., Higgins, J. P. T., & Rothstein, H. R. (2009). Introduction to Meta-Analysis. John Wiley & Sons.
theta_hat <- (1/vi + 1/tau2)^(-1) * (yi/vi + mu/tau2)

# Cuantificamos la variabilidad:
frequentist_sd <- sd(theta_hat)

# Esto calcula solo tau^2 que calcula la heterogeneidad entre estudios pero no cuenta con la intra
# mean_estimate <- map_meta$TE.random
# CI_lower <- map_meta$lower.random
# CI_upper <- map_meta$upper.random
# 
# SE <- (CI_upper - CI_lower) / (2 * 1.96)
#SE <- SE*3

# # Gamma parameters
alpha_map_freq <- (mu/frequentist_sd)^2
beta_map_freq  <- mu/frequentist_sd^2
# 
# ## MAP Bayesiano ##
# 
# post_samples <- brms::posterior_samples(brm_out)
# 
# fixed_effects <- post_samples$b_Intercept
# 
# #colnames(post_samples)[grep("r_study", colnames(post_samples))]
# 
# random_effects <- post_samples[, grep("r_study", colnames(post_samples))]
# 
# combined_effects <- sweep(as.matrix(random_effects), 2, fixed_effects, `+`)
# 
# true_avg_effect <- apply(combined_effects, 1, mean)
# 
# combined_mean <- mean(true_avg_effect)
# combined_sd <- sd(true_avg_effect)
# 
# # Gamma
# 
# alpha_map_bayes <- (combined_mean/combined_sd)^2
# beta_map_bayes <- combined_mean / combined_sd^2

parameters_gamma <- data.frame(shape = c(1, 6.059319, 605.9319, alpha_map_freq),
                               rate = c( 1/16, 1, 100, beta_map_freq),
                               label = c("Non-informative: Gamma(1, 1/16)", "Weak: Gamma(6.059319, 1)", "Informative: Gamma(605.9319, 100)", "MAP freq"))


gamma_density <- function(shape, rate, label) {
  data.frame(x = seq(0, 35, length.out = 100)) %>%
    mutate(density = dgamma(x, shape = shape, rate = rate),
           parameter = label)
}

densities <- purrr::pmap_df(parameters_gamma, gamma_density)

ggplot(densities, aes(x, density, color = parameter)) +
  geom_line() +
  labs(title = "Gamma Prior Distributions",
       x = "Median control in months",
       y = "Density") +
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 14, face = "bold"),
        axis.text = element_text(size = 12))

```


```{r `Gamma priors Tesis`, eval = T}


parameters_gamma <- data.frame(
  shape = c(1, 6.059319, 317.3929, 605.9319, 894.4709, 3.173929, 8.944709, alpha_map_freq),
  rate = c(1/16, 1, 100, 100, 100, 1, 1, beta_map_freq),
  label = factor(
    c(
      "Non-informative Prior", 
      "Weak Informative Prior centered at 4.2 months", 
      "Informative Prior centered at 2.2 months", 
      "Informative Prior centered at 4.2 months", 
      "Informative Prior centered at 6.2 months", 
      "Weak Informative Prior centered at 2.2 months", 
      "Weak Informative Prior centered at 6.2 months", 
      "Frequentist Meta-Analysis"
    ),
    levels = c(
      "Non-informative Prior", 
      "Weak Informative Prior centered at 4.2 months", 
      "Informative Prior centered at 2.2 months", 
      "Informative Prior centered at 4.2 months", 
      "Informative Prior centered at 6.2 months", 
      "Weak Informative Prior centered at 2.2 months", 
      "Weak Informative Prior centered at 6.2 months", 
      "Frequentist Meta-Analysis"
    )
  )
)

gamma_density <- function(shape, rate, label) {
  data.frame(x = seq(0, 32, length.out = 1000)) %>%
    mutate(density = dgamma(x, shape = shape, rate = rate),
           parameter = label)
}

densities <- purrr::pmap_df(parameters_gamma, gamma_density)

ggplot(densities, aes(x, density, color = parameter, linetype = parameter)) +
  geom_line(size = 1.2) +
  scale_color_manual(
    values = c(
      "Non-informative Prior" = "blue",
      "Weak Informative Prior centered at 4.2 months" = "orange",
      "Informative Prior centered at 4.2 months" = "green",
      "Informative Prior centered at 2.2 months" = "purple",
      "Informative Prior centered at 6.2 months" = "red",
      "Weak Informative Prior centered at 2.2 months" = "brown",
      "Weak Informative Prior centered at 6.2 months" = "deeppink2",
      "Frequentist Meta-Analysis" = "black"
    )
  ) +
  scale_linetype_manual(
    values = c(
      "Non-informative Prior" = "solid",
      "Weak Informative Prior centered at 4.2 months" = "solid",
      "Informative Prior centered at 4.2 months" = "solid",
      "Informative Prior centered at 2.2 months" = "dotted",
      "Informative Prior centered at 6.2 months" = "dotted",
      "Weak Informative Prior centered at 2.2 months" = "dotdash",
      "Weak Informative Prior centered at 6.2 months" = "dotdash",
      "Frequentist Meta-Analysis" = "dashed"
    )
  ) +
  labs(
    title = "Gamma Prior Distributions",
    x = "Scale Parameter for the Control Arm",
    y = "Density",
    color = "Scale Prior Distributions",
    linetype = "Scale Prior Distributions"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 10, face = "bold"),
    axis.text = element_text(size = 12),
    axis.title.x = element_text(size = 12),
    axis.title.y = element_text(size = 12),
    legend.margin = margin(12, 12, 12, 12),
    legend.text = element_text(size = 11),
    legend.title = element_text(size = 12, face = "bold")
  )


```

Al ver la forma de la prior informativa usando tanto el MAP frecuentista como el MAP Bayesiano, he decidido seguir sólo con el MAP Bayesiano ya que es el menos informativo comparado con el frecuentista.

Características Operantes del MAP Frecuentista:
  
```{r `Bayes: Bayesiano MAP_CO1`, eval = T}

shape_parameter <- 1 

control_medians <- c(2,2.25,2.5,2.75,3,3.25,3.5,3.75,4,4.2,4.25,4.5,4.75,5,5.25,5.5,5.75,6,6.25,6.5,6.75,7,7.25,7.5,7.75,8,8.25,8.5,8.75,9)

medians <- matrix(NA, nrow = length(control_medians), ncol = 3, 
                  dimnames = list(NULL, c("Control", "Treatment", "Hazard Ratio")))

desired_HR = 0.7

for (i in 1:length(control_medians)) {
  medians[i, "Control"] <- control_medians[i]
  
  lambda_control = control_medians[i] / (log(2)^(1/shape_parameter))
  lambda_treatment = lambda_control / desired_HR^(1/shape_parameter)
  
  medians[i, "Treatment"] = lambda_treatment * (log(2)^(1/shape_parameter))
  medians[i, "Hazard Ratio"] = (lambda_control / lambda_treatment)^shape_parameter
}

medians <- medians[,1:2]
sample_size <- 400
ratio <- c(2/3,1/3)
rand_type <- "CR" 
scenarios_eff <- as.matrix(medians, nrow = length(control_medians), ncol = 2, byrow = TRUE)
censor <- c(0.05,0.05) # 10% drop-out
Tmax <- 32 # Aquí tengo dudas, muy pocos pacientes llegan al final pero parece que es lo que pone en el SAP
alpha <- 0.05 
test.type <- 2
HR_1 <- TRUE
IA <- c(0.5, 0.75)
method_IA <- "OF"
n_exp_events <- 330
Plot_Power <- FALSE
plot_pvalues = FALSE 
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = TRUE
Dynamic_Borrowing_PP = FALSE

analysis = "bayes"
n_sim <- 3000
seed <- 24
# 1) Shape control, 2) rate control, 3) Shape experimental y 4) rate experimental
prior_gamma <- matrix(c(alpha_map_freq, beta_map_freq, 1, 1/16), nrow = 2, ncol = 2, byrow = TRUE) 
prior_type <- c("MAP") # Este vector es para que aparezca el nombre en las tablas
P_HR_data_Boundary <- 0.8 # P(HR < 0.8 | data)
modelo_weibull_sep <- rstan::stan_model("weibull_gamma_def.stan" ,verbose = F)
modelo = modelo_weibull_sep
modelo_bayes_test = "weibull"
w = NULL
a0 = NULL
# 
# sim11 <-  sim_trials(n_sim = n_sim,
#                     analysis = "bayes",
#                     sample_size = sample_size,
#                     ratio = ratio,
#                     rand_type = rand_type,
#                     Tmax = Tmax,
#                     scenarios_eff = scenarios_eff,
#                     shape_parameter = shape_parameter,
#                     censor = censor,
#                     test.type = test.type,
#                     alpha = alpha,
#                     method_IA = method_IA,
#                     IA = IA,
#                     n_exp_events = n_exp_events,
#                     HR_1 = HR_1,
#                     Plot_Power = Plot_Power,
#                     modelo = modelo,
#                     modelo_bayes_test = modelo_bayes_test,
#                     prior_type = prior_type,
#                     P_HR_data_Boundary = P_HR_data_Boundary,
#                     prior_gamma = prior_gamma,
#                     Plot_Power_scenarios = Plot_Power_scenarios,
#                     desired_HRs = desired_HRs,
#                     plot_pvalues = plot_pvalues,
#                     Plot_Control_Scenarios = Plot_Control_Scenarios,
#                     Dynamic_Borrowing_PP = Dynamic_Borrowing_PP,
#                     w = w,
#                     a0 = a0,
#                     seed = seed)
# sim11[[2]]
# sim11[[3]]
# sim11[[4]]
# 
# sim110 <- sim11[[1]]
# 
# wd <- createWorkbook()
# addWorksheet(wd, "Sheet1")
# writeData(wd, "Sheet1", sim110)
# saveWorkbook(wd, "MAP_Freq_400_3000_HR_07.xlsx", overwrite = TRUE)


sheet_names <- c("Sheet1")
MAP <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/Blincyto_PhALL_Tablas/MAP_Freq_400_3000_HR_07.xlsx", sheet = sheet_names[1])

```


```{r `Data gathering2 `, eval = T}


# MAP
data_MAP <- MAP %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "MAP")

data_filtered_diff_not_zero_MAP <- data_MAP %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_MAP <- data_MAP %>%
  filter(median_control == median_treatment)


combined_data_diff_not_zero <- bind_rows(data_filtered_diff_not_zero_frequentist,
                                         data_filtered_diff_not_zero_non_informative, 
                                         data_filtered_diff_not_zero_informative, 
                                         data_filtered_diff_not_zero_mid_informative,
                                         data_filtered_diff_not_zero_MAP)

combined_data_diff_not_zero$Prior <- factor(
  combined_data_diff_not_zero$Prior,
  levels = c(
    "Frequentist",
     "Strongly Informative",
     "Non-informative",
    "Weakly informative",
    "MAP"
  )
)

combined_data_diff_zero <- bind_rows(data_filtered_diff_zero_frequentist,
                                     data_filtered_diff_zero_non_informative, 
                                     data_filtered_diff_zero_informative, 
                                     data_filtered_diff_zero_mid_informative,
                                     data_filtered_diff_zero_MAP)

combined_data_diff_zero$Prior <- factor(
  combined_data_diff_not_zero$Prior,
  levels = c(
    "Frequentist",
     "Strongly Informative",
     "Non-informative",
    "Weakly informative",
    "MAP"
  )
)

```


En el gráfico de MSE vemos que el MAP frecuentista funciona muy bien en escenarios donde la mediana control está cerca de 4.5 pero el rendimiento va empeorando según se aleja, tiene un rendimiento parecido a la muy informativa (no tan bueno en valores centrales de su densidad porque no es tan informativa). Por otro lado, el MAP bayesiano tiene un mejor rendimiento a lo largo de todos los valores de la mediana, estando por debajo incluso de la weak, frecuentista, etc.

```{r MSE_w_MAP, eval = T}

p6 <- ggplot(combined_data_diff_not_zero, aes(x = median_control, y = mean_MSE, color = Prior)) + 
  geom_line(size = 1.2) +
  geom_vline(xintercept = median_control_center, linetype = "solid") +
  labs(
    title = "Mean Square Error (MSE)",
    x = "Median Control Arm (in months)",
    y = "Mean MSE",
    color = "Bayesian Prior Distributions"
  ) +
  theme_minimal() + 
  theme(
    plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 10, face = "bold"),
    axis.text = element_text(size = 12),
    axis.title.x = element_text(size = 11),
    axis.title.y = element_text(size = 11),
    legend.margin = margin(9, 9, 9, 9),
    legend.text = element_text(size = 9),
    legend.title = element_text(size = 10, face = "bold")
  ) +
  scale_color_discrete(name = "Bayesian Prior Distributions") +
  scale_x_continuous(breaks = seq(min(combined_data_diff_not_zero$median_control), max(combined_data_diff_not_zero$median_control), by = 0.5)) +
  scale_y_continuous(limits = c(0, 0.075))

p6

```

Con respecto al poder, al ser un tamaño muestral muy alto para lo que se necesita es difícil distinguirlo. Aún así, se ven que los dos métodos tienen bastante poder.

```{r Power_w_MAP, eval = T}

p7 <- ggplot(combined_data_diff_not_zero, aes(x = median_control, y = prop_significant, color = Prior)) +
  geom_line(size = 1.2) + 
  geom_line() +
  geom_vline(xintercept = median_control_center, linetype = "dashed") +
  labs(title = "Power", x = "Median Control Arm (in months)", y = "Proportion of Significant Trials", color = "Bayesian Prior Distributions") +
  theme_minimal() + 
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 12),
        axis.title.x = element_text(size = 11),
        axis.title.y = element_text(size = 11),
        legend.margin = margin(12, 12, 12, 12),
        legend.text = element_text(size = 11),
        legend.title = element_text(size = 12, face = "bold")) +
  scale_color_discrete(name = "Bayesian Prior Distributions") +
  scale_linetype_discrete(name = "Bayesian Prior Distributions") +
  scale_x_continuous(breaks = seq(min(combined_data_diff_not_zero$median_control), max(combined_data_diff_not_zero$median_control), by = 0.5)) +
  scale_y_continuous(limits = c(0.5, 1))
p7

```

Por último, el error de Tipo I: El MAP frecuentista se dispara según se aleja de 4.5 (media aproximada), podemos ver que tiene un peor comportamiento que la muy informativa. Coger alguna de las dos es como la lotería, si aciertas te llevas el premio gordo pero si no, el ET1 se dispara. Por eso es más importante ser conservador.

Por otro lado, el MAP Bayes infla el ET1 en valores superiores a 6. Aún así, no se dispara mucho y con un poco de ajuste podemos controlar este error mientras que guardamos el buen rendimiento de este modelo.

```{r T1E_w_MAP, eval = T}

p8 <- ggplot(combined_data_diff_zero, aes(x = median_control, y = prop_significant, color = Prior)) +
  geom_line(size = 1.2) + 
  geom_line() +
  geom_vline(xintercept = median_control_center, linetype = "dashed") +
  geom_hline(yintercept = 0.025, linetype = "dashed", color = "green") +
  geom_hline(yintercept = 0.05, linetype = "dashed", color = "purple") +
  labs(title = "Type I Error (T1E)", x = "Median Control (in months)", y = "Proportion of Significant Trials", color = "Bayesian Prior Distributions") +
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 12),
        axis.title.x = element_text(size = 11),
        axis.title.y = element_text(size = 11),
        legend.margin = margin(12, 12, 12, 12),
        legend.text = element_text(size = 11),
        legend.title = element_text(size = 12, face = "bold")) +
  scale_color_discrete(name = "Bayesian Prior Distributions") +
  scale_linetype_discrete(name = "Bayesian Prior Distributions") +
  scale_x_continuous(breaks = seq(min(combined_data_diff_zero$median_control), max(combined_data_diff_zero$median_control), by = 0.5)) +
  scale_y_continuous(limits = c(0, 0.2))
p8

```

```{r T1E_combined_all, eval = T}

library(cowplot)

p66 <- p6 + scale_color_discrete(
  name = "Bayesian Prior Distributions", 
  labels = c(
        "Frequentist",
         "Informative Prior\ncentered at 4.2 months",
    "Non-informative Prior",
    "Weak Informative Prior\ncentered at 4.2 months",
        "Frequentist\nMeta-Analysis Prior",
    "Frequentist\nMeta-Analysis Prior"

  )
) +
  guides(color = guide_legend(ncol = 6))  

legend <- get_legend(
  p66 +
    theme(
      # legend.box = "horizontal", 
      legend.justification = c(0, 1),
      # legend.margin = margin(8, 8, 8, 8),
      legend.text = element_text(size = 10), 
      legend.title = element_text(size = 11, face = "bold")
    )
)

# Remove individual legends from the plots
p66 <- p66 + theme(legend.position = "none")
p77 <- p7 + theme(legend.position = "none")
p88 <- p8 + theme(legend.position = "none")

p66 <- p66 + theme(plot.background = element_rect(colour = "black", size = 0.5, fill = NA))
p77 <- p77 + theme(plot.background = element_rect(colour = "black", size = 0.5, fill = NA))
p88 <- p88 + theme(plot.background = element_rect(colour = "black", size = 0.5, fill = NA))

plots_row <- plot_grid(p66, p77, p88, ncol = 3, labels = c("A", "B", "C"), label_size = 14)

combined_plot <- plot_grid(
  plots_row,
  legend,
  ncol = 1,                 
  rel_heights = c(3, 0.4)   
)

print(combined_plot)

```

Ahora evaluamos los diferentes HRs para el MAP

```{r ` MAP Bayes Power changing HRs`, eval = T}

shape_parameter <- 1

desired_HRs <- c(1.6, 1.5, 1.4, 1.3, 1.2, 1.1, 1, 0.95, 0.9, 0.85, 0.8, 0.775, 0.75, 0.725, 0.7, 0.675, 0.65, 0.625, 0.6, 0.575, 0.55, 0.525, 0.5, 0.45, 0.4, 0.35, 0.3)
control_medians <- rep(4.2, times = length(desired_HRs))

medians_control_fijo <- matrix(NA, nrow = length(desired_HRs), ncol = 2, dimnames = list(paste0("HR ", desired_HRs), c("Control", "Treatment")))

for (i in 1:length(desired_HRs)) {
  medians_control_fijo[i, "Treatment"] <- control_medians[i] / (desired_HRs[i]^(1/shape_parameter))
  medians_control_fijo[i, "Control"] <- control_medians[i]
}


sample_size <- 400
ratio <- c(2/3,1/3)
rand_type <- "CR" 
scenarios_eff <- as.matrix(medians_control_fijo, nrow = length(medians_control_fijo), ncol = 2, byrow = TRUE)
censor <- c(0.05,0.05) # 10% drop-out
Tmax <- 32 
alpha <- 0.05 
test.type <- 2
HR_1 <- FALSE
IA <- c(0.5, 0.75)
method_IA <- "OF"
n_exp_events <- 330
Plot_Power <- FALSE
plot_pvalues = FALSE 
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = FALSE
Dynamic_Borrowing_PP = FALSE

analysis = "bayes"
n_sim <- 3000
seed <- 24
# 1) Shape control, 2) rate control, 3) Shape experimental y 4) rate experimental
prior_gamma <- matrix(c(alpha_map_freq, beta_map_freq, 1, 1/16), nrow = 2, ncol = 2, byrow = TRUE) 
prior_type <- c("MAP") # Este vector es para que aparezca el nombre en las tablas
P_HR_data_Boundary <- 0.8 # P(HR < 0.8 | data)
modelo_weibull_sep <- rstan::stan_model("weibull_gamma_def.stan" ,verbose = F)
modelo = modelo_weibull_sep
modelo_bayes_test = "weibull"
w = NULL
a0 = NULL

# sim12 <-  sim_trials(n_sim = n_sim,
#                     analysis = "bayes",
#                     sample_size = sample_size,
#                     ratio = ratio,
#                     rand_type = rand_type,
#                     Tmax = Tmax,
#                     scenarios_eff = scenarios_eff,
#                     shape_parameter = shape_parameter,
#                     censor = censor,
#                     test.type = test.type,
#                     alpha = alpha,
#                     method_IA = method_IA,
#                     IA = IA,
#                     n_exp_events = n_exp_events,
#                     HR_1 = HR_1,
#                     Plot_Power = Plot_Power,
#                     modelo = modelo,
#                     modelo_bayes_test = modelo_bayes_test,
#                     prior_type = prior_type,
#                     P_HR_data_Boundary = P_HR_data_Boundary,
#                     prior_gamma = prior_gamma,
#                     Plot_Power_scenarios = Plot_Power_scenarios,
#                     desired_HRs = desired_HRs,
#                     plot_pvalues = plot_pvalues,
#                     Plot_Control_Scenarios = Plot_Control_Scenarios,
#                     Dynamic_Borrowing_PP = Dynamic_Borrowing_PP,
#                     w = w,
#                     a0 = a0,
#                     seed = seed)
# 
# wd <- createWorkbook()
# addWorksheet(wd, "Sheet1")
# writeData(wd, "Sheet1", sim12)
# saveWorkbook(wd, "MAP_Freq_400_3000_HR_changing.xlsx", overwrite = TRUE)

sheet_names <- c("Sheet1")
MAP_freq_HRs <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/Blincyto_PhALL_Tablas/MAP_Freq_400_3000_HR_changing.xlsx", sheet = sheet_names[1])

```



```{r `Data combined MAPs`, eval = T}

data_sim3_results <- sim3_results %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE))%>%
  mutate(Prior = "Frequentist")

data_weak_informative_gamma_2.2 <- weak_informative_gamma_2.2 %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE))%>%
  mutate(Prior = "Weak Informative: Median control at 2.2")

data_informative_gamma_2.2 <- informative_gamma_2.2 %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  mutate(Prior = "Informative: Median control at 2.2")

data_weak_informative_gamma_4.2 <- weak_informative_gamma_4.2 %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE))%>%
  mutate(Prior = "Weak Informative: Median control at 4.2")

data_informative_gamma_4.2 <- informative_gamma_4.2 %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  mutate(Prior = "Informative:  Median control at 4.2")

data_weak_informative_gamma_6.2 <- weak_informative_gamma_6.2 %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE))%>%
  mutate(Prior = "Weak Informative: Median control at 6.2")      

data_informative_gamma_6.2 <- informative_gamma_6.2 %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  mutate(Prior = "Informative:  Median control at 6.2")  

# MAP

data_MAP_freq_HRs <- MAP_freq_HRs %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) +                                          sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  mutate(Prior = "MAP")   

# 2.2
combined_data_2.2 <- bind_rows(data_sim3_results,
                               data_weak_informative_gamma_2.2, 
                               data_informative_gamma_2.2,
                               data_MAP_freq_HRs)

combined_data_2.2 <- combined_data_2.2 %>%
  group_by(Prior) %>%
  mutate(desired_HRs = (desired_HRs))

combined_data_2.2 <- combined_data_2.2 %>%
  mutate(diff_HR = abs(mean_HR - desired_HRs))

# 4.2
combined_data_4.2 <- bind_rows(data_sim3_results,
                               data_weak_informative_gamma_4.2, 
                               data_informative_gamma_4.2,
                               data_MAP_freq_HRs)


combined_data_4.2 <- combined_data_4.2 %>%
  group_by(Prior) %>%
  mutate(desired_HRs = (desired_HRs))

combined_data_4.2 <- combined_data_4.2 %>%
  mutate(diff_HR = abs(mean_HR - desired_HRs))

# 6.2

combined_data_6.2 <- bind_rows(data_sim3_results,
                               data_weak_informative_gamma_6.2, 
                               data_informative_gamma_6.2,
                               data_MAP_freq_HRs)

combined_data_6.2 <- combined_data_6.2 %>%
  group_by(Prior) %>%
  mutate(desired_HRs = (desired_HRs))

combined_data_6.2 <- combined_data_6.2 %>%
  mutate(diff_HR = abs(mean_HR - desired_HRs))

```

Dibujamos los de la mediana de 2.2

```{r `Simulation scenarios w fixed experimental & bayes w plot 3.5_2`, eval = T, echo = T}


p6 <- ggplot(combined_data_2.2, aes(x = desired_HRs, y = prop_significant, group = Prior, color = Prior)) +
  geom_point(size = 3) +
  geom_line(linewidth = 1) +
  geom_vline(xintercept = 1, linetype = "dashed", color = "red", size = 1) +
  geom_vline(xintercept = 0.55, linetype = "dashed", color = "red", size = 1) +
  geom_vline(xintercept = 0.5, linetype = "dashed", color = "red", size = 1) +
  geom_hline(yintercept = c(0.8, 0.9), linetype = "dotted", color = c("purple", "green"), size = 1) +
  scale_x_continuous(breaks = seq(min(combined_data_2.2$desired_HRs), max(combined_data_2.2$desired_HRs), 0.1), labels = sprintf("%.2f", seq(min(combined_data_2.2$desired_HRs), max(combined_data_2.2$desired_HRs), 0.1))) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Power vs Hazard Ratio w prior median control at 2.2",
       x = "Theoretical Hazard Ratio",
       y = "Power") +
  theme_minimal() +
  theme(plot.title = element_text(size = 12, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 10),
        legend.position = "right")

p6 <- p6 +
  annotate("text", x = max(combined_data_2.2$desired_HRs), y = 0.8, label = "80% power", hjust = 1, vjust = -0.5, size = 3.5, color = "purple") +
  annotate("text", x = max(combined_data_2.2$desired_HRs), y = 0.9, label = "90% power", hjust = 1, vjust = -0.5, size = 3.5, color = "green") +
  geom_label(aes(x = 1, y = Inf, label = "H0"), vjust = 2, color = "black", fill = "white", size = 3.5, label.size = 0, fontface = "bold") +
  geom_label(aes(x = 0.55, y = Inf, label = "H1"), vjust = 2, color = "black", fill = "white", size = 3.5, label.size = 0, fontface = "bold") +
  geom_label(aes(x = 0.5, y = Inf, label = "Real HR"), vjust = 2, color = "black", fill = "white", size = 3.5, label.size = 0, fontface = "bold")

p6

# Graficamos las diferencias

p7 <- ggplot(combined_data_2.2, aes(x = desired_HRs, y = diff_HR, color = Prior)) +
  geom_point(size = 3) +
  geom_line(aes(group = Prior), linewidth = 1) +
  scale_x_continuous(breaks = seq(min(combined_data_2.2$desired_HRs), max(combined_data_2.2$desired_HRs), 0.1), labels = sprintf("%.2f", seq(min(combined_data_2.2$desired_HRs), max(combined_data_2.2$desired_HRs), 0.1))) +
  labs(title = "Diff btw Simulated HR and Theoretical HRs w prior median control = 2.2",
       x = "Theoretical Hazard Ratio",
       y = "Difference") +
  theme_minimal() +
  theme(plot.title = element_text(size = 10, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 8, face = "bold"),
        axis.text = element_text(size = 8),
        legend.position = "right")

p7
```

Dibujamos los de la mediana de 4.2

```{r `Simulation scenarios w fixed experimental & bayes w plot 5.5_2`, eval = T, echo = T}


p8 <- ggplot(combined_data_4.2, aes(x = desired_HRs, y = prop_significant, group = Prior, color = Prior)) +
  geom_point(size = 3) +
  geom_line(linewidth = 1) +
  geom_vline(xintercept = 1, linetype = "dashed", color = "red", size = 1) +
  geom_vline(xintercept = 0.55, linetype = "dashed", color = "red", size = 1) +
  geom_vline(xintercept = 0.5, linetype = "dashed", color = "red", size = 1) +
  geom_hline(yintercept = c(0.8, 0.9), linetype = "dotted", color = c("purple", "green"), size = 1) +
  scale_x_continuous(breaks = seq(min(combined_data_4.2$desired_HRs), max(combined_data_4.2$desired_HRs), 0.1), labels = sprintf("%.2f", seq(min(combined_data_4.2$desired_HRs), max(combined_data_4.2$desired_HRs), 0.1))) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Power vs Hazard Ratio w prior median control at 4.2",
       x = "Theoretical Hazard Ratio",
       y = "Power") +
  theme_minimal() +
  theme(plot.title = element_text(size = 12, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 10),
        legend.position = "right")

p8 <- p8 +
  annotate("text", x = max(combined_data_4.2$desired_HRs), y = 0.8, label = "80% power", hjust = 1, vjust = -0.5, size = 3.5, color = "purple") +
  annotate("text", x = max(combined_data_4.2$desired_HRs), y = 0.9, label = "90% power", hjust = 1, vjust = -0.5, size = 3.5, color = "green") +
  geom_label(aes(x = 1, y = Inf, label = "H0"), vjust = 2, color = "black", fill = "white", size = 3.5, label.size = 0, fontface = "bold") +
  geom_label(aes(x = 0.55, y = Inf, label = "H1"), vjust = 2, color = "black", fill = "white", size = 3.5, label.size = 0, fontface = "bold") +
  geom_label(aes(x = 0.5, y = Inf, label = "Real HR"), vjust = 2, color = "black", fill = "white", size = 3.5, label.size = 0, fontface = "bold")

p8

# Graficamos las diferencias

p9 <- ggplot(combined_data_4.2, aes(x = desired_HRs, y = diff_HR, color = Prior)) +
  geom_point(size = 3) +
  geom_line(aes(group = Prior), linewidth = 1) +
  scale_x_continuous(breaks = seq(min(combined_data_4.2$desired_HRs), max(combined_data_4.2$desired_HRs), 0.1), labels = sprintf("%.2f", seq(min(combined_data_4.2$desired_HRs), max(combined_data_4.2$desired_HRs), 0.1))) +
  scale_y_continuous(limits = c(NA, 0.4)) + # Setting the y-axis max limit here
  labs(title = "Diff btw Simulated HR and Theoretical HRs w prior median control = 4.2",
       x = "Theoretical Hazard Ratio",
       y = "Difference") +
  theme_minimal() +
  theme(plot.title = element_text(size = 10, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 8, face = "bold"),
        axis.text = element_text(size = 8),
        legend.position = "right")

p9

```

Dibujamos los de la mediana de 6.2

```{r `Simulation scenarios w fixed experimental & bayes w plot 7.5_2`, eval = T, echo = T}


p10 <- ggplot(combined_data_6.2, aes(x = desired_HRs, y = prop_significant, group = Prior, color = Prior)) +
  geom_point(size = 3) +
  geom_line(linewidth = 1) +
  geom_vline(xintercept = 1, linetype = "dashed", color = "red", size = 1) +
  geom_vline(xintercept = 0.55, linetype = "dashed", color = "red", size = 1) +
  geom_vline(xintercept = 0.5, linetype = "dashed", color = "red", size = 1) +
  geom_hline(yintercept = c(0.8, 0.9), linetype = "dotted", color = c("purple", "green"), size = 1) +
  scale_x_continuous(breaks = seq(min(combined_data_6.2$desired_HRs), max(combined_data_6.2$desired_HRs), 0.1), labels = sprintf("%.2f", seq(min(combined_data_6.2$desired_HRs), max(combined_data_6.2$desired_HRs), 0.1))) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Power vs Hazard Ratio w prior median control at 6.2",
       x = "Theoretical Hazard Ratio",
       y = "Power") +
  theme_minimal() +
  theme(plot.title = element_text(size = 12, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 10),
        legend.position = "right")

p10 <- p10 +
  annotate("text", x = max(combined_data_6.2$desired_HRs), y = 0.8, label = "80% power", hjust = 1, vjust = -0.5, size = 3.5, color = "purple") +
  annotate("text", x = max(combined_data_6.2$desired_HRs), y = 0.9, label = "90% power", hjust = 1, vjust = -0.5, size = 3.5, color = "green") +
  geom_label(aes(x = 1, y = Inf, label = "H0"), vjust = 2, color = "black", fill = "white", size = 3.5, label.size = 0, fontface = "bold") +
  geom_label(aes(x = 0.55, y = Inf, label = "H1"), vjust = 2, color = "black", fill = "white", size = 3.5, label.size = 0, fontface = "bold") +
  geom_label(aes(x = 0.5, y = Inf, label = "Real HR"), vjust = 2, color = "black", fill = "white", size = 3.5, label.size = 0, fontface = "bold")

p10

# Graficamos las diferencias

p11 <- ggplot(combined_data_6.2, aes(x = desired_HRs, y = diff_HR, color = Prior)) +
  geom_point(size = 3) +
  geom_line(aes(group = Prior), linewidth = 1) +
  scale_x_continuous(breaks = seq(min(combined_data_6.2$desired_HRs), max(combined_data_6.2$desired_HRs), 0.1), labels = sprintf("%.2f", seq(min(combined_data_6.2$desired_HRs), max(combined_data_6.2$desired_HRs), 0.1))) +
  labs(title = "Diff btw Simulated HR and Theoretical HRs w prior median control = 6.2",
       x = "Theoretical Hazard Ratio",
       y = "Difference") +
  theme_minimal() +
  theme(plot.title = element_text(size = 10, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 8, face = "bold"),
        axis.text = element_text(size = 8),
        legend.position = "right")

p11
```

# Mixture Meta-Analytic Prior with non-informative

Para hacer el mixture es apropiado considerar la 2 diferentes priors, informativa usando MAP y no informativa, de la misma distribución.

Por un lado tenemos:
  
1) Mixture Prior: Combinación de 2 priors

2) Robust Mixture Prior: Combinación de un MAP + Componente no informativo (the MAP prior is not available in analytical form. To allow for a concise description of the prior and tractable posterior analysis we approximate the MAP prior by a mixture of conjugate priors, with the Kullback–Leibler divergence as a measure of discrepancy.)

Ver también cuánto tamaño muestral nos ahorramos por cada calibración del peso puede ser interesante. Claro, pero aquí serían diferentes shape parameter para el componen.

Ahora vamos a ejecutar el código para obtener los resultados para diferentes mixture priors con diferentes w. 
W es el peso que se da a la parte informativa, en este caso obtenido en el MAP.
No tiene sentido proponer un diseño donde se de un peso de más del 50% a la parte informativa, por lo que este valor va a ser el cap.

Vamos a ir de 10 en 10 para el porcentaje de información para la parte informativa, i.e., 0.1, 0.20, 0.3, 0.4, 0.5.

Sólo se va a ensañar un código en el informe pero se ha realizado para todos los pesos y mostramos sus características.

- Se usa el MAP desde el punto de vista Frecuentista
  
- La prior no informativa va a ser una Gamma(1, 1/16)

A continuación se muestran las formas de las densidades:

```{r Densities_mixture_MW2, eval = F}

# Dibujamos las densidades del mixture

gamma_density_1 <- function(x, alpha, beta) {
  dgamma(x, shape=alpha, rate=beta)
}

gamma_density_2 <- function(x) {
  dgamma(x, shape=1, rate=1/16)
  
}

gamma_density_3 <- function(x, alpha, beta) {
  dgamma(x, shape=alpha, rate=beta)
}

mixture_density_1 <- function(x, w1, alpha1, beta1) {
  w1 * gamma_density_1(x, alpha1, beta1) + (1-w1) * gamma_density_2(x)
}


alpha1 = alpha_map_freq
beta1 = beta_map_freq
# alpha2 = alpha_map_bayes
# beta2 = beta_map_bayes

w1 = 0.2
w2 = 0.50

x_seq <- seq(0, 20, length.out = 400)
gamma1_densities <- gamma_density_1(x_seq, alpha1, beta1)
gamma2_densities <- gamma_density_2(x_seq)
gamma3_densities <- gamma_density_3(x_seq, alpha2, beta2)
mixture1_densities <- sapply(x_seq, function(x) mixture_density_1(x, w1, alpha1, beta1))
mixture2_densities <- sapply(x_seq, function(x) mixture_density_1(x, w2, alpha1, beta1))

df <- data.frame(x = x_seq, 
                 Prior_MAP_Frequentist = gamma1_densities, 
                 Prior_Non_informative = gamma2_densities,
                 Prior_MAP_Bayes = gamma3_densities,
                 Mixture_Freq_weight_0.2_informative_part = mixture1_densities,
                 Mixture_Freq_weight_0.5_informative_part = mixture2_densities)

ggplot(df, aes(x = x)) + 
  geom_line(aes(y = Prior_MAP_Frequentist, color = "Prior_MAP_Frequentist")) + 
  geom_line(aes(y = Prior_Non_informative, color = "Prior_Non_informative")) +
  geom_line(aes(y = Prior_MAP_Bayes, color = "Prior_MAP_Bayes")) +
  geom_line(aes(y = Mixture_Freq_weight_0.2_informative_part, color = "Mixture_Freq_weight_0.2_informative_part")) +
  geom_line(aes(y = Mixture_Freq_weight_0.5_informative_part, color = "Mixture_Freq_weight_0.5_informative_part")) +
  labs(title = "Gamma Densities and Their Mixtures", 
       x = "x", 
       y = "Density", 
       color = "Density Legend") + 
  theme_minimal()

# Dibujamos todas las densidades inclyendo las mixture

parameters_gamma <- data.frame(shape = c(0.00001, 1, 6.059319, 605.9319, alpha_map_freq, alpha_map_bayes),
                               rate = c(0.00001, 1/16, 1, 100, beta_map_freq, beta_map_bayes),
                               label = c("Non-informative: Gamma(0.00001, 0.00001)", "Non-informative: Gamma(1, 1/19)", "Weak: Gamma(6.059319, 1)", "Informative: Gamma(605.9319, 100)", "MAP freq", "MAP bayes"))

gamma_density <- function(shape, rate, label) {
  data.frame(x = seq(0, 50, length.out = 400)) %>%
    mutate(density = dgamma(x, shape = shape, rate = rate),
           parameter = label)
}

densities <- purrr::pmap_df(parameters_gamma, gamma_density)

alpha1 = alpha_map_freq  
beta1 = beta_map_freq  
w1 = 0.2
w2 = 0.50

gamma_density_1 <- function(x, alpha, beta) {
  dgamma(x, shape=alpha, rate=beta)
}

gamma_density_2 <- function(x) {
  dgamma(x, shape=1, rate=1/16)
}

gamma_density_3 <- function(x, alpha, beta) {
  dgamma(x, shape=alpha, rate=beta)
}

Mixture_weight_0.2_informative_part <- function(x, w1, alpha2, beta2) {
  w1 * gamma_density_1(x, alpha1, beta1) + (1-w1) * gamma_density_2(x)
}

Mixture_weight_0.5_informative_part <- function(x, w2, alpha2, beta2) {
  w2 * gamma_density_3(x, alpha1, beta1) + (1-w2) * gamma_density_2(x)
}

x_seq <- seq(0, 20, length.out = 400) # Make sure this covers the range of both plots

mixture_df <- data.frame(
  x = x_seq,
  density = c(
    sapply(x_seq, function(x) Mixture_weight_0.2_informative_part(x, w1, alpha1, beta1)),
    sapply(x_seq, function(x) Mixture_weight_0.5_informative_part(x, w2, alpha1, beta1))
  ),
  parameter = c(rep("Mixture_weight_0.2_informative_part", length(x_seq)), rep("Mixture_weight_0.5_informative_part", length(x_seq)))
)

final_df <- bind_rows(densities, mixture_df)

ggplot(mixture_df, aes(x = x, y = density, color = parameter)) +
  geom_line() +
  labs(title = "Gamma Prior Distributions and Their Mixtures", 
       x = "x", 
       y = "Density", 
       color = "Density Legend") +
  theme_minimal()

```

Las simulaciones con los mismos escenarios para los pesos w de 0.1 a 0.5 de 0.1 en 0.1

```{r MAP_Bayes_Mixture_Prior_w , eval = T}

shape_parameter <- 1 

control_medians <- c(2,2.25,2.5,2.75,3,3.25,3.5,3.75,4,4.2,4.25,4.5,4.75,5,5.25,5.5,5.75,6,6.25,6.5,6.75,7,7.25,7.5,7.75,8,8.25,8.5,8.75,9)

medians <- matrix(NA, nrow = length(control_medians), ncol = 3, 
                  dimnames = list(NULL, c("Control", "Treatment", "Hazard Ratio")))

desired_HR = 0.7

for (i in 1:length(control_medians)) {
  medians[i, "Control"] <- control_medians[i]
  
  lambda_control = control_medians[i] / (log(2)^(1/shape_parameter))
  lambda_treatment = lambda_control / desired_HR^(1/shape_parameter)
  
  medians[i, "Treatment"] = lambda_treatment * (log(2)^(1/shape_parameter))
  medians[i, "Hazard Ratio"] = (lambda_control / lambda_treatment)^shape_parameter
}

medians <- medians[,1:2]
sample_size <- 400
ratio <- c(2/3,1/3)
rand_type <- "CR" 
scenarios_eff <- as.matrix(medians, nrow = length(control_medians), ncol = 2, byrow = TRUE)
censor <- c(0.05,0.05) # 10% drop-out
Tmax <- 32 # Aquí tengo dudas, muy pocos pacientes llegan al final pero parece que es lo que pone en el SAP
alpha <- 0.05 
test.type <- 2
HR_1 <- TRUE
IA <- c(0.5, 0.75)
method_IA <- "OF"
n_exp_events <- 330
Plot_Power <- FALSE
plot_pvalues = FALSE 
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = TRUE
Dynamic_Borrowing_PP = FALSE

analysis = "bayes"
n_sim <- 3000
seed <- 24
# 1) Shape control, 2) rate control, 3) Shape experimental y 4) rate experimental
prior_gamma <- matrix(c(alpha_map_freq, beta_map_freq, 1, 1/16), nrow = 2, ncol = 2, byrow = TRUE) 
prior_type <- c("Robust Mixture MAP Prior w = 0.1") # Este vector es para que aparezca el nombre en las tablas
P_HR_data_Boundary <- 0.8 # P(HR < 0.8 | data)
modelo_weibull_sep <- rstan::stan_model("weibull_mixture_gamma_sh_uniform.stan" ,verbose = F) # Este es el STAN con Ga(1, 1/6)
modelo = modelo_weibull_sep
modelo_bayes_test = "weibull"
w = 0.1
a0 = NULL

# sim14 <-  sim_trials(n_sim = n_sim,
#                        analysis = "bayes",
#                        sample_size = sample_size,
#                        ratio = ratio,
#                        rand_type = rand_type,
#                        Tmax = Tmax,
#                        scenarios_eff = scenarios_eff,
#                        shape_parameter = shape_parameter,
#                        censor = censor,
#                        test.type = test.type,
#                        alpha = alpha,
#                        method_IA = method_IA,
#                        IA = IA,
#                        n_exp_events = n_exp_events,
#                        HR_1 = HR_1,
#                        Plot_Power = Plot_Power,
#                        modelo = modelo,
#                        modelo_bayes_test = modelo_bayes_test,
#                        prior_type = prior_type,
#                        P_HR_data_Boundary = P_HR_data_Boundary,
#                        prior_gamma = prior_gamma,
#                        Plot_Power_scenarios = Plot_Power_scenarios,
#                        desired_HRs = desired_HRs,
#                        plot_pvalues = plot_pvalues,
#                        Plot_Control_Scenarios = Plot_Control_Scenarios,
#                        Dynamic_Borrowing_PP = Dynamic_Borrowing_PP,
#                        w = w,
#                        a0 = a0,
#                        seed = seed)
# 
# sim14[[2]]
# sim14[[3]]
# sim14[[4]]
# 
# sim140 <- sim14[[1]]
# 
# wd <- createWorkbook()
# addWorksheet(wd, "Sheet1")
# writeData(wd, "Sheet1", sim140)
# saveWorkbook(wd, "Mixture_MAP_w_0.1_400_3000.xlsx", overwrite = TRUE)

## Leemos los datos de las tablas obtenidas con el ordenador de multicore ##

sheet_names <- c("Sheet1")

# 262 HORAS -> 10 DÍAS Y 20 HORAS

Mixture_MAP_w_0.1 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/Blincyto_PhALL_Tablas/Mixture_MAP_w_0.1_400_3000.xlsx", sheet = sheet_names[1])

Mixture_MAP_w_0.2 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/Blincyto_PhALL_Tablas/Mixture_MAP_w_0.2_400_3000.xlsx", sheet = sheet_names[1])

Mixture_MAP_w_0.3 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/Blincyto_PhALL_Tablas/Mixture_MAP_w_0.3_400_3000.xlsx", sheet = sheet_names[1])

Mixture_MAP_w_0.4 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/Blincyto_PhALL_Tablas/Mixture_MAP_w_0.4_400_3000.xlsx", sheet = sheet_names[1])

Mixture_MAP_w_0.5 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/Blincyto_PhALL_Tablas/Mixture_MAP_w_0.5_400_3000.xlsx", sheet = sheet_names[1])


## Ahora juntamos los datos para graficarlos ##

# MAP Bayes Mixture prior with weight 0.1

data_Mixture_MAP_w_0.1 <- Mixture_MAP_w_0.1 %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "MAP Bayes Mixture prior w weight of 0.1")

data_filtered_diff_not_zero_map_bayes_mixture_w_0.1 <- data_Mixture_MAP_w_0.1 %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_map_bayes_mixture_w_0.1 <- data_Mixture_MAP_w_0.1 %>%
  filter(median_control == median_treatment)

# MAP Bayes Mixture prior with weight 0.2

data_Mixture_MAP_w_0.2 <- Mixture_MAP_w_0.2 %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "MAP Bayes Mixture prior w weight of 0.2")

data_filtered_diff_not_zero_map_bayes_mixture_w_0.2 <- data_Mixture_MAP_w_0.2 %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_map_bayes_mixture_w_0.2 <- data_Mixture_MAP_w_0.2 %>%
  filter(median_control == median_treatment)

# MAP Bayes Mixture prior with weight 0.3

data_Mixture_MAP_w_0.3 <- Mixture_MAP_w_0.3 %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "MAP Bayes Mixture prior w weight of 0.3")

data_filtered_diff_not_zero_map_bayes_mixture_w_0.3 <- data_Mixture_MAP_w_0.3 %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_map_bayes_mixture_w_0.3 <- data_Mixture_MAP_w_0.3 %>%
  filter(median_control == median_treatment)

# MAP Bayes Mixture prior with weight 0.4

data_Mixture_MAP_w_0.4 <- Mixture_MAP_w_0.4 %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "MAP Bayes Mixture prior w weight of 0.4")

data_filtered_diff_not_zero_map_bayes_mixture_w_0.4 <- data_Mixture_MAP_w_0.4 %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_map_bayes_mixture_w_0.4 <- data_Mixture_MAP_w_0.4 %>%
  filter(median_control == median_treatment)

# MAP Bayes Mixture prior with weight 0.5

data_Mixture_MAP_w_0.5 <- Mixture_MAP_w_0.5 %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "MAP Bayes Mixture prior w weight of 0.5")

data_filtered_diff_not_zero_map_bayes_mixture_w_0.5 <- data_Mixture_MAP_w_0.5 %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_map_bayes_mixture_w_0.5 <- data_Mixture_MAP_w_0.5 %>%
  filter(median_control == median_treatment)


combined_data_diff_not_zero <- bind_rows(data_filtered_diff_not_zero_frequentist,
                                         data_filtered_diff_not_zero_map_bayes_mixture_w_0.1,
                                         data_filtered_diff_not_zero_map_bayes_mixture_w_0.2,
                                         data_filtered_diff_not_zero_map_bayes_mixture_w_0.3,
                                         data_filtered_diff_not_zero_map_bayes_mixture_w_0.4,
                                         data_filtered_diff_not_zero_map_bayes_mixture_w_0.5)

combined_data_diff_zero <- bind_rows(data_filtered_diff_zero_frequentist,
                                     data_filtered_diff_zero_map_bayes_mixture_w_0.1,
                                     data_filtered_diff_zero_map_bayes_mixture_w_0.2,
                                     data_filtered_diff_zero_map_bayes_mixture_w_0.3,
                                     data_filtered_diff_zero_map_bayes_mixture_w_0.4,
                                     data_filtered_diff_zero_map_bayes_mixture_w_0.5)

## Ahora sacamos las gráficas de las características operantes usando como prior el MAP Bayesiano con pesos ##

# Este es el gráfico de las densidades de las prior que se han considerado 

# Parte informativa: MAP Bayes
gamma_density_1 <- function(x, alpha, beta) {
  dgamma(x, shape=alpha, rate=beta)
}

# Parte no informativa (robusta)
gamma_density_2 <- function(x) {
  dgamma(x, shape=1, rate=1/16)
}

# La unión de las dos prior con peso prespecificado
mixture_density <- function(x, w1, alpha, beta) {
  w1 * gamma_density_1(x, alpha, beta) + (1-w1) * gamma_density_2(x)
}

# Parámetros obtenidos del MAP frecuentista para la distribución Gamma
alpha = alpha_map_freq
beta = beta_map_freq

w1 = 0.1; w2 = 0.2; w3 = 0.3; w4 = 0.4; w5 = 0.5

x_seq <- seq(0, 20, length.out = 400)
gamma1_densities <- gamma_density_1(x_seq, alpha, beta)
gamma2_densities <- gamma_density_2(x_seq)
mixture1_densities <- sapply(x_seq, function(x) mixture_density(x, w1, alpha, beta))
mixture2_densities <- sapply(x_seq, function(x) mixture_density(x, w2, alpha, beta))
mixture3_densities <- sapply(x_seq, function(x) mixture_density(x, w3, alpha, beta))
mixture4_densities <- sapply(x_seq, function(x) mixture_density(x, w4, alpha, beta))
mixture5_densities <- sapply(x_seq, function(x) mixture_density(x, w5, alpha, beta))

df <- data.frame(x = x_seq, 
                 MAP_Bayes = gamma1_densities, 
                 Non_Informative = gamma2_densities,
                 Mixture_weight_0.1 = mixture1_densities,
                 Mixture_weight_0.2 = mixture2_densities,
                 Mixture_weight_0.3 = mixture3_densities,
                 Mixture_weight_0.4 = mixture4_densities,
                 Mixture_weight_0.5 = mixture5_densities)

ggplot(df, aes(x = x), size = 1.2) + 
  geom_line(aes(y = MAP_Bayes, color = "Frequentist Meta-Analysis Prior"), size = 1.2) + 
  geom_line(aes(y = Non_Informative, color = "Non-Informative"), size = 1.2) +
  geom_line(aes(y = Mixture_weight_0.1, color = "Robust MAP Prior w=0.1"), size = 1.2) +
  geom_line(aes(y = Mixture_weight_0.2, color = "Robust MAP Prior w=0.2"), size = 1.2) +
  geom_line(aes(y = Mixture_weight_0.3, color = "Robust MAP Prior w=0.3"), size = 1.2) +
  geom_line(aes(y = Mixture_weight_0.4, color = "Robust MAP Prior w=0.4"), size = 1.2) +
  geom_line(aes(y = Mixture_weight_0.5, color = "Robust MAP Prior w=0.5"), size = 1.2) +
  labs(title = "Gamma Pior Distributions and Their Mixtures", 
       x = "Scale Parameter for the Control Arm", 
       y = "Density", 
       color = "Bayesian Prior Distributions") + 
  theme_minimal()

# MSE

p6 <- ggplot(combined_data_diff_not_zero, aes(x = median_control, y = mean_MSE, color = Prior)) + 
  geom_line(size = 1.2) +
  geom_vline(xintercept = median_control_center, linetype = "solid") +
  labs(
    title = "Mean Square Error (MSE)",
    x = "Median Control Arm (in months)",
    y = "Mean MSE",
    color = "Bayesian Prior Distributions"
  ) +
  theme_minimal() + 
  theme(
    plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 10, face = "bold"),
    axis.text = element_text(size = 12),
    axis.title.x = element_text(size = 11),
    axis.title.y = element_text(size = 11),
    legend.margin = margin(9, 9, 9, 9),
    legend.text = element_text(size = 9),
    legend.title = element_text(size = 10, face = "bold")
  ) +
  scale_color_discrete(name = "Bayesian Prior Distributions") +
  scale_x_continuous(breaks = seq(min(combined_data_diff_not_zero$median_control), max(combined_data_diff_not_zero$median_control), by = 0.5)) +
  scale_y_continuous(limits = c(0, 0.075))

p6


# Power

p7 <- ggplot(combined_data_diff_not_zero, aes(x = median_control, y = prop_significant, color = Prior)) +
  geom_line(size = 1.2) + 
  geom_line() +
  geom_vline(xintercept = median_control_center, linetype = "dashed") +
  labs(title = "Power", x = "Median Control Arm (in months)", y = "Proportion of Significant Trials", color = "Bayesian Prior Distributions") +
  theme_minimal() + 
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 12),
        axis.title.x = element_text(size = 11),
        axis.title.y = element_text(size = 11),
        legend.margin = margin(12, 12, 12, 12),
        legend.text = element_text(size = 11),
        legend.title = element_text(size = 12, face = "bold")) +
  scale_color_discrete(name = "Bayesian Prior Distributions") +
  scale_linetype_discrete(name = "Bayesian Prior Distributions") +
  scale_x_continuous(breaks = seq(min(combined_data_diff_not_zero$median_control), max(combined_data_diff_not_zero$median_control), by = 0.5)) +
  scale_y_continuous(limits = c(0.5, 1))
p7

# ET1

p8 <- ggplot(combined_data_diff_zero, aes(x = median_control, y = prop_significant, color = Prior)) +
  geom_line(size = 1.2) + 
  geom_line() +
  geom_vline(xintercept = median_control_center, linetype = "dashed") +
  geom_hline(yintercept = 0.025, linetype = "dashed", color = "green") +
  geom_hline(yintercept = 0.05, linetype = "dashed", color = "purple") +
  labs(title = "Type I Error (T1E)", x = "Median Control (in months)", y = "Proportion of Significant Trials", color = "Bayesian Prior Distributions") +
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 12),
        axis.title.x = element_text(size = 11),
        axis.title.y = element_text(size = 11),
        legend.margin = margin(12, 12, 12, 12),
        legend.text = element_text(size = 11),
        legend.title = element_text(size = 12, face = "bold")) +
  scale_color_discrete(name = "Bayesian Prior Distributions") +
  scale_linetype_discrete(name = "Bayesian Prior Distributions") +
  scale_x_continuous(breaks = seq(min(combined_data_diff_zero$median_control), max(combined_data_diff_zero$median_control), by = 0.5)) +
  scale_y_continuous(limits = c(0, 0.2))
p8

```

```{r T1E_combined_RMAP, eval = T}

library(cowplot)

p66 <- p6 + scale_color_discrete(
  name = "Bayesian Prior Distributions", 
  labels = c(
        "Frequentist",
         "Robust MAP\nPrior w=0.1",
         "Robust MAP\nPrior w=0.2",
         "Robust MAP\nPrior w=0.3",
         "Robust MAP\nPrior w=0.4",
         "Robust MAP\nPrior w=0.5"
  )
) +
  guides(color = guide_legend(ncol = 6))  

legend <- get_legend(
  p66 +
    theme(
      # legend.box = "horizontal", 
      legend.justification = c(0, 1),
      # legend.margin = margin(8, 8, 8, 8),
      legend.text = element_text(size = 10), 
      legend.title = element_text(size = 11, face = "bold")
    )
)

# Remove individual legends from the plots
p66 <- p66 + theme(legend.position = "none")
p77 <- p7 + theme(legend.position = "none")
p88 <- p8 + theme(legend.position = "none")

p66 <- p66 + theme(plot.background = element_rect(colour = "black", size = 0.5, fill = NA))
p77 <- p77 + theme(plot.background = element_rect(colour = "black", size = 0.5, fill = NA))
p88 <- p88 + theme(plot.background = element_rect(colour = "black", size = 0.5, fill = NA))

plots_row <- plot_grid(p66, p77, p88, ncol = 3, labels = c("A", "B", "C"), label_size = 14)

combined_plot <- plot_grid(
  plots_row,
  legend,
  ncol = 1,                 
  rel_heights = c(3, 0.4)   
)

print(combined_plot)

```


# Power prior: Incorporando IPD en el análisis

Como en el MAP, he hecho simulaciones para estudiar las características operantes con diferentes pesos para a0: 0.1, 0.2, 0.3, 0.4 y 0.5.
  
```{r Power_Prior , eval = T}

shape_parameter <- 1 

control_medians <- c(2,2.25,2.5,2.75,3,3.25,3.5,3.75,4,4.2,4.25,4.5,4.75,5,5.25,5.5,5.75,6,6.25,6.5,6.75,7,7.25,7.5,7.75,8,8.25,8.5,8.75,9)

medians <- matrix(NA, nrow = length(control_medians), ncol = 3, 
                  dimnames = list(NULL, c("Control", "Treatment", "Hazard Ratio")))

desired_HR = 0.7

for (i in 1:length(control_medians)) {
  medians[i, "Control"] <- control_medians[i]
  
  lambda_control = control_medians[i] / (log(2)^(1/shape_parameter))
  lambda_treatment = lambda_control / desired_HR^(1/shape_parameter)
  
  medians[i, "Treatment"] = lambda_treatment * (log(2)^(1/shape_parameter))
  medians[i, "Hazard Ratio"] = (lambda_control / lambda_treatment)^shape_parameter
}

medians <- medians[,1:2]
sample_size <- 400
ratio <- c(2/3,1/3)
rand_type <- "CR" 
scenarios_eff <- as.matrix(medians, nrow = length(control_medians), ncol = 2, byrow = TRUE)
censor <- c(0.05,0.05) # 10% drop-out
Tmax <- 32 # Aquí tengo dudas, muy pocos pacientes llegan al final pero parece que es lo que pone en el SAP
alpha <- 0.05 
test.type <- 2
HR_1 <- TRUE
IA <- c(0.5, 0.75)
method_IA <- "OF"
n_exp_events <- 330
Plot_Power <- FALSE
plot_pvalues = FALSE 
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = TRUE
Dynamic_Borrowing_PP = FALSE

analysis = "bayes"
n_sim <- 3000
seed <- 24
# 1) Shape control, 2) rate control, 3) Shape experimental y 4) rate experimental
prior_gamma <- matrix(c(alpha_map_freq, beta_map_freq, 1, 1/16), nrow = 2, ncol = 2, byrow = TRUE) 
prior_type <- c("Robust Mixture MAP Prior w = 0.1") # Este vector es para que aparezca el nombre en las tablas
P_HR_data_Boundary <- 0.8 # P(HR < 0.8 | data)
modelo_weibull_sep <- rstan::stan_model("weibull_power_prior.stan" ,verbose = F)
modelo = modelo_weibull_sep
modelo_bayes_test = "weibull"
w = NULL
a0 = 0.1

# Datos externos

# Cogemos los datos que más se parecen

data_hist2 <- read.csv("IPD_Externo_2_bueno.csv")
data_hist2$arm <- 1
external_data <- data_hist2
external_data$dataset <- 'external'
names(external_data)[names(external_data) == "Survival.time"] <- "time"
names(external_data)[names(external_data) == "Status"] <- "status"
external_data$id <- seq(1, dim(external_data)[1], by = 1)
external_data$status <- ifelse(external_data$status==1, TRUE, FALSE)

# sim15 <-  sim_trials(n_sim = n_sim,
#                        analysis = "bayes",
#                        sample_size = sample_size,
#                        ratio = ratio,
#                        rand_type = rand_type,
#                        Tmax = Tmax,
#                        scenarios_eff = scenarios_eff,
#                        shape_parameter = shape_parameter,
#                        censor = censor,
#                        test.type = test.type,
#                        alpha = alpha,
#                        method_IA = method_IA,
#                        IA = IA,
#                        n_exp_events = n_exp_events,
#                        HR_1 = HR_1,
#                        Plot_Power = Plot_Power,
#                        modelo = modelo,
#                        modelo_bayes_test = modelo_bayes_test,
#                        prior_type = prior_type,
#                        P_HR_data_Boundary = P_HR_data_Boundary,
#                        prior_gamma = prior_gamma,
#                        Plot_Power_scenarios = Plot_Power_scenarios,
#                        desired_HRs = desired_HRs,
#                        plot_pvalues = plot_pvalues,
#                        Plot_Control_Scenarios = Plot_Control_Scenarios,
#                        Dynamic_Borrowing_PP = Dynamic_Borrowing_PP,
#                        external_data = external_data,
#                        w = w,
#                        a0 = a0,
#                        seed = seed)
# 
# sim15[[2]]
# sim15[[3]]
# sim15[[4]]
# 
# sim150 <- sim15[[1]]
# 
# wd <- createWorkbook()
# addWorksheet(wd, "Sheet1")
# writeData(wd, "Sheet1", sim150)
# saveWorkbook(wd, "Power_Prior_a0_0.1_400_3000.xlsx", overwrite = TRUE)

## Leemos los datos de las tablas obtenidas con el ordenador de multicore ##

sheet_names <- c("Sheet1")

Power_Prior_a0_0.1 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/Blincyto_PhALL_Tablas/Power_Prior_a0_0.1_400_3000.xlsx", sheet = sheet_names[1])

Power_Prior_a0_0.2 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/Blincyto_PhALL_Tablas/Power_Prior_a0_0.2_400_3000.xlsx", sheet = sheet_names[1])

Power_Prior_a0_0.3 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/Blincyto_PhALL_Tablas/Power_Prior_a0_0.3_400_3000.xlsx", sheet = sheet_names[1])

Power_Prior_a0_0.4 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/Blincyto_PhALL_Tablas/Power_Prior_a0_0.4_400_3000.xlsx", sheet = sheet_names[1])

Power_Prior_a0_0.5 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/Blincyto_PhALL_Tablas/Power_Prior_a0_0.5_400_3000.xlsx", sheet = sheet_names[1])


## Ahora juntamos los datos para graficarlos ##


# Bayes_Power_Prior_a0_0.1

data_Bayes_Power_Prior_a0_0.1 <- Power_Prior_a0_0.1 %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "Power Prior a0 = 0.1")

data_filtered_diff_not_zero_Bayes_Power_Prior_a0_0.1 <- data_Bayes_Power_Prior_a0_0.1 %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_Bayes_Power_Prior_a0_0.1 <- data_Bayes_Power_Prior_a0_0.1 %>%
  filter(median_control == median_treatment)


# Bayes_Power_Prior_a0_0.2

data_Bayes_Power_Prior_a0_0.2 <- Power_Prior_a0_0.2 %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "Power Prior a0 = 0.2")

data_filtered_diff_not_zero_Bayes_Power_Prior_a0_0.2 <- data_Bayes_Power_Prior_a0_0.2 %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_Bayes_Power_Prior_a0_0.2 <- data_Bayes_Power_Prior_a0_0.2 %>%
  filter(median_control == median_treatment)


# Bayes_Power_Prior_a0_0.3

data_Bayes_Power_Prior_a0_0.3 <- Power_Prior_a0_0.3 %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "Power Prior a0 = 0.3")

data_filtered_diff_not_zero_Bayes_Power_Prior_a0_0.3 <- data_Bayes_Power_Prior_a0_0.3 %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_Bayes_Power_Prior_a0_0.3<- data_Bayes_Power_Prior_a0_0.3 %>%
  filter(median_control == median_treatment)

# Bayes_Power_Prior_a0_0.4

data_Bayes_Power_Prior_a0_0.4 <- Power_Prior_a0_0.4 %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "Power Prior a0 = 0.4")

data_filtered_diff_not_zero_Bayes_Power_Prior_a0_0.4 <- data_Bayes_Power_Prior_a0_0.4 %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_Bayes_Power_Prior_a0_0.4 <- data_Bayes_Power_Prior_a0_0.4 %>%
  filter(median_control == median_treatment)

# Bayes_Power_Prior_a0_0.5

data_Bayes_Power_Prior_a0_0.5 <- Power_Prior_a0_0.5 %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "Power Prior a0 = 0.5")

data_filtered_diff_not_zero_Bayes_Power_Prior_a0_0.5 <- data_Bayes_Power_Prior_a0_0.5 %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_Bayes_Power_Prior_a0_0.5 <- data_Bayes_Power_Prior_a0_0.5 %>%
  filter(median_control == median_treatment)


combined_data_diff_not_zero <- bind_rows(data_filtered_diff_not_zero_frequentist,
                                         data_filtered_diff_not_zero_Bayes_Power_Prior_a0_0.1,
                                         data_filtered_diff_not_zero_Bayes_Power_Prior_a0_0.2,
                                         data_filtered_diff_not_zero_Bayes_Power_Prior_a0_0.3,
                                         data_filtered_diff_not_zero_Bayes_Power_Prior_a0_0.4,
                                         data_filtered_diff_not_zero_Bayes_Power_Prior_a0_0.5)

combined_data_diff_zero <- bind_rows(data_filtered_diff_zero_frequentist,
                                     data_filtered_diff_zero_Bayes_Power_Prior_a0_0.1,
                                     data_filtered_diff_zero_Bayes_Power_Prior_a0_0.2,
                                     data_filtered_diff_zero_Bayes_Power_Prior_a0_0.3,
                                     data_filtered_diff_zero_Bayes_Power_Prior_a0_0.4,
                                     data_filtered_diff_zero_Bayes_Power_Prior_a0_0.5)

## Ahora sacamos las gráficas de las características operantes usando como prior el MAP Bayesiano con pesos ##

# MSE

p6 <- ggplot(combined_data_diff_not_zero, aes(x = median_control, y = mean_MSE, color = Prior)) + 
  geom_line(size = 1.2) +
  geom_vline(xintercept = median_control_center, linetype = "solid") +
  labs(
    title = "Mean Square Error (MSE)",
    x = "Median Control Arm (in months)",
    y = "Mean MSE",
    color = "Bayesian Prior Distributions"
  ) +
  theme_minimal() + 
  theme(
    plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 10, face = "bold"),
    axis.text = element_text(size = 12),
    axis.title.x = element_text(size = 11),
    axis.title.y = element_text(size = 11),
    legend.margin = margin(9, 9, 9, 9),
    legend.text = element_text(size = 9),
    legend.title = element_text(size = 10, face = "bold")
  ) +
  scale_color_discrete(name = "Bayesian Prior Distributions") +
  scale_x_continuous(breaks = seq(min(combined_data_diff_not_zero$median_control), max(combined_data_diff_not_zero$median_control), by = 0.5)) +
  scale_y_continuous(limits = c(0, 0.075))

p6

# Power

p7 <- ggplot(combined_data_diff_not_zero, aes(x = median_control, y = prop_significant, color = Prior)) +
  geom_line(size = 1.2) + 
  geom_line() +
  geom_vline(xintercept = median_control_center, linetype = "dashed") +
  labs(title = "Power", x = "Median Control Arm (in months)", y = "Proportion of Significant Trials", color = "Bayesian Prior Distributions") +
  theme_minimal() + 
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 12),
        axis.title.x = element_text(size = 11),
        axis.title.y = element_text(size = 11),
        legend.margin = margin(12, 12, 12, 12),
        legend.text = element_text(size = 11),
        legend.title = element_text(size = 12, face = "bold")) +
  scale_color_discrete(name = "Bayesian Prior Distributions") +
  scale_linetype_discrete(name = "Bayesian Prior Distributions") +
  scale_x_continuous(breaks = seq(min(combined_data_diff_not_zero$median_control), max(combined_data_diff_not_zero$median_control), by = 0.5)) +
  scale_y_continuous(limits = c(0.5, 1))
p7

# ET1

p8 <- ggplot(combined_data_diff_zero, aes(x = median_control, y = prop_significant, color = Prior)) +
  geom_line(size = 1.2) + 
  geom_line() +
  geom_vline(xintercept = median_control_center, linetype = "dashed") +
  geom_hline(yintercept = 0.025, linetype = "dashed", color = "green") +
  geom_hline(yintercept = 0.05, linetype = "dashed", color = "purple") +
  labs(title = "Type I Error (T1E)", x = "Median Control (in months)", y = "Proportion of Significant Trials", color = "Bayesian Prior Distributions") +
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 12),
        axis.title.x = element_text(size = 11),
        axis.title.y = element_text(size = 11),
        legend.margin = margin(12, 12, 12, 12),
        legend.text = element_text(size = 11),
        legend.title = element_text(size = 12, face = "bold")) +
  scale_color_discrete(name = "Bayesian Prior Distributions") +
  scale_linetype_discrete(name = "Bayesian Prior Distributions") +
  scale_x_continuous(breaks = seq(min(combined_data_diff_zero$median_control), max(combined_data_diff_zero$median_control), by = 0.5)) +
  scale_y_continuous(limits = c(0, 0.2))
p8

      
```

```{r T1E_combined_powerprior, eval = T}

library(cowplot)

p66 <- p6 + scale_color_discrete(
  name = "Bayesian Prior Distributions", 
  labels = c(
        "Frequentist",
         "Power Prior\na0=0.1",
         "Power Prior\na0=0.2",
         "Power Prior\na0=0.3",
         "Power Prior\na0=0.4",
         "Power Prior\na0=0.5")
) +
  guides(color = guide_legend(ncol = 6))  

legend <- get_legend(
  p66 +
    theme(
      # legend.box = "horizontal", 
      legend.justification = c(0, 1),
      # legend.margin = margin(8, 8, 8, 8),
      legend.text = element_text(size = 10), 
      legend.title = element_text(size = 11, face = "bold")
    )
)

# Remove individual legends from the plots
p66 <- p66 + theme(legend.position = "none")
p77 <- p7 + theme(legend.position = "none")
p88 <- p8 + theme(legend.position = "none")

p66 <- p66 + theme(plot.background = element_rect(colour = "black", size = 0.5, fill = NA))
p77 <- p77 + theme(plot.background = element_rect(colour = "black", size = 0.5, fill = NA))
p88 <- p88 + theme(plot.background = element_rect(colour = "black", size = 0.5, fill = NA))

plots_row <- plot_grid(p66, p77, p88, ncol = 3, labels = c("A", "B", "C"), label_size = 14)

combined_plot <- plot_grid(
  plots_row,
  legend,
  ncol = 1,                 
  rel_heights = c(3, 0.4)   
)

print(combined_plot)

```


# Dynamic Power Prior

A continuación se propone el último modelo que me parece de mucho interés. Este es parte de la familia de los Power Prior y la diferencia con el anterior es que, en vez de prespecificar pesos para el descuento del control externo a0, vamos a crear unas reglas hechas de antemano para la elección automática del a0.

Aquí tenemos el diagrama de barras para entenderlo mucho más fácilmente para los dos modelos que he hecho, 1) con pesos más altos con un máximo de 0.5 y 2) el mismo esquema, pero los pesos considerados están a la mitad, siendo el máximo de 0.25.

```{r Tabla_condiciones_Dynamic_Power_Prior1 , eval = T}

# Dibujamos los esquemas dinámicos en los que se va a prestar información en función de cómo se parezca el brazo control y el control externo.

# 1) Pesos más altos


breakpoints <- c(0.775, 0.825, 0.875, 0.925, 0.975, 1.025, 1.075, 1.125, 1.175, 1.225)
strengths <- c(0.1, 0.2, 0.3, 0.4, 0.5, 0.4, 0.3, 0.2, 0.1, 0)

df <- data.frame(
  HR = breakpoints[-length(breakpoints)], 
  HR_next = breakpoints[-1], 
  Strength = strengths[-length(strengths)] 
)

p1 <- ggplot(df, aes(xmin = HR, xmax = HR_next, ymin = 0, ymax = Strength)) +
  geom_rect(color = "black", fill = "lightsteelblue1") +
  geom_vline(xintercept = 1, linetype = "dashed", color = "red") +
  scale_x_continuous(name = "Hazard Ratio", limits = c(0.7, 1.3), breaks = seq(0.6, 1.4, 0.05)) +
  scale_y_continuous(name = "Borrowing Strength", limits = c(0, 0.6), breaks = seq(0, 0.5, 0.05)) +
  theme_minimal() +
  theme(panel.grid.major.x = element_blank(), panel.grid.minor.x = element_blank()) 

p1

# 2) Pesos ma la mitad

breakpoints <- c(0.775, 0.825, 0.875, 0.925, 0.975, 1.025, 1.075, 1.125, 1.175, 1.225)
strengths <- c(0.05, 0.1, 0.15, 0.2, 0.25, 0.2, 0.15, 0.1, 0.05, 0)

df <- data.frame(
  HR = breakpoints[-length(breakpoints)], 
  HR_next = breakpoints[-1], 
  Strength = strengths[-length(strengths)] 
)

p2 <- ggplot(df, aes(xmin = HR, xmax = HR_next, ymin = 0, ymax = Strength)) +
  geom_rect(color = "black", fill = "lightsteelblue1") +
  geom_vline(xintercept = 1, linetype = "dashed", color = "red") +
  scale_x_continuous(name = "Hazard Ratio", limits = c(0.7, 1.3), breaks = seq(0.6, 1.4, 0.05)) +
  scale_y_continuous(name = "Borrowing Strength", limits = c(0, 0.3), breaks = seq(0, 0.5, 0.05)) +
  theme_minimal() +
  theme(panel.grid.major.x = element_blank(), panel.grid.minor.x = element_blank()) 

p2
      
```

```{r T1E_combined_all, eval = T}

library(cowplot)

p11 <- p1 + theme(plot.background = element_rect(colour = "black", size = 0.5, fill = NA))
p22 <- p2 + theme(plot.background = element_rect(colour = "black", size = 0.5, fill = NA))

plots_row <- plot_grid(p11, p22, ncol = 2, labels = c("A", "B"), label_size = 14)

combined_plot <- plot_grid(
  plots_row,
  #legend,
  ncol = 1,                 
  rel_heights = c(3, 0.4)   
)

print(combined_plot)

```


Para que se decida de manera dinámica el peso para a0, vamos a hacer para cada uno de los ensayos simulados en cada uno de los escenarios una comparación en los datos obtenidos de esa simulación para el brazo control vs los datos del brazo control externo (Kantarjian et al, 2010).

Como podemos observar, si los datos se parecen (i.e., HR=1), entonces se va a prestar más información y a0 tendrá el máximo valor que es 0.5, de lo contrario, si se va diferenciando progresivamente el peso para a0 va a ir disminuyendo. Si el HR entre el brazo control y el brazo control externo es menor de 0.7 o mayor de 1.3, entonces no se va a el power prior y se hará un análisis normal (a0 = 0).

Para estudiar esta similitud, he hecho un código STAN adhoc usando una regresión de Cox para compararlo, sin embargo, el tiempo de simulación tarda el doble. Es por eso, que para comparar estos 2 brazos control, lo he hecho con una regresión de Cox frecuentista. Simplemente para ahorrar tiempo ya que lo he comprobado y sale exactamente lo mismo al usar en el Bayesiano priors no informativas N(0,10).

La condición que se ve en el gráfico de barras lo he puesto directamente en la función madre para no complicarme, así que por eso no está como input. Pero ya con más tiempo se puede hacer especificarlo desde la llamada de la función. 

Esto es muy útil porque no es una caja negra como si usáramos el peso como otra variable aleatoria más, si no que sabemos de antemano las condiciones y esto podemos verlo desde un punto de vista regulatorio.

```{r Dynamic_Power_Prior , eval = T}

shape_parameter <- 1 

control_medians <- c(2,2.25,2.5,2.75,3,3.25,3.5,3.75,4,4.2,4.25,4.5,4.75,5,5.25,5.5,5.75,6,6.25,6.5,6.75,7,7.25,7.5,7.75,8,8.25,8.5,8.75,9)

medians <- matrix(NA, nrow = length(control_medians), ncol = 3, 
                  dimnames = list(NULL, c("Control", "Treatment", "Hazard Ratio")))

desired_HR = 0.7

for (i in 1:length(control_medians)) {
  medians[i, "Control"] <- control_medians[i]
  
  lambda_control = control_medians[i] / (log(2)^(1/shape_parameter))
  lambda_treatment = lambda_control / desired_HR^(1/shape_parameter)
  
  medians[i, "Treatment"] = lambda_treatment * (log(2)^(1/shape_parameter))
  medians[i, "Hazard Ratio"] = (lambda_control / lambda_treatment)^shape_parameter
}

medians <- medians[,1:2]
sample_size <- 400
ratio <- c(2/3,1/3)
rand_type <- "CR" 
scenarios_eff <- as.matrix(medians, nrow = length(control_medians), ncol = 2, byrow = TRUE)
censor <- c(0.05,0.05) # 10% drop-out
Tmax <- 32 # Aquí tengo dudas, muy pocos pacientes llegan al final pero parece que es lo que pone en el SAP
alpha <- 0.05 
test.type <- 2
HR_1 <- TRUE
IA <- c(0.5, 0.75)
method_IA <- "OF"
n_exp_events <- 330
Plot_Power <- FALSE
plot_pvalues = FALSE 
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = TRUE

analysis = "bayes"
n_sim <- 3000
seed <- 24
# 1) Shape control, 2) rate control, 3) Shape experimental y 4) rate experimental
prior_gamma <- matrix(c(alpha_map_freq, beta_map_freq, 1, 1/16), nrow = 2, ncol = 2, byrow = TRUE) 
prior_type <- c("Dynamic Power Prior LW") # Este vector es para que aparezca el nombre en las tablas
P_HR_data_Boundary <- 0.8 # P(HR < 0.8 | data)
modelo_weibull_sep <- rstan::stan_model("weibull_power_prior.stan" ,verbose = F)
modelo = modelo_weibull_sep
modelo_bayes_test = "weibull"
w = NULL
a0 = NULL

# Datos externos

# Cogemos los datos que más se parecen

data_hist2 <- read.csv("IPD_Externo_2_bueno.csv")
data_hist2$arm <- 1
external_data <- data_hist2
external_data$dataset <- 'external'
names(external_data)[names(external_data) == "Survival.time"] <- "time"
names(external_data)[names(external_data) == "Status"] <- "status"
external_data$id <- seq(1, dim(external_data)[1], by = 1)
external_data$status <- ifelse(external_data$status==1, TRUE, FALSE)

# Lo que decide que haga el dynamic borrowing

Dynamic_Borrowing_PP = TRUE


# sim20 <-  sim_trials(n_sim = n_sim,
#                        analysis = "bayes",
#                        sample_size = sample_size,
#                        ratio = ratio,
#                        rand_type = rand_type,
#                        Tmax = Tmax,
#                        scenarios_eff = scenarios_eff,
#                        shape_parameter = shape_parameter,
#                        censor = censor,
#                        test.type = test.type,
#                        alpha = alpha,
#                        method_IA = method_IA,
#                        IA = IA,
#                        n_exp_events = n_exp_events,
#                        HR_1 = HR_1,
#                        Plot_Power = Plot_Power,
#                        modelo = modelo,
#                        modelo_bayes_test = modelo_bayes_test,
#                        prior_type = prior_type,
#                        P_HR_data_Boundary = P_HR_data_Boundary,
#                        prior_gamma = prior_gamma,
#                        Plot_Power_scenarios = Plot_Power_scenarios,
#                        desired_HRs = desired_HRs,
#                        plot_pvalues = plot_pvalues,
#                        Plot_Control_Scenarios = Plot_Control_Scenarios,
#                        Dynamic_Borrowing_PP = Dynamic_Borrowing_PP,
#                        external_data = external_data,
#                        w = w,
#                        a0 = a0,
#                        seed = seed)
# 
# sim20[[2]]
# sim20[[3]]
# sim20[[4]]
# 
# sim200 <- sim20[[1]]
# 
# wd <- createWorkbook()
# addWorksheet(wd, "Sheet1")
# writeData(wd, "Sheet1", sim200)
# saveWorkbook(wd, "Dynamic_Power_Prior_LW_400_3000.xlsx", overwrite = TRUE)


## Leemos los datos de las tablas obtenidas con el ordenador de multicore ##

sheet_names <- c("Sheet1")

# 1) Dynamic Power Prior 1: Pesos bajos
# Tiempo = ??

Bayes_Dynamic_Power_Prior_LW <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/Blincyto_PhALL_Tablas/Dynamic_Power_Prior_LW_400_3000.xlsx", sheet = sheet_names[1])

# 1) Dynamic Power Prior 2: Pesos altos
# Tiempo = 16h19m24s

Bayes_Dynamic_Power_Prior_HW <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/Blincyto_PhALL_Tablas/Dynamic_Power_Prior_HW_400_3000.xlsx", sheet = sheet_names[1])


# Bayes_Dynamic_Power_Prior_LW

data_Bayes_Dynamic_Power_Prior_LW <- Bayes_Dynamic_Power_Prior_LW %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "Dynamic Power Prior LW")

data_filtered_diff_not_zero_Bayes_Dynamic_Power_Prior_LW <- data_Bayes_Dynamic_Power_Prior_LW %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_Bayes_Dynamic_Power_Prior_LW <- data_Bayes_Dynamic_Power_Prior_LW %>%
  filter(median_control == median_treatment)

# Bayes_Dynamic_Power_Prior_HW

data_Bayes_Dynamic_Power_Prior_HW <- Bayes_Dynamic_Power_Prior_HW %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "Dynamic Power Prior HW")

data_filtered_diff_not_zero_Bayes_Dynamic_Power_Prior_HW <- data_Bayes_Dynamic_Power_Prior_HW %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_Bayes_Dynamic_Power_Prior_HW <- data_Bayes_Dynamic_Power_Prior_HW %>%
  filter(median_control == median_treatment)


combined_data_diff_not_zero <- bind_rows(data_filtered_diff_not_zero_frequentist,
                                         data_filtered_diff_not_zero_Bayes_Dynamic_Power_Prior_LW,
                                         data_filtered_diff_not_zero_Bayes_Dynamic_Power_Prior_HW)

combined_data_diff_not_zero$Prior <- factor(
  combined_data_diff_not_zero$Prior,
  levels = c(
    "Frequentist",
     "Dynamic Power Prior HW",
     "Dynamic Power Prior LW"
  )
)

combined_data_diff_zero <- bind_rows(data_filtered_diff_zero_frequentist,
                                     data_filtered_diff_zero_Bayes_Dynamic_Power_Prior_LW,
                                     data_filtered_diff_zero_Bayes_Dynamic_Power_Prior_HW)

combined_data_diff_zero$Prior <- factor(
  combined_data_diff_not_zero$Prior,
  levels = c(
    "Frequentist",
     "Dynamic Power Prior HW",
     "Dynamic Power Prior LW"
  )
)

## Ahora sacamos las gráficas de las características operantes usando como prior el MAP Bayesiano con pesos ##

# MSE

p6 <- ggplot(combined_data_diff_not_zero, aes(x = median_control, y = mean_MSE, color = Prior)) + 
  geom_line(size = 1.2) +
  geom_vline(xintercept = median_control_center, linetype = "solid") +
  labs(
    title = "Mean Square Error (MSE)",
    x = "Median Control Arm (in months)",
    y = "Mean MSE",
    color = "Bayesian Prior Distributions"
  ) +
  theme_minimal() + 
  theme(
    plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 10, face = "bold"),
    axis.text = element_text(size = 12),
    axis.title.x = element_text(size = 11),
    axis.title.y = element_text(size = 11),
    legend.margin = margin(9, 9, 9, 9),
    legend.text = element_text(size = 9),
    legend.title = element_text(size = 10, face = "bold")
  ) +
  scale_color_discrete(name = "Bayesian Prior Distributions") +
  scale_x_continuous(breaks = seq(min(combined_data_diff_not_zero$median_control), max(combined_data_diff_not_zero$median_control), by = 0.5)) +
  scale_y_continuous(limits = c(0, 0.075))

p6

# Power

p7 <- ggplot(combined_data_diff_not_zero, aes(x = median_control, y = prop_significant, color = Prior)) +
  geom_line(size = 1.2) + 
  geom_line() +
  geom_vline(xintercept = median_control_center, linetype = "dashed") +
  labs(title = "Power", x = "Median Control Arm (in months)", y = "Proportion of Significant Trials", color = "Bayesian Prior Distributions") +
  theme_minimal() + 
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 12),
        axis.title.x = element_text(size = 11),
        axis.title.y = element_text(size = 11),
        legend.margin = margin(12, 12, 12, 12),
        legend.text = element_text(size = 11),
        legend.title = element_text(size = 12, face = "bold")) +
  scale_color_discrete(name = "Bayesian Prior Distributions") +
  scale_linetype_discrete(name = "Bayesian Prior Distributions") +
  scale_x_continuous(breaks = seq(min(combined_data_diff_not_zero$median_control), max(combined_data_diff_not_zero$median_control), by = 0.5)) +
  scale_y_continuous(limits = c(0.5, 1))
p7

# ET1

p8 <- ggplot(combined_data_diff_zero, aes(x = median_control, y = prop_significant, color = Prior)) +
  geom_line(size = 1.2) + 
  geom_line() +
  geom_vline(xintercept = median_control_center, linetype = "dashed") +
  geom_hline(yintercept = 0.025, linetype = "dashed", color = "green") +
  geom_hline(yintercept = 0.05, linetype = "dashed", color = "purple") +
  labs(title = "Type I Error (T1E)", x = "Median Control (in months)", y = "Proportion of Significant Trials", color = "Bayesian Prior Distributions") +
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 12),
        axis.title.x = element_text(size = 11),
        axis.title.y = element_text(size = 11),
        legend.margin = margin(12, 12, 12, 12),
        legend.text = element_text(size = 11),
        legend.title = element_text(size = 12, face = "bold")) +
  scale_color_discrete(name = "Bayesian Prior Distributions") +
  scale_linetype_discrete(name = "Bayesian Prior Distributions") +
  scale_x_continuous(breaks = seq(min(combined_data_diff_zero$median_control), max(combined_data_diff_zero$median_control), by = 0.5)) +
  scale_y_continuous(limits = c(0, 0.2))
p8
      
```

```{r T1E_combined_powerprior2, eval = T}

library(cowplot)

p66 <- p6 + scale_color_discrete(
  name = "Bayesian Prior Distributions", 
  labels = c(
        "Frequentist",
        "Dynamic Power Prior with High Weights (0, 0.5)",
        "Dynamic Power Prior with Low Weights (0, 0.25)"
  )
) +
  guides(color = guide_legend(ncol = 3))  

legend <- get_legend(
  p66 +
    theme(
      # legend.box = "horizontal", 
      legend.justification = c(0, 1),
      # legend.margin = margin(8, 8, 8, 8),
      legend.text = element_text(size = 10), 
      legend.title = element_text(size = 11, face = "bold")
    )
)

# Remove individual legends from the plots
p66 <- p66 + theme(legend.position = "none")
p77 <- p7 + theme(legend.position = "none")
p88 <- p8 + theme(legend.position = "none")

p66 <- p66 + theme(plot.background = element_rect(colour = "black", size = 0.5, fill = NA))
p77 <- p77 + theme(plot.background = element_rect(colour = "black", size = 0.5, fill = NA))
p88 <- p88 + theme(plot.background = element_rect(colour = "black", size = 0.5, fill = NA))

plots_row <- plot_grid(p66, p77, p88, ncol = 3, labels = c("A", "B", "C"), label_size = 14)

combined_plot <- plot_grid(
  plots_row,
  legend,
  ncol = 1,                 
  rel_heights = c(3, 0.4)   
)

print(combined_plot)

```


# BONUS: Weak Informative using the results from O'Brien and Kantarijan

## Weak Informative with O'Brien

La fórmula para transformar las medianas en parámetro escala para la Weibull es la siguiente (asumiendo un shape=1 que es exponencial):
  
parameters <- medians / (log(2)^(1/shape_parameter))

Control: Mediana de 3 es 4.328085

```{r `Bayes: Weak informative prior distribution OBrien`, eval = T}


shape_parameter <- 1 

control_medians <- c(2,2.25,2.5,2.75,3,3.25,3.5,3.75,4,4.2,4.25,4.5,4.75,5,5.25,5.5,5.75,6,6.25,6.5,6.75,7,7.25,7.5,7.75,8,8.25,8.5,8.75,9)

medians <- matrix(NA, nrow = length(control_medians), ncol = 3, 
                  dimnames = list(NULL, c("Control", "Treatment", "Hazard Ratio")))

desired_HR = 0.7

for (i in 1:length(control_medians)) {
  medians[i, "Control"] <- control_medians[i]
  
  lambda_control = control_medians[i] / (log(2)^(1/shape_parameter))
  lambda_treatment = lambda_control / desired_HR^(1/shape_parameter)
  
  medians[i, "Treatment"] = lambda_treatment * (log(2)^(1/shape_parameter))
  medians[i, "Hazard Ratio"] = (lambda_control / lambda_treatment)^shape_parameter
}

medians <- medians[,1:2]
sample_size <- 400
ratio <- c(2/3,1/3)
rand_type <- "CR" 
scenarios_eff <- as.matrix(medians, nrow = length(control_medians), ncol = 2, byrow = TRUE)
censor <- c(0.05,0.05) # 10% drop-out
Tmax <- 32
alpha <- 0.05 
test.type <- 2
HR_1 <- TRUE
IA <- c(0.5, 0.75)
method_IA <- "OF"
n_exp_events <- 330
Plot_Power <- FALSE
plot_pvalues = FALSE 
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = TRUE
analysis = "bayes"
n_sim <- 3000
seed <- 24
# 1) Shape control, 2) rate control, 3) Shape experimental y 4) rate experimental
prior_gamma <- matrix(c(4.328085, 1, 1, 1/16), nrow = 2, ncol = 2, byrow = TRUE) 
prior_type <- c("Weak Informative prior (O'Brien) ~ Ga(4.328085, 1)") 
P_HR_data_Boundary <- 0.8 # P(HR < 0.8 | data)
modelo_weibull_sep <- rstan::stan_model("weibull_gamma_def.stan" ,verbose = F)
modelo = modelo_weibull_sep
modelo_bayes_test = "weibull"
w = NULL
a0 = NULL

# sim15 <-  sim_trials(n_sim = n_sim,
#                      analysis = "bayes",
#                      sample_size = sample_size,
#                      ratio = ratio,
#                      rand_type = rand_type,
#                      Tmax = Tmax,
#                      scenarios_eff = scenarios_eff,
#                      shape_parameter = shape_parameter,
#                      censor = censor,
#                      test.type = test.type,
#                      alpha = alpha,
#                      method_IA = method_IA,
#                      IA = IA,
#                      n_exp_events = n_exp_events,
#                      HR_1 = HR_1,
#                      Plot_Power = Plot_Power,
#                      modelo = modelo,
#                      modelo_bayes_test = modelo_bayes_test,
#                      prior_type = prior_type,
#                      P_HR_data_Boundary = P_HR_data_Boundary,
#                      prior_gamma = prior_gamma,
#                      Plot_Power_scenarios = Plot_Power_scenarios,
#                      desired_HRs = desired_HRs,
#                      plot_pvalues = plot_pvalues,
#                      Plot_Control_Scenarios = Plot_Control_Scenarios,
#                      seed = seed)
# sim15[[2]]
# sim15[[3]]
# sim15[[4]]
# 
# sim1515 <- sim15[[1]]
# 
# wd <- createWorkbook()
# addWorksheet(wd, "Sheet1")
# writeData(wd, "Sheet1", sim1515)
# saveWorkbook(wd, "Bayes_Weak_Informative_OBrien_400_3000.xlsx", overwrite = TRUE)


sheet_names <- c("Sheet1")
weak_informative_gamma_obrien <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/Blincyto_PhALL_Tablas/Bayes_Weak_Informative_OBrien_400_3000.xlsx", sheet = sheet_names[1])

```

## Weak Informative con Kantarijan

parameters <- medians / (log(2)^(1/shape_parameter))

Control: Mediana de 4.7 es 6.780667

```{r `Bayes: Weak informative prior distribution Kantarijan`, eval = T}


shape_parameter <- 1 

control_medians <- c(2,2.25,2.5,2.75,3,3.25,3.5,3.75,4,4.2,4.25,4.5,4.75,5,5.25,5.5,5.75,6,6.25,6.5,6.75,7,7.25,7.5,7.75,8,8.25,8.5,8.75,9)

medians <- matrix(NA, nrow = length(control_medians), ncol = 3, 
                  dimnames = list(NULL, c("Control", "Treatment", "Hazard Ratio")))

desired_HR = 0.7

for (i in 1:length(control_medians)) {
  medians[i, "Control"] <- control_medians[i]
  
  lambda_control = control_medians[i] / (log(2)^(1/shape_parameter))
  lambda_treatment = lambda_control / desired_HR^(1/shape_parameter)
  
  medians[i, "Treatment"] = lambda_treatment * (log(2)^(1/shape_parameter))
  medians[i, "Hazard Ratio"] = (lambda_control / lambda_treatment)^shape_parameter
}

medians <- medians[,1:2]
sample_size <- 400
ratio <- c(2/3,1/3)
rand_type <- "CR" 
scenarios_eff <- as.matrix(medians, nrow = length(control_medians), ncol = 2, byrow = TRUE)
censor <- c(0.05,0.05) # 10% drop-out
Tmax <- 32 # Aquí tengo dudas, muy pocos pacientes llegan al final pero parece que es lo que pone en el SAP
alpha <- 0.05 
test.type <- 2
HR_1 <- TRUE
IA <- c(0.5, 0.75)
method_IA <- "OF"
n_exp_events <- 330
Plot_Power <- FALSE
plot_pvalues = FALSE 
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = TRUE
analysis = "bayes"
n_sim <- 3000
seed <- 24
# 1) Shape control, 2) rate control, 3) Shape experimental y 4) rate experimental
prior_gamma <- matrix(c(6.780667, 1, 1, 1/16), nrow = 2, ncol = 2, byrow = TRUE) 
prior_type <- c("Weak Informative prior (Kantarijan) ~ Ga(6.780667, 1)") 
P_HR_data_Boundary <- 0.8 # P(HR < 0.8 | data)
modelo_weibull_sep <- rstan::stan_model("weibull_gamma_def.stan" ,verbose = F)
modelo = modelo_weibull_sep
modelo_bayes_test = "weibull"
w = NULL
a0 = NULL

# sim23 <-  sim_trials(n_sim = n_sim,
#                      analysis = "bayes",
#                      sample_size = sample_size,
#                      ratio = ratio,
#                      rand_type = rand_type,
#                      Tmax = Tmax,
#                      scenarios_eff = scenarios_eff,
#                      shape_parameter = shape_parameter,
#                      censor = censor,
#                      test.type = test.type,
#                      alpha = alpha,
#                      method_IA = method_IA,
#                      IA = IA,
#                      n_exp_events = n_exp_events,
#                      HR_1 = HR_1,
#                      Plot_Power = Plot_Power,
#                      modelo = modelo,
#                      modelo_bayes_test = modelo_bayes_test,
#                      prior_type = prior_type,
#                      P_HR_data_Boundary = P_HR_data_Boundary,
#                      prior_gamma = prior_gamma,
#                      Plot_Power_scenarios = Plot_Power_scenarios,
#                      desired_HRs = desired_HRs,
#                      plot_pvalues = plot_pvalues,
#                      Plot_Control_Scenarios = Plot_Control_Scenarios,
#                      seed = seed)
# sim23[[2]]
# sim23[[3]]
# sim23[[4]]
# 
# sim230 <- sim23[[1]]
# 
# wd <- createWorkbook()
# addWorksheet(wd, "Sheet1")
# writeData(wd, "Sheet1", sim230)
# saveWorkbook(wd, "Bayes_Weak_Informative_Kantarijan_400_3000.xlsx", overwrite = TRUE)


sheet_names <- c("Sheet1")
weak_informative_gamma_Kantarijan <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/Blincyto_PhALL_Tablas/Bayes_Weak_Informative_Kantarijan_400_3000.xlsx", sheet = sheet_names[1])

# OBRIEN

data_weak_informative_gamma_obrien <- weak_informative_gamma_obrien %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "Weak Prior O'Brien")

data_filtered_diff_not_zero_weak_informative_gamma_obrien <- data_weak_informative_gamma_obrien %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_weak_informative_gamma_obrien <- data_weak_informative_gamma_obrien %>%
  filter(median_control == median_treatment)

#KANTARIJAN

data_weak_informative_gamma_Kantarijan <- weak_informative_gamma_Kantarijan %>%
  group_by(scenario) %>%
  summarize(prop_significant = sum(count_significant) / (sum(count_significant) + sum(count_not_significant)),
            mean_HR = mean(mean_HR), mean_MSE = mean(MSE)) %>%
  left_join(scenarios_eff_df, by = "scenario") %>%
  mutate(Prior = "Weak Prior Kantarijan")

data_filtered_diff_not_zero_weak_informative_gamma_Kantarijan <- data_weak_informative_gamma_Kantarijan %>%
  filter(median_control != median_treatment)

data_filtered_diff_zero_weak_informative_gamma_Kantarijan <- data_weak_informative_gamma_Kantarijan %>%
  filter(median_control == median_treatment)


combined_data_diff_not_zero <- bind_rows(data_filtered_diff_not_zero_frequentist,
                                         data_filtered_diff_not_zero_weak_informative_gamma_obrien,
                                         data_filtered_diff_not_zero_weak_informative_gamma_Kantarijan)

combined_data_diff_zero <- bind_rows(data_filtered_diff_zero_frequentist,
                                     data_filtered_diff_zero_weak_informative_gamma_obrien,
                                     data_filtered_diff_zero_weak_informative_gamma_Kantarijan)

## Ahora sacamos las gráficas de las características operantes usando como prior el MAP Bayesiano con pesos ##

# MSE

p6 <- ggplot(combined_data_diff_not_zero, aes(x = median_control, y = mean_MSE, color = Prior)) + 
  geom_line(size = 1.2) +
  geom_vline(xintercept = median_control_center, linetype = "solid") +
  labs(
    title = "Mean Square Error (MSE)",
    x = "Median Control Arm (in months)",
    y = "Mean MSE",
    color = "Bayesian Prior Distributions"
  ) +
  theme_minimal() + 
  theme(
    plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 10, face = "bold"),
    axis.text = element_text(size = 12),
    axis.title.x = element_text(size = 11),
    axis.title.y = element_text(size = 11),
    legend.margin = margin(9, 9, 9, 9),
    legend.text = element_text(size = 9),
    legend.title = element_text(size = 10, face = "bold")
  ) +
  scale_color_discrete(name = "Bayesian Prior Distributions") +
  scale_x_continuous(breaks = seq(min(combined_data_diff_not_zero$median_control), max(combined_data_diff_not_zero$median_control), by = 0.5)) +
  scale_y_continuous(limits = c(0, 0.075))

p6

# Power

p7 <- ggplot(combined_data_diff_not_zero, aes(x = median_control, y = prop_significant, color = Prior)) +
  geom_line(size = 1.2) + 
  geom_line() +
  geom_vline(xintercept = median_control_center, linetype = "dashed") +
  labs(title = "Power", x = "Median Control Arm (in months)", y = "Proportion of Significant Trials", color = "Bayesian Prior Distributions") +
  theme_minimal() + 
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 12),
        axis.title.x = element_text(size = 11),
        axis.title.y = element_text(size = 11),
        legend.margin = margin(12, 12, 12, 12),
        legend.text = element_text(size = 11),
        legend.title = element_text(size = 12, face = "bold")) +
  scale_color_discrete(name = "Bayesian Prior Distributions") +
  scale_linetype_discrete(name = "Bayesian Prior Distributions") +
  scale_x_continuous(breaks = seq(min(combined_data_diff_not_zero$median_control), max(combined_data_diff_not_zero$median_control), by = 0.5)) +
  scale_y_continuous(limits = c(0.5, 1))
p7

# ET1

p8 <- ggplot(combined_data_diff_zero, aes(x = median_control, y = prop_significant, color = Prior)) +
  geom_line(size = 1.2) + 
  geom_line() +
  geom_vline(xintercept = median_control_center, linetype = "dashed") +
  geom_hline(yintercept = 0.025, linetype = "dashed", color = "green") +
  geom_hline(yintercept = 0.05, linetype = "dashed", color = "purple") +
  labs(title = "Type I Error (T1E)", x = "Median Control (in months)", y = "Proportion of Significant Trials", color = "Bayesian Prior Distributions") +
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 12),
        axis.title.x = element_text(size = 11),
        axis.title.y = element_text(size = 11),
        legend.margin = margin(12, 12, 12, 12),
        legend.text = element_text(size = 11),
        legend.title = element_text(size = 12, face = "bold")) +
  scale_color_discrete(name = "Bayesian Prior Distributions") +
  scale_linetype_discrete(name = "Bayesian Prior Distributions") +
  scale_x_continuous(breaks = seq(min(combined_data_diff_zero$median_control), max(combined_data_diff_zero$median_control), by = 0.5)) +
  scale_y_continuous(limits = c(0, 0.2))
p8

```

```{r T1E_combined_powerprior2, eval = T}

library(cowplot)

p66 <- p6 + scale_color_discrete(
  name = "Bayesian Prior Distributions", 
  labels = c(
        "Frequentist",
        "Weak Informative Prior Based on Kantarjian",
        "Weak Informative Prior Based on O'Brien"
  )
) +
  guides(color = guide_legend(ncol = 3))  

legend <- get_legend(
  p66 +
    theme(
      # legend.box = "horizontal", 
      legend.justification = c(0, 1),
      # legend.margin = margin(8, 8, 8, 8),
      legend.text = element_text(size = 10), 
      legend.title = element_text(size = 11, face = "bold")
    )
)

# Remove individual legends from the plots
p66 <- p66 + theme(legend.position = "none")
p77 <- p7 + theme(legend.position = "none")
p88 <- p8 + theme(legend.position = "none")

p66 <- p66 + theme(plot.background = element_rect(colour = "black", size = 0.5, fill = NA))
p77 <- p77 + theme(plot.background = element_rect(colour = "black", size = 0.5, fill = NA))
p88 <- p88 + theme(plot.background = element_rect(colour = "black", size = 0.5, fill = NA))

plots_row <- plot_grid(p66, p77, p88, ncol = 3, labels = c("A", "B", "C"), label_size = 14)

combined_plot <- plot_grid(
  plots_row,
  legend,
  ncol = 1,                 
  rel_heights = c(3, 0.4)   
)

print(combined_plot)

```

# Selección de Modelos para calcular el tamaño muestral con diferentes efectos de tratamiento.

Control: Mediana de 4.2 es 6.059319
Experimental: Mediana de 6 es 8.65617

Ahora vamos a elegir modelos tipos para ver cuántos pacientes nos ahorramos seleccionando algunos de los modelos anteriormente vistos. En todos los modelos se han hecho 5K simulaciones por cada tamaño muestral, mientras que en el frecuentista se ha hecho 100K (también hay otro de 5K pero ya que hecho el otro lo dejo):
  
  1) Frecuentista (100K) -> T = 15h42m48s
  2) Prior poco informativa centered at median 4.2 months con Ga(6.059319, 1). (Se infla un poco en mes 8.5)
  3) Robust Mixture Prior: 0.1 Prior MAP + 0.9 Prior no informativa 
  4) Robust Mixture Prior: 0.2 Prior MAP + 0.8 Prior no informativa 
  5) Robust Mixture Prior: 0.3 Prior MAP + 0.7 Prior no informativa 
  6) Weak Kantarijan


Al final todos los MAP inflan un poco el ET1, aunque hasta el 0.3 podría ser aceptable levantando la mano
En la Power prior todos los modelos se disparan a partir del mes 5, así que de estos ninguno. Así mismo, en los dos dynamic power prior tiene un comportamiento similar y se disparan como en los power prior, así que nada.

Creo que como solución y viendo las referencias de O'Brien (3 meses) y Kantarijan (4.7), voy a hacer tanto el weak informative con la asunción de 2.2 y 6.2 (o hago con la de 3 o 4.7?), mejor con el de las referencias.


  
Usando estos modelos, vamos a ver cuántos pacientes son necesarios para obtener un poder del 80%, 85% y 90% de poder. Como para evaluar estos modelos se han usado diferentes asunciones para el efecto del brazo control, vamos a asumir 2 tipos de efectos para cada uno de los modelos a la hora de generar los datos:
    
1) Efecto que se especificó en el SAP para el brazo experimental y control
2) Efecto obtenido al final del estudio para el brazo experimental y control. Para este, tengo que modificar el código para poder tener 2 shapes diferentes a la hora de general los datos para cada uno de los brazos. Primero hago una regresión weibull para cada uno de los brazos por separado y ahí, lo incorporo en el código.

Luego hay que crear una tabla resumen con cada uno de los modelos y los números de pacientes necesarios para cada uno de los 3 poderes para cada uno de los efectos diferentes. Así mismo, se especificarán los valores de MSE, poder y T1E obtenidos anteriormente.

Sin necesidad de poner los inputs para todos los modelos ya que se han hecho anteriormente, aquí sólo muestro como son los inputs para el modelo frecuentista y uno de los modelos Bayesianos.

Como esto es para los resultados finales, el nº de simulaciones por escenario ha aumentado de 3.000 a 5.000.

Como ya se han ejecutado, voy a leer los resultados directamente de todos los modelos moviendo todos los tamaños muestrales.

1) Frecuentista - SAP

```{r `Final models: Frequentist - SAP`, eval = T, echo = T}

shape_parameter <- 1
sample_size <- seq(from = 250, to= 500, by = 5)
ratio <- c(2/3,1/3)
rand_type <- "CR" 
scenarios_eff <- matrix(c(4.2,6), nrow = 1, ncol = 2, byrow = TRUE) # HR=0.7
censor <- c(0.05,0.05) # 10% drop-out
Tmax <- 32 
alpha <- 0.05 
test.type <- 2
IA <- c(0.5, 0.75)
method_IA <- "OF"
n_exp_events <- 330
HR_1 <- FALSE
Plot_Power = TRUE
plot_pvalues = FALSE
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = FALSE
analysis = "freq" 
n_sim <- 3000
seed <- 24


 # sim2 <- sim_trials(n_sim = n_sim,
 #                    analysis = "freq",
 #                    sample_size = sample_size,
 #                    ratio = ratio,
 #                    rand_type = rand_type,
 #                    Tmax = Tmax,
 #                    shape_parameter = shape_parameter,
 #                    scenarios_eff = scenarios_eff,
 #                    censor = censor,
 #                    alpha = alpha,
 #                    test.type = test.type,
 #                    IA = IA,
 #                    method_IA = method_IA,
 #                    n_exp_events = n_exp_events,
 #                    HR_1 = HR_1,
 #                    seed=seed,
 #                    Plot_Power = Plot_Power,
 #                    plot_pvalues = plot_pvalues)
 # 
 # 
 # wd <- createWorkbook()
 # addWorksheet(wd, "Sheet1")
 # writeData(wd, "Sheet1", sim2)
 # saveWorkbook(wd, "DEF_SAP_Freq_con_IAs_SampleSizes.xlsx", overwrite = TRUE)

# Con IAs
sheet_names <- c("Sheet1")
SAP_Freq_SampleSizes <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/DEF_SAP_Freq_con_IAs_SampleSizes.xlsx", sheet = sheet_names[1])

DEF_SAP_Freq_con_IAs_Power <- subset(SAP_Freq_SampleSizes, scenario == 1,
                             select = c(scenario, sample_size, prop_significant)) %>%
  mutate(Prior = "Frequentist")

# # Sin IAs
# sheet_names <- c("Sheet1")
# SAP_Freq_SampleSizes <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/DEF_SAP_Freq_sin_IAs_SampleSizes.xlsx", sheet = sheet_names[1])
# 
# DEF_SAP_Freq_sin_IAs_Power <- subset(SAP_Freq_SampleSizes, scenario == 1,
#                              select = c(scenario, sample_size, prop_significant)) %>%
#   mutate(Prior = "Frequentist (no IAs)")

```


2) Bayes: Weak Prior centered at median 4.2 months, Gamma(6.059319, 1) - SAP

```{r `Final models: Bayes - Weak prior Gamma(7.213475, 1) - SAP`, eval = T}

shape_parameter <- 1 
sample_size <- seq(from = 250, to= 500, by = 5)
ratio <- c(2/3,1/3)
rand_type <- "CR" 
scenarios_eff <- matrix(c(4.2,6), nrow = 1, ncol = 2, byrow = TRUE) # HR=0.7
censor <- c(0.05,0.05) # 10% drop-out
Tmax <- 32 
alpha <- 0.05 
test.type <- 2
IA <- c(0.5, 0.75)
method_IA <- "OF"
n_exp_events <- 330
HR_1 <- FALSE
Plot_Power = TRUE
plot_pvalues = FALSE
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = FALSE
analysis = "bayes"
n_sim <- 3000
seed <- 24
# 1) Shape control, 2) rate control, 3) Shape experimental y 4) rate experimental
prior_gamma <- matrix(c(6.059319, 1, 1, 1/16), nrow = 2, ncol = 2, byrow = TRUE) 
prior_type <- c("Weak Informative prior ~ Ga(6.059319, 1)") 
P_HR_data_Boundary <- 0.8 # P(HR < 0.8 | data)
modelo_weibull_sep <- rstan::stan_model("weibull_gamma_def.stan" ,verbose = F)
modelo = modelo_weibull_sep
modelo_bayes_test = "weibull"
w = NULL
a0 = NULL

# sim6 <-  sim_trials(n_sim = n_sim,
#                      analysis = "bayes",
#                      sample_size = sample_size,
#                      ratio = ratio,
#                      rand_type = rand_type,
#                      Tmax = Tmax,
#                      scenarios_eff = scenarios_eff,
#                      shape_parameter = shape_parameter,
#                      censor = censor,
#                      test.type = test.type,
#                      alpha = alpha,
#                      method_IA = method_IA,
#                      IA = IA,
#                      n_exp_events = n_exp_events,
#                      HR_1 = HR_1,
#                      Plot_Power = Plot_Power,
#                      modelo = modelo,
#                      modelo_bayes_test = modelo_bayes_test,
#                      prior_type = prior_type,
#                      P_HR_data_Boundary = P_HR_data_Boundary,
#                      prior_gamma = prior_gamma,
#                      Plot_Power_scenarios = Plot_Power_scenarios,
#                      desired_HRs = desired_HRs,
#                      plot_pvalues = plot_pvalues,
#                      Plot_Control_Scenarios = Plot_Control_Scenarios,
#                      seed = seed)
# 
# wd <- createWorkbook()
# addWorksheet(wd, "Sheet1")
# writeData(wd, "Sheet1", sim6)
# saveWorkbook(wd, "DEF_SAP_Bayes_Weak_Informative_SampleSizes.xlsx", overwrite = TRUE)


sheet_names <- c("Sheet1")

# Weak Prior 
DEF_SAP_Bayes_Weak_Informative_SampleSizes <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/Blincyto_PhALL_Tablas/DEF_SAP_Bayes_Weak_Informative_SampleSizes.xlsx", sheet = sheet_names[1])

DEF_SAP_Weak_informative_Power <- subset(DEF_SAP_Bayes_Weak_Informative_SampleSizes, scenario == 1,
                                         select = c(scenario, sample_size, Prior, prop_significant)) %>%
  mutate(Prior = "Weak Informative Prior centered at 4.2 months")

# Weak Prior Kantarijan
DEF_SAP_Bayes_Weak_Informative_Kantarijan_SampleSizes <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/Blincyto_PhALL_Tablas/DEF_SAP_Bayes_Weak_Informative_Kantarijan_SampleSizes.xlsx", sheet = sheet_names[1])

DEF_SAP_Weak_informative_Kantarijan_Power <- subset(DEF_SAP_Bayes_Weak_Informative_Kantarijan_SampleSizes, scenario == 1, select = c(scenario, sample_size, Prior, prop_significant)) %>%
  mutate(Prior = "Weak Informative Prior centered at 4.7 months (Kantarjian)")

```

3) Robust Mixture Prior: 0.1 Prior MAP + 0.9 Prior no informativa
4) Robust Mixture Prior: 0.2 Prior MAP + 0.8 Prior no informativa
5) Robust Mixture Prior: 0.3 Prior MAP + 0.7 Prior no informativa

```{r `Final models: Robust Mixture Prior - SAP`, eval = T}

shape_parameter <- 1 
sample_size <- seq(from = 250, to= 500, by = 5)
ratio <- c(2/3,1/3)
rand_type <- "CR" 
scenarios_eff <- matrix(c(4.2,6), nrow = 1, ncol = 2, byrow = TRUE) # HR=0.7
censor <- c(0.05,0.05) # 10% drop-out
Tmax <- 32 
alpha <- 0.05 
test.type <- 2
IA <- c(0.5, 0.75)
method_IA <- "OF"
n_exp_events <- 330
HR_1 <- FALSE
Plot_Power = TRUE
plot_pvalues = FALSE
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = FALSE
Dynamic_Borrowing_PP = FALSE
analysis = "bayes"
n_sim <- 3000
seed <- 24
# 1) Shape control, 2) rate control, 3) Shape experimental y 4) rate experimental
prior_gamma <- matrix(c(alpha_map_freq, beta_map_freq, 1, 1/16), nrow = 2, ncol = 2, byrow = TRUE) 
prior_type <- c("Robust Mixture MAP Prior w = 0.1") # Este vector es para que aparezca el nombre en las tablas
P_HR_data_Boundary <- 0.8 # P(HR < 0.8 | data)
modelo_weibull_sep <- rstan::stan_model("weibull_mixture_gamma_sh_uniform.stan" ,verbose = F) # Este es el STAN con Ga(1, 1/6)
modelo = modelo_weibull_sep
modelo_bayes_test = "weibull"
w = 0.1
a0 = NULL

# sim7 <-  sim_trials(n_sim = n_sim,
#                        analysis = "bayes",
#                        sample_size = sample_size,
#                        ratio = ratio,
#                        rand_type = rand_type,
#                        Tmax = Tmax,
#                        scenarios_eff = scenarios_eff,
#                        shape_parameter = shape_parameter,
#                        censor = censor,
#                        test.type = test.type,
#                        alpha = alpha,
#                        method_IA = method_IA,
#                        IA = IA,
#                        n_exp_events = n_exp_events,
#                        HR_1 = HR_1,
#                        Plot_Power = Plot_Power,
#                        modelo = modelo,
#                        modelo_bayes_test = modelo_bayes_test,
#                        prior_type = prior_type,
#                        P_HR_data_Boundary = P_HR_data_Boundary,
#                        prior_gamma = prior_gamma,
#                        Plot_Power_scenarios = Plot_Power_scenarios,
#                        desired_HRs = desired_HRs,
#                        plot_pvalues = plot_pvalues,
#                        Plot_Control_Scenarios = Plot_Control_Scenarios,
#                        w = w,
#                        a0 = a0,
#                        seed = seed)
# 
# 
# wd <- createWorkbook()
# addWorksheet(wd, "Sheet1")
# writeData(wd, "Sheet1", sim7)
# saveWorkbook(wd, "DEF_SAP_Bayes_Mixture_MAP_w_0.1_SampleSizes.xlsx", overwrite = TRUE)

sheet_names <- c("Sheet1")

# 3) Robust Mixture Prior: 0.1 Prior MAP + 0.9 Prior no informativa

SAP_Bayes_Mixture_MAP_w_0.1_SampleSizes <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/Blincyto_PhALL_Tablas/DEF_SAP_Bayes_Mixture_MAP_w_0.1_SampleSizes.xlsx", sheet = sheet_names[1])

DEF_SAP_Mixture_0.1_Power <- subset(SAP_Bayes_Mixture_MAP_w_0.1_SampleSizes, scenario == 1,
                                     select = c(scenario, sample_size, Prior, prop_significant)) %>%
  mutate(Prior = "Robust Mixture MAP Prior w=0.1")

# 4) Robust Mixture Prior: 0.2 Prior MAP + 0.8 Prior no informativa

SAP_Bayes_Mixture_MAP_w_0.2_SampleSizes <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/Blincyto_PhALL_Tablas/DEF_SAP_Bayes_Mixture_MAP_w_0.2_SampleSizes.xlsx", sheet = sheet_names[1])

DEF_SAP_Mixture_0.2_Power <- subset(SAP_Bayes_Mixture_MAP_w_0.2_SampleSizes, scenario == 1,
                                     select = c(scenario, sample_size, Prior, prop_significant)) %>%
  mutate(Prior = "Robust Mixture MAP Prior w=0.2")

# 5) Robust Mixture Prior: 0.3 Prior MAP + 0.7 Prior no informativa

SAP_Bayes_Mixture_MAP_w_0.3_SampleSizes <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/Blincyto_PhALL_Tablas/DEF_SAP_Bayes_Mixture_MAP_w_0.3_SampleSizes.xlsx", sheet = sheet_names[1])

DEF_SAP_Mixture_0.3_Power <- subset(SAP_Bayes_Mixture_MAP_w_0.3_SampleSizes, scenario == 1,
                                     select = c(scenario, sample_size, Prior, prop_significant)) %>%
  mutate(Prior = "Robust Mixture MAP Prior w=0.3")

```

# LECTURA RESULTADOS TAMAÑOS MUESTRALES DEL SAP

```{r `Final models: Lectura datos SAP`, eval = T}

# Combinamos los datos 



combined_data_DEF_SAP_Power <- bind_rows(DEF_SAP_Freq_con_IAs_Power,
                                         DEF_SAP_Weak_informative_Power,
                                         DEF_SAP_Weak_informative_Kantarijan_Power,
                                         DEF_SAP_Mixture_0.1_Power,
                                         DEF_SAP_Mixture_0.2_Power,
                                         DEF_SAP_Mixture_0.3_Power)


# Dibujamos el plot del poder:

desired_powers <- c(0.8, 0.85, 0.9, 0.95)
colors_for_dotted_lines <- c("purple", "blue", "green", "red") 

p1 <- ggplot(combined_data_DEF_SAP_Power, aes(x = sample_size, y = prop_significant, group = Prior, color = Prior)) +
  geom_point(size = 3) +  
  geom_line(linewidth = 1) +  
  geom_hline(yintercept = desired_powers, linetype = "dotted", color = colors_for_dotted_lines, size = 1) + 
  scale_x_continuous(breaks = seq(min(combined_data_DEF_SAP_Power$sample_size)-5, max(combined_data_DEF_SAP_Power$sample_size)+5, 25)) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Power for Selected Bayesian Models",
       x = "Sample Size",
       y = "Power") +
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 12),
        axis.title.x = element_text(size = 11),
        axis.title.y = element_text(size = 11),
        legend.margin = margin(12, 12, 12, 12),
        legend.text = element_text(size = 11),
        legend.title = element_text(size = 12, face = "bold")) +
  scale_color_discrete(name = "Bayesian Prior Distributions") +
  scale_linetype_discrete(name = "Bayesian Prior Distributions") 

rightmost_x <- max(combined_data_DEF_SAP_Power$sample_size) - 5  
for (i in 1:length(desired_powers)) {
  p1 <- p1 + annotate("text", 
                      x = rightmost_x, 
                      y = desired_powers[i], 
                      label = sprintf("%.0f%% power", desired_powers[i] * 100), 
                      hjust = 1,  
                      vjust = -0.3,  
                      size = 3.5, 
                      color = colors_for_dotted_lines[i])
}

p1

#Ahora hacemos una tabla para identificar cuál alcanza el poder antes.

desired_powers <- c(0.8, 0.85, 0.9, 0.95)

tabla <- function(df, target) {
  df %>%
    group_by(Prior) %>%
    filter(prop_significant >= target) %>%
    arrange(sample_size) %>%
    slice(1) %>%
    summarize(sample_size = first(sample_size), .groups = 'drop') %>%
    mutate(Power = as.character(target))  
}

results <- lapply(desired_powers, function(p) tabla(combined_data_DEF_SAP_Power, p))
results_df <- do.call(rbind, results)

Table_Power <- pivot_wider(
  results_df, 
  names_from = Prior, 
  values_from = sample_size, 
  id_cols = Power,
  values_fill = list(sample_size = NA)
)

Table_Power_df <- as.data.frame(Table_Power)

Table_Power_df <- Table_Power_df[c("Power", "Frequentist", "Weak Informative Prior centered at 4.2 months", "Weak Informative Prior centered at 4.7 months (Kantarjian)", 
            "Robust Mixture MAP Prior w=0.1", "Robust Mixture MAP Prior w=0.2", "Robust Mixture MAP Prior w=0.3")]

Table_Power_df[is.na(Table_Power_df)] <- "-"

table5 <- gt(Table_Power_df) %>%
  tab_header(title = "Sample Sizes Achieving Target Powers with Different Bayesian Models") %>%
  cols_label(
  ) %>%
  fmt_number(
    columns = c(-Power),
    decimals = 0  
  ) %>%
  tab_style(
    style = cell_text(weight = "bold", align = "center"),
    locations = cells_column_labels(columns = everything())
  ) %>%
  tab_options(
    column_labels.background.color = "lightsteelblue1",
    table.font.size = px(25),
    table.background.color = "white"
  ) %>%
  tab_style(
    style = cell_fill(color = "lightsteelblue1"),
    locations = cells_body(rows = seq(2, nrow(Table_Power_df), by = 2))
  ) %>%
  tab_style(
    style = cell_fill(color = "white"),
    locations = cells_body(rows = seq(1, nrow(Table_Power_df), by = 2))
  ) %>%
  tab_style(
    style = cell_text(align = "center"),
    locations = cells_body(columns = everything())
  ) %>% 
  tab_style(
    style = cell_fill(color = "lightsteelblue1"),  
    locations = cells_body(columns = "Power")
  ) %>%
  tab_style(
    style = cell_borders(sides = "bottom", color = "black", weight = px(2)),
    locations = cells_column_labels(columns = names(Table_Power_df)[names(Table_Power_df) != "Power"])
  ) %>%
  tab_style(
    style = cell_borders(sides = "right", color = "black", weight = px(2)),
    locations = cells_body(columns = "Power")
  ) %>%
  tab_style(
    style = cell_text(weight = "bold"),  
    locations = cells_body(columns = "Power")
  ) 

table5


```


TABLA DE TAMAÑOS MUESTALES: 

       Freq   Freq (sin IAs)   Weak       Weak_Kantarijan    MAP_10%     MAP_20%    MAP_30%
0.75    350         340         315              320           345         345       355
 0.8    400         380         365              380           390         390       390
0.85    450         440         410              420           440         440       440
 0.9     -          495         495              495            -           -         -


PD: Para quedarme con los tamaños muestrales, ignoro los obtenidos por los 2 métodos frecuentistas.
Así mismo, los tamaños muestrales de 400 y 456 los he añadido ya que son los tamaños que planearon en el SAP y el que obtuvieron respectivamente.

Tamaños muestrales diferentes: 315, 320, 345, 355, 365, 380, 390, 400, 410, 420, 440, 456, 495


# Datos Reales obtenidos en el ensayo

Se han evaluado los resultados finales de este estudio para hacernos una idea de los parámetros necesarios para los modelos parámetricos que se va a utilizar. Para ello es necesario tener los datos paciente a paciente para poder usar estos datos en R y poder hacer inferencias. Ya que por temas de confidencialidad no ha sido posible, lo que se ha hecho ha sido digitalizar las curvas de Kaplan-Meier para el resultado de PFS (variable principal). 

Esta digitalización se ha hecho usando las funciones propuestas por Lui et al 2021.

Link paper: https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/s12874-021-01308-8#availability-of-data-and-materials

Link shiny app: https://www.trialdesign.org/one-page-shell.html#IPDfromKM

Cuando se escriba la tesis pondré el resto de referencias y como funciona esto.

A continuación tenemos el resultado final de PFS:
  

```{r `Results using pseudo-IPD in both arms`, eval = T, echo = T}

# Leemos los datos obtenidos a través de las coordenadas de cada uno de los puntos seleccionados de las dos curvas:

trt <- read.csv("IPD_Experimental_Blincyto.csv")
trt$arm <- "Blincyto"
soc <- read.csv("IPD_SoC_Blincyto.csv")
soc$arm <- "SOC"

# Juntamos los datasets para hacer la regresion de Cox
data <- rbind(trt,soc)

# Estimacion Cox (lo que se hace en la simulacion de momento)
fit <- coxph(Surv(Survival.time, Status) ~ arm, data = data)
Estimate <- c(1/exp(confint(fit))[2], 1/summary(fit)$coefficients[2], 1/exp(confint(fit))[1])

fit_soc <- survfit(Surv(Survival.time, Status) ~ 1, data = soc)
fit_trt <- survfit(Surv(Survival.time, Status) ~ 1, data = trt)

time_seq <- seq(min(data$Survival.time), max(data$Survival.time), length.out = 100)

plot(fit_soc, col = "blue", main = "Kaplan-Meier Plot with pseudo IPD", xlab = "Time", ylab = "Survival Probability", lty = 1, conf.int = FALSE)
lines(fit_trt, col = "red", lty = 1, conf.int = FALSE)

```

Podemos observar que las dos curvas son prácticamente iguales usando los pseudo-datos de paciente a paciente estimado con la digitalización. Así mismo, los resultados son muy similares ya que en el estudio real se obtuvo un HR en PFS de 0.71 (0.55, 0.93) con medianas de 7.7 (5.6, 9.6) y 4 (2.9, 5.3) para el brazo experimental y el control respectivamente. Por otro lado, usando los datos digitalizados tenemos un HR de 0.763 (0.563, 1.035).

# Parametric survival model applied to a pseudo IPD from the Blincyto

Una vez que tenemos unos datos que se aproximan bastante bien a los reales, vamos a hacer un fit paramétrico. Para ello, vamos a ver que modelo se aproximan mejor a estos datos. La elección para el modelo en cuestión se va a hacer en función del AIC (cuanto más bajo el valor, mejor modelo es comparado con el resto)

```{r `Fitting of parametric models`, eval = T, echo = T}
# Se van a considerar 4 modelos: Exponencial, Weibull, Gompertz y Log-normal
exp_mod <- flexsurvreg(Surv(Survival.time, Status) ~ arm, data = data, dist = "exp")
weibull_mod <- flexsurvreg(Surv(Survival.time, Status) ~ arm, data = data, dist = "weibull")
gompertz_mod <- flexsurvreg(Surv(Survival.time, Status) ~ arm, data = data, dist = "gompertz")
lognormal_mod <- flexsurvreg(Surv(Survival.time, Status) ~ arm, data = data, dist = "lnorm")

# Comparamos los modelos
model_list <- list(Exponential = exp_mod, Weibull = weibull_mod, Gompertz = gompertz_mod, LogNormal = lognormal_mod)
#sapply(model_list, AIC)

```

Podemos ver que la distribución Weibull es la que mejor se aproxima bien.

```{r `Weibull Fit`, eval = T, echo = T}

weibull_surv <- survreg(Surv(Survival.time, Status) ~ arm, dist = "weibull", data = data)

# El shape parameter común es 1.13017  (1/Scale)
# El scale parameter para el brazo experimental es 13.03967 (exp(Intercept))
# El scale parameter para el brazo control es 6.725033 (exp(Intercept+armsoc))
# El HR es 0.516 (exp(-armsoc))

# Por último, dibujar las curvas con el pseudo-IPD y el fit paramétrico del Weibull

time_seq <- seq(min(data$Survival.time), max(data$Survival.time), length.out = 100)

# P de supervivencia usando el modelo Weibull
weibull_soc_surv <- 1 - pweibull(time_seq, shape = 1/weibull_surv$scale, scale = exp(2.8348356-0.3640767))
weibull_trt_surv <- 1 - pweibull(time_seq, shape = 1/weibull_surv$scale, scale = exp(2.8348356))

plot(fit_soc, col = "blue", main = "Kaplan-Meier Plot with Weibull", xlab = "Time", ylab = "Survival Probability", lty = 1, conf.int = FALSE)
lines(fit_trt, col = "red", lty = 1, conf.int = FALSE)
lines(time_seq, weibull_soc_surv, col = "green", lty = 2)
lines(time_seq, weibull_trt_surv, col = "black", lty = 2)



```

Ahora vamos a hacer lo mismo pero brazo a brazo para simular los datos reales y obtener los parámetros de interés para la generación de datos.

```{r `Weibull Fit arm by arm`, eval = T, echo = T}


blincyto_data <- subset(data, arm == "Blincyto")
soc_data <- subset(data, arm == "SOC")

fit_blincyto_data <- coxph(Surv(Survival.time, Status) ~ 1, data = blincyto_data)
weibull_blincyto_data <- survreg(Surv(Survival.time, Status) ~ 1, dist = "weibull", data = blincyto_data)

# El shape parameter común es 0.813522  (1/Scale)
# El scale parameter para el brazo experimental es 16.94963 (exp(Intercept))

fit_soc_data <- survfit(Surv(Survival.time, Status) ~ 1, data = soc_data)
weibull_soc_data <- survreg(Surv(Survival.time, Status) ~ 1, dist = "weibull", data = soc_data)

# El shape parameter común es 0.7992308  (1/Scale)
# El scale parameter para el brazo experimental es 11.90518 (exp(Intercept))

fit_soc <- survfit(Surv(Survival.time, Status) ~ 1, data = soc)
fit_trt <- survfit(Surv(Survival.time, Status) ~ 1, data = trt)

time_seq <- seq(min(data$Survival.time), max(data$Survival.time), length.out = 100)

# P de supervivencia usando el modelo Weibull
weibull_blincyto_surv <- 1 - pweibull(time_seq, shape = 1/weibull_blincyto_data$scale, scale = 16.94963)
weibull_socc_surv <- 1 - pweibull(time_seq, shape = 1/weibull_soc_data$scale, scale = 11.90518)


# Kaplan-Meier survival data preparation for ggplot
fit_trt_df <- data.frame(time = fit_trt$time, surv = fit_trt$surv, group = "Blincyto (Pseudo-IPD)")
fit_soc_df <- data.frame(time = fit_soc$time, surv = fit_soc$surv, group = "SoC (Pseudo-IPD)")

# Weibull survival data preparation for ggplot
weibull_blincyto_df <- data.frame(time = time_seq, surv = weibull_blincyto_surv, group = "Blincyto (Weibull Model)")
weibull_soc_df <- data.frame(time = time_seq, surv = weibull_socc_surv, group = "SoC (Weibull Model)")

# Combine all data
combined_surv_df <- rbind(fit_trt_df, fit_soc_df, weibull_blincyto_df, weibull_soc_df)

# Plot using ggplot2
ggplot(combined_surv_df, aes(x = time, y = surv, color = group, linetype = group)) +
  geom_line(size = 1.2) +
  labs(
    title = "Kaplan-Meier of Pseudo-IPD with Weibull Model",
    x = "Months",
    y = "Survival Probability",
    color = "Group",
    linetype = "Group"
  ) +
  scale_color_manual(values = c("blue", "red", "green", "black")) +
  scale_linetype_manual(values = c("solid", "dashed", "solid", "dashed")) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 10, face = "bold"),
    axis.text = element_text(size = 12),
    axis.title.x = element_text(size = 11),
    axis.title.y = element_text(size = 11),
    legend.position = "bottom",
    legend.text = element_text(size = 10)
  )




plot(fit_trt, col = "blue", main = "Kaplan-Meier Plot with Weibull", xlab = "Months", ylab = "Survival Probability", lty = 1, conf.int = FALSE)
lines(fit_soc, col = "red", lty = 1, conf.int = FALSE)
lines(time_seq, weibull_blincyto_surv, col = "green", lty = 2)
lines(time_seq, weibull_socc_surv, col = "black", lty = 2) +
    theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 12),
        axis.title.x = element_text(size = 11),
        axis.title.y = element_text(size = 11))

# A ver, tengo que cambiar el shape para que se puedan generar diferentes shapes y scales. Muy a tener en cuenta, cuando tengamos un vector las comparaciones de MSE y coverage probability ya no son válidas por que le HR teórico no se puede calcular al necesitar un punto en concreto. No pasa nada, lo importante es que salga sifnificativo o no.


# Dibujo para asegurarme las líneas con sus scales y shapes de la weibull de los datos reales

weibull_survival <- function(time_seq, shape, scale) {
  return(exp(- (time_seq / scale)^shape))
}

# Parametros del soc
shape1 <- 0.7992308
scale1 <- 11.90518

# Parametros del blincyto
shape2 <- 0.813522
scale2 <- 11.90518

surv1 <- weibull_survival(time_seq, shape1, scale1)
surv2 <- weibull_survival(time_seq, shape2, scale2)

# Plot
# plot(time_seq, surv1, type = "l", col = "red", xlab = "Time", ylab = "Survival Probability", 
#      main = "Weibull Survival Curves")
# lines(time_seq, surv2, col = "blue")
# legend("topright", legend = c("SoC", "Pembro"), col = c("red", "blue"), lty = 1)

# Están bien los valores





```

Para entender qué hubiera pasado si se hubieran aplicado estos modelos en el momento del diseño del estudio, es interesante analizar los datos reales obtenidos y ver cómo estos modelos se comportan con los datos obtenidos.

Tengo que mirar publicaciones de otros paquetes que se han hecho para ver qué más resultados puedo tener

Para ello se van a cambiar los parámetros necesarios, por ejemplo el tamaño muestral, el efecto obtenido finalmente, etc.

En los datos reales mirando los resultados en OS. Aquí está el resumen:
  
1) HR: 0.71 (95% CI: 0.55, 0.93)
2) Mediana real en meses del brazo control: 4.0 (2.9, 5.3) 
3) Mediana real en meses del brazo experimental: 7.7 (5.6, 9.6) 

Por otro lado, para generar los datos simulados lo más realistas posibles se ha hecho lo siguiente:
  
1) Se han obtenido los datos paciente a paciente digitalizando las curvas para cada uno de los brazos
2) Se han sacado el fit para obtener los parámetros Shape y Scala de cada uno de los brazos.
3) Sólo se modifica el código de la función gen_surv_data.r común tanto para la simulación frecuentista como      Bayesiana. Hay que tener en cuenta que estoy forzando de manera artifical al poner estos parámetros dentro     de la función ya que el parámetro shape común y el parámetro de las eficacias se usan para diferentes    c     cosas y métricas, por lo que iba a ser muy jaleo modificar todo esto para ponerlo como input.
4) En el ordenador de multicore también se actualiza ya que de ahí es de donde saco los resultados finales.
5) Se obtienen los resultados como siempre, la diferencia radica en que cada uno de los dataset obtenidos por     cada simulación van a ser mucho más realistas a los obtenidos finalemente.

Por último, dado que estos son los resultados definitivos aproximando lo mejor posible a resultados reales, se han incrementado las simulaciones en cada escenario de 5.000 a 10.000 simulaciones.

Ahora tenemos un ejemplo de los nuevos parámetros que se van a considerar para la simulación frecuentista:

Tamaños muestrales diferentes: 315, 320, 345, 355, 365, 380, 390, 400, 410, 420, 440, 456, 495

  
```{r `Freq ejemplo con datos reales`, eval = T}

# SIMULACIÓN FRECUENTISTA CON Análisis Intermedios

shape_parameter <- 1
sample_size <- c(315, 320, 345, 355, 365, 380, 390, 400, 410, 420, 440, 456, 495)
ratio <- c(2/3,1/3)
rand_type <- "CR" 
scenarios_eff <- matrix(c(4.2,6), nrow = 1, ncol = 2, byrow = TRUE) # HR=0.7
censor <- c(0.052,0.1045) # SAP: 10% drop-out // REAL: 5,2% -> Experimental y 10,45% -> Control
Tmax <- 24 # Lo hicieron 8 meses más corto
alpha <- 0.05 
test.type <- 2
HR_1 <- FALSE
IA <- c(0.5, 0.75)
method_IA <- "OF"
n_exp_events <- 330
Plot_Power = FALSE
plot_pvalues = FALSE
analysis = "freq" 
n_sim <- 10000
seed <- 24

# sim9 <- sim_trials(n_sim = n_sim,
#                    analysis = "freq",
#                    sample_size = sample_size,
#                    ratio = ratio,
#                    rand_type = rand_type,
#                    Tmax = Tmax,
#                    shape_parameter = shape_parameter,
#                    scenarios_eff = scenarios_eff,
#                    censor = censor,
#                    alpha = alpha,
#                    test.type = test.type,
#                    IA = IA,
#                    method_IA = method_IA,
#                    n_exp_events = n_exp_events,
#                    HR_1 = HR_1,
#                    seed=seed,
#                    Plot_Power = Plot_Power,
#                    plot_pvalues = plot_pvalues)
# 
# 
# wd <- createWorkbook()
# addWorksheet(wd, "Sheet1")
# writeData(wd, "Sheet1", sim9)
# saveWorkbook(wd, "DEF_RESULTADOS_REALES_Freq_CON_IAs_10K_SampleSizes_DEF.xlsx", overwrite = TRUE)

# SIMULACIÓN FRECUENTISTA SIN Análisis Intermedios

shape_parameter <- 1
sample_size <- c(315, 320, 345, 355, 365, 380, 390, 400, 410, 420, 440, 456, 495)
ratio <- c(2/3,1/3)
rand_type <- "CR" 
scenarios_eff <- matrix(c(4.2,6), nrow = 1, ncol = 2, byrow = TRUE) # HR=0.7
censor <- c(0.052,0.1045) # SAP: 10% drop-out // REAL: 5,2% -> Experimental y 10,45% -> Control
Tmax <- 24 # Lo hicieron 8 meses más corto
alpha <- 0.05 
test.type <- 2
HR_1 <- FALSE
IA <- NULL
method_IA <- "OF"
n_exp_events <- 330
Plot_Power = FALSE
plot_pvalues = FALSE
analysis = "freq" 
n_sim <- 10000
seed <- 24

# sim10 <- sim_trials(n_sim = n_sim,
#                    analysis = "freq",
#                    sample_size = sample_size,
#                    ratio = ratio,
#                    rand_type = rand_type,
#                    Tmax = Tmax,
#                    shape_parameter = shape_parameter,
#                    scenarios_eff = scenarios_eff,
#                    censor = censor,
#                    alpha = alpha,
#                    test.type = test.type,
#                    IA = IA,
#                    method_IA = method_IA,
#                    n_exp_events = n_exp_events,
#                    HR_1 = HR_1,
#                    seed=seed,
#                    Plot_Power = Plot_Power,
#                    plot_pvalues = plot_pvalues)
# 
# 
# wd <- createWorkbook()
# addWorksheet(wd, "Sheet1")
# writeData(wd, "Sheet1", sim10)
# saveWorkbook(wd, "DEF_RESULTADOS_REALES_Freq_SIN_IAs_10K_SampleSizes_DEF.xlsx", overwrite = TRUE)

```

Y un ejemplo de un Bayesiano, en este caso el Weak:
  
```{r `Final models: Bayes - Weak prior Gamma(7.213475, 1) - SAP2`, eval = T}


# 1) # ESTE ES EL WEAK PRIOR

shape_parameter <- 1
sample_size <- c(315, 320, 345, 355, 365, 380, 390, 400, 410, 420, 440, 456, 495)
ratio <- c(2/3,1/3)
rand_type <- "CR" 
scenarios_eff <- matrix(c(4.2,6), nrow = 1, ncol = 2, byrow = TRUE) # HR=0.7
censor <- c(0.052,0.1045) # SAP: 10% drop-out // REAL: 5,2% -> Experimental y 10,45% -> Control
Tmax <- 24 # Lo hicieron 8 meses más corto
alpha <- 0.05 
test.type <- 2
IA <- c(0.5, 0.75)
method_IA <- "OF"
n_exp_events <- 330
HR_1 <- FALSE
Plot_Power = FALSE
plot_pvalues = FALSE 
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = FALSE
analysis = "bayes"
n_sim <- 10000
seed <- 24
# 1) Shape control, 2) rate control, 3) Shape experimental y 4) rate experimental
prior_gamma <- matrix(c(6.059319, 1, 1, 1/16), nrow = 2, ncol = 2, byrow = TRUE) 
prior_type <- c("Weak Informative prior ~ Ga(6.059319, 1)") 
P_HR_data_Boundary <- 0.8 # P(HR < 0.8 | data)
modelo_weibull_sep <- rstan::stan_model("weibull_gamma_def.stan" ,verbose = F)
modelo = modelo_weibull_sep
modelo_bayes_test = "weibull"
w = NULL
a0 = NULL

# sim10 <-  sim_trials(n_sim = n_sim,
#                     analysis = "bayes",
#                     sample_size = sample_size,
#                     ratio = ratio,
#                     rand_type = rand_type,
#                     Tmax = Tmax,
#                     scenarios_eff = scenarios_eff,
#                     shape_parameter = shape_parameter,
#                     censor = censor,
#                     test.type = test.type,
#                     alpha = alpha,
#                     method_IA = method_IA,
#                     IA = IA,
#                     n_exp_events = n_exp_events,
#                     HR_1 = HR_1,
#                     Plot_Power = Plot_Power,
#                     modelo = modelo,
#                     modelo_bayes_test = modelo_bayes_test,
#                     prior_type = prior_type,
#                     P_HR_data_Boundary = P_HR_data_Boundary,
#                     prior_gamma = prior_gamma,
#                     Plot_Power_scenarios = Plot_Power_scenarios,
#                     desired_HRs = desired_HRs,
#                     plot_pvalues = plot_pvalues,
#                     Plot_Control_Scenarios = Plot_Control_Scenarios,
#                     seed = seed)
# 
# 
# wd <- createWorkbook()
# addWorksheet(wd, "Sheet1")
# writeData(wd, "Sheet1", sim10)
# saveWorkbook(wd, "DEF_RESULTADOS_REALES_Bayes_Weak_10K_SampleSizes.xlsx", overwrite = TRUE)


# 2) # ESTE ES EL WEAK PRIOR KANTARIJAN

shape_parameter <- 1
sample_size <- c(315, 320, 345, 355, 365, 380, 390, 400, 410, 420, 440, 456, 495)
ratio <- c(2/3,1/3)
rand_type <- "CR" 
scenarios_eff <- matrix(c(4.2,6), nrow = 1, ncol = 2, byrow = TRUE) # HR=0.7
censor <- c(0.052,0.1045) # SAP: 10% drop-out // REAL: 5,2% -> Experimental y 10,45% -> Control
Tmax <- 24 # Lo hicieron 8 meses más corto
alpha <- 0.05 
test.type <- 2
IA <- c(0.5, 0.75)
method_IA <- "OF"
n_exp_events <- 330
HR_1 <- FALSE
Plot_Power = FALSE
plot_pvalues = FALSE 
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = FALSE
analysis = "bayes"
n_sim <- 10000
seed <- 24
# 1) Shape control, 2) rate control, 3) Shape experimental y 4) rate experimental
prior_gamma <- matrix(c(6.780667, 1, 1, 1/16), nrow = 2, ncol = 2, byrow = TRUE) 
prior_type <- c("Weak Informative prior Kantarijan ~ Ga(6.780667, 1)") 
P_HR_data_Boundary <- 0.8 # P(HR < 0.8 | data)
modelo_weibull_sep <- rstan::stan_model("weibull_gamma_def.stan" ,verbose = F)
modelo = modelo_weibull_sep
modelo_bayes_test = "weibull"
w = NULL
a0 = NULL

# sim11 <-  sim_trials(n_sim = n_sim,
#                     analysis = "bayes",
#                     sample_size = sample_size,
#                     ratio = ratio,
#                     rand_type = rand_type,
#                     Tmax = Tmax,
#                     scenarios_eff = scenarios_eff,
#                     shape_parameter = shape_parameter,
#                     censor = censor,
#                     test.type = test.type,
#                     alpha = alpha,
#                     method_IA = method_IA,
#                     IA = IA,
#                     n_exp_events = n_exp_events,
#                     HR_1 = HR_1,
#                     Plot_Power = Plot_Power,
#                     modelo = modelo,
#                     modelo_bayes_test = modelo_bayes_test,
#                     prior_type = prior_type,
#                     P_HR_data_Boundary = P_HR_data_Boundary,
#                     prior_gamma = prior_gamma,
#                     Plot_Power_scenarios = Plot_Power_scenarios,
#                     desired_HRs = desired_HRs,
#                     plot_pvalues = plot_pvalues,
#                     Plot_Control_Scenarios = Plot_Control_Scenarios,
#                     seed = seed)
# 
# 
# wd <- createWorkbook()
# addWorksheet(wd, "Sheet1")
# writeData(wd, "Sheet1", sim11)
# saveWorkbook(wd, "DEF_RESULTADOS_REALES_Bayes_Weak_Kantarijan_10K_SampleSizes.xlsx", overwrite = TRUE)

# 3) # ESTE ES EL MAP PRIOR 

shape_parameter <- 1
sample_size <- c(315, 320, 345, 355, 365, 380, 390, 400, 410, 420, 440, 456, 495)
ratio <- c(2/3,1/3)
rand_type <- "CR" 
scenarios_eff <- matrix(c(4.2,6), nrow = 1, ncol = 2, byrow = TRUE) # HR=0.7
censor <- c(0.052,0.1045) # SAP: 10% drop-out // REAL: 5,2% -> Experimental y 10,45% -> Control
Tmax <- 24 # Lo hicieron 8 meses más corto
alpha <- 0.05 
test.type <- 2
IA <- c(0.5, 0.75)
method_IA <- "OF"
n_exp_events <- 330
HR_1 <- FALSE
Plot_Power = FALSE
plot_pvalues = FALSE 
Plot_Power_scenarios = FALSE
Plot_Control_Scenarios = FALSE
analysis = "bayes"
n_sim <- 10000
seed <- 24
# 1) Shape control, 2) rate control, 3) Shape experimental y 4) rate experimental
prior_gamma <- matrix(c(alpha_map_freq, beta_map_freq, 1, 1/16), nrow = 2, ncol = 2, byrow = TRUE) 
prior_type <- c("Robust Mixture MAP Prior w = 0.1") # Este vector es para que aparezca el nombre en las tablas
P_HR_data_Boundary <- 0.8 # P(HR < 0.8 | data)
modelo_weibull_sep <- rstan::stan_model("weibull_mixture_gamma_sh_uniform.stan" ,verbose = F) # Este es el STAN con Ga(1, 1/6)
modelo = modelo_weibull_sep
modelo_bayes_test = "weibull"
w = 0.1
a0 = NULL


# sim12 <-  sim_trials(n_sim = n_sim,
#                     analysis = "bayes",
#                     sample_size = sample_size,
#                     ratio = ratio,
#                     rand_type = rand_type,
#                     Tmax = Tmax,
#                     scenarios_eff = scenarios_eff,
#                     shape_parameter = shape_parameter,
#                     censor = censor,
#                     test.type = test.type,
#                     alpha = alpha,
#                     method_IA = method_IA,
#                     IA = IA,
#                     n_exp_events = n_exp_events,
#                     HR_1 = HR_1,
#                     Plot_Power = Plot_Power,
#                     modelo = modelo,
#                     modelo_bayes_test = modelo_bayes_test,
#                     prior_type = prior_type,
#                     P_HR_data_Boundary = P_HR_data_Boundary,
#                     prior_gamma = prior_gamma,
#                     Plot_Power_scenarios = Plot_Power_scenarios,
#                     desired_HRs = desired_HRs,
#                     plot_pvalues = plot_pvalues,
#                     Plot_Control_Scenarios = Plot_Control_Scenarios,
#                     w = w,
#                     a0 = a0,
#                     seed = seed)
# 
# 
# wd <- createWorkbook()
# addWorksheet(wd, "Sheet1")
# writeData(wd, "Sheet1", sim12)
# saveWorkbook(wd, "DEF_RESULTADOS_REALES_Bayes_MAP_0.1_10K_SampleSizes.xlsx", overwrite = TRUE)

```

# LECTURA RESULTADOS TAMAÑOS MUESTRALES DEL REAL

```{r `Final models: Lectura datos REAL`, eval = T}

sheet_names <- c("Sheet1")

# 1) Frecuentista con IAs

DEF_REAL_Freq_with_IAs <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/DEF_RESULTADOS_REALES_Freq_CON_IAs_10K_SampleSizes_DEF.xlsx", sheet = sheet_names[1])
DEF_REAL_Freq_with_IAs_Power <- subset(DEF_REAL_Freq_with_IAs, scenario == 1,
                              select = c(scenario, sample_size, prop_significant)) %>%
  mutate(Prior = "Frequentist")

colnames(DEF_REAL_Freq_with_IAs)[colnames(DEF_REAL_Freq_with_IAs) == "mean_Lower_IC"] <- "mean_Lower_ICrI"
colnames(DEF_REAL_Freq_with_IAs)[colnames(DEF_REAL_Freq_with_IAs) == "mean_Upper_IC"] <- "mean_Upper_CrI"

DEF_REAL_Freq_with_IAs_HRs <- subset(DEF_REAL_Freq_with_IAs, scenario == 1,
                              select = c(scenario, sample_size, mean_HR, mean_Lower_ICrI, mean_Upper_CrI, `IA 1`, `IA 2`, FA)) %>%
  mutate(Prior = "Frequentist") 

# 2) Frecuentista sin IAs
# 
# DEF_REAL_Freq_without_IAs <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/DEF_RESULTADOS_REALES_Freq_SIN_IAs_10K_SampleSizes_DEF.xlsx", sheet = sheet_names[1])
# DEF_REAL_Freq_without_IAs_Power <- subset(DEF_REAL_Freq_without_IAs, scenario == 1,
#                               select = c(scenario, sample_size, prop_significant)) %>%
#   mutate(Prior = "Frequentist without IAs")


# 3) Prior poco informativa  

DEF_REAL_Weak_informative <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/Blincyto_PhALL_Tablas/DEF_RESULTADOS_REALES_Bayes_Weak_10K_SampleSizes.xlsx", sheet = sheet_names[1])
DEF_REAL_Weak_informative_Power <- subset(DEF_REAL_Weak_informative, scenario == 1,
                                          select = c(scenario, sample_size, Prior, prop_significant)) %>%
  mutate(Prior = "Weak Informative Prior\ncentered at 4.2 months")


DEF_REAL_Weak_informative_HRs <- subset(DEF_REAL_Weak_informative, scenario == 1,
                              select = c(scenario, sample_size, Prior, mean_HR, mean_Upper_CrI, mean_Lower_ICrI, `IA 1`, `IA 2`, FA)) %>%
  mutate(Prior = "Weak Informative Prior\ncentered at 4.2 months") 

# 4) Prior poco informativa (Kantarijan)

DEF_REAL_Weak_informative_Kantarijan <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/Blincyto_PhALL_Tablas/DEF_RESULTADOS_REALES_Bayes_Weak_Kantarijan_10K_SampleSizes.xlsx", sheet = sheet_names[1])
DEF_REAL_Weak_informative_Kantarijan_Power <- subset(DEF_REAL_Weak_informative_Kantarijan, scenario == 1,
                                      select = c(scenario, sample_size, Prior, prop_significant)) %>%
  mutate(Prior = "Weak Informative Prior\ncentered at 4.7 months (Kantarjian)")

DEF_REAL_Weak_informative_Kantarijan_HRs <- subset(DEF_REAL_Weak_informative_Kantarijan, scenario == 1,
                              select = c(scenario, sample_size, Prior, mean_HR, mean_Upper_CrI, mean_Lower_ICrI, `IA 1`, `IA 2`, FA)) %>%
  mutate(Prior = "Weak Informative Prior\ncentered at 4.7 months (Kantarjian)")

# 5) Robust Mixture Prior: 0.1 Prior MAP + 0.9 Prior no informativa 

DEF_REAL_MAP_0.1 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/Blincyto_PhALL_Tablas/DEF_RESULTADOS_REALES_Bayes_MAP_0.1_10K_SampleSizes.xlsx", sheet = sheet_names[1])
DEF_REAL_MAP_0.1_Power <- subset(DEF_REAL_MAP_0.1, scenario == 1,
                                      select = c(scenario, sample_size, Prior, prop_significant)) %>%
  mutate(Prior = "Robust MAP Prior w=0.1")

DEF_REAL_MAP_0.1_HRs <- subset(DEF_REAL_MAP_0.1, scenario == 1,
                              select = c(scenario, sample_size, Prior, mean_HR, mean_Upper_CrI, mean_Lower_ICrI, `IA 1`, `IA 2`, FA)) %>%
  mutate(Prior = "Robust MAP Prior w=0.1") 

# 6) Robust Mixture Prior: 0.2 Prior MAP + 0.8 Prior no informativa 

DEF_REAL_MAP_0.2 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/Blincyto_PhALL_Tablas/DEF_RESULTADOS_REALES_Bayes_MAP_0.2_10K_SampleSizes.xlsx", sheet = sheet_names[1])
DEF_REAL_MAP_0.2_Power <- subset(DEF_REAL_MAP_0.2, scenario == 1,
                                      select = c(scenario, sample_size, Prior, prop_significant)) %>%
  mutate(Prior = "Robust MAP Prior w=0.2")

DEF_REAL_MAP_0.2_HRs <- subset(DEF_REAL_MAP_0.2, scenario == 1,
                              select = c(scenario, sample_size, Prior, mean_HR, mean_Upper_CrI, mean_Lower_ICrI, `IA 1`, `IA 2`, FA)) %>%
  mutate(Prior = "Robust MAP Prior w=0.2") 

# 7) Robust Mixture Prior: 0.3 Prior MAP + 0.7 Prior no informativa 

DEF_REAL_MAP_0.3 <- read_excel("C:/Users/borja/Documents/PhD/Simulaciones/Bayes/Simulacion_Survival_Blincyto_PhALL/Blincyto_PhALL_Tablas/DEF_RESULTADOS_REALES_Bayes_MAP_0.3_10K_SampleSizes.xlsx", sheet = sheet_names[1])
DEF_REAL_MAP_0.3_Power <- subset(DEF_REAL_MAP_0.3, scenario == 1,
                                      select = c(scenario, sample_size, Prior, prop_significant)) %>%
  mutate(Prior = "Robust MAP Prior w=0.3")

DEF_REAL_MAP_0.3_HRs <- subset(DEF_REAL_MAP_0.3, scenario == 1,
                              select = c(scenario, sample_size, Prior, mean_HR, mean_Upper_CrI, mean_Lower_ICrI, `IA 1`, `IA 2`, FA)) %>%
  mutate(Prior = "Robust MAP Prior w=0.3") 

# Combinamos los datos 



combined_data_DEF_REAL_Power <- bind_rows(DEF_REAL_Freq_with_IAs_Power,
                                          #DEF_REAL_Freq_without_IAs_Power,
                                          DEF_REAL_Weak_informative_Power,
                                          DEF_REAL_Weak_informative_Kantarijan_Power,
                                          DEF_REAL_MAP_0.1_Power,
                                          DEF_REAL_MAP_0.2_Power,
                                          DEF_REAL_MAP_0.3_Power)

combined_data_DEF_REAL_HRs <- bind_rows(DEF_REAL_Freq_with_IAs_HRs,
                                          DEF_REAL_Weak_informative_HRs,
                                          DEF_REAL_Weak_informative_Kantarijan_HRs,
                                          DEF_REAL_MAP_0.1_HRs,
                                          DEF_REAL_MAP_0.2_HRs,
                                          DEF_REAL_MAP_0.3_HRs)



# Dibujamos el plot del poder:

desired_powers <- c(0.8, 0.85, 0.9, 0.95)
colors_for_dotted_lines <- c("purple", "blue", "green", "red") 

p1 <- ggplot(combined_data_DEF_REAL_Power, aes(x = sample_size, y = prop_significant, group = Prior, color = Prior)) +
  geom_point(size = 3) +  
  geom_line(linewidth = 1) +  
  geom_hline(yintercept = desired_powers, linetype = "dotted", color = colors_for_dotted_lines, size = 1) + 
  scale_x_continuous(breaks = seq(min(combined_data_DEF_REAL_Power$sample_size)-5, max(combined_data_DEF_REAL_Power$sample_size)+5, 25)) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Power vs. Sample Size",
       x = "Sample Size",
       y = "Power") +
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 14, face = "bold"),
        axis.text = element_text(size = 12))

rightmost_x <- max(combined_data_DEF_REAL_Power$sample_size) - 5  

for (i in 1:length(desired_powers)) {
  p1 <- p1 + annotate("text", 
                      x = rightmost_x, 
                      y = desired_powers[i], 
                      label = sprintf("%.0f%% power", desired_powers[i] * 100), 
                      hjust = 1,  
                      vjust = -0.3,  
                      size = 3.5, 
                      color = colors_for_dotted_lines[i])
}

p1

#Ahora hacemos una tabla para identificar cuál alcanza el poder antes.

combined_data_DEF_REAL_Power <- combined_data_DEF_REAL_Power %>%
  mutate(sample_size = as.integer(sample_size)) %>%
  select(-scenario)

Table_Power <- combined_data_DEF_REAL_Power %>%
  pivot_wider(
    names_from = Prior,
    values_from = prop_significant,
    id_cols = sample_size,
    values_fill = list(prop_significant = NA))

Table_Power_df <- as.data.frame(Table_Power)

library(gt)

table6 <- gt(Table_Power_df) %>%
 # tab_header(title = "Proportion Significant by Sample Size and Prior Type") %>%
  cols_label(
    sample_size = "Sample Size" 
  ) %>%
  fmt_number(
    columns = c(-sample_size),  
    decimals = 4  
  ) %>%
  tab_style(
    style = cell_text(weight = "bold", align = "center"),
    locations = cells_column_labels(columns = everything())
  ) %>%
  tab_options(
    column_labels.background.color = "lightsteelblue1",
    table.font.size = px(25),
    table.background.color = "white"
  ) %>%
  tab_style(
    style = cell_fill(color = "lightsteelblue1"),
    locations = cells_body(rows = seq(2, nrow(Table_Power_df), by = 2))
  ) %>%
  tab_style(
    style = cell_fill(color = "white"),
    locations = cells_body(rows = seq(1, nrow(Table_Power_df), by = 2))
  ) %>%
  tab_style(
    style = cell_text(align = "center"),
    locations = cells_body(columns = everything())
  ) %>%
  tab_style(
    style = cell_fill(color = "lightsteelblue1"),  
    locations = cells_body(columns = vars(sample_size))
  ) %>%
  tab_style(
    style = cell_borders(sides = "bottom", color = "black", weight = px(2)),
    locations = cells_column_labels(columns = names(Table_Power_df)[names(Table_Power_df) != "sample_size"])
  ) %>%
  tab_style(
    style = cell_borders(sides = "right", color = "black", weight = px(2)),
    locations = cells_body(columns = vars(sample_size))
  ) %>%
  tab_style(
    style = cell_text(weight = "bold"),  
    locations = cells_body(columns = vars(sample_size))
  ) 

table6

# Current version of R from multicore's computer
# 
# R version 4.3.2 (2023-10-31 ucrt) -- "Eye Holes"
# Copyright (C) 2023 The R Foundation for Statistical Computing
# Platform: x86_64-w64-mingw32/x64 (64-bit)


```


```{r `Final models: Lectura datos REAL2`, eval = T}

library(highcharter)
library(dplyr)

custom_prior_order <- c(
  "Frequentist",
  "Weak Informative Prior\ncentered at 4.2 months",
  "Weak Informative Prior\ncentered at 4.7 months (Kantarjian)",
  "Robust MAP Prior w=0.1",
  "Robust MAP Prior w=0.2",
  "Robust MAP Prior w=0.3"
)

custom_colors <- c(
  "#e31a1c",  # Frequentist
  "#1f78b4",  # Weak Informative Prior centered at 4.2 months
  "#6a3d9a",  # Weak Informative Prior centered at 4.7 months (Kantarjian)
  "#b15928",  # Robust MAP Prior w=0.1
  "#33a02c",  # Robust MAP Prior w=0.2
  "#ff7f00"   # Robust MAP Prior w=0.3
)

combined_data_DEF_REAL_HRs <- combined_data_DEF_REAL_HRs %>%
  mutate(
    sample_size = as.factor(sample_size), 
    Prior = factor(Prior, levels = custom_prior_order)  
  )

combined_data_DEF_REAL_HRs2 <- combined_data_DEF_REAL_HRs %>%
  mutate(
    mean_HR = as.numeric(mean_HR),
    mean_Lower_ICrI = as.numeric(mean_Lower_ICrI),
    mean_Upper_CrI = as.numeric(mean_Upper_CrI),
    sample_size = as.character(sample_size)  
  )

p <- hchart(
  combined_data_DEF_REAL_HRs2,
  type = "columnrange", 
  hcaes(
    x = sample_size,        
    low = mean_Lower_ICrI,  
    high = mean_Upper_CrI,  
    group = Prior         
  )
) %>%
  hc_chart(polar = TRUE) %>%  
  hc_colors(custom_colors) %>%  
  hc_yAxis(
    max = 1.2,    
    min = 0.4,    
    labels = list(
      formatter = JS("function() { return 'HR = ' + this.value; }"),  
      style = list(fontSize = "13px", fontWeight = "bold")
    ),
    title = NULL  
  ) %>%
  hc_xAxis(
    title = NULL,  
    categories = levels(combined_data_DEF_REAL_HRs2$sample_size),  
    labels = list(format = "{value}", style = list(fontSize = "14px", fontWeight = "bold")),
    gridLineWidth = 0.5
  ) %>%
  hc_exporting(enabled = TRUE, buttons = list(contextButton = list(enabled = FALSE))) %>%
  hc_add_theme(hc_theme_elementary()) 

p <- p %>% 
  hc_legend(
    align = "center",
    verticalAlign = "bottom",
    layout = "horizontal",
    title = list(
      text = "Bayesian Prior Distributions",
      style = list(fontSize = "16px", fontWeight = "bold") 
    ),
    itemStyle = list(fontSize = "13px")  
  )

p


```


```{r `Final models: Lectura datos REAL3`, eval = T}



combined_data_DEF_REAL_HRs3 <- combined_data_DEF_REAL_HRs %>%
  mutate(
    sample_size = as.character(sample_size)  
  ) %>%
  select(-scenario, -mean_HR, -mean_Lower_ICrI, -mean_Upper_CrI)

colnames(combined_data_DEF_REAL_HRs3) <- c("sample_size", "IA1", "IA2", "FA", "Prior")

combined_data_DEF_REAL_HRs3 <- combined_data_DEF_REAL_HRs3 %>%
  mutate(
    Total_Significant = IA1 + IA2 + FA,  # Sum of IA1, IA2, FA
    Proportion_IA1 = IA1 / Total_Significant,
    Proportion_IA2 = IA2 / Total_Significant,
    Proportion_FA = FA / Total_Significant
  ) %>%
  select(sample_size, Prior, Proportion_IA1, Proportion_IA2, Proportion_FA) %>%
  pivot_longer(
    cols = starts_with("Proportion"),
    names_to = "Stopping_Point",
    values_to = "Proportion"
  ) %>%
  mutate(
    Stopping_Point = recode(
      Stopping_Point, 
      "Proportion_IA1" = "IA1",
      "Proportion_IA2" = "IA2",
      "Proportion_FA" = "FA"
    ),
    Stopping_Point = factor(Stopping_Point, levels = c("IA1", "IA2", "FA"))
  )


custom_colors <- c(
  "Frequentist" = "#1f78b4",
  "Weak Informative Prior\ncentered at 4.2 months" = "#33a02c",
  "Weak Informative Prior\ncentered at 4.7 months (Kantarjian)" = "#e31a1c",
  "Robust MAP Prior w=0.1" = "#ff7f00",
  "Robust MAP Prior w=0.2" = "#6a3d9a",
  "Robust MAP Prior w=0.3" = "#b15928"
)


facet_labels <- c(
  "IA1" = "Trials Stopped Early for Efficacy at the First Interim Analysis (IA1)",
  "IA2" = "Trials Stopped Early for Efficacy at the Second Interim Analysis (IA2)",
  "FA" = "Trials Stopped at the Final Analysis (FA)"
)

combined_data_DEF_REAL_HRs3 <- combined_data_DEF_REAL_HRs3 %>%
  mutate(Prior = factor(Prior, levels = names(custom_colors)))  

ggplot(combined_data_DEF_REAL_HRs3, aes(x = as.numeric(sample_size), y = Proportion, color = Prior, group = Prior)) +
  geom_line(size = 1) +
  geom_point(size = 2) +
  facet_wrap(
    ~ Stopping_Point, 
    ncol = 1, 
    scales = "fixed", 
    labeller = as_labeller(facet_labels) 
  ) +  
  scale_color_manual(values = custom_colors) +
  labs(
    x = "Sample Size",
    y = "Proportion of Significant Trials",
    color = "Bayesian Prior Distributions"
  ) +
  theme_minimal() +
  theme(
    strip.text = element_text(size = 12, face = "bold"),  
    axis.title = element_text(size = 11, face = "bold"),
    axis.text = element_text(size = 12), 
    legend.position = "top",
    legend.title = element_text(size = 11, face = "bold"),  
    legend.background = element_rect(color = "black", fill = "transparent") 
  ) +
  scale_x_continuous(
    breaks = as.numeric(unique(combined_data_DEF_REAL_HRs3$sample_size)),  
    labels = unique(combined_data_DEF_REAL_HRs3$sample_size)
  )




```